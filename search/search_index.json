{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Grant Curell's Dell Projects Every time Dell asks me to figure something out, I write it down. Mostly because more often than not someone asks me about it a year later and I have to remember what I did. Questions If you have any questions about something I did, open an issue on the repo at grantcurell.github.io or write me at grant_curell AT dell dot com . Additional Files Most of the files I use in the projects are linked from the markdown documentation but often there might be additional files not visible for this site. It may be easier to browse to the actual docs folder and look at the appropriate folder. Disclaimer These are just my personal notes for the random things I test. I'm generally thorough, but there is no guarentee on completeness :-D How to Configure ONIE I ran the network version of the ONIE installation using a web server. Below is what I did to get things installed. We will host the OS installer on our web server and then we will use ONIE to grab it. We will use a DNS record to control the ONIE server location. Install Apache on RHEL or your favorite Linux distro. Make sure you allow HTTP traffic through the firewall Download your operating system of choice and untar it. Upload <YOUR INSTALLER>.bin to the root of your web server. Create a symlink to the installer with ln -s <YOUR INSTALLER>.bin onie-installer . The file must have this name for the installation to work. The switch will use DHCP to acquire an IP address. On the DNS server pointed to by your DHCP configuration, add a record for onie-server and point it at the host running Apache. On a test box, run a DHCP request, ensure you pull the correct DNS server and that the host can resolve onie-server . After you confirm DNS is working, browse to the onie-installer file on your Apache server and make sure you can download it without issue. Warning: It must be able to resolve the hostname onie-server with the FQDN. If onie-server is not immediately resolvable, the install process will not work. ONIE Boot the Switch Connect to the switch over the console port. My configuration was: Baud Rate: 115200 Data Bits: 8 Stop Bits: 1 Parity: None Flow Control: None Connect the ethernet management port of the switch to the same network containing your web server. ONIE will use the management port to establish a connection to the ONIE server. Once the grub menu appears, select ONIE Installer. In my case this was the top option. At this point the ONIE discovery process will commence. It will print each location it attempts to search. It should find the onie-server DNS record and the installation should begin automatically. If this doesn't happen it means there is an issue with the preconfiguration above. Try swapping out the ethernet management cable with a host. Make sure that host pulls DNS/DHCP correctly and is able to download the onie-installer file. Wait for the installation to finish and the switch to reboot. Login with admin/admin. If after logging in you are told you can't enter configuration mode because \"% Error: ZTD is in progress(configuration is locked).\" run ztd cancel Configure Managment Interface on Dell OS10 Do the following to configure a management interface on Dell OS10 OS10# configure terminal OS10(config)# interface mgmt 1/1/1 OS10(conf-if-ma-1/1/1)# ip address 192.168.1.20/24 OS10(conf-if-ma-1/1/1)# <165>1 2019-10-28T19:04:39.385196+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IP_ADDRESS_ADD: IP Address add is successful. IP 192.168.1.20/24 in VRF:default added successfully OS10(conf-if-ma-1/1/1)# do write memory","title":"Grant Curell's Dell Projects"},{"location":"#grant-curells-dell-projects","text":"Every time Dell asks me to figure something out, I write it down. Mostly because more often than not someone asks me about it a year later and I have to remember what I did.","title":"Grant Curell's Dell Projects"},{"location":"#questions","text":"If you have any questions about something I did, open an issue on the repo at grantcurell.github.io or write me at grant_curell AT dell dot com .","title":"Questions"},{"location":"#additional-files","text":"Most of the files I use in the projects are linked from the markdown documentation but often there might be additional files not visible for this site. It may be easier to browse to the actual docs folder and look at the appropriate folder.","title":"Additional Files"},{"location":"#disclaimer","text":"These are just my personal notes for the random things I test. I'm generally thorough, but there is no guarentee on completeness :-D","title":"Disclaimer"},{"location":"#how-to-configure-onie","text":"I ran the network version of the ONIE installation using a web server. Below is what I did to get things installed. We will host the OS installer on our web server and then we will use ONIE to grab it. We will use a DNS record to control the ONIE server location. Install Apache on RHEL or your favorite Linux distro. Make sure you allow HTTP traffic through the firewall Download your operating system of choice and untar it. Upload <YOUR INSTALLER>.bin to the root of your web server. Create a symlink to the installer with ln -s <YOUR INSTALLER>.bin onie-installer . The file must have this name for the installation to work. The switch will use DHCP to acquire an IP address. On the DNS server pointed to by your DHCP configuration, add a record for onie-server and point it at the host running Apache. On a test box, run a DHCP request, ensure you pull the correct DNS server and that the host can resolve onie-server . After you confirm DNS is working, browse to the onie-installer file on your Apache server and make sure you can download it without issue. Warning: It must be able to resolve the hostname onie-server with the FQDN. If onie-server is not immediately resolvable, the install process will not work.","title":"How to Configure ONIE"},{"location":"#onie-boot-the-switch","text":"Connect to the switch over the console port. My configuration was: Baud Rate: 115200 Data Bits: 8 Stop Bits: 1 Parity: None Flow Control: None Connect the ethernet management port of the switch to the same network containing your web server. ONIE will use the management port to establish a connection to the ONIE server. Once the grub menu appears, select ONIE Installer. In my case this was the top option. At this point the ONIE discovery process will commence. It will print each location it attempts to search. It should find the onie-server DNS record and the installation should begin automatically. If this doesn't happen it means there is an issue with the preconfiguration above. Try swapping out the ethernet management cable with a host. Make sure that host pulls DNS/DHCP correctly and is able to download the onie-installer file. Wait for the installation to finish and the switch to reboot. Login with admin/admin. If after logging in you are told you can't enter configuration mode because \"% Error: ZTD is in progress(configuration is locked).\" run ztd cancel","title":"ONIE Boot the Switch"},{"location":"#configure-managment-interface-on-dell-os10","text":"Do the following to configure a management interface on Dell OS10 OS10# configure terminal OS10(config)# interface mgmt 1/1/1 OS10(conf-if-ma-1/1/1)# ip address 192.168.1.20/24 OS10(conf-if-ma-1/1/1)# <165>1 2019-10-28T19:04:39.385196+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IP_ADDRESS_ADD: IP Address add is successful. IP 192.168.1.20/24 in VRF:default added successfully OS10(conf-if-ma-1/1/1)# do write memory","title":"Configure Managment Interface on Dell OS10"},{"location":"Get%20NVMe%20Drives%20from%20iDRAC%20Redfish/","text":"Get NVMe Drives from iDRAC Redfish Get NVMe Drives from iDRAC Redfish Exploring iDRAC Detected Storage Understand the Behavior of Unqualified Drives Getting a Drive's Stats Exploring iDRAC Detected Storage I used the Storage API endpoint to accomplish this. From my host I received: {\"@odata.context\":\"/redfish/v1/$metadata#StorageCollection.StorageCollection\",\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/\",\"@odata.type\":\"#StorageCollection.StorageCollection\",\"Description\":\"Collection Of Storage entities\",\"Members\":[{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/RAID.Slot.4-1\"},{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/RAID.Embedded.1-1\"},{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1\"},{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/AHCI.Slot.2-1\"}],\"Members@odata.count\":4,\"Name\":\"Storage Collection\"} I'm running an R840 which is Dell 14G which I know does not have NVMe RAID controllers as an option so I know my NVMe drives must be hanging off the CPU. IE: /redfish/v1/Systems/System.Embedded.1/Storage/CPU.1 . I can expect that the BOSS card is hanging off of AHCI and that any SAS/SATA drives are likely on the RAID controller. The results above also imply that the host above runs a mixed backplane given the presence of RAID and CPU.1. Checking CPU.1 gets me: { \"@odata.context\": \"/redfish/v1/$metadata#Storage.Storage\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1\", \"@odata.type\": \"#Storage.v1_8_0.Storage\", \"Description\": \"CPU.1\", \"Drives\": [ { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.19:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.20:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.23:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.18:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.22:Enclosure.Internal.0-1\" } ], \"Drives@odata.count\": 6, \"Id\": \"CPU.1\", \"Links\": { \"Enclosures\": [ { \"@odata.id\": \"/redfish/v1/Chassis/Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Chassis/System.Embedded.1\" } ], \"Enclosures@odata.count\": 2 }, \"Name\": \"CPU.1\", \"Status\": { \"Health\": \"OK\", \"HealthRollup\": \"OK\", \"State\": \"Enabled\" }, \"Volumes\": { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Volumes\" } } From the above I can deduce that CPU 1 has six drives attached to it. Or does it? Understand the Behavior of Unqualified Drives Here is a picture of the front of my server: Here is the front of my server. You might say, \"Wait, there are 7 drives!?\" The problem is this 7th drive isn't qualified by Dell. It will still work just fine however, iDRAC won't know how to talk to it so it won't show up: You can confirm this is the case by checking the Storage->Physical Disks tab inside the iDRAC itself: Here you can see that I only have the 6 NVMe drives plus two SATA SSDs. While the iDRAC's personality module won't be able to properly sort the drive into Storage it will detect it as a PCIe device and accurately read the vendor information: Getting a Drive's Stats We can select one of them with /redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1 . This achieves the desired result and gets a dump of that drive's data. The size is available under the field CapacityBytes. { \"@odata.context\": \"/redfish/v1/$metadata#Drive.Drive\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1\", \"@odata.type\": \"#Drive.v1_9_0.Drive\", \"Actions\": { \"#Drive.SecureErase\": { \"@Redfish.OperationApplyTimeSupport\": { \"@odata.type\": \"#Settings.v1_3_0.OperationApplyTimeSupport\", \"SupportedValues\": [ \"Immediate\", \"OnReset\" ] }, \"target\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Actions/Drive.SecureErase\" } }, \"Assembly\": { \"@odata.id\": \"/redfish/v1/Chassis/System.Embedded.1/Assembly\" }, \"BlockSizeBytes\": 0, \"CapableSpeedGbs\": 7.876923076923077, \"CapacityBytes\": 3200631791616, \"Description\": \"PCIe SSD in Slot 21 in Bay 1\", \"EncryptionAbility\": \"None\", \"EncryptionStatus\": \"Unencrypted\", \"FailurePredicted\": false, \"HotspareType\": \"None\", \"Id\": \"Disk.Bay.21:Enclosure.Internal.0-1\", \"Identifiers\": [ { \"DurableName\": null, \"DurableNameFormat\": null } ], \"Identifiers@odata.count\": 1, \"Links\": { \"Chassis\": { \"@odata.id\": \"/redfish/v1/Chassis/Enclosure.Internal.0-1\" }, \"PCIeFunctions\": [], \"PCIeFunctions@odata.count\": 0, \"Volumes\": [ { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Volumes/Disk.Bay.21:Enclosure.Internal.0-1\" } ], \"Volumes@odata.count\": 1 }, \"Location\": [], \"Manufacturer\": \"Intel Corporation \", \"MediaType\": \"SSD\", \"Model\": \"Dell Express Flash NVMe P4610 3.2TB SFF\", \"Name\": \"PCIe SSD in Slot 21 in Bay 1\", \"NegotiatedSpeedGbs\": 7.876923076923077, \"Oem\": { \"Dell\": { \"@odata.type\": \"#DellOem.v1_1_0.DellOemResources\", \"DellDriveSMARTAttributes\": null, \"DellNVMeSMARTAttributes\": { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Oem/Dell/DellNVMeSMARTAttributes\" }, \"DellPCIeSSD\": { \"@odata.context\": \"/redfish/v1/$metadata#DellPCIeSSD.DellPCIeSSD\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Oem/Dell/DellPCIeSSDs/Disk.Bay.21:Enclosure.Internal.0-1\", \"@odata.type\": \"#DellPCIeSSD.v1_4_0.DellPCIeSSD\", \"Bus\": \"CA\", \"BusProtocol\": \"PCIE\", \"Description\": \"An instance of DellPCIeSSD will have PCIe Solid State Drive specific data.\", \"Device\": \"0\", \"DeviceProtocol\": \"NVMe-MI1.0\", \"DriveFormFactor\": \"2.5Inch\", \"FreeSizeInBytes\": null, \"Function\": \"0\", \"HotSpareStatus\": null, \"Id\": \"Disk.Bay.21:Enclosure.Internal.0-1\", \"MediaType\": \"SolidStateDrive\", \"Name\": \"DellPCIeSSD\", \"PCIeCapableLinkWidth\": \"x4\", \"PCIeNegotiatedLinkWidth\": \"x4\", \"ProductID\": \"a54\", \"RAIDType\": \"Unknown\", \"RaidStatus\": null, \"Slot\": 21, \"SystemEraseCapability\": \"CryptographicErasePD\", \"UsedSizeInBytes\": 0 }, \"DellPhysicalDisk\": { \"@odata.context\": \"/redfish/v1/$metadata#DellPhysicalDisk.DellPhysicalDisk\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Oem/Dell/DellDrives/Disk.Bay.21:Enclosure.Internal.0-1\", \"@odata.type\": \"#DellPhysicalDisk.v1_3_0.DellPhysicalDisk\", \"Certified\": null, \"Connector\": null, \"Description\": \"An instance of DellPhysicalDisk will have Physical Disk specific data.\", \"DeviceProtocol\": \"NVMe-MI1.0\", \"DriveFormFactor\": \"2.5Inch\", \"EncryptionProtocol\": null, \"ForeignKeyIdentifier\": null, \"FreeSizeInBytes\": null, \"Id\": \"Disk.Bay.21:Enclosure.Internal.0-1\", \"LastSystemInventoryTime\": null, \"LastUpdateTime\": null, \"ManufacturingDay\": null, \"ManufacturingWeek\": null, \"ManufacturingYear\": null, \"Name\": \"DellPhysicalDisk\", \"NonRAIDDiskCachePolicy\": null, \"OperationName\": null, \"OperationPercentCompletePercent\": null, \"PCIeCapableLinkWidth\": \"x4\", \"PCIeNegotiatedLinkWidth\": \"x4\", \"PPID\": null, \"PowerStatus\": null, \"PredictiveFailureState\": null, \"ProductID\": \"a54\", \"RAIDType\": \"Unknown\", \"RaidStatus\": null, \"SASAddress\": null, \"Slot\": 21, \"SystemEraseCapability\": \"CryptographicErasePD\", \"T10PICapability\": null, \"UsedSizeInBytes\": 0, \"WWN\": null } } }, \"Operations\": [], \"Operations@odata.count\": 0, \"PartNumber\": \"TW02CN1TPIHIT9A9013TA02\", \"PhysicalLocation\": { \"PartLocation\": { \"LocationOrdinalValue\": 21, \"LocationType\": \"Slot\" } }, \"PredictedMediaLifeLeftPercent\": 100, \"Protocol\": \"PCIe\", \"Revision\": \"VDV1DP23\", \"RotationSpeedRPM\": null, \"SerialNumber\": \"PHLN9396002Q3P2BGN\", \"Status\": { \"Health\": \"OK\", \"HealthRollup\": \"OK\", \"State\": \"Enabled\" }, \"WriteCacheEnabled\": false }","title":"Get NVMe Drives from iDRAC Redfish"},{"location":"Get%20NVMe%20Drives%20from%20iDRAC%20Redfish/#get-nvme-drives-from-idrac-redfish","text":"Get NVMe Drives from iDRAC Redfish Exploring iDRAC Detected Storage Understand the Behavior of Unqualified Drives Getting a Drive's Stats","title":"Get NVMe Drives from iDRAC Redfish"},{"location":"Get%20NVMe%20Drives%20from%20iDRAC%20Redfish/#exploring-idrac-detected-storage","text":"I used the Storage API endpoint to accomplish this. From my host I received: {\"@odata.context\":\"/redfish/v1/$metadata#StorageCollection.StorageCollection\",\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/\",\"@odata.type\":\"#StorageCollection.StorageCollection\",\"Description\":\"Collection Of Storage entities\",\"Members\":[{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/RAID.Slot.4-1\"},{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/RAID.Embedded.1-1\"},{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1\"},{\"@odata.id\":\"/redfish/v1/Systems/System.Embedded.1/Storage/AHCI.Slot.2-1\"}],\"Members@odata.count\":4,\"Name\":\"Storage Collection\"} I'm running an R840 which is Dell 14G which I know does not have NVMe RAID controllers as an option so I know my NVMe drives must be hanging off the CPU. IE: /redfish/v1/Systems/System.Embedded.1/Storage/CPU.1 . I can expect that the BOSS card is hanging off of AHCI and that any SAS/SATA drives are likely on the RAID controller. The results above also imply that the host above runs a mixed backplane given the presence of RAID and CPU.1. Checking CPU.1 gets me: { \"@odata.context\": \"/redfish/v1/$metadata#Storage.Storage\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1\", \"@odata.type\": \"#Storage.v1_8_0.Storage\", \"Description\": \"CPU.1\", \"Drives\": [ { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.19:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.20:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.23:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.18:Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.22:Enclosure.Internal.0-1\" } ], \"Drives@odata.count\": 6, \"Id\": \"CPU.1\", \"Links\": { \"Enclosures\": [ { \"@odata.id\": \"/redfish/v1/Chassis/Enclosure.Internal.0-1\" }, { \"@odata.id\": \"/redfish/v1/Chassis/System.Embedded.1\" } ], \"Enclosures@odata.count\": 2 }, \"Name\": \"CPU.1\", \"Status\": { \"Health\": \"OK\", \"HealthRollup\": \"OK\", \"State\": \"Enabled\" }, \"Volumes\": { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Volumes\" } } From the above I can deduce that CPU 1 has six drives attached to it. Or does it?","title":"Exploring iDRAC Detected Storage"},{"location":"Get%20NVMe%20Drives%20from%20iDRAC%20Redfish/#understand-the-behavior-of-unqualified-drives","text":"Here is a picture of the front of my server: Here is the front of my server. You might say, \"Wait, there are 7 drives!?\" The problem is this 7th drive isn't qualified by Dell. It will still work just fine however, iDRAC won't know how to talk to it so it won't show up: You can confirm this is the case by checking the Storage->Physical Disks tab inside the iDRAC itself: Here you can see that I only have the 6 NVMe drives plus two SATA SSDs. While the iDRAC's personality module won't be able to properly sort the drive into Storage it will detect it as a PCIe device and accurately read the vendor information:","title":"Understand the Behavior of Unqualified Drives"},{"location":"Get%20NVMe%20Drives%20from%20iDRAC%20Redfish/#getting-a-drives-stats","text":"We can select one of them with /redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1 . This achieves the desired result and gets a dump of that drive's data. The size is available under the field CapacityBytes. { \"@odata.context\": \"/redfish/v1/$metadata#Drive.Drive\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1\", \"@odata.type\": \"#Drive.v1_9_0.Drive\", \"Actions\": { \"#Drive.SecureErase\": { \"@Redfish.OperationApplyTimeSupport\": { \"@odata.type\": \"#Settings.v1_3_0.OperationApplyTimeSupport\", \"SupportedValues\": [ \"Immediate\", \"OnReset\" ] }, \"target\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Actions/Drive.SecureErase\" } }, \"Assembly\": { \"@odata.id\": \"/redfish/v1/Chassis/System.Embedded.1/Assembly\" }, \"BlockSizeBytes\": 0, \"CapableSpeedGbs\": 7.876923076923077, \"CapacityBytes\": 3200631791616, \"Description\": \"PCIe SSD in Slot 21 in Bay 1\", \"EncryptionAbility\": \"None\", \"EncryptionStatus\": \"Unencrypted\", \"FailurePredicted\": false, \"HotspareType\": \"None\", \"Id\": \"Disk.Bay.21:Enclosure.Internal.0-1\", \"Identifiers\": [ { \"DurableName\": null, \"DurableNameFormat\": null } ], \"Identifiers@odata.count\": 1, \"Links\": { \"Chassis\": { \"@odata.id\": \"/redfish/v1/Chassis/Enclosure.Internal.0-1\" }, \"PCIeFunctions\": [], \"PCIeFunctions@odata.count\": 0, \"Volumes\": [ { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Volumes/Disk.Bay.21:Enclosure.Internal.0-1\" } ], \"Volumes@odata.count\": 1 }, \"Location\": [], \"Manufacturer\": \"Intel Corporation \", \"MediaType\": \"SSD\", \"Model\": \"Dell Express Flash NVMe P4610 3.2TB SFF\", \"Name\": \"PCIe SSD in Slot 21 in Bay 1\", \"NegotiatedSpeedGbs\": 7.876923076923077, \"Oem\": { \"Dell\": { \"@odata.type\": \"#DellOem.v1_1_0.DellOemResources\", \"DellDriveSMARTAttributes\": null, \"DellNVMeSMARTAttributes\": { \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Oem/Dell/DellNVMeSMARTAttributes\" }, \"DellPCIeSSD\": { \"@odata.context\": \"/redfish/v1/$metadata#DellPCIeSSD.DellPCIeSSD\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Oem/Dell/DellPCIeSSDs/Disk.Bay.21:Enclosure.Internal.0-1\", \"@odata.type\": \"#DellPCIeSSD.v1_4_0.DellPCIeSSD\", \"Bus\": \"CA\", \"BusProtocol\": \"PCIE\", \"Description\": \"An instance of DellPCIeSSD will have PCIe Solid State Drive specific data.\", \"Device\": \"0\", \"DeviceProtocol\": \"NVMe-MI1.0\", \"DriveFormFactor\": \"2.5Inch\", \"FreeSizeInBytes\": null, \"Function\": \"0\", \"HotSpareStatus\": null, \"Id\": \"Disk.Bay.21:Enclosure.Internal.0-1\", \"MediaType\": \"SolidStateDrive\", \"Name\": \"DellPCIeSSD\", \"PCIeCapableLinkWidth\": \"x4\", \"PCIeNegotiatedLinkWidth\": \"x4\", \"ProductID\": \"a54\", \"RAIDType\": \"Unknown\", \"RaidStatus\": null, \"Slot\": 21, \"SystemEraseCapability\": \"CryptographicErasePD\", \"UsedSizeInBytes\": 0 }, \"DellPhysicalDisk\": { \"@odata.context\": \"/redfish/v1/$metadata#DellPhysicalDisk.DellPhysicalDisk\", \"@odata.id\": \"/redfish/v1/Systems/System.Embedded.1/Storage/CPU.1/Drives/Disk.Bay.21:Enclosure.Internal.0-1/Oem/Dell/DellDrives/Disk.Bay.21:Enclosure.Internal.0-1\", \"@odata.type\": \"#DellPhysicalDisk.v1_3_0.DellPhysicalDisk\", \"Certified\": null, \"Connector\": null, \"Description\": \"An instance of DellPhysicalDisk will have Physical Disk specific data.\", \"DeviceProtocol\": \"NVMe-MI1.0\", \"DriveFormFactor\": \"2.5Inch\", \"EncryptionProtocol\": null, \"ForeignKeyIdentifier\": null, \"FreeSizeInBytes\": null, \"Id\": \"Disk.Bay.21:Enclosure.Internal.0-1\", \"LastSystemInventoryTime\": null, \"LastUpdateTime\": null, \"ManufacturingDay\": null, \"ManufacturingWeek\": null, \"ManufacturingYear\": null, \"Name\": \"DellPhysicalDisk\", \"NonRAIDDiskCachePolicy\": null, \"OperationName\": null, \"OperationPercentCompletePercent\": null, \"PCIeCapableLinkWidth\": \"x4\", \"PCIeNegotiatedLinkWidth\": \"x4\", \"PPID\": null, \"PowerStatus\": null, \"PredictiveFailureState\": null, \"ProductID\": \"a54\", \"RAIDType\": \"Unknown\", \"RaidStatus\": null, \"SASAddress\": null, \"Slot\": 21, \"SystemEraseCapability\": \"CryptographicErasePD\", \"T10PICapability\": null, \"UsedSizeInBytes\": 0, \"WWN\": null } } }, \"Operations\": [], \"Operations@odata.count\": 0, \"PartNumber\": \"TW02CN1TPIHIT9A9013TA02\", \"PhysicalLocation\": { \"PartLocation\": { \"LocationOrdinalValue\": 21, \"LocationType\": \"Slot\" } }, \"PredictedMediaLifeLeftPercent\": 100, \"Protocol\": \"PCIe\", \"Revision\": \"VDV1DP23\", \"RotationSpeedRPM\": null, \"SerialNumber\": \"PHLN9396002Q3P2BGN\", \"Status\": { \"Health\": \"OK\", \"HealthRollup\": \"OK\", \"State\": \"Enabled\" }, \"WriteCacheEnabled\": false }","title":"Getting a Drive's Stats"},{"location":"High%20Speed%20Packet%20Capture/","text":"High Speed Packet Capture See https://github.com/grantcurell/packet_capture For testing notes see: DPDK on ESXi with CentOS 7 (Incomplete) DPDK on FC640 with RHEL 8 DPDK on R940 with Napatech ntop ntop on R940 with Napatech","title":"High Speed Packet Capture"},{"location":"High%20Speed%20Packet%20Capture/#high-speed-packet-capture","text":"See https://github.com/grantcurell/packet_capture For testing notes see: DPDK on ESXi with CentOS 7 (Incomplete) DPDK on FC640 with RHEL 8 DPDK on R940 with Napatech ntop ntop on R940 with Napatech","title":"High Speed Packet Capture"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/","text":"How to Get DPDK with pdump Running The purpose of this experiment is to get Intel's DPDK framework up and running on a virtual machine. Useful Materials VMWare info on Intel DPDK How to Compile DPDK Info on Linux Drivers for DPDK My Environment I am running this inital test on ESXi 6.7 in a virtual machine CentOS Release Info NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core) Kernel Info Linux centos.lan 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Installation Configure GRUB Command Line for Virtualized DPDK In order for DPDK to work in a virtual environment you must disable memory protection. The reason for this is that with memory protection enabled CentOS will block read/write/execution to the DMA'd portion of memory. See this post. Do the following: cd /etc/default vim grub Edit GRUB-CMDLINE and Add \u201cnopku\u201d GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet nopku transparent_hugepage=never log_buf_len=8M\" Recompile grub: sudo grub2-mkconfig -o /boot/grub2/grub.cfg reboot Install DPDK Download from https://core.dpdk.org/download/ Run yum install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc libpcap-devel Extract dpdk and cd into its directory set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=<YOUR_DIR> Run make install T=x86_64-native-linux-gcc DESTDIR=<INSTALL_DIR> to build dpdk. Ensure your install directory exists. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile Configuration Update Ulimits Edit the security limits with vim /etc/security/limits.conf Add the following lines at the end of the file: root hard memlock unlimited root soft memlock unlimited Reboot and see if the system has the newly updated value Configure vfio-pci to Load on Boot Go to /etc/modules-load.d/ cd /etc/modules-load.d Run echo vfio-pci > vfio-pci.conf If you don't reboot you will need to run modprobe vfio-pci Configure Ports Move to your INSTALL_DIR and run ./usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script WARNING : If you run Option 3 to insert the VFIO module I found that it actually caused DPDK to stop working. Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. Run option 7 and make sure you receive output and that network devices are listed. My output looks like this: Network devices using kernel driver =================================== 0000:0b:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens192 drv=vmxnet3 unused=vfio-pci *Active* 0000:13:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens224 drv=vmxnet3 unused=vfio-pci *Active* No 'Baseband' devices detected ============================== No 'Crypto' devices detected ============================ No 'Eventdev' devices detected ============================== No 'Mempool' devices detected ============================= No 'Compress' devices detected ============================== No 'Misc (rawdev)' devices detected =================================== NOTE : The active keyword means that DPDK thinks the interface is under active use. This typically means it has an IP address assigned to it. Run option 9 to bind an interface to DPDK Notes You can use PCI passthrough on the x520 and x710 Run ethtool -i <your_interface> to figure out what kind of driver you have Run bash /opt/dpdk-19.08/usertools/dpdk-setup.sh Run option 47 and then enter 64 when prompted Run option 44 to insert the VRIO module Run ulimit -u unlimited to increase the memlock limit (NOTE: I don't think this did what I needed it to.) add iommu=pt intel_iommu=on grub2-mkconfig -o /boot/grub2/grub.cfg","title":"How to Get DPDK with pdump Running"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#how-to-get-dpdk-with-pdump-running","text":"The purpose of this experiment is to get Intel's DPDK framework up and running on a virtual machine.","title":"How to Get DPDK with pdump Running"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#useful-materials","text":"VMWare info on Intel DPDK How to Compile DPDK Info on Linux Drivers for DPDK","title":"Useful Materials"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#my-environment","text":"I am running this inital test on ESXi 6.7 in a virtual machine","title":"My Environment"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#centos-release-info","text":"NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core)","title":"CentOS Release Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#kernel-info","text":"Linux centos.lan 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux","title":"Kernel Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#installation","text":"","title":"Installation"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#configure-grub-command-line-for-virtualized-dpdk","text":"In order for DPDK to work in a virtual environment you must disable memory protection. The reason for this is that with memory protection enabled CentOS will block read/write/execution to the DMA'd portion of memory. See this post. Do the following: cd /etc/default vim grub Edit GRUB-CMDLINE and Add \u201cnopku\u201d GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet nopku transparent_hugepage=never log_buf_len=8M\" Recompile grub: sudo grub2-mkconfig -o /boot/grub2/grub.cfg reboot","title":"Configure GRUB Command Line for Virtualized DPDK"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#install-dpdk","text":"Download from https://core.dpdk.org/download/ Run yum install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc libpcap-devel Extract dpdk and cd into its directory set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=<YOUR_DIR> Run make install T=x86_64-native-linux-gcc DESTDIR=<INSTALL_DIR> to build dpdk. Ensure your install directory exists. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile","title":"Install DPDK"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#configuration","text":"","title":"Configuration"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#update-ulimits","text":"Edit the security limits with vim /etc/security/limits.conf Add the following lines at the end of the file: root hard memlock unlimited root soft memlock unlimited Reboot and see if the system has the newly updated value","title":"Update Ulimits"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#configure-vfio-pci-to-load-on-boot","text":"Go to /etc/modules-load.d/ cd /etc/modules-load.d Run echo vfio-pci > vfio-pci.conf If you don't reboot you will need to run modprobe vfio-pci","title":"Configure vfio-pci to Load on Boot"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#configure-ports","text":"Move to your INSTALL_DIR and run ./usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script WARNING : If you run Option 3 to insert the VFIO module I found that it actually caused DPDK to stop working. Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. Run option 7 and make sure you receive output and that network devices are listed. My output looks like this: Network devices using kernel driver =================================== 0000:0b:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens192 drv=vmxnet3 unused=vfio-pci *Active* 0000:13:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens224 drv=vmxnet3 unused=vfio-pci *Active* No 'Baseband' devices detected ============================== No 'Crypto' devices detected ============================ No 'Eventdev' devices detected ============================== No 'Mempool' devices detected ============================= No 'Compress' devices detected ============================== No 'Misc (rawdev)' devices detected =================================== NOTE : The active keyword means that DPDK thinks the interface is under active use. This typically means it has an IP address assigned to it. Run option 9 to bind an interface to DPDK","title":"Configure Ports"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20ESXi%20with%20CentOS%207%20%28INCOMPLETE%29/#notes","text":"You can use PCI passthrough on the x520 and x710 Run ethtool -i <your_interface> to figure out what kind of driver you have Run bash /opt/dpdk-19.08/usertools/dpdk-setup.sh Run option 47 and then enter 64 when prompted Run option 44 to insert the VRIO module Run ulimit -u unlimited to increase the memlock limit (NOTE: I don't think this did what I needed it to.) add iommu=pt intel_iommu=on grub2-mkconfig -o /boot/grub2/grub.cfg","title":"Notes"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/","text":"How to Get DPDK with pdump Running The purpose of this experiment is to get Intel's DPDK framework up and running on a server. Useful Materials How to Compile DPDK Info on Linux Drivers for DPDK Description of the TestPMD Program DPDK Testpmd Application User Guide My Environment I am running a Dell FC640 on a TFX2HE chassis. Red Hat Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.1 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.1\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.1 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.1:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.1 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.1\" Red Hat Enterprise Linux release 8.1 (Ootpa) Red Hat Enterprise Linux release 8.1 (Ootpa) Kernel Info Linux dpdkdemo.lan 4.18.0-147.el8.x86_64 #1 SMP Thu Sep 26 15:52:44 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Physical Setup I ran the traffic generator to port 5 of the passthrough module which maps to port 1 my internal x710 card. Installation Enable Red Hat Repos Run subscription-manager list --available | less and find the subscription which provides CodeReady for x86. Note the pool number associated with the subscription. Run subscription-manager attach --pool=<POOL_NUMBER> to enable the subscription. Then run: subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms to enable the repo. Install DPDK Download from https://core.dpdk.org/download/ Edit the security limits with vim /etc/security/limits.conf 1.Add the following lines at the end of the file. This assumes you are running as root: root hard memlock unlimited root soft memlock unlimited Make sure your kernel is up to date with dnf update -y && reboot . Run dnf install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc Extract dpdk and cd into its directory set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=<YOUR_DIR> Run make install T=x86_64-native-linux-gcc CONFIG_RTE_LIBRTE_PMD_PCAP=y CONFIG_RTE_LIBRTE_PDUMP=y DESTDIR=<INSTALL_DIR> to build dpdk. Ensure your install directory exists. NOTE : The option CONFIG_RTE_LIBRTE_PMD_PCAP=y enabled libpcap support in DPDK. This is required for pdump to work. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile Install ELF Tools Run the following: dnf install -y python36-devel pip3 install numpy pip3 install elftools pip3 install pyelftools Configuration TODO: Need to update the instructions with this. Why can't the setup tool find it? I had to run modprobe uio && insmod /opt/dpdk-19.08/install/lib/modules/4.18.0-147.el8.x86_64/extra/dpdk/igb_uio.ko to get this to load. The modprobe uio is necessary because the uio module is a depency of igb_uio. Configure vfio-pci to Load on Boot (TODO REMOVE) Go to /etc/modules-load.d/ cd /etc/modules-load.d Run echo vfio-pci > vfio-pci.conf If you don't reboot you will need to run modprobe vfio-pci Configure Ports Move to your dpdk dir and run ./install/share/dpdk/usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. Run option 7 and make sure you receive output and that network devices are listed. My output looks like this: Network devices using kernel driver =================================== 0000:0b:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens192 drv=vmxnet3 unused=vfio-pci *Active* 0000:13:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens224 drv=vmxnet3 unused=vfio-pci *Active* No 'Baseband' devices detected ============================== No 'Crypto' devices detected ============================ No 'Eventdev' devices detected ============================== No 'Mempool' devices detected ============================= No 'Compress' devices detected ============================== No 'Misc (rawdev)' devices detected =================================== NOTE : The active keyword means that DPDK thinks the interface is under active use. This means that the interface has routes installed in the routing table. Run option 8 to bind an interface to DPDK using the IGB UIO driver. Performing Packet Capture Initial Setup Get the core layout with ./install/share/dpdk/usertools/cpu_layout.py View your port layout with ./install/share/dpdk/usertools/dpdk-devbind.py -s If you haven't already load the right kernel modules with: modprobe uio && insmod /opt/dpdk-19.08/install/lib/modules/4.18.0-147.el8.x86_64/extra/dpdk/igb_uio.ko Starting testpmd NOTE : The -- separates the argumentsn for the EAL vs TestPMD. ./install/bin/testpmd -l 4,8,10,12 -n 4 -- -i --forward-mode=rxonly After testpmd has started don't forget to run the start command on the testpmd command line. pdump ./install/bin/dpdk-pdump -- --pdump 'port=0,queue=*,rx-dev=/tmp/capture.pcap' Helpful Tips Getting CPU Info DPDK provides a tool for seeing the CPU layout with ./install/share/dpdk/usertools/cpu_layout.py You can see the logical layout of the cores with cat /proc/cpuinfo You can alse run lstopo-no-graphics Notice that the cores alternate back and forth. Process Types in DPDK DPDK runs two different types of processes. There are as follows: primary processes, which can initialize and which have full permissions on shared memory secondary processes, which cannot initialize shared memory, but can attach to pre- initialized shared memory and create objects in it. Standalone DPDK processes are primary processes, while secondary processes can only run alongside a primary process or after a primary process has already configured the hugepage shared memory for them. TestPMD The test pmd manual is available here Interactive Commands Starting transmit start Get Port Info show port info all Forwarding Modes TestPMD has different forwarding modes that can be used within the application. Input/output mode: This mode is generally referred to as IO mode. It is the most common forwarding mode and is the default mode when TestPMD is started. In IO mode a CPU core receives packets from one port (Rx) and transmits them to another port (Tx). The same port can be used for reception and transmission if required. Rx-only mode: In this mode the application polls packets from the Rx ports and frees them without transmitting them. In this way it acts as a packet sink. Tx-only mode: In this mode the application generates 64-byte IP packets and transmits them from the Tx ports. It doesn\u2019t handle the reception of packets and as such acts as a packet source. These latter two modes (Rx-only and Tx-only) are useful for checking packet reception and transmission separately. Apart from these three modes there are other forwarding modes that are explained in the TestPMD documentation . Port Topology Modes In paired mode, the forwarding is between pairs of ports, for example: (0,1), (2,3), (4,5). In chained mode, the forwarding is to the next available port in the port mask, for example: (0,1), (1,2), (2,0). The ordering of the ports can be changed using the portlist testpmd runtime function. In loop mode, ingress traffic is simply transmitted back on the same interface. Receive Side Scaling =Receive-Side Scaling (RSS), also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs. RSS can be used to relieve bottlenecks in receive interrupt processing caused by overloading a single CPU, and to reduce network latency. To determine whether your network interface card supports RSS, check whether multiple interrupt request queues are associated with the interface in /proc/interrupts. For example, if you are interested in the p1p1 interface: # egrep 'CPU|p1p1' /proc/interrupts CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 89: 40187 0 0 0 0 0 IR-PCI-MSI-edge p1p1-0 90: 0 790 0 0 0 0 IR-PCI-MSI-edge p1p1-1 91: 0 0 959 0 0 0 IR-PCI-MSI-edge p1p1-2 92: 0 0 0 3310 0 0 IR-PCI-MSI-edge p1p1-3 93: 0 0 0 0 622 0 IR-PCI-MSI-edge p1p1-4 94: 0 0 0 0 0 2475 IR-PCI-MSI-edge p1p1-5 huge pages https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-memory-configuring-huge-pages","title":"How to Get DPDK with pdump Running"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#how-to-get-dpdk-with-pdump-running","text":"The purpose of this experiment is to get Intel's DPDK framework up and running on a server.","title":"How to Get DPDK with pdump Running"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#useful-materials","text":"How to Compile DPDK Info on Linux Drivers for DPDK Description of the TestPMD Program DPDK Testpmd Application User Guide","title":"Useful Materials"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#my-environment","text":"I am running a Dell FC640 on a TFX2HE chassis.","title":"My Environment"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#red-hat-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.1 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.1\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.1 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.1:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.1 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.1\" Red Hat Enterprise Linux release 8.1 (Ootpa) Red Hat Enterprise Linux release 8.1 (Ootpa)","title":"Red Hat Release Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#kernel-info","text":"Linux dpdkdemo.lan 4.18.0-147.el8.x86_64 #1 SMP Thu Sep 26 15:52:44 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux","title":"Kernel Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#physical-setup","text":"I ran the traffic generator to port 5 of the passthrough module which maps to port 1 my internal x710 card.","title":"Physical Setup"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#installation","text":"","title":"Installation"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#enable-red-hat-repos","text":"Run subscription-manager list --available | less and find the subscription which provides CodeReady for x86. Note the pool number associated with the subscription. Run subscription-manager attach --pool=<POOL_NUMBER> to enable the subscription. Then run: subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms to enable the repo.","title":"Enable Red Hat Repos"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#install-dpdk","text":"Download from https://core.dpdk.org/download/ Edit the security limits with vim /etc/security/limits.conf 1.Add the following lines at the end of the file. This assumes you are running as root: root hard memlock unlimited root soft memlock unlimited Make sure your kernel is up to date with dnf update -y && reboot . Run dnf install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc Extract dpdk and cd into its directory set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=<YOUR_DIR> Run make install T=x86_64-native-linux-gcc CONFIG_RTE_LIBRTE_PMD_PCAP=y CONFIG_RTE_LIBRTE_PDUMP=y DESTDIR=<INSTALL_DIR> to build dpdk. Ensure your install directory exists. NOTE : The option CONFIG_RTE_LIBRTE_PMD_PCAP=y enabled libpcap support in DPDK. This is required for pdump to work. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile","title":"Install DPDK"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#install-elf-tools","text":"Run the following: dnf install -y python36-devel pip3 install numpy pip3 install elftools pip3 install pyelftools","title":"Install ELF Tools"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#configuration","text":"TODO: Need to update the instructions with this. Why can't the setup tool find it? I had to run modprobe uio && insmod /opt/dpdk-19.08/install/lib/modules/4.18.0-147.el8.x86_64/extra/dpdk/igb_uio.ko to get this to load. The modprobe uio is necessary because the uio module is a depency of igb_uio.","title":"Configuration"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#configure-vfio-pci-to-load-on-boot-todo-remove","text":"Go to /etc/modules-load.d/ cd /etc/modules-load.d Run echo vfio-pci > vfio-pci.conf If you don't reboot you will need to run modprobe vfio-pci","title":"Configure vfio-pci to Load on Boot (TODO REMOVE)"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#configure-ports","text":"Move to your dpdk dir and run ./install/share/dpdk/usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. Run option 7 and make sure you receive output and that network devices are listed. My output looks like this: Network devices using kernel driver =================================== 0000:0b:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens192 drv=vmxnet3 unused=vfio-pci *Active* 0000:13:00.0 'VMXNET3 Ethernet Controller 07b0' if=ens224 drv=vmxnet3 unused=vfio-pci *Active* No 'Baseband' devices detected ============================== No 'Crypto' devices detected ============================ No 'Eventdev' devices detected ============================== No 'Mempool' devices detected ============================= No 'Compress' devices detected ============================== No 'Misc (rawdev)' devices detected =================================== NOTE : The active keyword means that DPDK thinks the interface is under active use. This means that the interface has routes installed in the routing table. Run option 8 to bind an interface to DPDK using the IGB UIO driver.","title":"Configure Ports"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#performing-packet-capture","text":"","title":"Performing Packet Capture"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#initial-setup","text":"Get the core layout with ./install/share/dpdk/usertools/cpu_layout.py View your port layout with ./install/share/dpdk/usertools/dpdk-devbind.py -s If you haven't already load the right kernel modules with: modprobe uio && insmod /opt/dpdk-19.08/install/lib/modules/4.18.0-147.el8.x86_64/extra/dpdk/igb_uio.ko","title":"Initial Setup"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#starting-testpmd","text":"NOTE : The -- separates the argumentsn for the EAL vs TestPMD. ./install/bin/testpmd -l 4,8,10,12 -n 4 -- -i --forward-mode=rxonly After testpmd has started don't forget to run the start command on the testpmd command line.","title":"Starting testpmd"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#pdump","text":"./install/bin/dpdk-pdump -- --pdump 'port=0,queue=*,rx-dev=/tmp/capture.pcap'","title":"pdump"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#helpful-tips","text":"","title":"Helpful Tips"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#getting-cpu-info","text":"DPDK provides a tool for seeing the CPU layout with ./install/share/dpdk/usertools/cpu_layout.py You can see the logical layout of the cores with cat /proc/cpuinfo You can alse run lstopo-no-graphics Notice that the cores alternate back and forth.","title":"Getting CPU Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#process-types-in-dpdk","text":"DPDK runs two different types of processes. There are as follows: primary processes, which can initialize and which have full permissions on shared memory secondary processes, which cannot initialize shared memory, but can attach to pre- initialized shared memory and create objects in it. Standalone DPDK processes are primary processes, while secondary processes can only run alongside a primary process or after a primary process has already configured the hugepage shared memory for them.","title":"Process Types in DPDK"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#testpmd","text":"The test pmd manual is available here","title":"TestPMD"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#interactive-commands","text":"","title":"Interactive Commands"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#starting-transmit","text":"start","title":"Starting transmit"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#get-port-info","text":"show port info all","title":"Get Port Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#forwarding-modes","text":"TestPMD has different forwarding modes that can be used within the application. Input/output mode: This mode is generally referred to as IO mode. It is the most common forwarding mode and is the default mode when TestPMD is started. In IO mode a CPU core receives packets from one port (Rx) and transmits them to another port (Tx). The same port can be used for reception and transmission if required. Rx-only mode: In this mode the application polls packets from the Rx ports and frees them without transmitting them. In this way it acts as a packet sink. Tx-only mode: In this mode the application generates 64-byte IP packets and transmits them from the Tx ports. It doesn\u2019t handle the reception of packets and as such acts as a packet source. These latter two modes (Rx-only and Tx-only) are useful for checking packet reception and transmission separately. Apart from these three modes there are other forwarding modes that are explained in the TestPMD documentation .","title":"Forwarding Modes"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#port-topology-modes","text":"In paired mode, the forwarding is between pairs of ports, for example: (0,1), (2,3), (4,5). In chained mode, the forwarding is to the next available port in the port mask, for example: (0,1), (1,2), (2,0). The ordering of the ports can be changed using the portlist testpmd runtime function. In loop mode, ingress traffic is simply transmitted back on the same interface.","title":"Port Topology Modes"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20FC640%20with%20RHEL%208/#receive-side-scaling","text":"=Receive-Side Scaling (RSS), also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs. RSS can be used to relieve bottlenecks in receive interrupt processing caused by overloading a single CPU, and to reduce network latency. To determine whether your network interface card supports RSS, check whether multiple interrupt request queues are associated with the interface in /proc/interrupts. For example, if you are interested in the p1p1 interface: # egrep 'CPU|p1p1' /proc/interrupts CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 89: 40187 0 0 0 0 0 IR-PCI-MSI-edge p1p1-0 90: 0 790 0 0 0 0 IR-PCI-MSI-edge p1p1-1 91: 0 0 959 0 0 0 IR-PCI-MSI-edge p1p1-2 92: 0 0 0 3310 0 0 IR-PCI-MSI-edge p1p1-3 93: 0 0 0 0 622 0 IR-PCI-MSI-edge p1p1-4 94: 0 0 0 0 0 2475 IR-PCI-MSI-edge p1p1-5 huge pages https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-memory-configuring-huge-pages","title":"Receive Side Scaling"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/","text":"How to Get DPDK with pdump Running The purpose of this experiment is to get Intel's DPDK framework up and running on a server. Useful Materials How to Compile DPDK Info on Linux Drivers for DPDK Description of the TestPMD Program My Environment I am running a Dell R940 with Napatech Card NT200A02 CentOS Release Info NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core) Kernel Info Linux r940.lan 3.10.0-1062.4.3.el7.x86_64 #1 SMP Wed Nov 13 23:58:53 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Physical Setup Installation NapaTech Driver Install Driver Download the Napatech software from here Run yum groupinstall \"Development Tools\" && yum install -y kernel-devel gettext-devel openssl-devel perl-CPAN perl-devel zlib-devel pciutils && yum install -y https://centos7.iuscommunity.org/ius-release.rpm && yum remove -y git && yum install -y git2u-all Unzip and run package_install_3gd.sh Install DPDK export NAPATECH3_PATH=/opt/napatech3 Download with git clone https://github.com/napatech/dpdk.git Edit the security limits with vim /etc/security/limits.conf . After making the below edits you will need to log out and log back in for them to take effect. 1.Add the following lines at the end of the file. This assumes you are running as root: root hard memlock unlimited root soft memlock unlimited Run yum install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc libpcap-devel python36-devel Extract dpdk and cd into its directory set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=<YOUR_DIR> Run make config T=x86_64-native-linuxapp-gcc install CONFIG_RTE_LIBRTE_PMD_PCAP=y CONFIG_RTE_LIBRTE_PDUMP=y DESTDIR=install CONFIG_RTE_LIBRTE_PMD_NTACC=y to build dpdk. Ensure your install directory exists. make -j NOTE : The option CONFIG_RTE_LIBRTE_PMD_PCAP=y enabled libpcap support in DPDK. This is required for pdump to work. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile Update Your Bash Profile Add: export RTE_SDK=/opt/dpdk export NAPATECH3_PATH=/opt/napatech3 export RTE_TARGET=/opt/dpdk/x86_64-native-linuxapp-gcc to ~/.bash_profile Install ELF Tools Run the following: pip3 install numpy pip3 install elftools pip3 install pyelftools Configuration Configure Ports Move to your dpdk dir and run ./install/share/dpdk/usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. I used a value of 4096 for each NUMA node. Performing Packet Capture Setup the NapaTech Card Initial Setup Get the core layout with ./install/share/dpdk/usertools/cpu_layout.py View your port layout with ./install/share/dpdk/usertools/dpdk-devbind.py -s Starting testpmd NOTE : The -- separates the argumentsn for the EAL vs TestPMD. ./install/bin/testpmd -l 0,4,8,12,16,20,24,28,32,36 -n 4 -- -i After testpmd has started don't forget to run the start command on the testpmd command line. pdump ./install/bin/dpdk-pdump -- --pdump 'device_id=0000:5b:00.0,queue=*,rx-dev=/tmp/capture.pcap' Helpful Tips NapaTech Detecting Installed Cards /opt/napatech3/bin/imgctrl -q Load the Driver /opt/napatech3/bin/ntload.sh Run the ntserver /opt/napatech3/bin/ntstart.sh Show Interface Info /opt/napatech3/bin/adapterinfo Getting CPU Info DPDK provides a tool for seeing the CPU layout with ./install/share/dpdk/usertools/cpu_layout.py You can see the logical layout of the cores with cat /proc/cpuinfo You can alse run lstopo-no-graphics Notice that the cores alternate back and forth. Process Types in DPDK DPDK runs two different types of processes. There are as follows: primary processes, which can initialize and which have full permissions on shared memory secondary processes, which cannot initialize shared memory, but can attach to pre- initialized shared memory and create objects in it. Standalone DPDK processes are primary processes, while secondary processes can only run alongside a primary process or after a primary process has already configured the hugepage shared memory for them. TestPMD The test pmd manual is available here Interactive Commands Starting transmit start Get Port Info show port info all Forwarding Modes TestPMD has different forwarding modes that can be used within the application. Input/output mode: This mode is generally referred to as IO mode. It is the most common forwarding mode and is the default mode when TestPMD is started. In IO mode a CPU core receives packets from one port (Rx) and transmits them to another port (Tx). The same port can be used for reception and transmission if required. Rx-only mode: In this mode the application polls packets from the Rx ports and frees them without transmitting them. In this way it acts as a packet sink. Tx-only mode: In this mode the application generates 64-byte IP packets and transmits them from the Tx ports. It doesn\u2019t handle the reception of packets and as such acts as a packet source. These latter two modes (Rx-only and Tx-only) are useful for checking packet reception and transmission separately. Apart from these three modes there are other forwarding modes that are explained in the TestPMD documentation . Port Topology Modes In paired mode, the forwarding is between pairs of ports, for example: (0,1), (2,3), (4,5). In chained mode, the forwarding is to the next available port in the port mask, for example: (0,1), (1,2), (2,0). The ordering of the ports can be changed using the portlist testpmd runtime function. In loop mode, ingress traffic is simply transmitted back on the same interface. Receive Side Scaling =Receive-Side Scaling (RSS), also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs. RSS can be used to relieve bottlenecks in receive interrupt processing caused by overloading a single CPU, and to reduce network latency. To determine whether your network interface card supports RSS, check whether multiple interrupt request queues are associated with the interface in /proc/interrupts. For example, if you are interested in the p1p1 interface: # egrep 'CPU|p1p1' /proc/interrupts CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 89: 40187 0 0 0 0 0 IR-PCI-MSI-edge p1p1-0 90: 0 790 0 0 0 0 IR-PCI-MSI-edge p1p1-1 91: 0 0 959 0 0 0 IR-PCI-MSI-edge p1p1-2 92: 0 0 0 3310 0 0 IR-PCI-MSI-edge p1p1-3 93: 0 0 0 0 622 0 IR-PCI-MSI-edge p1p1-4 94: 0 0 0 0 0 2475 IR-PCI-MSI-edge p1p1-5 huge pages https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-memory-configuring-huge-pages","title":"How to Get DPDK with pdump Running"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#how-to-get-dpdk-with-pdump-running","text":"The purpose of this experiment is to get Intel's DPDK framework up and running on a server.","title":"How to Get DPDK with pdump Running"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#useful-materials","text":"How to Compile DPDK Info on Linux Drivers for DPDK Description of the TestPMD Program","title":"Useful Materials"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#my-environment","text":"I am running a Dell R940 with Napatech Card NT200A02","title":"My Environment"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#centos-release-info","text":"NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core)","title":"CentOS Release Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#kernel-info","text":"Linux r940.lan 3.10.0-1062.4.3.el7.x86_64 #1 SMP Wed Nov 13 23:58:53 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux","title":"Kernel Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#physical-setup","text":"","title":"Physical Setup"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#installation-napatech-driver","text":"","title":"Installation NapaTech Driver"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#install-driver","text":"Download the Napatech software from here Run yum groupinstall \"Development Tools\" && yum install -y kernel-devel gettext-devel openssl-devel perl-CPAN perl-devel zlib-devel pciutils && yum install -y https://centos7.iuscommunity.org/ius-release.rpm && yum remove -y git && yum install -y git2u-all Unzip and run package_install_3gd.sh","title":"Install Driver"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#install-dpdk","text":"export NAPATECH3_PATH=/opt/napatech3 Download with git clone https://github.com/napatech/dpdk.git Edit the security limits with vim /etc/security/limits.conf . After making the below edits you will need to log out and log back in for them to take effect. 1.Add the following lines at the end of the file. This assumes you are running as root: root hard memlock unlimited root soft memlock unlimited Run yum install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc libpcap-devel python36-devel Extract dpdk and cd into its directory set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=<YOUR_DIR> Run make config T=x86_64-native-linuxapp-gcc install CONFIG_RTE_LIBRTE_PMD_PCAP=y CONFIG_RTE_LIBRTE_PDUMP=y DESTDIR=install CONFIG_RTE_LIBRTE_PMD_NTACC=y to build dpdk. Ensure your install directory exists. make -j NOTE : The option CONFIG_RTE_LIBRTE_PMD_PCAP=y enabled libpcap support in DPDK. This is required for pdump to work. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile","title":"Install DPDK"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#update-your-bash-profile","text":"Add: export RTE_SDK=/opt/dpdk export NAPATECH3_PATH=/opt/napatech3 export RTE_TARGET=/opt/dpdk/x86_64-native-linuxapp-gcc to ~/.bash_profile","title":"Update Your Bash Profile"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#install-elf-tools","text":"Run the following: pip3 install numpy pip3 install elftools pip3 install pyelftools","title":"Install ELF Tools"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#configuration","text":"","title":"Configuration"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#configure-ports","text":"Move to your dpdk dir and run ./install/share/dpdk/usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. I used a value of 4096 for each NUMA node.","title":"Configure Ports"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#performing-packet-capture","text":"","title":"Performing Packet Capture"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#setup-the-napatech-card","text":"","title":"Setup the NapaTech Card"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#initial-setup","text":"Get the core layout with ./install/share/dpdk/usertools/cpu_layout.py View your port layout with ./install/share/dpdk/usertools/dpdk-devbind.py -s","title":"Initial Setup"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#starting-testpmd","text":"NOTE : The -- separates the argumentsn for the EAL vs TestPMD. ./install/bin/testpmd -l 0,4,8,12,16,20,24,28,32,36 -n 4 -- -i After testpmd has started don't forget to run the start command on the testpmd command line.","title":"Starting testpmd"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#pdump","text":"./install/bin/dpdk-pdump -- --pdump 'device_id=0000:5b:00.0,queue=*,rx-dev=/tmp/capture.pcap'","title":"pdump"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#helpful-tips","text":"","title":"Helpful Tips"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#napatech","text":"","title":"NapaTech"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#detecting-installed-cards","text":"/opt/napatech3/bin/imgctrl -q","title":"Detecting Installed Cards"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#load-the-driver","text":"/opt/napatech3/bin/ntload.sh","title":"Load the Driver"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#run-the-ntserver","text":"/opt/napatech3/bin/ntstart.sh","title":"Run the ntserver"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#show-interface-info","text":"/opt/napatech3/bin/adapterinfo","title":"Show Interface Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#getting-cpu-info","text":"DPDK provides a tool for seeing the CPU layout with ./install/share/dpdk/usertools/cpu_layout.py You can see the logical layout of the cores with cat /proc/cpuinfo You can alse run lstopo-no-graphics Notice that the cores alternate back and forth.","title":"Getting CPU Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#process-types-in-dpdk","text":"DPDK runs two different types of processes. There are as follows: primary processes, which can initialize and which have full permissions on shared memory secondary processes, which cannot initialize shared memory, but can attach to pre- initialized shared memory and create objects in it. Standalone DPDK processes are primary processes, while secondary processes can only run alongside a primary process or after a primary process has already configured the hugepage shared memory for them.","title":"Process Types in DPDK"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#testpmd","text":"The test pmd manual is available here","title":"TestPMD"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#interactive-commands","text":"","title":"Interactive Commands"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#starting-transmit","text":"start","title":"Starting transmit"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#get-port-info","text":"show port info all","title":"Get Port Info"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#forwarding-modes","text":"TestPMD has different forwarding modes that can be used within the application. Input/output mode: This mode is generally referred to as IO mode. It is the most common forwarding mode and is the default mode when TestPMD is started. In IO mode a CPU core receives packets from one port (Rx) and transmits them to another port (Tx). The same port can be used for reception and transmission if required. Rx-only mode: In this mode the application polls packets from the Rx ports and frees them without transmitting them. In this way it acts as a packet sink. Tx-only mode: In this mode the application generates 64-byte IP packets and transmits them from the Tx ports. It doesn\u2019t handle the reception of packets and as such acts as a packet source. These latter two modes (Rx-only and Tx-only) are useful for checking packet reception and transmission separately. Apart from these three modes there are other forwarding modes that are explained in the TestPMD documentation .","title":"Forwarding Modes"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#port-topology-modes","text":"In paired mode, the forwarding is between pairs of ports, for example: (0,1), (2,3), (4,5). In chained mode, the forwarding is to the next available port in the port mask, for example: (0,1), (1,2), (2,0). The ordering of the ports can be changed using the portlist testpmd runtime function. In loop mode, ingress traffic is simply transmitted back on the same interface.","title":"Port Topology Modes"},{"location":"High%20Speed%20Packet%20Capture/DPDK%20on%20R940%20with%20Napatech/#receive-side-scaling","text":"=Receive-Side Scaling (RSS), also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs. RSS can be used to relieve bottlenecks in receive interrupt processing caused by overloading a single CPU, and to reduce network latency. To determine whether your network interface card supports RSS, check whether multiple interrupt request queues are associated with the interface in /proc/interrupts. For example, if you are interested in the p1p1 interface: # egrep 'CPU|p1p1' /proc/interrupts CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 89: 40187 0 0 0 0 0 IR-PCI-MSI-edge p1p1-0 90: 0 790 0 0 0 0 IR-PCI-MSI-edge p1p1-1 91: 0 0 959 0 0 0 IR-PCI-MSI-edge p1p1-2 92: 0 0 0 3310 0 0 IR-PCI-MSI-edge p1p1-3 93: 0 0 0 0 622 0 IR-PCI-MSI-edge p1p1-4 94: 0 0 0 0 0 2475 IR-PCI-MSI-edge p1p1-5 huge pages https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-memory-configuring-huge-pages","title":"Receive Side Scaling"},{"location":"High%20Speed%20Packet%20Capture/ntop/","text":"Helpful Materials Drill Down Deeper: Using ntopng to Zoom In, Filter Out and Go Straight to the Packets Traffic Recording Manual Configuration Hardware Tracewell TFX2HE with 1 passthrough module, 1 switch module. Operating System Version CentOS Linux release 7.7.1908 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core) Kernel Version Linux ntopdemo.lan 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Install n2disk and ntop Perform Installation Install epel with yum install -y epel-release Erase the zeromq3 package with yum erase zeromq && yum clean all && yum update -y && reboot Pull ntop repo with wget http://packages.ntop.org/centos-stable/ntop.repo -O /etc/yum.repos.d/ntop.repo Install required packages with yum install pfring-dkms pfring n2disk nprobe ntopng ntopng-data cento pfring-drivers-zc-dkms redis hiredis-devel Perform Configuration Zero Copy Driver List interfaces with pf_ringcfg --list-interfaces Configure the driver with pf_ringcfg --configure-driver i40e Set promiscuous mode on the interface in question with /sbin/ip link set em1 promisc on Edit the pfring configuration file with vim /etc/pf_ring/interfaces.conf and add your configuration. MANAGEMENT_INTERFACES=\"<YOUR_MANAGEMENT_INTERFACE>\" CAPTURE_INTERFACES=\"<YOUR_CAPTURE_INTERFACE>\" Open the file etc/ntopng/ntopng.conf . If you do not have a license add --community to the end Configure the firewall to accept connections to ntopng with: firewall-cmd --zone=public --permanent --add-port=3000/tcp && firewall-cmd --reload Enable and start services with: systemctl enable redis.service systemctl enable ntopng.service systemctl enable pf_ring systemctl start redis.service systemctl start ntopng.service systemctl start pf_ring Make sure the services are running correctly with: systemctl status redis.service systemctl status ntopng.service systemctl status pf_ring Performing Filtering","title":"Helpful Materials"},{"location":"High%20Speed%20Packet%20Capture/ntop/#helpful-materials","text":"Drill Down Deeper: Using ntopng to Zoom In, Filter Out and Go Straight to the Packets Traffic Recording Manual","title":"Helpful Materials"},{"location":"High%20Speed%20Packet%20Capture/ntop/#configuration","text":"","title":"Configuration"},{"location":"High%20Speed%20Packet%20Capture/ntop/#hardware","text":"Tracewell TFX2HE with 1 passthrough module, 1 switch module.","title":"Hardware"},{"location":"High%20Speed%20Packet%20Capture/ntop/#operating-system-version","text":"CentOS Linux release 7.7.1908 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core)","title":"Operating System Version"},{"location":"High%20Speed%20Packet%20Capture/ntop/#kernel-version","text":"Linux ntopdemo.lan 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux","title":"Kernel Version"},{"location":"High%20Speed%20Packet%20Capture/ntop/#install-n2disk-and-ntop","text":"","title":"Install n2disk and ntop"},{"location":"High%20Speed%20Packet%20Capture/ntop/#perform-installation","text":"Install epel with yum install -y epel-release Erase the zeromq3 package with yum erase zeromq && yum clean all && yum update -y && reboot Pull ntop repo with wget http://packages.ntop.org/centos-stable/ntop.repo -O /etc/yum.repos.d/ntop.repo Install required packages with yum install pfring-dkms pfring n2disk nprobe ntopng ntopng-data cento pfring-drivers-zc-dkms redis hiredis-devel","title":"Perform Installation"},{"location":"High%20Speed%20Packet%20Capture/ntop/#perform-configuration-zero-copy-driver","text":"List interfaces with pf_ringcfg --list-interfaces Configure the driver with pf_ringcfg --configure-driver i40e Set promiscuous mode on the interface in question with /sbin/ip link set em1 promisc on Edit the pfring configuration file with vim /etc/pf_ring/interfaces.conf and add your configuration. MANAGEMENT_INTERFACES=\"<YOUR_MANAGEMENT_INTERFACE>\" CAPTURE_INTERFACES=\"<YOUR_CAPTURE_INTERFACE>\" Open the file etc/ntopng/ntopng.conf . If you do not have a license add --community to the end Configure the firewall to accept connections to ntopng with: firewall-cmd --zone=public --permanent --add-port=3000/tcp && firewall-cmd --reload Enable and start services with: systemctl enable redis.service systemctl enable ntopng.service systemctl enable pf_ring systemctl start redis.service systemctl start ntopng.service systemctl start pf_ring Make sure the services are running correctly with: systemctl status redis.service systemctl status ntopng.service systemctl status pf_ring","title":"Perform Configuration Zero Copy Driver"},{"location":"High%20Speed%20Packet%20Capture/ntop/#performing-filtering","text":"","title":"Performing Filtering"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/","text":"Useful Materials NapaTech Installation Instructions (Creatinga EXT4 Filesystem)[https://thelastmaimou.wordpress.com/2013/05/04/magic-soup-ext4-with-ssd-stripes-and-strides/] My Environment I am running a Dell FC640 on a Dell R940 See Server Specs for hardware details. Hard Drive Layout: I had a RAID of 12 SAS SSDs in RAID0 on the PERC740. I had 7 NVMe drives I used. I couldn't get the 8th NVMe drive working. [root@r940 /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 10.5T 0 disk /raiddata sdb 8:16 0 223.5G 0 disk \u251c\u2500sdb1 8:17 0 200M 0 part /boot/efi \u251c\u2500sdb2 8:18 0 1G 0 part /boot \u2514\u2500sdb3 8:19 0 222.3G 0 part \u251c\u2500centos-root 253:0 0 218.3G 0 lvm / \u2514\u2500centos-swap 253:1 0 4G 0 lvm [SWAP] sdc 8:32 0 59.8G 0 disk nvme0n1 259:6 0 1.5T 0 disk \u2514\u2500nvme0n1p1 259:8 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme1n1 259:0 0 1.5T 0 disk \u2514\u2500nvme1n1p1 259:1 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme2n1 259:2 0 1.5T 0 disk \u2514\u2500nvme2n1p1 259:3 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme3n1 259:4 0 1.5T 0 disk \u2514\u2500nvme3n1p1 259:5 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme4n1 259:10 0 1.5T 0 disk \u2514\u2500nvme4n1p1 259:13 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme5n1 259:11 0 1.5T 0 disk nvme6n1 259:7 0 1.5T 0 disk \u2514\u2500nvme6n1p1 259:9 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme7n1 259:12 0 1.5T 0 disk \u2514\u2500nvme7n1p1 259:14 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data [root@r940 /]# pvs PV VG Fmt Attr PSize PFree /dev/nvme0n1p1 data lvm2 a-- <1.46t 0 /dev/nvme1n1p1 data lvm2 a-- <1.46t 0 /dev/nvme2n1p1 data lvm2 a-- <1.46t 0 /dev/nvme3n1p1 data lvm2 a-- <1.46t 0 /dev/nvme4n1p1 data lvm2 a-- <1.46t 0 /dev/nvme6n1p1 data lvm2 a-- <1.46t 0 /dev/nvme7n1p1 data lvm2 a-- <1.46t 0 /dev/sdb3 centos lvm2 a-- <222.31g 0 [root@r940 /]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- <222.31g 0 data 7 1 0 wz--n- <10.19t 0 [root@r940 /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- <218.31g swap centos -wi-ao---- 4.00g data data -wi-ao---- <10.19t WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme1n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 759A1CF7-125F-469B-981E-149EBDBE3456 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme2n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 57898F4D-5B5E-4495-B695-E48EA3FCFA01 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme3n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: DB46E8E3-5E96-4228-A148-E6C8F0187DF4 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme0n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 4066CDE1-E36E-41FB-8277-5E3FFDB55B4A # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme6n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 0360D46A-9A41-4A8D-A449-94CCDC01FA8B # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme4n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: A5D3EDDF-C93D-4B33-92B0-D25B009EEB9D # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM Disk /dev/nvme5n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme7n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 71A0B583-E727-45B6-A1AB-791D341709B6 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM Disk /dev/sda: 11515.9 GB, 11515881062400 bytes, 22491955200 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 1048576 bytes / 1048576 bytes WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/sdb: 240.0 GB, 239990276096 bytes, 468731008 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk label type: gpt Disk identifier: F1E6A9A1-C85F-46C1-A27E-DBC41C9260AC # Start End Size Type Name 1 2048 411647 200M EFI System EFI System Partition 2 411648 2508799 1G Microsoft basic 3 2508800 468729855 222.3G Linux LVM Disk /dev/sdc: 64.2 GB, 64239960064 bytes, 125468672 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-root: 234.4 GB, 234407067648 bytes, 457826304 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk /dev/mapper/centos-swap: 4294 MB, 4294967296 bytes, 8388608 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk /dev/mapper/data-data: 11202.2 GB, 11202210037760 bytes, 21879316480 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 131072 bytes / 917504 bytes CPU Layout [root@r940 data]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 176 On-line CPU(s) list: 0-175 Thread(s) per core: 2 Core(s) per socket: 22 Socket(s): 4 NUMA node(s): 4 Vendor ID: GenuineIntel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz Stepping: 4 CPU MHz: 1394.146 CPU max MHz: 3700.0000 CPU min MHz: 1000.0000 BogoMIPS: 4200.00 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 30976K NUMA node0 CPU(s): 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 NUMA node1 CPU(s): 1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77,81,85,89,93,97,101,105,109,113,117,121,125,129,133,137,141,145,149,153,157,161,165,169,173 NUMA node2 CPU(s): 2,6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78,82,86,90,94,98,102,106,110,114,118,122,126,130,134,138,142,146,150,154,158,162,166,170,174 NUMA node3 CPU(s): 3,7,11,15,19,23,27,31,35,39,43,47,51,55,59,63,67,71,75,79,83,87,91,95,99,103,107,111,115,119,123,127,131,135,139,143,147,151,155,159,163,167,171,175 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_ppin intel_pt ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke md_clear spec_ctrl intel_stibp flush_l1d [root@r940 data]# cpu_layout.py ====================================================================== Core and Socket Information (as reported by '/sys/devices/system/cpu') ====================================================================== cores = [0, 5, 1, 4, 2, 3, 8, 12, 9, 11, 10, 21, 16, 20, 17, 19, 18, 28, 24, 27, 25, 26] sockets = [0, 1, 2, 3] Socket 0 Socket 1 Socket 2 Socket 3 -------- -------- -------- -------- Core 0 [0, 88] [1, 89] [2, 90] [3, 91] Core 5 [4, 92] [5, 93] [6, 94] [7, 95] Core 1 [8, 96] [9, 97] [10, 98] [11, 99] Core 4 [12, 100] [13, 101] [14, 102] [15, 103] Core 2 [16, 104] [17, 105] [18, 106] [19, 107] Core 3 [20, 108] [21, 109] [22, 110] [23, 111] Core 8 [24, 112] [25, 113] [26, 114] [27, 115] Core 12 [28, 116] [29, 117] [30, 118] [31, 119] Core 9 [32, 120] [33, 121] [34, 122] [35, 123] Core 11 [36, 124] [37, 125] [38, 126] [39, 127] Core 10 [40, 128] [41, 129] [42, 130] [43, 131] Core 21 [44, 132] [45, 133] [46, 134] [47, 135] Core 16 [48, 136] [49, 137] [50, 138] [51, 139] Core 20 [52, 140] [53, 141] [54, 142] [55, 143] Core 17 [56, 144] [57, 145] [58, 146] [59, 147] Core 19 [60, 148] [61, 149] [62, 150] [63, 151] Core 18 [64, 152] [65, 153] [66, 154] [67, 155] Core 28 [68, 156] [69, 157] [70, 158] [71, 159] Core 24 [72, 160] [73, 161] [74, 162] [75, 163] Core 27 [76, 164] [77, 165] [78, 166] [79, 167] Core 25 [80, 168] [81, 169] [82, 170] [83, 171] Core 26 [84, 172] [85, 173] [86, 174] [87, 175] CentOS 7 Release Info NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core) Kernel Info Linux r940.lan 3.10.0-1062.4.3.el7.x86_64 #1 SMP Wed Nov 13 23:58:53 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Format Your Data Partitions Create physical volumes and volume groups with: pvcreate <NVMe drive> vgcreate data <List of NVMe Drives> NOTE: I only did this on the NVMe drives. To create the logical volume I used: lvcreate -l 100%FREE -i7 -I128 -n data data To format the drive I used: mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 # This was the 12 SAS SSDs I had in a RAID mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 /dev/mapper/data-data # This was the NVMes I tied together with LVM mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 /dev/mapper/data2-data2 mount -o rw,auto,discard /dev/mapper/data-data /data mount -o rw,auto,discard /dev/sda /raiddata/ mount -o rw,auto,discard /dev/mapper/data2-data2 /data2 echo noop > /sys/block/sda/queue/scheduler Install NapaTech Driver Install Driver Download the Napatech software from here Run yum groupinstall \"Development Tools\" && yum install -y kernel-devel wget gettext-devel openssl-devel perl-CPAN perl-devel zlib-devel pciutils && yum install -y https://centos7.iuscommunity.org/ius-release.rpm && yum remove -y git && yum install -y git2u-all Unzip and run package_install_3gd.sh Run the following commands: /opt/napatech3/bin/ntload.sh /opt/napatech3/bin/ntstart.sh Install n2disk and ntop Perform Installation Install epel with yum install -y epel-release Erase the zeromq3 package with yum erase zeromq && yum clean all && yum update -y && reboot Pull ntop repo with wget http://packages.ntop.org/centos-stable/ntop.repo -O /etc/yum.repos.d/ntop.repo Install required packages with yum install -y pfring-dkms pfring n2disk nprobe ntopng ntopng-data cento pfring-drivers-zc-dkms redis hiredis-devel Configure n2disk Create backup of the the NapaTech ini file cp /opt/napatech3/config/ntservice.ini /opt/napatech3/config/ntservice.ini.bak Update /opt/napatech3/config/ntservice.ini with the following values: TimestampFormat = PCAP_NS PacketDescriptor = PCAP HostBufferSegmentSizeRx = 4 TODO change these lines see notes for help HostBuffersRx = [16,16,0],[16,16,1] HostBuffersTx = [16,16,0],[16,16,1] You will need to start and stop the ntservice for these changes to take effect with: /opt/napatech3/bin/ntstop.sh /opt/napatech3/bin/ntstart.sh Perform Configuration Zero Copy Driver Edit the pfring configuration file with vim /etc/pf_ring/interfaces.conf and add your configuration. MANAGEMENT_INTERFACES=\"em1\" CAPTURE_INTERFACES=\"nt:0\" Open the file /etc/ntopng/ntopng.conf . If you do not have a license add --community to the end Configure the firewall to accept connections to ntopng with: firewall-cmd --zone=public --permanent --add-port=3000/tcp && firewall-cmd --reload Enable and start services with: systemctl enable redis.service systemctl enable ntopng.service systemctl enable pf_ring systemctl start redis.service systemctl start ntopng.service systemctl start pf_ring Make sure the services are running correctly with: systemctl status redis.service systemctl status ntopng.service systemctl status pf_ring Configure License Run zcount -i nt:0 and note the serial number Output n2disk license to /etc/n2disk.license Output ntopng license to /etc/ntopng.license Useful Tips Hardware Filtering Napatech NICs support full-blown hardware filtering out of the box. Thanks to nBPF we convert BPF expressions to hardware filters. This feature is supported transparently, and thus all PF_RING/libpcap-over-PF_RING can benefit from it. Example: pfcount -i nt:3 -f \"tcp and port 80 and src host 192.168.1.1\" Hostbuffer Notes HostBuffersRx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] HostBuffersTx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] First number is the number of host buffers Second number is the size of the host buffers Third number is the NUMA node You have to have one set of numbers for each NUMA node. Testing Transmit Speed ./pktgen -p 1 -r 10G Testing the PCAP transmit speed To test to see if the Napatech card is up and running run this command: ./pfcount -i nt:0 ./monitoring You can press t to switch stats between receive and transmit. Testing Receive chmod -R 777 /data rm /tmp/*-none\\.* 2>/dev/null; while true; do grep 'Dropped:\\|Slow.*:' -C50 /proc/net/pf_ring/stats/* 2>/dev/null; cp /proc/net/pf_ring/stats/*none* /tmp 2>/dev/null; sleep 1; done NUMA Lookup Run lscpu Things we tried: We used the to list the cpu layout and determine where we wanted to run what threads. Tests 1-6 were with the default settings for a RAID0 partition on Linux at setup time. Test 1 This is running at 100Gb/s generation n2disk -a -v -l -o /<Storage path> -x $(date +%s.) -i nt:0 This seemed to dump everything to one thread. We maxed out and had ~82% packet loss. Test 2 This is running at 100Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 32 -z 2,3,4,5,6,7 -Z -w 16,17,18,19,20,20,21 -S 22 Throughput results: [root@r940 bin]# cat /proc/net/pf_ring/stats/*none* Duration: 0:00:00:53:022 Throughput: 2.12 Mpps 17.65 Gbps Packets: 78780625 Filtered: 78780625 Dropped: 518512807 Bytes: 81931850000 DumpedBytes: 71137406724 DumpedFiles: 17 SlowSlavesLoops: 0 SlowStorageLoops: 432580 CaptureLoops: 19532 FirstDumpedEpoch: 0 LastDumpedEpoch: 1574185087 Worked better but we got a warning saying the time thread was on a different core than the reader/writer threads. Test 3 This is running at 100Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 32 -z 2,3,4,5,6,7 -Z -w 16,17,18,19,20,20,21 -S 56 Worked better: 19/Nov/2019 12:41:59 [n2disk.c:1109] Average Capture Throughput: 22.49 Gbit / 2.69 Mpps Test 4 This is running at 100Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 Test 5 This is running at 20Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 Failed. We got a lot of packet loss. Test 6 This is running at 10Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 No packet drops. Test 7 This is running at 20Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 This was with a data partition formatting according to the above. Test 8 /opt/napatech3/bin/ntpl -e \"Delete = All\" /opt/napatech3/bin/ntpl -e \"Setup[NumaNode=2] = StreamID == 0\" # Repeat this for each stream ID. In our case 0-4 ./profiling # use this to see traffic being received # N is the NUMA node that the profiler detects the traffic on /opt/napatech3/bin/ntpl -e \"HashMode = Hash2TupleSorted\" /opt/napatech3/bin/ntpl -e \"Assign[StreamId=(0..3)] = port == 0\" The problem with this was that we couldn't get n2disk to listen on multiple interfaces. It also didn't really give us a way to split the traffic across multiple reader threads. Test 9 I made four directories, one for each n2disk process I did the following: /opt/napatech3/bin/ntpl -e \"Delete = All\" /opt/napatech3/bin/ntpl -e \"Setup[NumaNode=2] = StreamID == 0\" # Repeat this for each stream ID. In our case 0-4 /opt/napatech3/bin/ntpl -e \"HashMode = Hash2TupleSorted\" /opt/napatech3/bin/ntpl -e \"Assign[StreamId=(0..3)] = port == 0\" ./profiling # use this to see traffic being received # N is the NUMA node that the profiler detects the traffic on Run the following commands: n2disk -a -v -l -o /data/data0 -x $(date +%s.) -i nt:stream0 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 120 -z 0,4,8,12,16,20,24,28 -Z -w 88,92,96,100,104,108,112,116 -S 32 n2disk -a -v -l -o /data/data1 -x $(date +%s.) -i nt:stream1 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 121 -z 1,5,9,13,17,21,25,29 -Z -w 89,93,97,101,105,109,113,117 -S 33 n2disk -a -v -l -o /data/data2 -x $(date +%s.) -i nt:stream2 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 156 -z 36,40,44,48,52,56,60,64 -Z -w 124,128,132,136,140,144,148,152 -S 68 n2disk -a -v -l -o /data/data3 -x $(date +%s.) -i nt:stream3 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 157 -z 37,41,45,49,53,57,61,65 -Z -w 125,129,133,137,141,145,149,153 -S 69 -a : Archive pcap file (rename to .old) instead of overwriting if already present on disk. -v : Verbose. -o : Directory where dump files will be saved (multiple -o can be specified) -x : Dump file prefix. -i : Ingress packet device. -n : Max number of nested dump sub-directories. -m : Max number of files before restarting file name. -p : Max pcap file length (MBytes). -b : Buffer length (MBytes). -C : Size (KB) of the chunk written to disk (must be multiple of 4096). Default: 64 KB. -c : Bind the reader thread to the specified core. -z : Enable multithread compression and/or indexing and bind thread(s) to the specified core ids (e.g. 0,1,2,3) (mandatory with indexing on Napatech cards) -Z : Compute index on the thread(s) used for compression (-z) instead of using the capture thread(s). -w : Bind the writer thread(s) to the specified core ids. A comma-separated list of cores (e.g. 0,1,2,3) should be specified in case of multiple dump directories (-o). -S : Enable time pulse thread (optimise sw packet timestamping) and bind it to the specified core. With this setup I was able to get 70Gb/s. I tested 100Gb/s and got drops. Did not perform further testing to narrow down exactly how much traffic I could push before moving on to the next test. Test 10 I made seven directories, one for each n2disk process. 4 assigned to the NVMe drives and 3 assigned to the SAS SSD RAID I did the following: /opt/napatech3/bin/ntpl -e \"Delete = All\" /opt/napatech3/bin/ntpl -e \"Setup[NumaNode=2] = StreamID == 0\" # Repeat this for each stream ID. In our case 0-6 /opt/napatech3/bin/ntpl -e \"HashMode = Hash2TupleSorted\" /opt/napatech3/bin/ntpl -e \"Assign[StreamId=(0..6)] = port == 0\" ./profiling # use this to see traffic being received # N is the NUMA node that the profiler detects the traffic on watch cat /proc/net/pf_ring/stats/*none* Run the following commands: n2disk -a -v -l -o /data/data0 -x $(date +%s.) -i nt:stream0 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 120 -z 0,4,8,12,16,20,24,28 -Z -w 88,92,96,100,104,108,112,116 -S 32 n2disk -a -v -l -o /data/data1 -x $(date +%s.) -i nt:stream1 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 121 -z 1,5,9,13,17,21,25,29 -Z -w 89,93,97,101,105,109,113,117 -S 33 n2disk -a -v -l -o /data/data2 -x $(date +%s.) -i nt:stream2 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 156 -z 36,40,44,48,52,56,60,64 -Z -w 124,128,132,136,140,144,148,152 -S 68 n2disk -a -v -l -o /data/data3 -x $(date +%s.) -i nt:stream3 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 157 -z 37,41,45,49,53,57,61,65 -Z -w 125,129,133,137,141,145,149,153 -S 69 n2disk -a -v -l -o /raiddata/data0 -x $(date +%s.) -i nt:stream4 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 123 -z 3,7,11,15,19,23,27,31 -Z -w 91,95,99,103,107,111,115,119 -S 35 n2disk -a -v -l -o /raiddata/data1 -x $(date +%s.) -i nt:stream5 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 159 -z 39,43,47,51,55,59,63,67 -Z -w 127,131,135,139,143,147,151,155 -S 71 n2disk -a -v -l -o /raiddata/data2 -x $(date +%s.) -i nt:stream6 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 174 -z 54,58,62,66,70,74,78,82 -Z -w 142,146,150,154,158,162,166,170 -S 86 -a : Archive pcap file (rename to .old) instead of overwriting if already present on disk. -v : Verbose. -o : Directory where dump files will be saved (multiple -o can be specified) -x : Dump file prefix. -i : Ingress packet device. -n : Max number of nested dump sub-directories. -m : Max number of files before restarting file name. -p : Max pcap file length (MBytes). -b : Buffer length (MBytes). -C : Size (KB) of the chunk written to disk (must be multiple of 4096). Default: 64 KB. -c : Bind the reader thread to the specified core. -z : Enable multithread compression and/or indexing and bind thread(s) to the specified core ids (e.g. 0,1,2,3) (mandatory with indexing on Napatech cards) -Z : Compute index on the thread(s) used for compression (-z) instead of using the capture thread(s). -w : Bind the writer thread(s) to the specified core ids. A comma-separated list of cores (e.g. 0,1,2,3) should be specified in case of multiple dump directories (-o). -S : Enable time pulse thread (optimise sw packet timestamping) and bind it to the specified core. With this setup I was able to get 70Gb/s. I tested 100Gb/s and got drops. Did not perform further testing to narrow down exactly how much traffic I could push before moving on to the next test. Compile PF_RING Driver (PROBABLY NOT NECESSARY) NOTE There is a note in the documentation saying that installing from repository comes with NapaTech support. Move to opt run git clone https://github.com/ntop/PF_RING.git Move into the directory and run cd PF_RING/kernel && make && sudo insmod pf_ring.ko Next run cd ../userland/lib && ./configure && make Next run cd ../libpcap && ./configure && make Next run cd ../examples && make","title":"Useful Materials"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#useful-materials","text":"NapaTech Installation Instructions (Creatinga EXT4 Filesystem)[https://thelastmaimou.wordpress.com/2013/05/04/magic-soup-ext4-with-ssd-stripes-and-strides/]","title":"Useful Materials"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#my-environment","text":"I am running a Dell FC640 on a Dell R940 See Server Specs for hardware details.","title":"My Environment"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#hard-drive-layout","text":"I had a RAID of 12 SAS SSDs in RAID0 on the PERC740. I had 7 NVMe drives I used. I couldn't get the 8th NVMe drive working. [root@r940 /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 10.5T 0 disk /raiddata sdb 8:16 0 223.5G 0 disk \u251c\u2500sdb1 8:17 0 200M 0 part /boot/efi \u251c\u2500sdb2 8:18 0 1G 0 part /boot \u2514\u2500sdb3 8:19 0 222.3G 0 part \u251c\u2500centos-root 253:0 0 218.3G 0 lvm / \u2514\u2500centos-swap 253:1 0 4G 0 lvm [SWAP] sdc 8:32 0 59.8G 0 disk nvme0n1 259:6 0 1.5T 0 disk \u2514\u2500nvme0n1p1 259:8 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme1n1 259:0 0 1.5T 0 disk \u2514\u2500nvme1n1p1 259:1 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme2n1 259:2 0 1.5T 0 disk \u2514\u2500nvme2n1p1 259:3 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme3n1 259:4 0 1.5T 0 disk \u2514\u2500nvme3n1p1 259:5 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme4n1 259:10 0 1.5T 0 disk \u2514\u2500nvme4n1p1 259:13 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme5n1 259:11 0 1.5T 0 disk nvme6n1 259:7 0 1.5T 0 disk \u2514\u2500nvme6n1p1 259:9 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data nvme7n1 259:12 0 1.5T 0 disk \u2514\u2500nvme7n1p1 259:14 0 1.5T 0 part \u2514\u2500data-data 253:2 0 10.2T 0 lvm /data [root@r940 /]# pvs PV VG Fmt Attr PSize PFree /dev/nvme0n1p1 data lvm2 a-- <1.46t 0 /dev/nvme1n1p1 data lvm2 a-- <1.46t 0 /dev/nvme2n1p1 data lvm2 a-- <1.46t 0 /dev/nvme3n1p1 data lvm2 a-- <1.46t 0 /dev/nvme4n1p1 data lvm2 a-- <1.46t 0 /dev/nvme6n1p1 data lvm2 a-- <1.46t 0 /dev/nvme7n1p1 data lvm2 a-- <1.46t 0 /dev/sdb3 centos lvm2 a-- <222.31g 0 [root@r940 /]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- <222.31g 0 data 7 1 0 wz--n- <10.19t 0 [root@r940 /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- <218.31g swap centos -wi-ao---- 4.00g data data -wi-ao---- <10.19t WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme1n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 759A1CF7-125F-469B-981E-149EBDBE3456 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme2n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 57898F4D-5B5E-4495-B695-E48EA3FCFA01 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme3n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: DB46E8E3-5E96-4228-A148-E6C8F0187DF4 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme0n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 4066CDE1-E36E-41FB-8277-5E3FFDB55B4A # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme6n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 0360D46A-9A41-4A8D-A449-94CCDC01FA8B # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme4n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: A5D3EDDF-C93D-4B33-92B0-D25B009EEB9D # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM Disk /dev/nvme5n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/nvme7n1: 1600.3 GB, 1600321314816 bytes, 3125627568 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: gpt Disk identifier: 71A0B583-E727-45B6-A1AB-791D341709B6 # Start End Size Type Name 1 2048 3125626879 1.5T Linux LVM Disk /dev/sda: 11515.9 GB, 11515881062400 bytes, 22491955200 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 1048576 bytes / 1048576 bytes WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. Disk /dev/sdb: 240.0 GB, 239990276096 bytes, 468731008 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk label type: gpt Disk identifier: F1E6A9A1-C85F-46C1-A27E-DBC41C9260AC # Start End Size Type Name 1 2048 411647 200M EFI System EFI System Partition 2 411648 2508799 1G Microsoft basic 3 2508800 468729855 222.3G Linux LVM Disk /dev/sdc: 64.2 GB, 64239960064 bytes, 125468672 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/centos-root: 234.4 GB, 234407067648 bytes, 457826304 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk /dev/mapper/centos-swap: 4294 MB, 4294967296 bytes, 8388608 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk /dev/mapper/data-data: 11202.2 GB, 11202210037760 bytes, 21879316480 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 131072 bytes / 917504 bytes","title":"Hard Drive Layout:"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#cpu-layout","text":"[root@r940 data]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 176 On-line CPU(s) list: 0-175 Thread(s) per core: 2 Core(s) per socket: 22 Socket(s): 4 NUMA node(s): 4 Vendor ID: GenuineIntel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz Stepping: 4 CPU MHz: 1394.146 CPU max MHz: 3700.0000 CPU min MHz: 1000.0000 BogoMIPS: 4200.00 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 30976K NUMA node0 CPU(s): 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76,80,84,88,92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 NUMA node1 CPU(s): 1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77,81,85,89,93,97,101,105,109,113,117,121,125,129,133,137,141,145,149,153,157,161,165,169,173 NUMA node2 CPU(s): 2,6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78,82,86,90,94,98,102,106,110,114,118,122,126,130,134,138,142,146,150,154,158,162,166,170,174 NUMA node3 CPU(s): 3,7,11,15,19,23,27,31,35,39,43,47,51,55,59,63,67,71,75,79,83,87,91,95,99,103,107,111,115,119,123,127,131,135,139,143,147,151,155,159,163,167,171,175 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_ppin intel_pt ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke md_clear spec_ctrl intel_stibp flush_l1d [root@r940 data]# cpu_layout.py ====================================================================== Core and Socket Information (as reported by '/sys/devices/system/cpu') ====================================================================== cores = [0, 5, 1, 4, 2, 3, 8, 12, 9, 11, 10, 21, 16, 20, 17, 19, 18, 28, 24, 27, 25, 26] sockets = [0, 1, 2, 3] Socket 0 Socket 1 Socket 2 Socket 3 -------- -------- -------- -------- Core 0 [0, 88] [1, 89] [2, 90] [3, 91] Core 5 [4, 92] [5, 93] [6, 94] [7, 95] Core 1 [8, 96] [9, 97] [10, 98] [11, 99] Core 4 [12, 100] [13, 101] [14, 102] [15, 103] Core 2 [16, 104] [17, 105] [18, 106] [19, 107] Core 3 [20, 108] [21, 109] [22, 110] [23, 111] Core 8 [24, 112] [25, 113] [26, 114] [27, 115] Core 12 [28, 116] [29, 117] [30, 118] [31, 119] Core 9 [32, 120] [33, 121] [34, 122] [35, 123] Core 11 [36, 124] [37, 125] [38, 126] [39, 127] Core 10 [40, 128] [41, 129] [42, 130] [43, 131] Core 21 [44, 132] [45, 133] [46, 134] [47, 135] Core 16 [48, 136] [49, 137] [50, 138] [51, 139] Core 20 [52, 140] [53, 141] [54, 142] [55, 143] Core 17 [56, 144] [57, 145] [58, 146] [59, 147] Core 19 [60, 148] [61, 149] [62, 150] [63, 151] Core 18 [64, 152] [65, 153] [66, 154] [67, 155] Core 28 [68, 156] [69, 157] [70, 158] [71, 159] Core 24 [72, 160] [73, 161] [74, 162] [75, 163] Core 27 [76, 164] [77, 165] [78, 166] [79, 167] Core 25 [80, 168] [81, 169] [82, 170] [83, 171] Core 26 [84, 172] [85, 173] [86, 174] [87, 175]","title":"CPU Layout"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#centos-7-release-info","text":"NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core)","title":"CentOS 7 Release Info"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#kernel-info","text":"Linux r940.lan 3.10.0-1062.4.3.el7.x86_64 #1 SMP Wed Nov 13 23:58:53 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux","title":"Kernel Info"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#format-your-data-partitions","text":"Create physical volumes and volume groups with: pvcreate <NVMe drive> vgcreate data <List of NVMe Drives> NOTE: I only did this on the NVMe drives. To create the logical volume I used: lvcreate -l 100%FREE -i7 -I128 -n data data To format the drive I used: mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 # This was the 12 SAS SSDs I had in a RAID mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 /dev/mapper/data-data # This was the NVMes I tied together with LVM mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 /dev/mapper/data2-data2 mount -o rw,auto,discard /dev/mapper/data-data /data mount -o rw,auto,discard /dev/sda /raiddata/ mount -o rw,auto,discard /dev/mapper/data2-data2 /data2 echo noop > /sys/block/sda/queue/scheduler","title":"Format Your Data Partitions"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#install-napatech-driver","text":"","title":"Install NapaTech Driver"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#install-driver","text":"Download the Napatech software from here Run yum groupinstall \"Development Tools\" && yum install -y kernel-devel wget gettext-devel openssl-devel perl-CPAN perl-devel zlib-devel pciutils && yum install -y https://centos7.iuscommunity.org/ius-release.rpm && yum remove -y git && yum install -y git2u-all Unzip and run package_install_3gd.sh Run the following commands: /opt/napatech3/bin/ntload.sh /opt/napatech3/bin/ntstart.sh","title":"Install Driver"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#install-n2disk-and-ntop","text":"","title":"Install n2disk and ntop"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#perform-installation","text":"Install epel with yum install -y epel-release Erase the zeromq3 package with yum erase zeromq && yum clean all && yum update -y && reboot Pull ntop repo with wget http://packages.ntop.org/centos-stable/ntop.repo -O /etc/yum.repos.d/ntop.repo Install required packages with yum install -y pfring-dkms pfring n2disk nprobe ntopng ntopng-data cento pfring-drivers-zc-dkms redis hiredis-devel","title":"Perform Installation"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#configure-n2disk","text":"Create backup of the the NapaTech ini file cp /opt/napatech3/config/ntservice.ini /opt/napatech3/config/ntservice.ini.bak Update /opt/napatech3/config/ntservice.ini with the following values: TimestampFormat = PCAP_NS PacketDescriptor = PCAP HostBufferSegmentSizeRx = 4 TODO change these lines see notes for help HostBuffersRx = [16,16,0],[16,16,1] HostBuffersTx = [16,16,0],[16,16,1] You will need to start and stop the ntservice for these changes to take effect with: /opt/napatech3/bin/ntstop.sh /opt/napatech3/bin/ntstart.sh","title":"Configure n2disk"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#perform-configuration-zero-copy-driver","text":"Edit the pfring configuration file with vim /etc/pf_ring/interfaces.conf and add your configuration. MANAGEMENT_INTERFACES=\"em1\" CAPTURE_INTERFACES=\"nt:0\" Open the file /etc/ntopng/ntopng.conf . If you do not have a license add --community to the end Configure the firewall to accept connections to ntopng with: firewall-cmd --zone=public --permanent --add-port=3000/tcp && firewall-cmd --reload Enable and start services with: systemctl enable redis.service systemctl enable ntopng.service systemctl enable pf_ring systemctl start redis.service systemctl start ntopng.service systemctl start pf_ring Make sure the services are running correctly with: systemctl status redis.service systemctl status ntopng.service systemctl status pf_ring","title":"Perform Configuration Zero Copy Driver"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#configure-license","text":"Run zcount -i nt:0 and note the serial number Output n2disk license to /etc/n2disk.license Output ntopng license to /etc/ntopng.license","title":"Configure License"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#useful-tips","text":"","title":"Useful Tips"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#hardware-filtering","text":"Napatech NICs support full-blown hardware filtering out of the box. Thanks to nBPF we convert BPF expressions to hardware filters. This feature is supported transparently, and thus all PF_RING/libpcap-over-PF_RING can benefit from it. Example: pfcount -i nt:3 -f \"tcp and port 80 and src host 192.168.1.1\"","title":"Hardware Filtering"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#hostbuffer-notes","text":"HostBuffersRx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] HostBuffersTx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] First number is the number of host buffers Second number is the size of the host buffers Third number is the NUMA node You have to have one set of numbers for each NUMA node.","title":"Hostbuffer Notes"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#testing-transmit-speed","text":"./pktgen -p 1 -r 10G","title":"Testing Transmit Speed"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#testing-the-pcap-transmit-speed","text":"To test to see if the Napatech card is up and running run this command: ./pfcount -i nt:0 ./monitoring You can press t to switch stats between receive and transmit.","title":"Testing the PCAP transmit speed"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#testing-receive","text":"chmod -R 777 /data rm /tmp/*-none\\.* 2>/dev/null; while true; do grep 'Dropped:\\|Slow.*:' -C50 /proc/net/pf_ring/stats/* 2>/dev/null; cp /proc/net/pf_ring/stats/*none* /tmp 2>/dev/null; sleep 1; done","title":"Testing Receive"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#numa-lookup","text":"Run lscpu","title":"NUMA Lookup"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#things-we-tried","text":"We used the to list the cpu layout and determine where we wanted to run what threads. Tests 1-6 were with the default settings for a RAID0 partition on Linux at setup time.","title":"Things we tried:"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-1","text":"This is running at 100Gb/s generation n2disk -a -v -l -o /<Storage path> -x $(date +%s.) -i nt:0 This seemed to dump everything to one thread. We maxed out and had ~82% packet loss.","title":"Test 1"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-2","text":"This is running at 100Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 32 -z 2,3,4,5,6,7 -Z -w 16,17,18,19,20,20,21 -S 22 Throughput results: [root@r940 bin]# cat /proc/net/pf_ring/stats/*none* Duration: 0:00:00:53:022 Throughput: 2.12 Mpps 17.65 Gbps Packets: 78780625 Filtered: 78780625 Dropped: 518512807 Bytes: 81931850000 DumpedBytes: 71137406724 DumpedFiles: 17 SlowSlavesLoops: 0 SlowStorageLoops: 432580 CaptureLoops: 19532 FirstDumpedEpoch: 0 LastDumpedEpoch: 1574185087 Worked better but we got a warning saying the time thread was on a different core than the reader/writer threads.","title":"Test 2"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-3","text":"This is running at 100Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 32 -z 2,3,4,5,6,7 -Z -w 16,17,18,19,20,20,21 -S 56 Worked better: 19/Nov/2019 12:41:59 [n2disk.c:1109] Average Capture Throughput: 22.49 Gbit / 2.69 Mpps","title":"Test 3"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-4","text":"This is running at 100Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4","title":"Test 4"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-5","text":"This is running at 20Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 Failed. We got a lot of packet loss.","title":"Test 5"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-6","text":"This is running at 10Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 No packet drops.","title":"Test 6"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-7","text":"This is running at 20Gb/s generation n2disk -a -v -l -o /data/ -x $(date +%s.) -i nt:0 -n 5000 -m 10000 -p $((4*1024)) -b $((12*1024)) -C 4096 -c 0 -z 8,12,16,20,24,28,32,26,40,44,48,52,56,60,64,68,72,76,80,84,88 -Z -w 92,96,100,104,108,112,116,120,124,128,132,136,140,144,148,152,156,160,164,168,172 -S 4 This was with a data partition formatting according to the above.","title":"Test 7"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-8","text":"/opt/napatech3/bin/ntpl -e \"Delete = All\" /opt/napatech3/bin/ntpl -e \"Setup[NumaNode=2] = StreamID == 0\" # Repeat this for each stream ID. In our case 0-4 ./profiling # use this to see traffic being received # N is the NUMA node that the profiler detects the traffic on /opt/napatech3/bin/ntpl -e \"HashMode = Hash2TupleSorted\" /opt/napatech3/bin/ntpl -e \"Assign[StreamId=(0..3)] = port == 0\" The problem with this was that we couldn't get n2disk to listen on multiple interfaces. It also didn't really give us a way to split the traffic across multiple reader threads.","title":"Test 8"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-9","text":"I made four directories, one for each n2disk process I did the following: /opt/napatech3/bin/ntpl -e \"Delete = All\" /opt/napatech3/bin/ntpl -e \"Setup[NumaNode=2] = StreamID == 0\" # Repeat this for each stream ID. In our case 0-4 /opt/napatech3/bin/ntpl -e \"HashMode = Hash2TupleSorted\" /opt/napatech3/bin/ntpl -e \"Assign[StreamId=(0..3)] = port == 0\" ./profiling # use this to see traffic being received # N is the NUMA node that the profiler detects the traffic on Run the following commands: n2disk -a -v -l -o /data/data0 -x $(date +%s.) -i nt:stream0 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 120 -z 0,4,8,12,16,20,24,28 -Z -w 88,92,96,100,104,108,112,116 -S 32 n2disk -a -v -l -o /data/data1 -x $(date +%s.) -i nt:stream1 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 121 -z 1,5,9,13,17,21,25,29 -Z -w 89,93,97,101,105,109,113,117 -S 33 n2disk -a -v -l -o /data/data2 -x $(date +%s.) -i nt:stream2 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 156 -z 36,40,44,48,52,56,60,64 -Z -w 124,128,132,136,140,144,148,152 -S 68 n2disk -a -v -l -o /data/data3 -x $(date +%s.) -i nt:stream3 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 157 -z 37,41,45,49,53,57,61,65 -Z -w 125,129,133,137,141,145,149,153 -S 69 -a : Archive pcap file (rename to .old) instead of overwriting if already present on disk. -v : Verbose. -o : Directory where dump files will be saved (multiple -o can be specified) -x : Dump file prefix. -i : Ingress packet device. -n : Max number of nested dump sub-directories. -m : Max number of files before restarting file name. -p : Max pcap file length (MBytes). -b : Buffer length (MBytes). -C : Size (KB) of the chunk written to disk (must be multiple of 4096). Default: 64 KB. -c : Bind the reader thread to the specified core. -z : Enable multithread compression and/or indexing and bind thread(s) to the specified core ids (e.g. 0,1,2,3) (mandatory with indexing on Napatech cards) -Z : Compute index on the thread(s) used for compression (-z) instead of using the capture thread(s). -w : Bind the writer thread(s) to the specified core ids. A comma-separated list of cores (e.g. 0,1,2,3) should be specified in case of multiple dump directories (-o). -S : Enable time pulse thread (optimise sw packet timestamping) and bind it to the specified core. With this setup I was able to get 70Gb/s. I tested 100Gb/s and got drops. Did not perform further testing to narrow down exactly how much traffic I could push before moving on to the next test.","title":"Test 9"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#test-10","text":"I made seven directories, one for each n2disk process. 4 assigned to the NVMe drives and 3 assigned to the SAS SSD RAID I did the following: /opt/napatech3/bin/ntpl -e \"Delete = All\" /opt/napatech3/bin/ntpl -e \"Setup[NumaNode=2] = StreamID == 0\" # Repeat this for each stream ID. In our case 0-6 /opt/napatech3/bin/ntpl -e \"HashMode = Hash2TupleSorted\" /opt/napatech3/bin/ntpl -e \"Assign[StreamId=(0..6)] = port == 0\" ./profiling # use this to see traffic being received # N is the NUMA node that the profiler detects the traffic on watch cat /proc/net/pf_ring/stats/*none* Run the following commands: n2disk -a -v -l -o /data/data0 -x $(date +%s.) -i nt:stream0 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 120 -z 0,4,8,12,16,20,24,28 -Z -w 88,92,96,100,104,108,112,116 -S 32 n2disk -a -v -l -o /data/data1 -x $(date +%s.) -i nt:stream1 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 121 -z 1,5,9,13,17,21,25,29 -Z -w 89,93,97,101,105,109,113,117 -S 33 n2disk -a -v -l -o /data/data2 -x $(date +%s.) -i nt:stream2 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 156 -z 36,40,44,48,52,56,60,64 -Z -w 124,128,132,136,140,144,148,152 -S 68 n2disk -a -v -l -o /data/data3 -x $(date +%s.) -i nt:stream3 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 157 -z 37,41,45,49,53,57,61,65 -Z -w 125,129,133,137,141,145,149,153 -S 69 n2disk -a -v -l -o /raiddata/data0 -x $(date +%s.) -i nt:stream4 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 123 -z 3,7,11,15,19,23,27,31 -Z -w 91,95,99,103,107,111,115,119 -S 35 n2disk -a -v -l -o /raiddata/data1 -x $(date +%s.) -i nt:stream5 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 159 -z 39,43,47,51,55,59,63,67 -Z -w 127,131,135,139,143,147,151,155 -S 71 n2disk -a -v -l -o /raiddata/data2 -x $(date +%s.) -i nt:stream6 -n 5000 -m 10000 -p $((20*1024)) -b $((40*1024)) -C 4096 -c 174 -z 54,58,62,66,70,74,78,82 -Z -w 142,146,150,154,158,162,166,170 -S 86 -a : Archive pcap file (rename to .old) instead of overwriting if already present on disk. -v : Verbose. -o : Directory where dump files will be saved (multiple -o can be specified) -x : Dump file prefix. -i : Ingress packet device. -n : Max number of nested dump sub-directories. -m : Max number of files before restarting file name. -p : Max pcap file length (MBytes). -b : Buffer length (MBytes). -C : Size (KB) of the chunk written to disk (must be multiple of 4096). Default: 64 KB. -c : Bind the reader thread to the specified core. -z : Enable multithread compression and/or indexing and bind thread(s) to the specified core ids (e.g. 0,1,2,3) (mandatory with indexing on Napatech cards) -Z : Compute index on the thread(s) used for compression (-z) instead of using the capture thread(s). -w : Bind the writer thread(s) to the specified core ids. A comma-separated list of cores (e.g. 0,1,2,3) should be specified in case of multiple dump directories (-o). -S : Enable time pulse thread (optimise sw packet timestamping) and bind it to the specified core. With this setup I was able to get 70Gb/s. I tested 100Gb/s and got drops. Did not perform further testing to narrow down exactly how much traffic I could push before moving on to the next test.","title":"Test 10"},{"location":"High%20Speed%20Packet%20Capture/ntop%20on%20R940%20with%20Napatech/#compile-pf_ring-driver-probably-not-necessary","text":"NOTE There is a note in the documentation saying that installing from repository comes with NapaTech support. Move to opt run git clone https://github.com/ntop/PF_RING.git Move into the directory and run cd PF_RING/kernel && make && sudo insmod pf_ring.ko Next run cd ../userland/lib && ./configure && make Next run cd ../libpcap && ./configure && make Next run cd ../examples && make","title":"Compile PF_RING Driver (PROBABLY NOT NECESSARY)"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/","text":"How Bitcoin-Blockchain Works - Notes How Bitcoin-Blockchain Works - Notes Helpful Resources Azure Solution with Active Directory Bitcoin Unspent Transaction Output (UTXO) Blockchain What does each block have What is a permissionless blockchain? Consensus Algorithm What is a permissions blockchain? What is a block Genesis Block Creating a new transaction Khan Academy Notes Bitcoin What is It Bitcoin: Overview Bitcoin: Cryptographic Hash Functions Bitcoin: Digital Signatures Bitcoin: Transaction records Bitcoin: Proof of Work Bitcoin: Transaction Block Chains Bitcoin: The Bitcoin Money Supply Bitcoin: The security of transaction block chains Using Blockchain for Voting How the Keys are Generated Helpful Resources IBM Lecture: https://mediacenter.ibm.com/media/Blockchain%20Explained/1_e34h0ey8 The Bitcoin Protocol Explained: How it Actually Works: https://komodoplatform.com/en/academy/bitcoin-protocol/ Blockchain Learning Resources: https://github.com/mikeroyal/Blockchain-Guide Demo of Azure Solution: https://learn.microsoft.com/en-us/shows/azure-friday/issue-and-accept-verifiable-credentials-using-azure-active-directory?culture=en-us&country=US OpenID Connect: https://openid.net/connect/ Khan Academy Video Series: https://www.khanacademy.org/economics-finance-domain/core-finance/money-and-banking/bitcoin/v/bitcoin-what-is-it Follow My Vote (Blockchain used for voting): https://github.com/FollowMyVote Why Using Bitcoin/Blockchain for Voting is a Bad Idea: https://www.coindesk.com/tech/2020/11/16/new-mit-paper-roundly-rejects-blockchain-voting-as-solution-to-election-woes/ MIT Paper on Why Bitcoin/Blockchain is Bad for Voting: link Azure Solution with Active Directory See https://learn.microsoft.com/en-us/shows/azure-friday/issue-and-accept-verifiable-credentials-using-azure-active-directory?culture=en-us&country=US Under the hood, when a 3rd party attempts to validate a credential it is using OpenID connect. Microsoft created a client API where a single API call will allow you to validate user credentials. The return URL shown above is what is encoded in the QR code the person scans. The way this will work with an app is that the app (like authenticator in this case) can register itself as the protocol handler so whenever someone scans something with their camera it will automatically open with that app. Bitcoin Unspent Transaction Output (UTXO) See: https://komodoplatform.com/en/academy/bitcoin-protocol/ Blockchain What does each block have A hash A list of transactions that have occurred on that block Previous block's hash What is a permissionless blockchain? These are what is used by cryptocurrencies. Everyone can see all transactions that have ever taken place. You will see the transactions by each person's address. Any time it gets updated and new transactions are made you get a new block. Consensus Algorithm You have all these transactions coming in how do you decide which transactions will make up the next block. A client will first submit a transaction and that transaction will join a list of other transactions that have been made on the network. A node will start picking up the transactions, look through all the previous transactions on the blockchain and know those are valid. It will kind of emulate a block and then start a proof of work algorithm. The proof of work algorithm is a complex crypto-hash algorithm everyone works together to solve. Once one node resolves it, it will broadcast the position of that next block to all the other nodes in the network. What is a permissioned blockchain? There is an idea called pluggable consensus algorithms. You can use this when the nodes in the blockchain are trusted. In addition, the nodes may not be just users but entire organizations. Privacy here is important. Scenario: You have a retailer who buys 100 pounds of something at $1000. Then you have a shipper who wants $100 for shipping. The shipper should know when the order was placed, for what, and how much they charged, but they wouldn't know how much the total original cost was. Smart contracts: This allows you to do something like make sure the warehouse has enough goods at the manufacturer, the retailer has enough money to pay the shipper, and you can take automated action (like refunding money when goods aren't available) based on this information. What is a block From: https://followmyvote.com/blockchain-technology/ The blockchain further requires that an audit trail of all changes to the database is preserved, which allows anyone to audit that the database is correct at any time. This audit trail is composed to the individual changes to the database, which are called transactions. A group of transactions which were all added by a single node on its turn is called a block. Each block contains a reference to the block which preceded it, which establishes an ordering of the blocks. This is the origin of the term \u201cblockchain\u201d: it is a chain of blocks, each one containing a link to the previous block and a list of new transactions since that previous block. Genesis Block An empty block that is the beginning of the block chain. Creating a new transaction From: https://followmyvote.com/blockchain-technology/ The most obvious example of blockchain technology in use today is Bitcoin. Bitcoin is a digital currency system which uses a blockchain to keep track of ownership of the currency. Whenever someone wishes to spend their bitcoins, they create a transaction which states that they are sending a certain number of their bitcoins to someone else. Then they digitally sign this transaction to authorize it, and broadcast it to all of the nodes in the Bitcoin network. When the next node creates a block, it will check that the new transaction is valid, and include it in the new block, which is then propagated to all other nodes in the network, which adjust their databases to deduct the transferred bitcoins from the sender and credit them to the recipient. Khan Academy Notes Bitcoin What is It Bitcoin transactions can use a thick client or a 3rd party service. Bitcoin: Overview Transactions are tracked on the global ledger Transaction fees are used to motivated other nodes to validate the transaction To create the transaction, person 1 signs with private key and broadcasts the details of the transaction to other nodes How we avoid the double spending problem: We use bitcoin miners. They take all the transactions we see, take those transactions and compile them into a transaction block. This is like the entire page of a ledger block. The miners will include in the block an additional transaction which gives themselves a reward for completing this mining task. The miner will also include a proof of work (some sort of hash problem but he hasn't gotten to that) The transaction block will have a hash of the block's transactions / the hash of the previous block. This is what creates the chain. As soon as a node finishes creating the transaction block, it broadcasts it. The nodes will only consider the longest block chain - that is to say, the node with the most work which has been accomplished Bitcoin: Cryptographic Hash Functions Properties of cryptographic hash functions Computationally efficient Hard to find hash collision (colision resistant) Hide information about the original input Output should be well distributed Bitcoin: Digital Signatures Private key may also be referred to as signing key (SK) and public key can be verification key (VK) Usually you will hash then sign the message Bitcoin: Transaction records A transaction is just one party's intent to transfer some of their bitcoins to another party You can verify that a party possesses the Bitcoins they say they possess by searching for transactions showing that the party in question received that quantity of bitcoins See UTXO for a description of how transactions really work under the hood The idea here is that for each UTXO, there is a message digest of those transaction records and anyone can check those message digests and that the target was indeed the recipient In the case of a new transaction, the sender will create new transactions and then sign all of them with the private key. This will also include the transaction fees. If there is a double spend, remember that the order of transactions is included in the ledger which will prevent someone from committing a double spend to the ledger (because it would become obvious to the calculating node they have insufficient funds) Bitcoin: Proof of Work Other uses of Proof of Work: preventing DOS or SPAM In general, they begin with a challenge string (c) In the case of SPAM it might be an e-mail message In response there is a response or proof response (p) In example of the challenge might be to combine the challenge string and the response string such that a hash output of the two has a fixed number of leading zeros and then the other bits are whatever you want. If you said you want 40 bits of leading zeros this would require effectively 2^40 consecutive heads coin flips. If you want to increase the difficulty, you can simply require more leading zeros effectively doubling the effort. Someone just has to find the proof string to prove they have done the work. Bitcoin: Transaction Block Chains Nodes (Bitcoin miners) will take all these transactions they have received that have not yet been registered in the block chain. The first thing they will do is collate all these transactions. What they will do is take all the transactions they have collected and split them up into pairs. Then they will hash each pair, then take the hashes of the pairs, hash those, and so on and so forth until they have a single value. Ex: Then, they will combine that hash with the hash of the previous block in the blockchain. Then, after the node has created the new blockchain including their new block, they will take all that and hash it into the challenge as mentioned in Bitcoin: Proof of Work . Then, they must generate the proof, which when hashed will have some fixed number of leading zeros. The Bitcoin protocol is designed such that the average time to creating a new block is about every ten minutes The reward for miners is that in the first transaction block, they are allowed to insert a reward for themselves. This first transaction record's reward will change over time. These are called coinbase generation. This is how new coins are generated and placed into the system. In addition to the coinbase reward, you also get all the transaction fees. If there is a tie, then the chain with the most amount of work is selected Bitcoin: The Bitcoin Money Supply The bitcoin system is designed such that the maximum number of coins is 21,000,000 BTC The smallest possible bitcoin is .00000001 BTC called a Satoshi Bitcoin started around Jan 2009 and the first reward was 50 BTC After about 210,000 blocks the reward halves. This takes approximately 4 years. Around 2140 the entire Bitcoin supply will have been generated For every 2,016 blocks, the network estimates the amount of time it took to generate the blocks. It should take about two weeks. If it took far less time, than the protocol will make things harder and on the flip side it will make it easier This works out to about every 10 minutes per block. It may seem like all nodes are simultaneously working on many of the same transactions. While this may be true, recall that each node inserts its own transaction to reward itself with the coinbase transaction and that transaction includes information unique to the node. Subsequently each node has a different challenge string. Bitcoin: The security of transaction block chains TLDR: It's a synopsis of the other sections. You would have to fork the chain, add your own new block, plus add other blocks to make their chain longer, such that they then have the chain with the most work. Effectively, you would need at least 51% of the compute power in the network Using Blockchain for Voting From https://followmyvote.com/blockchain-technology/ Another application for blockchain technology is voting. By casting votes as transactions, we can create a blockchain which keeps track of the tallies of the votes. This way, everyone can agree on the final count because they can count the votes themselves, and because of the blockchain audit trail, they can verify that no votes were changed or removed, and no illegitimate votes were added. From: https://followmyvote.com/cryptographically-secure-voting-2/ How the Keys are Generated From: https://followmyvote.com/elliptic-curve-cryptography/ At Follow My Vote, we use this technology to create votes. During the registration process, voters create two ECC key-pairs. The voter reveals her identity to a verifier, who certifies the first key-pair (the identity key-pair) as belonging to that voter, then the voter anonymously registers her second key-pair (the voting key-pair) as belonging to one of the identity keys, but the way this is done, no one can determine which identity key owns her voting key. She can then create transactions which state her votes on the contests in an election, and use her voting private key to sign those transactions. Once these are published, everyone participating in the Follow My Vote network can verify that the signature is valid and adjust the tally accordingly. This way the votes are public and anonymous, but each voter can verify that her vote was correctly recorded and counted. Furthermore, all participants can verify that none of the votes were tampered with by validating the signatures. In this way, Follow My Vote software performs transparent, end-to-end verifiable online elections without compromising on security or voter anonymity.","title":"How Bitcoin-Blockchain Works - Notes"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#how-bitcoin-blockchain-works-notes","text":"How Bitcoin-Blockchain Works - Notes Helpful Resources Azure Solution with Active Directory Bitcoin Unspent Transaction Output (UTXO) Blockchain What does each block have What is a permissionless blockchain? Consensus Algorithm What is a permissions blockchain? What is a block Genesis Block Creating a new transaction Khan Academy Notes Bitcoin What is It Bitcoin: Overview Bitcoin: Cryptographic Hash Functions Bitcoin: Digital Signatures Bitcoin: Transaction records Bitcoin: Proof of Work Bitcoin: Transaction Block Chains Bitcoin: The Bitcoin Money Supply Bitcoin: The security of transaction block chains Using Blockchain for Voting How the Keys are Generated","title":"How Bitcoin-Blockchain Works - Notes"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#helpful-resources","text":"IBM Lecture: https://mediacenter.ibm.com/media/Blockchain%20Explained/1_e34h0ey8 The Bitcoin Protocol Explained: How it Actually Works: https://komodoplatform.com/en/academy/bitcoin-protocol/ Blockchain Learning Resources: https://github.com/mikeroyal/Blockchain-Guide Demo of Azure Solution: https://learn.microsoft.com/en-us/shows/azure-friday/issue-and-accept-verifiable-credentials-using-azure-active-directory?culture=en-us&country=US OpenID Connect: https://openid.net/connect/ Khan Academy Video Series: https://www.khanacademy.org/economics-finance-domain/core-finance/money-and-banking/bitcoin/v/bitcoin-what-is-it Follow My Vote (Blockchain used for voting): https://github.com/FollowMyVote Why Using Bitcoin/Blockchain for Voting is a Bad Idea: https://www.coindesk.com/tech/2020/11/16/new-mit-paper-roundly-rejects-blockchain-voting-as-solution-to-election-woes/ MIT Paper on Why Bitcoin/Blockchain is Bad for Voting: link","title":"Helpful Resources"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#azure-solution-with-active-directory","text":"See https://learn.microsoft.com/en-us/shows/azure-friday/issue-and-accept-verifiable-credentials-using-azure-active-directory?culture=en-us&country=US Under the hood, when a 3rd party attempts to validate a credential it is using OpenID connect. Microsoft created a client API where a single API call will allow you to validate user credentials. The return URL shown above is what is encoded in the QR code the person scans. The way this will work with an app is that the app (like authenticator in this case) can register itself as the protocol handler so whenever someone scans something with their camera it will automatically open with that app.","title":"Azure Solution with Active Directory"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin","text":"","title":"Bitcoin"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#unspent-transaction-output-utxo","text":"See: https://komodoplatform.com/en/academy/bitcoin-protocol/","title":"Unspent Transaction Output (UTXO)"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#blockchain","text":"","title":"Blockchain"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#what-does-each-block-have","text":"A hash A list of transactions that have occurred on that block Previous block's hash","title":"What does each block have"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#what-is-a-permissionless-blockchain","text":"These are what is used by cryptocurrencies. Everyone can see all transactions that have ever taken place. You will see the transactions by each person's address. Any time it gets updated and new transactions are made you get a new block.","title":"What is a permissionless blockchain?"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#consensus-algorithm","text":"You have all these transactions coming in how do you decide which transactions will make up the next block. A client will first submit a transaction and that transaction will join a list of other transactions that have been made on the network. A node will start picking up the transactions, look through all the previous transactions on the blockchain and know those are valid. It will kind of emulate a block and then start a proof of work algorithm. The proof of work algorithm is a complex crypto-hash algorithm everyone works together to solve. Once one node resolves it, it will broadcast the position of that next block to all the other nodes in the network.","title":"Consensus Algorithm"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#what-is-a-permissioned-blockchain","text":"There is an idea called pluggable consensus algorithms. You can use this when the nodes in the blockchain are trusted. In addition, the nodes may not be just users but entire organizations. Privacy here is important. Scenario: You have a retailer who buys 100 pounds of something at $1000. Then you have a shipper who wants $100 for shipping. The shipper should know when the order was placed, for what, and how much they charged, but they wouldn't know how much the total original cost was. Smart contracts: This allows you to do something like make sure the warehouse has enough goods at the manufacturer, the retailer has enough money to pay the shipper, and you can take automated action (like refunding money when goods aren't available) based on this information.","title":"What is a permissioned blockchain?"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#what-is-a-block","text":"From: https://followmyvote.com/blockchain-technology/ The blockchain further requires that an audit trail of all changes to the database is preserved, which allows anyone to audit that the database is correct at any time. This audit trail is composed to the individual changes to the database, which are called transactions. A group of transactions which were all added by a single node on its turn is called a block. Each block contains a reference to the block which preceded it, which establishes an ordering of the blocks. This is the origin of the term \u201cblockchain\u201d: it is a chain of blocks, each one containing a link to the previous block and a list of new transactions since that previous block.","title":"What is a block"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#genesis-block","text":"An empty block that is the beginning of the block chain.","title":"Genesis Block"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#creating-a-new-transaction","text":"From: https://followmyvote.com/blockchain-technology/ The most obvious example of blockchain technology in use today is Bitcoin. Bitcoin is a digital currency system which uses a blockchain to keep track of ownership of the currency. Whenever someone wishes to spend their bitcoins, they create a transaction which states that they are sending a certain number of their bitcoins to someone else. Then they digitally sign this transaction to authorize it, and broadcast it to all of the nodes in the Bitcoin network. When the next node creates a block, it will check that the new transaction is valid, and include it in the new block, which is then propagated to all other nodes in the network, which adjust their databases to deduct the transferred bitcoins from the sender and credit them to the recipient.","title":"Creating a new transaction"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#khan-academy-notes","text":"","title":"Khan Academy Notes"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-what-is-it","text":"Bitcoin transactions can use a thick client or a 3rd party service.","title":"Bitcoin What is It"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-overview","text":"Transactions are tracked on the global ledger Transaction fees are used to motivated other nodes to validate the transaction To create the transaction, person 1 signs with private key and broadcasts the details of the transaction to other nodes How we avoid the double spending problem: We use bitcoin miners. They take all the transactions we see, take those transactions and compile them into a transaction block. This is like the entire page of a ledger block. The miners will include in the block an additional transaction which gives themselves a reward for completing this mining task. The miner will also include a proof of work (some sort of hash problem but he hasn't gotten to that) The transaction block will have a hash of the block's transactions / the hash of the previous block. This is what creates the chain. As soon as a node finishes creating the transaction block, it broadcasts it. The nodes will only consider the longest block chain - that is to say, the node with the most work which has been accomplished","title":"Bitcoin: Overview"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-cryptographic-hash-functions","text":"Properties of cryptographic hash functions Computationally efficient Hard to find hash collision (colision resistant) Hide information about the original input Output should be well distributed","title":"Bitcoin: Cryptographic Hash Functions"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-digital-signatures","text":"Private key may also be referred to as signing key (SK) and public key can be verification key (VK) Usually you will hash then sign the message","title":"Bitcoin: Digital Signatures"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-transaction-records","text":"A transaction is just one party's intent to transfer some of their bitcoins to another party You can verify that a party possesses the Bitcoins they say they possess by searching for transactions showing that the party in question received that quantity of bitcoins See UTXO for a description of how transactions really work under the hood The idea here is that for each UTXO, there is a message digest of those transaction records and anyone can check those message digests and that the target was indeed the recipient In the case of a new transaction, the sender will create new transactions and then sign all of them with the private key. This will also include the transaction fees. If there is a double spend, remember that the order of transactions is included in the ledger which will prevent someone from committing a double spend to the ledger (because it would become obvious to the calculating node they have insufficient funds)","title":"Bitcoin: Transaction records"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-proof-of-work","text":"Other uses of Proof of Work: preventing DOS or SPAM In general, they begin with a challenge string (c) In the case of SPAM it might be an e-mail message In response there is a response or proof response (p) In example of the challenge might be to combine the challenge string and the response string such that a hash output of the two has a fixed number of leading zeros and then the other bits are whatever you want. If you said you want 40 bits of leading zeros this would require effectively 2^40 consecutive heads coin flips. If you want to increase the difficulty, you can simply require more leading zeros effectively doubling the effort. Someone just has to find the proof string to prove they have done the work.","title":"Bitcoin: Proof of Work"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-transaction-block-chains","text":"Nodes (Bitcoin miners) will take all these transactions they have received that have not yet been registered in the block chain. The first thing they will do is collate all these transactions. What they will do is take all the transactions they have collected and split them up into pairs. Then they will hash each pair, then take the hashes of the pairs, hash those, and so on and so forth until they have a single value. Ex: Then, they will combine that hash with the hash of the previous block in the blockchain. Then, after the node has created the new blockchain including their new block, they will take all that and hash it into the challenge as mentioned in Bitcoin: Proof of Work . Then, they must generate the proof, which when hashed will have some fixed number of leading zeros. The Bitcoin protocol is designed such that the average time to creating a new block is about every ten minutes The reward for miners is that in the first transaction block, they are allowed to insert a reward for themselves. This first transaction record's reward will change over time. These are called coinbase generation. This is how new coins are generated and placed into the system. In addition to the coinbase reward, you also get all the transaction fees. If there is a tie, then the chain with the most amount of work is selected","title":"Bitcoin: Transaction Block Chains"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-the-bitcoin-money-supply","text":"The bitcoin system is designed such that the maximum number of coins is 21,000,000 BTC The smallest possible bitcoin is .00000001 BTC called a Satoshi Bitcoin started around Jan 2009 and the first reward was 50 BTC After about 210,000 blocks the reward halves. This takes approximately 4 years. Around 2140 the entire Bitcoin supply will have been generated For every 2,016 blocks, the network estimates the amount of time it took to generate the blocks. It should take about two weeks. If it took far less time, than the protocol will make things harder and on the flip side it will make it easier This works out to about every 10 minutes per block. It may seem like all nodes are simultaneously working on many of the same transactions. While this may be true, recall that each node inserts its own transaction to reward itself with the coinbase transaction and that transaction includes information unique to the node. Subsequently each node has a different challenge string.","title":"Bitcoin: The Bitcoin Money Supply"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#bitcoin-the-security-of-transaction-block-chains","text":"TLDR: It's a synopsis of the other sections. You would have to fork the chain, add your own new block, plus add other blocks to make their chain longer, such that they then have the chain with the most work. Effectively, you would need at least 51% of the compute power in the network","title":"Bitcoin: The security of transaction block chains"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#using-blockchain-for-voting","text":"From https://followmyvote.com/blockchain-technology/ Another application for blockchain technology is voting. By casting votes as transactions, we can create a blockchain which keeps track of the tallies of the votes. This way, everyone can agree on the final count because they can count the votes themselves, and because of the blockchain audit trail, they can verify that no votes were changed or removed, and no illegitimate votes were added. From: https://followmyvote.com/cryptographically-secure-voting-2/","title":"Using Blockchain for Voting"},{"location":"How%20Bitcoin-Blockchain%20Works%20-%20Notes/#how-the-keys-are-generated","text":"From: https://followmyvote.com/elliptic-curve-cryptography/ At Follow My Vote, we use this technology to create votes. During the registration process, voters create two ECC key-pairs. The voter reveals her identity to a verifier, who certifies the first key-pair (the identity key-pair) as belonging to that voter, then the voter anonymously registers her second key-pair (the voting key-pair) as belonging to one of the identity keys, but the way this is done, no one can determine which identity key owns her voting key. She can then create transactions which state her votes on the contests in an election, and use her voting private key to sign those transactions. Once these are published, everyone participating in the Follow My Vote network can verify that the signature is valid and adjust the tally accordingly. This way the votes are public and anonymous, but each voter can verify that her vote was correctly recorded and counted. Furthermore, all participants can verify that none of the votes were tampered with by validating the signatures. In this way, Follow My Vote software performs transparent, end-to-end verifiable online elections without compromising on security or voter anonymity.","title":"How the Keys are Generated"},{"location":"How%20OS10%20Installer%20Works/","text":"How OS10 Installer Works The OS10 installer is a binary file with a bash stub: #!/bin/sh ####################################################################### # Dell OS10 Installer ####################################################################### ####################################################################### # OS10 Data export OS_NAME=\"Dell EMC Networking OS10 Enterprise\" export OS_VERSION=\"10.5.2.7\" export PLATFORM=\"generic-x86_64\" export ARCHITECTURE=\"x86_64\" export INTERNAL_BUILD_ID=\"Dell EMC OS10 Enterprise Edition Blueprint 1.0.0\" export BUILD_VERSION=\"10.5.2.7.374\" export BUILD_DATE=\"2021-07-28T04:48:06+0000\" ####################################################################### # Magic cookies for OS10 feature detection. DO NOT CHANGE! # !OS10!1PART! # Enable error handling set -e INSTALLER=$(realpath \"$0\") TMP_DIR=$(mktemp -d) cd $TMP_DIR # Extract installer scripts echo -n \"Initializing installer ... \" sed -e '1,/^__INSTALLER__$/d;/^__IMAGE__$/,$d' \"$INSTALLER\" | base64 -d | tar xzf - echo \"OK\" # Load the installer library files cd installer . install_support.sh install_main \"$@\" rc=\"$?\" exit $rc __INSTALLER__ <BASE_64_ENCODED_INSTALLER> __IMAGE__ <BINARY_IMAGE_HERE> What this does is grab the installer's name with INSTALLER=$(realpath \"$0\") and then extracts itself with sed -e '1,/^__INSTALLER__$/d;/^__IMAGE__$/,$d' \"$INSTALLER\" | base64 -d | tar xzf - . This grabs everything between the INSTALLER and IMAGE tags, base64 decodes it, and then extracts it with tar.","title":"How OS10 Installer Works"},{"location":"How%20OS10%20Installer%20Works/#how-os10-installer-works","text":"The OS10 installer is a binary file with a bash stub: #!/bin/sh ####################################################################### # Dell OS10 Installer ####################################################################### ####################################################################### # OS10 Data export OS_NAME=\"Dell EMC Networking OS10 Enterprise\" export OS_VERSION=\"10.5.2.7\" export PLATFORM=\"generic-x86_64\" export ARCHITECTURE=\"x86_64\" export INTERNAL_BUILD_ID=\"Dell EMC OS10 Enterprise Edition Blueprint 1.0.0\" export BUILD_VERSION=\"10.5.2.7.374\" export BUILD_DATE=\"2021-07-28T04:48:06+0000\" ####################################################################### # Magic cookies for OS10 feature detection. DO NOT CHANGE! # !OS10!1PART! # Enable error handling set -e INSTALLER=$(realpath \"$0\") TMP_DIR=$(mktemp -d) cd $TMP_DIR # Extract installer scripts echo -n \"Initializing installer ... \" sed -e '1,/^__INSTALLER__$/d;/^__IMAGE__$/,$d' \"$INSTALLER\" | base64 -d | tar xzf - echo \"OK\" # Load the installer library files cd installer . install_support.sh install_main \"$@\" rc=\"$?\" exit $rc __INSTALLER__ <BASE_64_ENCODED_INSTALLER> __IMAGE__ <BINARY_IMAGE_HERE> What this does is grab the installer's name with INSTALLER=$(realpath \"$0\") and then extracts itself with sed -e '1,/^__INSTALLER__$/d;/^__IMAGE__$/,$d' \"$INSTALLER\" | base64 -d | tar xzf - . This grabs everything between the INSTALLER and IMAGE tags, base64 decodes it, and then extracts it with tar.","title":"How OS10 Installer Works"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/","text":"How to ONIE Install and ZTP Config Dell SONiC How to ONIE Install and ZTP Config Dell SONiC My Test Platform Switch Server OS Prepare to Install Operating System Manually Install SONiC via ONIE Fully Automated Installation from OS10 to SONiC Overview Configure DHCP Server for SONiC ZTP Configure DHCP for ZTP Configure Your HTTP Server More Configuration Options Running ZTP Get Command Line See Install Workflow for an overview of how this process flows. Video of the full sequence: https://youtu.be/Xm4stcPvnUc My Test Platform Switch OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2021 by Dell Inc. All Rights Reserved. OS Version: 10.5.3.0 Build Version: 10.5.3.0.44 Build Time: 2021-10-06T23:03:55+0000 System Type: S5212F-ON Architecture: x86_64 Up Time: 00:34:10 Server OS Fedora release 35 (Thirty Five) NAME=\"Fedora Linux\" VERSION=\"35 (Workstation Edition)\" ID=fedora VERSION_ID=35 VERSION_CODENAME=\"\" PLATFORM_ID=\"platform:f35\" PRETTY_NAME=\"Fedora Linux 35 (Workstation Edition)\" ANSI_COLOR=\"0;38;2;60;110;180\" LOGO=fedora-logo-icon CPE_NAME=\"cpe:/o:fedoraproject:fedora:35\" HOME_URL=\"https://fedoraproject.org/\" DOCUMENTATION_URL=\"https://docs.fedoraproject.org/en-US/fedora/f35/system-administrators-guide/\" SUPPORT_URL=\"https://ask.fedoraproject.org/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Fedora\" REDHAT_BUGZILLA_PRODUCT_VERSION=35 REDHAT_SUPPORT_PRODUCT=\"Fedora\" REDHAT_SUPPORT_PRODUCT_VERSION=35 PRIVACY_POLICY_URL=\"https://fedoraproject.org/wiki/Legal:PrivacyPolicy\" VARIANT=\"Workstation Edition\" VARIANT_ID=workstation Fedora release 35 (Thirty Five) Fedora release 35 (Thirty Five) Prepare to Install Operating System This first section discusses operating system installation. If you manually install the OS, you will start the next section of the instructions with the OS already installed. If you are performing the fully automated setup, you will install the OS later on in the instructions. Manually Install SONiC via ONIE Download SONiC OS for your manufacturer. In my case I pulled Dell's stable image. Follow the instructions for setting up and running ONIE Use SONiC binary instead of OS10 Fully Automated Installation from OS10 to SONiC Overview On a separate host, set up an HTTP server to host your operating system files You could also use TFTP but for demonstration here I am using HTTP On a separate host, set up a DHCP server to feed the ZTD/ZTP options Force OS10 to reboot in ONIE uninstall mode and then allow it to boot in ONIE install mode Install SONiC Dell switches are often shipped with OS10 by default (many times to meet TAA compliance requirements). In this scenario you may have just purchased several switches and you want to fully automate their out-of-the-box installation by replacing OS10 with SONiC. By default, OS10 will boot for the first time in Zero Touch Deployment (ZTD) mode. Entering configuration mode or rebooting the switch disables it. You can re-enable it with reload ztd . WARNING This will delete your startup configuration. You can check ztd status with show ztd-status . At time of writing this is the current OS10 manual. See page 93 for information on ZTD. While you can ONIe boot / ZTD with the switch's frontpanel ports, I tested this configuration using the management interface. These instructions are written assuming you have the management interface plugged in. If you need to console into the management interface the settings are: Baud Rate: 115200 Data Bits: 8 Stop Bits: 1 Parity: None Flow Control: None Configure HTTP server On your Fedora box run dnf install httpd Start it with systemctl start httpd Upload the SONiC binary to var/www/html Run ln -s Enterprise_SONiC_OS_4.0.1_Enterprise_Premium.bin onie-installer to create a symbolic link with the name onie-installer. This is the name ONIE will automatically search for. Confirm your web server is working by browsing to onie-installer at http://<your_ip>/onie-installer . On your Fedora box run dnf install -y dhcp-server Edit your DHCP server configuration with vim /etc/dhcp/dhcpd.conf . Replace the IP addresses with your IP addresses. Note: You will modify the line option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) further on in the instructions # # DHCP Server Configuration file. # see /usr/share/doc/dhcp-server/dhcpd.conf.example # see dhcpd.conf(5) man page # ddns-update-style interim; option ztd-provision-url code 240 = text; subnet 192.168.1.0 netmask 255.255.255.0 { max-lease-time 86400; min-lease-time 60; default-lease-time 86400; option netbios-node-type 8; host OS10 { hardware ethernet b0:4f:13:37:b8:c0; fixed-address 192.168.1.90; option default-url \"http://192.168.1.186/ztd/onie-installer\"; # For Option 114 (Default URL) option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) } } Run systemctl restart dhcpd to apply the configuration and ensure that dhcpd is running. You are now ready to move on to the ZTP configuration Configure DHCP Server for SONiC ZTP The official ZTP documentation for SONiC is here . Configure DHCP for ZTP The first thing you will need to do is configure the DHCP server servicing the devices to provide option 67 which will point to initial boot file used by SONiC's ZTP agent. The options for URL are defined here . As shown above, I used the following DHCP configuration file (located at /etc/dhcp/dhcpd.conf on Fedora): # # DHCP Server Configuration file. # see /usr/share/doc/dhcp-server/dhcpd.conf.example # see dhcpd.conf(5) man page # ddns-update-style interim; option ztd-provision-url code 240 = text; subnet 192.168.1.0 netmask 255.255.255.0 { max-lease-time 86400; min-lease-time 60; default-lease-time 86400; option netbios-node-type 8; host OS10 { hardware ethernet b0:4f:13:37:b8:c0; fixed-address 192.168.1.90; option default-url \"http://192.168.1.186/ztd/onie-installer\"; # For Option 114 (Default URL) option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) } } Notice the line option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) . If you want to use TFTP you can replace the http:// with tftp:// . This line tells SONiC where to look for a configuration pointer. The name initial.json does not matter - you can name this file whatever you want. This file will contain a web address pointing to config_db.json which is the file SONiC gives ZTP to configure itself. Run systemctl restart dhcpd to ensure your changes take effect. Configure Your HTTP Server As mentioned above, you have to create a file which points to config_db.json. A copy of mine is below. { \"ztp\": { \"configdb-json\" : { \"url\": { \"source\": \"http://192.168.1.186:80/config_db.json\" } } } } The source field points to the actual configuration file you want to deploy to the networking device. On your web server you will also need to provide this configuration file. In my case I only had it update the device's management IP address but you can have it configure any aspect of the switch: { \"MGMT_INTERFACE\": { \"eth0|192.168.1.96/24\": { \"gwaddr\": \"192.168.1.1\" } } } This file's sections are identical to what is in /etc/sonic/config_db.json . If you want to see what something should look like you can look there and then copy/paste. More Configuration Options The file initial.json has a myriad of options allowing you to do things like set firmware options, set the password, perform connection tests on completion, etc. I only demonstrated one here just to get started. See Dell's SONiC manual for additional options. Running ZTP If you have already installed SONiC manually, at this point you can leave things running and SONiC's ZTP should automatically start. If not, you can make sure it is on with ztp enable and then ztp run to force it to run. If you are performing a fully automated install, then at this point, if your DHCP server config is correct, you should see OS10 reboot into ONIE uninstall mode. It will uninstall OS10, reboot in ONIE install mode, and install SONiC. Note: The way this works is OS10 checks the onie-installer argument provided in the DHCP configuration. If the installer is not OS10, it reboots in ONIE uninstall mode. See https://youtu.be/Xm4stcPvnUc for a depiction of what the entire process looks like from start to finish. Get Command Line Run sonic-cli to get an OS-10 style command line.","title":"How to ONIE Install and ZTP Config Dell SONiC"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#how-to-onie-install-and-ztp-config-dell-sonic","text":"How to ONIE Install and ZTP Config Dell SONiC My Test Platform Switch Server OS Prepare to Install Operating System Manually Install SONiC via ONIE Fully Automated Installation from OS10 to SONiC Overview Configure DHCP Server for SONiC ZTP Configure DHCP for ZTP Configure Your HTTP Server More Configuration Options Running ZTP Get Command Line See Install Workflow for an overview of how this process flows. Video of the full sequence: https://youtu.be/Xm4stcPvnUc","title":"How to ONIE Install and ZTP Config Dell SONiC"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#my-test-platform","text":"","title":"My Test Platform"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#switch","text":"OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2021 by Dell Inc. All Rights Reserved. OS Version: 10.5.3.0 Build Version: 10.5.3.0.44 Build Time: 2021-10-06T23:03:55+0000 System Type: S5212F-ON Architecture: x86_64 Up Time: 00:34:10","title":"Switch"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#server-os","text":"Fedora release 35 (Thirty Five) NAME=\"Fedora Linux\" VERSION=\"35 (Workstation Edition)\" ID=fedora VERSION_ID=35 VERSION_CODENAME=\"\" PLATFORM_ID=\"platform:f35\" PRETTY_NAME=\"Fedora Linux 35 (Workstation Edition)\" ANSI_COLOR=\"0;38;2;60;110;180\" LOGO=fedora-logo-icon CPE_NAME=\"cpe:/o:fedoraproject:fedora:35\" HOME_URL=\"https://fedoraproject.org/\" DOCUMENTATION_URL=\"https://docs.fedoraproject.org/en-US/fedora/f35/system-administrators-guide/\" SUPPORT_URL=\"https://ask.fedoraproject.org/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Fedora\" REDHAT_BUGZILLA_PRODUCT_VERSION=35 REDHAT_SUPPORT_PRODUCT=\"Fedora\" REDHAT_SUPPORT_PRODUCT_VERSION=35 PRIVACY_POLICY_URL=\"https://fedoraproject.org/wiki/Legal:PrivacyPolicy\" VARIANT=\"Workstation Edition\" VARIANT_ID=workstation Fedora release 35 (Thirty Five) Fedora release 35 (Thirty Five)","title":"Server OS"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#prepare-to-install-operating-system","text":"This first section discusses operating system installation. If you manually install the OS, you will start the next section of the instructions with the OS already installed. If you are performing the fully automated setup, you will install the OS later on in the instructions.","title":"Prepare to Install Operating System"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#manually-install-sonic-via-onie","text":"Download SONiC OS for your manufacturer. In my case I pulled Dell's stable image. Follow the instructions for setting up and running ONIE Use SONiC binary instead of OS10","title":"Manually Install SONiC via ONIE"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#fully-automated-installation-from-os10-to-sonic","text":"","title":"Fully Automated Installation from OS10 to SONiC"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#overview","text":"On a separate host, set up an HTTP server to host your operating system files You could also use TFTP but for demonstration here I am using HTTP On a separate host, set up a DHCP server to feed the ZTD/ZTP options Force OS10 to reboot in ONIE uninstall mode and then allow it to boot in ONIE install mode Install SONiC Dell switches are often shipped with OS10 by default (many times to meet TAA compliance requirements). In this scenario you may have just purchased several switches and you want to fully automate their out-of-the-box installation by replacing OS10 with SONiC. By default, OS10 will boot for the first time in Zero Touch Deployment (ZTD) mode. Entering configuration mode or rebooting the switch disables it. You can re-enable it with reload ztd . WARNING This will delete your startup configuration. You can check ztd status with show ztd-status . At time of writing this is the current OS10 manual. See page 93 for information on ZTD. While you can ONIe boot / ZTD with the switch's frontpanel ports, I tested this configuration using the management interface. These instructions are written assuming you have the management interface plugged in. If you need to console into the management interface the settings are: Baud Rate: 115200 Data Bits: 8 Stop Bits: 1 Parity: None Flow Control: None Configure HTTP server On your Fedora box run dnf install httpd Start it with systemctl start httpd Upload the SONiC binary to var/www/html Run ln -s Enterprise_SONiC_OS_4.0.1_Enterprise_Premium.bin onie-installer to create a symbolic link with the name onie-installer. This is the name ONIE will automatically search for. Confirm your web server is working by browsing to onie-installer at http://<your_ip>/onie-installer . On your Fedora box run dnf install -y dhcp-server Edit your DHCP server configuration with vim /etc/dhcp/dhcpd.conf . Replace the IP addresses with your IP addresses. Note: You will modify the line option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) further on in the instructions # # DHCP Server Configuration file. # see /usr/share/doc/dhcp-server/dhcpd.conf.example # see dhcpd.conf(5) man page # ddns-update-style interim; option ztd-provision-url code 240 = text; subnet 192.168.1.0 netmask 255.255.255.0 { max-lease-time 86400; min-lease-time 60; default-lease-time 86400; option netbios-node-type 8; host OS10 { hardware ethernet b0:4f:13:37:b8:c0; fixed-address 192.168.1.90; option default-url \"http://192.168.1.186/ztd/onie-installer\"; # For Option 114 (Default URL) option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) } } Run systemctl restart dhcpd to apply the configuration and ensure that dhcpd is running. You are now ready to move on to the ZTP configuration","title":"Overview"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#configure-dhcp-server-for-sonic-ztp","text":"The official ZTP documentation for SONiC is here .","title":"Configure DHCP Server for SONiC ZTP"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#configure-dhcp-for-ztp","text":"The first thing you will need to do is configure the DHCP server servicing the devices to provide option 67 which will point to initial boot file used by SONiC's ZTP agent. The options for URL are defined here . As shown above, I used the following DHCP configuration file (located at /etc/dhcp/dhcpd.conf on Fedora): # # DHCP Server Configuration file. # see /usr/share/doc/dhcp-server/dhcpd.conf.example # see dhcpd.conf(5) man page # ddns-update-style interim; option ztd-provision-url code 240 = text; subnet 192.168.1.0 netmask 255.255.255.0 { max-lease-time 86400; min-lease-time 60; default-lease-time 86400; option netbios-node-type 8; host OS10 { hardware ethernet b0:4f:13:37:b8:c0; fixed-address 192.168.1.90; option default-url \"http://192.168.1.186/ztd/onie-installer\"; # For Option 114 (Default URL) option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) } } Notice the line option bootfile-name \"http://192.168.1.186:80/initial.json\"; # For Option 67 (HTTP) . If you want to use TFTP you can replace the http:// with tftp:// . This line tells SONiC where to look for a configuration pointer. The name initial.json does not matter - you can name this file whatever you want. This file will contain a web address pointing to config_db.json which is the file SONiC gives ZTP to configure itself. Run systemctl restart dhcpd to ensure your changes take effect.","title":"Configure DHCP for ZTP"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#configure-your-http-server","text":"As mentioned above, you have to create a file which points to config_db.json. A copy of mine is below. { \"ztp\": { \"configdb-json\" : { \"url\": { \"source\": \"http://192.168.1.186:80/config_db.json\" } } } } The source field points to the actual configuration file you want to deploy to the networking device. On your web server you will also need to provide this configuration file. In my case I only had it update the device's management IP address but you can have it configure any aspect of the switch: { \"MGMT_INTERFACE\": { \"eth0|192.168.1.96/24\": { \"gwaddr\": \"192.168.1.1\" } } } This file's sections are identical to what is in /etc/sonic/config_db.json . If you want to see what something should look like you can look there and then copy/paste.","title":"Configure Your HTTP Server"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#more-configuration-options","text":"The file initial.json has a myriad of options allowing you to do things like set firmware options, set the password, perform connection tests on completion, etc. I only demonstrated one here just to get started. See Dell's SONiC manual for additional options.","title":"More Configuration Options"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#running-ztp","text":"If you have already installed SONiC manually, at this point you can leave things running and SONiC's ZTP should automatically start. If not, you can make sure it is on with ztp enable and then ztp run to force it to run. If you are performing a fully automated install, then at this point, if your DHCP server config is correct, you should see OS10 reboot into ONIE uninstall mode. It will uninstall OS10, reboot in ONIE install mode, and install SONiC. Note: The way this works is OS10 checks the onie-installer argument provided in the DHCP configuration. If the installer is not OS10, it reboots in ONIE uninstall mode. See https://youtu.be/Xm4stcPvnUc for a depiction of what the entire process looks like from start to finish.","title":"Running ZTP"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/#get-command-line","text":"Run sonic-cli to get an OS-10 style command line.","title":"Get Command Line"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/webserver/","text":"Configuring the Webserver Requirements: - Python 3 - flask (install with pip install flask ) Run the config server from this directory with python config_server.py --host 0.0.0.0 --port 80","title":"Configuring the Webserver"},{"location":"How%20to%20ONIE%20Install%20and%20ZTP%20Config%20Dell%20SONiC/webserver/#configuring-the-webserver","text":"Requirements: - Python 3 - flask (install with pip install flask ) Run the config server from this directory with python config_server.py --host 0.0.0.0 --port 80","title":"Configuring the Webserver"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/","text":"How to Read lstopo and a PCIe Overview The first time I looked at lstopo , I found the output rather overwhelming so I wrote this guide to break down what I was looking at. Subject Platform Dell R840 Package The word package is synonymous with the word socket. In the R840's case there are four separate, physical, sockets. Caches (LXi, LXd, and L3) This in particular confused me at first as the nomenclature is specific to your architecture (ex: Intel or AMD). Here you see three caches LXi, LXd, and L3. L i refers to an instruction cache , L d refers to a data cache , and L3 is a mixed cache including data and instructions. In the Intel architecture the first couple of levels may be dedicated to data or instruction caches but higher levels are mixed. Cores It helps here to look at the output of lscpu [root@r8402 ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 80 On-line CPU(s) list: 0-79 Thread(s) per core: 2 Core(s) per socket: 10 Socket(s): 4 NUMA node(s): 4 Vendor ID: GenuineIntel BIOS Vendor ID: Intel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Gold 5215 CPU @ 2.50GHz BIOS Model name: Intel(R) Xeon(R) Gold 5215 CPU @ 2.50GHz Stepping: 7 CPU MHz: 2643.471 CPU max MHz: 3400.0000 CPU min MHz: 1000.0000 BogoMIPS: 5000.00 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 14080K NUMA node0 CPU(s): 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76 NUMA node1 CPU(s): 1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77 NUMA node2 CPU(s): 2,6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78 NUMA node3 CPU(s): 3,7,11,15,19,23,27,31,35,39,43,47,51,55,59,63,67,71,75,79 First we need to understand a bit about computer architecture. In modern servers, you have the physical processors, cores within those processors, and finally logical cores (due to HyperThreading in Intel architectures ar Simultaneous Multi-Threading [SMT] in AMD architectures). AS you can see from the output of lscpu , in my server, each processor has 10 cores and each of those cores, due to hyperthreading, has 20 logical cores (as indicated by the NUMA node field). What you are seeing in this part: are the 10 cores in each proc. Notice that the numbers are in ascending order starting with package L#0 which has cores 0-9, then L#1 has 10-19, on up to 39 in package L#3. Also notice that the output omits some of the procs for space reasons and simply says \"10x total\" to indicate that there are actually 10 procs total. You can see that each individual core: Further has PU L#0 and PU L#1. These refer to the two aforementioned logacl cores created from hyperthreading. NUMA Nodes Perhaps more confusing are the smaller numbers. In package L#0 we see P#0, P#4, P#36, P#40, P#44, and P#76 actually drawn. As other posts have mentioned, these correspond to the various NUMA Nodes . As mentioned in Wikipedia, modern architectures use some sort of cache coherent NUMA (ccNUMA). The subject can be quite complicated but a simple explanation is this: we want memory access to be faster. The best way to do this is to literally put the memory closer to the processor. NUMA nodes do this by directly attaching processors to some part of memory. The smaller numbers indicate the logical cores created by HyperThreading. From the output of lscpu you can see that all the logical processes shown in package L#0: are included in NUMA node 0. You may also notice at the top it says NUMANode L#0 P#0 (45GB). This refers to the fact that NUMA node 0 has direct access to 1/4 of the total memory or 45GB. We can confirm this by looking at cat /proc/meminfo : [root@r8402 ~]# cat /proc/meminfo MemTotal: 196207488 kB MemFree: 191452708 kB MemAvailable: 191700740 kB ...SNIP... In our example, if a process is running on Core L#0, logical processor P#36, then it can directly access any of the 45GBs directly attached to package L#0. An important note: modern operating systems are NUMA aware and will do their absolute best when you spawn a process to make sure that the memory allocated for that process will be on the same NUMA node. However, let's say that there is some larger process and that multiple threads are sharing access to memory. In this case you may have a scenario where a process is running on logical processor P#5 on package L#1 in which case that process will have to reach out from physical package of L#1 through what's called the QPI bus, through package L#0, and then gain access to the memory local to package L#0. The QPI bus is part of the Intel architecture and it provides interconnects between all the physical packages for exactly this purpose. AMD uses something called XGMI. This gets us pretty in the weeds on computer architecture because this actually changes over time. For example, on Intel's newer Skylake processors it is no longer the QPI bus but ULtra Path Interconnect that serves this function so when you're working at this level you have to pay attention to exactly what processor you are using. Fun fact: When looking at things like the Technical Guide for servers you have to account for this when looking at total PCIe lane availability. The AMD EPYC gen 2/3 processors both support up to 128 PCIe lanes per processor BUT this is a bit misleading. When you have servers like the Dell R7525 (or any other vendor's two socket AMD server like HP's DL385) the two procs are connected via XGMI however XGMI consumes 48 PCIe lanes per processor so when doing your calculus you actually only end up seeing 80 per processor for a total of 160. PCIe Background The last part of the diagram we haven't touched on is PCIe. Not to be confused with NUMA, PCIe devices also have locality to processors. Each processor has a certain number of PCIe lanes attached directly to it. Just like memory, if you have a process running on, let's say, package L#3 and it is writing to NVMe drive nvme3n1 that process will write more quickly than a process running on package L#0 which must write across the QPI bus, through package L#3, and then to the drive. To fully understand how to interpret the PCIe results, it helps to understand a few PCIe basics. This is lengthy but all the things mentioned will help you interpret a potential configuration you might see in lstopo. PCIe Root Complex All PCIe Express (PCIe) devices connect to the processor and memory through what is called the PCIe root complex It is important to understand that PCIe devices can write directly to memory in modern architectures without ever touching the CPU. This is generically called Direct Memory Access (DMA). Each PCIe device has some region of memory assigned to it. This gets pretty deep - see here for an overview. In modern computer architectures, there is more than one root complex in a system ( NOTE that link does a good job of explaining things but has references to older architectures with pieces that are no longer in existence [Ex: the platform controller hub (PCH) is no longer a thing]). There is a root complex for every processor on the system. Now, where this gets confusing is a mixing of terminology. In an attempt to abstract the very architecture-specific nature of PCIe people use different terms like host bridge, root complex, and system on chip, etc. In modern architectures, from a physical perspective, there is no longer a physically separate thing for the root complex. Modern architectures have what is called system on chip (SoC) where all that stuff is built into the processor die (including the PCIe root complex). PCIe Switches Another concept that can be confusing is that you generally have two different devices which attach to the root complex. Either a PCIe switch or a PCIe endpoint. PCIe works more or less just like a network does and like a network it has switches. Say for example that a manufacturer wants to cram more PCIe devices onto a server than the server actually has PCIe lanes. A real world example: when the new AMD Rome processors dropped, manufacturers rushed to get servers to market. There wasn't time to actually make new motherboards fully supporting all the features the Rome processor offered so they instead modified existing motherboards which lead to some sub-optimal designs which included oversubscribing PCIe (it was not a single vendor that did this - I've seen this across the board). Let's say you have a server that supports 24 NVMe drives on a single backplane but each side of the backplane only has two x8 cables. NVMe drives run at x4 speeds so if you have 12 drives per side of the backplane, you're looking at a total of 48 PCIe lanes required to not have oversubscription. However, you only have 16 lanes available to play with. What do you do? Put a PCIe switch in front of the drives. It works just like an oversubscribed network. So in this case the NVMe drives are oversubscribed at a rate of 48:16 or simplified, 3:1. Another common use is bifurcation. Let's say you have one x16 lane but you want to use two x8 devices. You can bifurcate the lane to do just that - break a single x16 lane into two x8 lanes. This is where you might also hear the terminology \"electrically x16\". For example, a vendor might make a riser that allows two x8 devices but in reality, the electrical traces will each independently support x16. The BIOS will let you reconfigure the PCIe switch to instead operate at x16 speeds and you can ignore one of the riser slots. There are a lot of other fancy uses for PCIe switches but those two are the most common. For example NVLink will let graphics cards talk directly to each other. PCIe Bridge This term is also overused and confusing. In older architectures there's a lot about connecting to legacy PCI which isn't really a concern in 2022. In 2022 all a bridge does is connect a PCIe slot to the microprocessor responsible for controlling it. Generically, it is just a hardware connection between two different buses. What is the PCIe bus : This term is also super confusing in 2022. Way back in the original PCI spec before PCIe was a thing there was a literal parallel bus. As in, you had a whole bunch of devices sharing a physical bus along with all the problems that brings (of which there are many). In PCIe devices aren't attached to this kind of bus. In fact, I find it a bit obnoxious that we even use the word bus (even though it is technically correct). When I see people use the word \"bus\" in terms of PCIe what they usually mean is the serial connection consisting of multiple bidirectional PCIe lanes connecting the PCIe device (endpoint) to the root complex or PCIe switch. Interpreting PCIe As you might be able to guess, this is extremely device specific. The numbers shown next to the wires (3.9, 1.2, etc) are the unrounded transfer speeds in gigabytes per second . The various NVMe devices are fairly self explanatory. However, when it comes to networking, this is where it gets interesting. The network device shown is actually a Dell network daughter card (NDC) and all four interfaces shown in Package L#0 are actually the same network card. I confirmed this by cross referencing the xml output of lstopo with ip a s . See below picture It would seem that under the hood, for the NDC, Dell actually ran a x4 lane to the two SFP interfaces and a x2 lane for the copper interfaces. This makes sense because those ethernet interfaces are only 1Gb/s. The rest of the devices are as follows: Bus 25:00:0 is a BOSS card Bus 00:11.5 is the platform controller hub (PCH) If you're curious why you don't see the iDRAC's ethernet interface, this is because all communication with the iDRAC, assuming you aren't using RMI, goes through the PCH. Bus 03:00.0 is the VGA port For the eagle eyed you may notice the PERC is absent - I have it disconnected right now. It would normally have shown up on package L#0. Understanding PCIe Switches vs Functions The last thing I thought was a bit hard to descipher without some cross reference Research Translation Lookaside Buffer See: https://en.wikipedia.org/wiki/Translation_lookaside_buffer A translation lookaside buffer (TLB) is a memory cache that is used to reduce the time taken to access a user memory location.[1] It is a part of the chip's memory-management unit (MMU). The TLB stores the recent translations of virtual memory to physical memory and can be called an address-translation cache. A TLB may reside between the CPU and the CPU cache, between CPU cache and the main memory or between the different levels of the multi-level cache. The majority of desktop, laptop, and server processors include one or more TLBs in the memory-management hardware, and it is nearly always present in any processor that utilizes paged or segmented virtual memory. TLB Misses See 18-notes.pdf Data and Instruction Caches See 18-notes.pdf StackExchange Explanaton of lstopo https://unix.stackexchange.com/a/113549/240147","title":"How to Read lstopo and a PCIe Overview"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#how-to-read-lstopo-and-a-pcie-overview","text":"The first time I looked at lstopo , I found the output rather overwhelming so I wrote this guide to break down what I was looking at.","title":"How to Read lstopo and a PCIe Overview"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#subject-platform","text":"Dell R840","title":"Subject Platform"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#package","text":"The word package is synonymous with the word socket. In the R840's case there are four separate, physical, sockets.","title":"Package"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#caches-lxi-lxd-and-l3","text":"This in particular confused me at first as the nomenclature is specific to your architecture (ex: Intel or AMD). Here you see three caches LXi, LXd, and L3. L i refers to an instruction cache , L d refers to a data cache , and L3 is a mixed cache including data and instructions. In the Intel architecture the first couple of levels may be dedicated to data or instruction caches but higher levels are mixed.","title":"Caches (LXi, LXd, and L3)"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#cores","text":"It helps here to look at the output of lscpu [root@r8402 ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 80 On-line CPU(s) list: 0-79 Thread(s) per core: 2 Core(s) per socket: 10 Socket(s): 4 NUMA node(s): 4 Vendor ID: GenuineIntel BIOS Vendor ID: Intel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Gold 5215 CPU @ 2.50GHz BIOS Model name: Intel(R) Xeon(R) Gold 5215 CPU @ 2.50GHz Stepping: 7 CPU MHz: 2643.471 CPU max MHz: 3400.0000 CPU min MHz: 1000.0000 BogoMIPS: 5000.00 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 14080K NUMA node0 CPU(s): 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,64,68,72,76 NUMA node1 CPU(s): 1,5,9,13,17,21,25,29,33,37,41,45,49,53,57,61,65,69,73,77 NUMA node2 CPU(s): 2,6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78 NUMA node3 CPU(s): 3,7,11,15,19,23,27,31,35,39,43,47,51,55,59,63,67,71,75,79 First we need to understand a bit about computer architecture. In modern servers, you have the physical processors, cores within those processors, and finally logical cores (due to HyperThreading in Intel architectures ar Simultaneous Multi-Threading [SMT] in AMD architectures). AS you can see from the output of lscpu , in my server, each processor has 10 cores and each of those cores, due to hyperthreading, has 20 logical cores (as indicated by the NUMA node field). What you are seeing in this part: are the 10 cores in each proc. Notice that the numbers are in ascending order starting with package L#0 which has cores 0-9, then L#1 has 10-19, on up to 39 in package L#3. Also notice that the output omits some of the procs for space reasons and simply says \"10x total\" to indicate that there are actually 10 procs total. You can see that each individual core: Further has PU L#0 and PU L#1. These refer to the two aforementioned logacl cores created from hyperthreading.","title":"Cores"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#numa-nodes","text":"Perhaps more confusing are the smaller numbers. In package L#0 we see P#0, P#4, P#36, P#40, P#44, and P#76 actually drawn. As other posts have mentioned, these correspond to the various NUMA Nodes . As mentioned in Wikipedia, modern architectures use some sort of cache coherent NUMA (ccNUMA). The subject can be quite complicated but a simple explanation is this: we want memory access to be faster. The best way to do this is to literally put the memory closer to the processor. NUMA nodes do this by directly attaching processors to some part of memory. The smaller numbers indicate the logical cores created by HyperThreading. From the output of lscpu you can see that all the logical processes shown in package L#0: are included in NUMA node 0. You may also notice at the top it says NUMANode L#0 P#0 (45GB). This refers to the fact that NUMA node 0 has direct access to 1/4 of the total memory or 45GB. We can confirm this by looking at cat /proc/meminfo : [root@r8402 ~]# cat /proc/meminfo MemTotal: 196207488 kB MemFree: 191452708 kB MemAvailable: 191700740 kB ...SNIP... In our example, if a process is running on Core L#0, logical processor P#36, then it can directly access any of the 45GBs directly attached to package L#0. An important note: modern operating systems are NUMA aware and will do their absolute best when you spawn a process to make sure that the memory allocated for that process will be on the same NUMA node. However, let's say that there is some larger process and that multiple threads are sharing access to memory. In this case you may have a scenario where a process is running on logical processor P#5 on package L#1 in which case that process will have to reach out from physical package of L#1 through what's called the QPI bus, through package L#0, and then gain access to the memory local to package L#0. The QPI bus is part of the Intel architecture and it provides interconnects between all the physical packages for exactly this purpose. AMD uses something called XGMI. This gets us pretty in the weeds on computer architecture because this actually changes over time. For example, on Intel's newer Skylake processors it is no longer the QPI bus but ULtra Path Interconnect that serves this function so when you're working at this level you have to pay attention to exactly what processor you are using. Fun fact: When looking at things like the Technical Guide for servers you have to account for this when looking at total PCIe lane availability. The AMD EPYC gen 2/3 processors both support up to 128 PCIe lanes per processor BUT this is a bit misleading. When you have servers like the Dell R7525 (or any other vendor's two socket AMD server like HP's DL385) the two procs are connected via XGMI however XGMI consumes 48 PCIe lanes per processor so when doing your calculus you actually only end up seeing 80 per processor for a total of 160.","title":"NUMA Nodes"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#pcie-background","text":"The last part of the diagram we haven't touched on is PCIe. Not to be confused with NUMA, PCIe devices also have locality to processors. Each processor has a certain number of PCIe lanes attached directly to it. Just like memory, if you have a process running on, let's say, package L#3 and it is writing to NVMe drive nvme3n1 that process will write more quickly than a process running on package L#0 which must write across the QPI bus, through package L#3, and then to the drive. To fully understand how to interpret the PCIe results, it helps to understand a few PCIe basics. This is lengthy but all the things mentioned will help you interpret a potential configuration you might see in lstopo.","title":"PCIe Background"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#pcie-root-complex","text":"All PCIe Express (PCIe) devices connect to the processor and memory through what is called the PCIe root complex It is important to understand that PCIe devices can write directly to memory in modern architectures without ever touching the CPU. This is generically called Direct Memory Access (DMA). Each PCIe device has some region of memory assigned to it. This gets pretty deep - see here for an overview. In modern computer architectures, there is more than one root complex in a system ( NOTE that link does a good job of explaining things but has references to older architectures with pieces that are no longer in existence [Ex: the platform controller hub (PCH) is no longer a thing]). There is a root complex for every processor on the system. Now, where this gets confusing is a mixing of terminology. In an attempt to abstract the very architecture-specific nature of PCIe people use different terms like host bridge, root complex, and system on chip, etc. In modern architectures, from a physical perspective, there is no longer a physically separate thing for the root complex. Modern architectures have what is called system on chip (SoC) where all that stuff is built into the processor die (including the PCIe root complex).","title":"PCIe Root Complex"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#pcie-switches","text":"Another concept that can be confusing is that you generally have two different devices which attach to the root complex. Either a PCIe switch or a PCIe endpoint. PCIe works more or less just like a network does and like a network it has switches. Say for example that a manufacturer wants to cram more PCIe devices onto a server than the server actually has PCIe lanes. A real world example: when the new AMD Rome processors dropped, manufacturers rushed to get servers to market. There wasn't time to actually make new motherboards fully supporting all the features the Rome processor offered so they instead modified existing motherboards which lead to some sub-optimal designs which included oversubscribing PCIe (it was not a single vendor that did this - I've seen this across the board). Let's say you have a server that supports 24 NVMe drives on a single backplane but each side of the backplane only has two x8 cables. NVMe drives run at x4 speeds so if you have 12 drives per side of the backplane, you're looking at a total of 48 PCIe lanes required to not have oversubscription. However, you only have 16 lanes available to play with. What do you do? Put a PCIe switch in front of the drives. It works just like an oversubscribed network. So in this case the NVMe drives are oversubscribed at a rate of 48:16 or simplified, 3:1. Another common use is bifurcation. Let's say you have one x16 lane but you want to use two x8 devices. You can bifurcate the lane to do just that - break a single x16 lane into two x8 lanes. This is where you might also hear the terminology \"electrically x16\". For example, a vendor might make a riser that allows two x8 devices but in reality, the electrical traces will each independently support x16. The BIOS will let you reconfigure the PCIe switch to instead operate at x16 speeds and you can ignore one of the riser slots. There are a lot of other fancy uses for PCIe switches but those two are the most common. For example NVLink will let graphics cards talk directly to each other.","title":"PCIe Switches"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#pcie-bridge","text":"This term is also overused and confusing. In older architectures there's a lot about connecting to legacy PCI which isn't really a concern in 2022. In 2022 all a bridge does is connect a PCIe slot to the microprocessor responsible for controlling it. Generically, it is just a hardware connection between two different buses. What is the PCIe bus : This term is also super confusing in 2022. Way back in the original PCI spec before PCIe was a thing there was a literal parallel bus. As in, you had a whole bunch of devices sharing a physical bus along with all the problems that brings (of which there are many). In PCIe devices aren't attached to this kind of bus. In fact, I find it a bit obnoxious that we even use the word bus (even though it is technically correct). When I see people use the word \"bus\" in terms of PCIe what they usually mean is the serial connection consisting of multiple bidirectional PCIe lanes connecting the PCIe device (endpoint) to the root complex or PCIe switch.","title":"PCIe Bridge"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#interpreting-pcie","text":"As you might be able to guess, this is extremely device specific. The numbers shown next to the wires (3.9, 1.2, etc) are the unrounded transfer speeds in gigabytes per second . The various NVMe devices are fairly self explanatory. However, when it comes to networking, this is where it gets interesting. The network device shown is actually a Dell network daughter card (NDC) and all four interfaces shown in Package L#0 are actually the same network card. I confirmed this by cross referencing the xml output of lstopo with ip a s . See below picture It would seem that under the hood, for the NDC, Dell actually ran a x4 lane to the two SFP interfaces and a x2 lane for the copper interfaces. This makes sense because those ethernet interfaces are only 1Gb/s. The rest of the devices are as follows: Bus 25:00:0 is a BOSS card Bus 00:11.5 is the platform controller hub (PCH) If you're curious why you don't see the iDRAC's ethernet interface, this is because all communication with the iDRAC, assuming you aren't using RMI, goes through the PCH. Bus 03:00.0 is the VGA port For the eagle eyed you may notice the PERC is absent - I have it disconnected right now. It would normally have shown up on package L#0.","title":"Interpreting PCIe"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#understanding-pcie-switches-vs-functions","text":"The last thing I thought was a bit hard to descipher without some cross reference","title":"Understanding PCIe Switches vs Functions"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#research","text":"","title":"Research"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#translation-lookaside-buffer","text":"See: https://en.wikipedia.org/wiki/Translation_lookaside_buffer A translation lookaside buffer (TLB) is a memory cache that is used to reduce the time taken to access a user memory location.[1] It is a part of the chip's memory-management unit (MMU). The TLB stores the recent translations of virtual memory to physical memory and can be called an address-translation cache. A TLB may reside between the CPU and the CPU cache, between CPU cache and the main memory or between the different levels of the multi-level cache. The majority of desktop, laptop, and server processors include one or more TLBs in the memory-management hardware, and it is nearly always present in any processor that utilizes paged or segmented virtual memory.","title":"Translation Lookaside Buffer"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#tlb-misses","text":"See 18-notes.pdf","title":"TLB Misses"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#data-and-instruction-caches","text":"See 18-notes.pdf","title":"Data and Instruction Caches"},{"location":"How%20to%20Read%20lstopo%20and%20a%20PCIe%20Overview/#stackexchange-explanaton-of-lstopo","text":"https://unix.stackexchange.com/a/113549/240147","title":"StackExchange Explanaton of lstopo"},{"location":"IO%20Identities%20with%20LifeCycle%20Controller/","text":"IO Identities with LifeCycle Controller Sources IO Identity Setup Using Lifecycle Controller Dell Simple NIC Profile Dell SystemInfo Profile Explanation On a per card basis there is a way to set virtual attributes for all of the following:\u200b Virtual MAC Address Virtual iSCSI MAC Address Virtual FIP MAC Address Virtual WWN Virtual WWPN When you create an identity pool in OME, it leverages this capability under the hood to make it happen. The way it works is Dell seems to provide an upper API capability described here: https://downloads.dell.com/manuals/common/dell-simple_nic_profile.pdf\u200b via the idrac with a thing called CIM (Common Information Model - see https://downloads.dell.com/solutions/general-solution-resources/White%20Papers/Dell_SystemInfo_Profile.pdf). The common information model is basically our standardized way of representing resources on the idrac. One of those resources is \"Simple NIC profile\": \u200b You can see from the spec sheet that the following functions have to be implemented for any given NIC: The DCIM_NICService class is the one that implements the SetAttributes method mentioned in the white paper. The white paper explores how this is done for each card, but the TLDR is that we really do have a card-specific API implementation for all our major vendors and that is how we are changing this stuff under the hood.","title":"IO Identities with LifeCycle Controller"},{"location":"IO%20Identities%20with%20LifeCycle%20Controller/#io-identities-with-lifecycle-controller","text":"","title":"IO Identities with LifeCycle Controller"},{"location":"IO%20Identities%20with%20LifeCycle%20Controller/#sources","text":"IO Identity Setup Using Lifecycle Controller Dell Simple NIC Profile Dell SystemInfo Profile","title":"Sources"},{"location":"IO%20Identities%20with%20LifeCycle%20Controller/#explanation","text":"On a per card basis there is a way to set virtual attributes for all of the following:\u200b Virtual MAC Address Virtual iSCSI MAC Address Virtual FIP MAC Address Virtual WWN Virtual WWPN When you create an identity pool in OME, it leverages this capability under the hood to make it happen. The way it works is Dell seems to provide an upper API capability described here: https://downloads.dell.com/manuals/common/dell-simple_nic_profile.pdf\u200b via the idrac with a thing called CIM (Common Information Model - see https://downloads.dell.com/solutions/general-solution-resources/White%20Papers/Dell_SystemInfo_Profile.pdf). The common information model is basically our standardized way of representing resources on the idrac. One of those resources is \"Simple NIC profile\": \u200b You can see from the spec sheet that the following functions have to be implemented for any given NIC: The DCIM_NICService class is the one that implements the SetAttributes method mentioned in the white paper. The white paper explores how this is done for each card, but the TLDR is that we really do have a card-specific API implementation for all our major vendors and that is how we are changing this stuff under the hood.","title":"Explanation"},{"location":"Importing%20Elasticsearch%20Data/","text":"Importing Elasticsearch Data WARNING These instructions are rough. Move your Elasticsearch snapshot folder to a known folder. For our example, I used /opt/snapshots . Next you will need to tell Elasticsearch about this path by adding the path.repo directive in the configuration file. Run: vim /etc/elasticsearch/elasticsearch.yml # Add `path.repo: [\"/opt/snapshots\"]` Now you need to import the data itself into Elasticsearch. Import with: curl -X PUT \"localhost:9200/_snapshot/esdata?pretty\" -H 'Content-Type: application/json' -d' { \"type\": \"fs\", \"settings\": { \"location\": \"/opt/snapshots\", \"compress\": true } } ' Note: It took about 5 minutes for the snapshot to load Next you will need to restore the snapshot by doing the following: Go to management, saved objects, import, select file on your local computer Import dashboards into Elasticsearch curl -O http://192.168.122.1:8000/kibana-export.json Helpful Commands View a list of the snapshots: curl localhost:9200/_cat/snapshots/esdata curl -X GET \"localhost:9200/_snapshot/_status?pretty\" Restore the snapshot with: curl -X POST \"localhost:9200/_snapshot/esdata/snapshot_1/_restore?pretty\" Install Moloch Run yum install -y https://files.molo.ch/builds/centos-7/moloch-1.1.1-1.x86_64.rpm Configure Moloch with /data/moloch/bin/Configure Run /data/moloch/db/db.pl http://ESHOST:9200 init to init the cluster Add user /data/moloch/bin/moloch_add_user.sh admin \"Admin User\" password --admin Import your data with ./bin/moloch-capture -c etc/config.ini -R <YOUR_DIRECTORY> . You can import individual files with lowercase -r.","title":"Importing Elasticsearch Data"},{"location":"Importing%20Elasticsearch%20Data/#importing-elasticsearch-data","text":"WARNING These instructions are rough. Move your Elasticsearch snapshot folder to a known folder. For our example, I used /opt/snapshots . Next you will need to tell Elasticsearch about this path by adding the path.repo directive in the configuration file. Run: vim /etc/elasticsearch/elasticsearch.yml # Add `path.repo: [\"/opt/snapshots\"]` Now you need to import the data itself into Elasticsearch. Import with: curl -X PUT \"localhost:9200/_snapshot/esdata?pretty\" -H 'Content-Type: application/json' -d' { \"type\": \"fs\", \"settings\": { \"location\": \"/opt/snapshots\", \"compress\": true } } ' Note: It took about 5 minutes for the snapshot to load Next you will need to restore the snapshot by doing the following: Go to management, saved objects, import, select file on your local computer Import dashboards into Elasticsearch curl -O http://192.168.122.1:8000/kibana-export.json","title":"Importing Elasticsearch Data"},{"location":"Importing%20Elasticsearch%20Data/#helpful-commands","text":"View a list of the snapshots: curl localhost:9200/_cat/snapshots/esdata curl -X GET \"localhost:9200/_snapshot/_status?pretty\" Restore the snapshot with: curl -X POST \"localhost:9200/_snapshot/esdata/snapshot_1/_restore?pretty\"","title":"Helpful Commands"},{"location":"Importing%20Elasticsearch%20Data/#install-moloch","text":"Run yum install -y https://files.molo.ch/builds/centos-7/moloch-1.1.1-1.x86_64.rpm Configure Moloch with /data/moloch/bin/Configure Run /data/moloch/db/db.pl http://ESHOST:9200 init to init the cluster Add user /data/moloch/bin/moloch_add_user.sh admin \"Admin User\" password --admin Import your data with ./bin/moloch-capture -c etc/config.ini -R <YOUR_DIRECTORY> . You can import individual files with lowercase -r.","title":"Install Moloch"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/","text":"Installing DPDK with NapaTech Card System Info I wrote this on CentOS 7 Release CentOS Linux release 7.7.1908 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core) Kernel Linux r840-1.lan 3.10.0-1062.9.1.el7.x86_64 #1 SMP Fri Dec 6 15:49:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux Helpful Documents NUMA Nodes and NapaTech Optimizing the NapaTech Card Settings Install NapaTech Driver Download the Napatech software from here Run yum groupinstall \"Development Tools\" && yum install -y kernel-devel gettext-devel openssl-devel perl-CPAN perl-devel zlib-devel pciutils && yum install -y https://centos7.iuscommunity.org/ius-release.rpm && yum remove -y git && yum install -y git2u-all Unzip and run package_install_3gd.sh Run /opt/napatech3/bin/ntstop.sh && /opt/napatech3/bin/ntstart.sh to restart the NapaTech driver which will create a default configuration file. Update Host Buffers The /opt/napatech3/config/ntservice.ini contains the following settings that control the number and size of hostbuffers. To increase the number of CPUs/Cores which we can leverage with the SmartNIC, we need to increase the number of hostbuffers. Host buffers in Napatech Software Suite are the buffers used for moving (DMA) data packets between the accelerator and the applications. In the config file it should look like this: HostBuffersRx = [64,16,-1] # [x1, x2, x3], ... HostBuffersTx = [64,16,-1] # [x1, x2, x3], ... First number is the number of host buffers Second number is the size of the host buffers in MegaBytes Third number is the NUMA node You have to have one set of numbers for each NUMA node. -1 means read the NUMA node setting in the NumaNode directive in the configuration file. HostBuffersRx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] HostBuffersTx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] You can check what NUMA node your card is on with: cat \"/sys/bus/pci/devices/0000:5b:00.0/numa_node\" . You'll just have to replace the bus ID with your card's bus ID. You can retrieve that with the /opt/napatech3/bin/adapterinfo command. Install DPDK export NAPATECH3_PATH=/opt/napatech3 Download with git clone https://github.com/napatech/dpdk.git 1.I put this in /opt and will assume you have done the same in this guide. Edit the security limits with vim /etc/security/limits.conf . After making the below edits you will need to log out and log back in for them to take effect. 1.Add the following lines at the end of the file. This assumes you are running as root: root hard memlock unlimited root soft memlock unlimited Run yum install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc libpcap-devel python36-devel set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=/opt/dpdk (or your directory) Run make config T=x86_64-native-linuxapp-gcc install CONFIG_RTE_LIBRTE_PMD_PCAP=y CONFIG_RTE_LIBRTE_PDUMP=y DESTDIR=install CONFIG_RTE_LIBRTE_PMD_NTACC=y to build dpdk. Ensure your install directory exists. make -j NOTE : The option CONFIG_RTE_LIBRTE_PMD_PCAP=y enabled libpcap support in DPDK. This is required for pdump to work. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile Update Your Bash Profile Add: export RTE_SDK=/opt/dpdk export NAPATECH3_PATH=/opt/napatech3 export RTE_TARGET=/opt/dpdk/x86_64-native-linuxapp-gcc to ~/.bash_profile Install ELF Tools Run the following: pip3 install numpy pip3 install elftools pip3 install pyelftools Configuration Configure Ports Move to your dpdk dir and run ./install/share/dpdk/usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. I used a value of 4096 for each NUMA node. For 1GB per NUMA node insert 512.","title":"Installing DPDK with NapaTech Card"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#installing-dpdk-with-napatech-card","text":"","title":"Installing DPDK with NapaTech Card"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#system-info","text":"I wrote this on CentOS 7","title":"System Info"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#release","text":"CentOS Linux release 7.7.1908 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.7.1908 (Core) CentOS Linux release 7.7.1908 (Core)","title":"Release"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#kernel","text":"Linux r840-1.lan 3.10.0-1062.9.1.el7.x86_64 #1 SMP Fri Dec 6 15:49:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux","title":"Kernel"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#helpful-documents","text":"NUMA Nodes and NapaTech Optimizing the NapaTech Card Settings","title":"Helpful Documents"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#install-napatech-driver","text":"Download the Napatech software from here Run yum groupinstall \"Development Tools\" && yum install -y kernel-devel gettext-devel openssl-devel perl-CPAN perl-devel zlib-devel pciutils && yum install -y https://centos7.iuscommunity.org/ius-release.rpm && yum remove -y git && yum install -y git2u-all Unzip and run package_install_3gd.sh Run /opt/napatech3/bin/ntstop.sh && /opt/napatech3/bin/ntstart.sh to restart the NapaTech driver which will create a default configuration file.","title":"Install NapaTech Driver"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#update-host-buffers","text":"The /opt/napatech3/config/ntservice.ini contains the following settings that control the number and size of hostbuffers. To increase the number of CPUs/Cores which we can leverage with the SmartNIC, we need to increase the number of hostbuffers. Host buffers in Napatech Software Suite are the buffers used for moving (DMA) data packets between the accelerator and the applications. In the config file it should look like this: HostBuffersRx = [64,16,-1] # [x1, x2, x3], ... HostBuffersTx = [64,16,-1] # [x1, x2, x3], ... First number is the number of host buffers Second number is the size of the host buffers in MegaBytes Third number is the NUMA node You have to have one set of numbers for each NUMA node. -1 means read the NUMA node setting in the NumaNode directive in the configuration file. HostBuffersRx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] HostBuffersTx = [16,2048,0],[16,2048,1],[16,2048,2],[16,2048,3] You can check what NUMA node your card is on with: cat \"/sys/bus/pci/devices/0000:5b:00.0/numa_node\" . You'll just have to replace the bus ID with your card's bus ID. You can retrieve that with the /opt/napatech3/bin/adapterinfo command.","title":"Update Host Buffers"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#install-dpdk","text":"export NAPATECH3_PATH=/opt/napatech3 Download with git clone https://github.com/napatech/dpdk.git 1.I put this in /opt and will assume you have done the same in this guide. Edit the security limits with vim /etc/security/limits.conf . After making the below edits you will need to log out and log back in for them to take effect. 1.Add the following lines at the end of the file. This assumes you are running as root: root hard memlock unlimited root soft memlock unlimited Run yum install -y gcc numactl-devel kernel-devel pciutils elfutils-libelf-devel make libpcap python3 tar vim wget tmux vim mlocate hwloc libpcap-devel python36-devel set the environment variable RTE_SDK. It is the directory in which you extracted all the DPDK files. export RTE_SDK=/opt/dpdk (or your directory) Run make config T=x86_64-native-linuxapp-gcc install CONFIG_RTE_LIBRTE_PMD_PCAP=y CONFIG_RTE_LIBRTE_PDUMP=y DESTDIR=install CONFIG_RTE_LIBRTE_PMD_NTACC=y to build dpdk. Ensure your install directory exists. make -j NOTE : The option CONFIG_RTE_LIBRTE_PMD_PCAP=y enabled libpcap support in DPDK. This is required for pdump to work. Once an DPDK target environment directory has been created (such as x86_64-native-linux-gcc), it contains all libraries and header files required to build an application. When compiling an application in the Linux* environment on the DPDK, the following variables must be exported: RTE_TARGET - Points to the DPDK target environment directory. export RTE_TARGET=/opt/dpdk-19.08/x86_64-native-linux-gcc You may want to add this variable and RTE_SDK to ~/.bash_profile","title":"Install DPDK"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#update-your-bash-profile","text":"Add: export RTE_SDK=/opt/dpdk export NAPATECH3_PATH=/opt/napatech3 export RTE_TARGET=/opt/dpdk/x86_64-native-linuxapp-gcc to ~/.bash_profile","title":"Update Your Bash Profile"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#install-elf-tools","text":"Run the following: pip3 install numpy pip3 install elftools pip3 install pyelftools","title":"Install ELF Tools"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#configuration","text":"","title":"Configuration"},{"location":"Installing%20DPDK%20with%20NapaTech%20Card/#configure-ports","text":"Move to your dpdk dir and run ./install/share/dpdk/usertools/dpdk-setup.sh . This should give you a menu with all available DPDK options. The menu is setup in such a way that you must perform each step listed in the menu. If things have gone correctly to this point your Step 1 should look like the following: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * My menu looks like this: ---------------------------------------------------------- Step 1: Select the DPDK environment to build ---------------------------------------------------------- [1] * ---------------------------------------------------------- Step 2: Setup linux environment ---------------------------------------------------------- [2] Insert IGB UIO module [3] Insert VFIO module [4] Insert KNI module [5] Setup hugepage mappings for non-NUMA systems [6] Setup hugepage mappings for NUMA systems [7] Display current Ethernet/Baseband/Crypto device settings [8] Bind Ethernet/Baseband/Crypto device to IGB UIO module [9] Bind Ethernet/Baseband/Crypto device to VFIO module [10] Setup VFIO permissions ---------------------------------------------------------- Step 3: Run test application for linux environment ---------------------------------------------------------- [11] Run test application ($RTE_TARGET/app/test) [12] Run testpmd application in interactive mode ($RTE_TARGET/app/testpmd) ---------------------------------------------------------- Step 4: Other tools ---------------------------------------------------------- [13] List hugepage info from /proc/meminfo ---------------------------------------------------------- Step 5: Uninstall and system cleanup ---------------------------------------------------------- [14] Unbind devices from IGB UIO or VFIO driver [15] Remove IGB UIO module [16] Remove VFIO module [17] Remove KNI module [18] Remove hugepage mappings [19] Exit Script Next run option 6 to instert huge pages for NUMA systems. Notice you will be prompted to select an amount of memory on a per processor basis. This is because there are pages associated with each individual processor to increase performance via locality. I used a value of 4096 for each NUMA node. For 1GB per NUMA node insert 512.","title":"Configure Ports"},{"location":"LDAP%20with%20OpenManage/","text":"LDAP with OpenManage My Environment RHEL Version NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.2 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.2\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.2 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.2\" Red Hat Enterprise Linux release 8.2 (Ootpa) Red Hat Enterprise Linux release 8.2 (Ootpa) FreeIPA Version [root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235 OpenManage Version Version 3.4.1 (Build 24) Helpful Resources Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN Install Instructions Install RHEL Change hostname 1. hostname freeipa.grant.lan && hostnamectl set-hostname freeipa.grant.lan 2.Change in /etc/hostname 3.Configure DNS to return for this hostname. Double check with dig +short freeipa.grant.lan A && dig +short -x 192.168.1.95 Follow RHEL's instructions 1.I used Chapter 5 for primary installation 2.Make sure you add the requested DNS entries at the end Run firewall-cmd --permanent --add-port={80/tcp,443/tcp,389/tcp,636/tcp,88/tcp,464/tcp,88/udp,464/udp,123/udp} && firewall-cmd --reload to allow the appropriate ports Run kinit admin - this allows you to use the command line tools otherwise they'll complain about kerberos. Log into FreeIPA server at https://<your_hostname> . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Add a user other than administrator. Go to Users and then directory services in OpenManage. I used the following: Note: You can get the Bind DN by running ldapsearch from the command line. Create a new user and new group in the UI and assign the new user to the new group. Install OpenManage Go to Application Settings -> Directory Services Substitute with your values and then click test. I wasn't able to get this to work with the generic admin user. In the test screen I used that new user to connect to directory services Helpful Commands To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status . Test LDAP credentials: ldapwhoami -vvv -h 192.168.1.95 -p 389 -D 'uid=grant,cn=users,cn=accounts,dc=grant,dc=lan' -x -w <PASSWORD> Dump the structure of FreeIPA: ldapsearch -x -H ldap://localhost -b \"cn=accounts,dc=grant,dc=lan\" -D \"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" -w <YOUR_USERS_PASSWORD> | less You can also use this to check to see if a user is a member of a group by changing the base path to search (-b). Change it to what you think the FQDN of the group is. The user in question should show up. Update FreeIPA Schema Request received: [23/Oct/2020:07:12:13.558111497 -0400] conn=22 fd=101 slot=101 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:07:12:13.605452505 -0400] conn=22 TLS1.2 128-bit AES-GCM [23/Oct/2020:07:12:13.607423551 -0400] conn=22 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [23/Oct/2020:07:12:13.633734712 -0400] conn=22 op=0 RESULT err=0 tag=97 nentries=0 etime=0.075252172 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [23/Oct/2020:07:12:13.634444660 -0400] conn=22 op=1 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [23/Oct/2020:07:12:13.636377426 -0400] conn=22 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001994528 [23/Oct/2020:07:12:13.637728783 -0400] conn=22 op=2 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(|(member=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan)(member=grant))\" attrs=ALL [23/Oct/2020:07:12:13.638251981 -0400] conn=22 op=2 RESULT err=0 tag=101 nentries=2 etime=0.000588138 [23/Oct/2020:07:12:13.640124457 -0400] conn=23 fd=103 slot=103 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:07:12:13.684231843 -0400] conn=23 TLS1.2 128-bit AES-GCM [23/Oct/2020:07:12:13.685087831 -0400] conn=23 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [23/Oct/2020:07:12:13.685478906 -0400] conn=23 op=0 RESULT err=0 tag=97 nentries=0 etime=0.044995726 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [23/Oct/2020:07:12:13.686411703 -0400] conn=23 op=1 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(|(member=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan)(member=grant))\" attrs=\"entryuuid cn\" [23/Oct/2020:07:12:13.686675968 -0400] conn=23 op=1 RESULT err=0 tag=101 nentries=2 etime=0.000324070 [23/Oct/2020:07:12:13.687691917 -0400] conn=23 op=2 UNBIND [23/Oct/2020:07:12:13.687704782 -0400] conn=23 op=2 fd=103 closed - U1 sed -i -e \"s/NAME 'ipaUniqueID'/NAME ('ipaUniqueID' 'entryUUID')/\" /etc/dirsrv/slapd-*/schema/60basev2.ldif ipa-ldap-updater -u --schema-file=$(ls /etc/dirsrv/slapd-*/schema/60basev2.ldif) After making the above modification I now get: [23/Oct/2020:08:16:51.891366602 -0400] conn=30 fd=101 slot=101 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:08:16:51.938289338 -0400] conn=30 TLS1.2 128-bit AES-GCM [23/Oct/2020:08:16:51.939209205 -0400] conn=30 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [23/Oct/2020:08:16:51.965507560 -0400] conn=30 op=0 RESULT err=49 tag=97 nentries=0 etime=0.073775627 - Invalid credentials [23/Oct/2020:08:16:51.966077916 -0400] conn=30 op=-1 fd=101 closed - B1 [23/Oct/2020:08:16:51.970300516 -0400] conn=31 fd=101 slot=101 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:08:16:52.015244484 -0400] conn=31 TLS1.2 128-bit AES-GCM [23/Oct/2020:08:16:52.015949382 -0400] conn=31 op=0 BIND dn=\"\" method=128 version=3 [23/Oct/2020:08:16:52.016032928 -0400] conn=31 op=0 RESULT err=0 tag=97 nentries=0 etime=0.045312604 dn=\"\" [23/Oct/2020:08:16:52.017337373 -0400] conn=31 op=1 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(|(member=null)(member=grant))\" attrs=\"ipaUniqueID cn\" [23/Oct/2020:08:16:52.017436879 -0400] conn=31 op=1 RESULT err=0 tag=101 nentries=0 etime=0.000150394 [23/Oct/2020:08:16:52.018338463 -0400] conn=31 op=2 UNBIND [23/Oct/2020:08:16:52.018350155 -0400] conn=31 op=2 fd=101 closed - U1 [23/Oct/2020:08:20:26.725516663 -0400] conn=21 op=2 SRCH base=\"ou=sessions,ou=Security Domain,o=ipaca\" scope=2 filter=\"(objectClass=securityDomainSessionEntry)\" attrs=\"cn\" [23/Oct/2020:08:20:26.725732986 -0400] conn=21 op=2 RESULT err=32 tag=101 nentries=0 etime=0.000316769","title":"LDAP with OpenManage"},{"location":"LDAP%20with%20OpenManage/#ldap-with-openmanage","text":"","title":"LDAP with OpenManage"},{"location":"LDAP%20with%20OpenManage/#my-environment","text":"","title":"My Environment"},{"location":"LDAP%20with%20OpenManage/#rhel-version","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.2 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.2\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.2 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.2\" Red Hat Enterprise Linux release 8.2 (Ootpa) Red Hat Enterprise Linux release 8.2 (Ootpa)","title":"RHEL Version"},{"location":"LDAP%20with%20OpenManage/#freeipa-version","text":"[root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235","title":"FreeIPA Version"},{"location":"LDAP%20with%20OpenManage/#openmanage-version","text":"Version 3.4.1 (Build 24)","title":"OpenManage Version"},{"location":"LDAP%20with%20OpenManage/#helpful-resources","text":"Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN","title":"Helpful Resources"},{"location":"LDAP%20with%20OpenManage/#install-instructions","text":"Install RHEL Change hostname 1. hostname freeipa.grant.lan && hostnamectl set-hostname freeipa.grant.lan 2.Change in /etc/hostname 3.Configure DNS to return for this hostname. Double check with dig +short freeipa.grant.lan A && dig +short -x 192.168.1.95 Follow RHEL's instructions 1.I used Chapter 5 for primary installation 2.Make sure you add the requested DNS entries at the end Run firewall-cmd --permanent --add-port={80/tcp,443/tcp,389/tcp,636/tcp,88/tcp,464/tcp,88/udp,464/udp,123/udp} && firewall-cmd --reload to allow the appropriate ports Run kinit admin - this allows you to use the command line tools otherwise they'll complain about kerberos. Log into FreeIPA server at https://<your_hostname> . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Add a user other than administrator. Go to Users and then directory services in OpenManage. I used the following: Note: You can get the Bind DN by running ldapsearch from the command line. Create a new user and new group in the UI and assign the new user to the new group. Install OpenManage Go to Application Settings -> Directory Services Substitute with your values and then click test. I wasn't able to get this to work with the generic admin user. In the test screen I used that new user to connect to directory services","title":"Install Instructions"},{"location":"LDAP%20with%20OpenManage/#helpful-commands","text":"To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status . Test LDAP credentials: ldapwhoami -vvv -h 192.168.1.95 -p 389 -D 'uid=grant,cn=users,cn=accounts,dc=grant,dc=lan' -x -w <PASSWORD> Dump the structure of FreeIPA: ldapsearch -x -H ldap://localhost -b \"cn=accounts,dc=grant,dc=lan\" -D \"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" -w <YOUR_USERS_PASSWORD> | less You can also use this to check to see if a user is a member of a group by changing the base path to search (-b). Change it to what you think the FQDN of the group is. The user in question should show up.","title":"Helpful Commands"},{"location":"LDAP%20with%20OpenManage/#update-freeipa-schema","text":"Request received: [23/Oct/2020:07:12:13.558111497 -0400] conn=22 fd=101 slot=101 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:07:12:13.605452505 -0400] conn=22 TLS1.2 128-bit AES-GCM [23/Oct/2020:07:12:13.607423551 -0400] conn=22 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [23/Oct/2020:07:12:13.633734712 -0400] conn=22 op=0 RESULT err=0 tag=97 nentries=0 etime=0.075252172 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [23/Oct/2020:07:12:13.634444660 -0400] conn=22 op=1 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [23/Oct/2020:07:12:13.636377426 -0400] conn=22 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001994528 [23/Oct/2020:07:12:13.637728783 -0400] conn=22 op=2 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(|(member=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan)(member=grant))\" attrs=ALL [23/Oct/2020:07:12:13.638251981 -0400] conn=22 op=2 RESULT err=0 tag=101 nentries=2 etime=0.000588138 [23/Oct/2020:07:12:13.640124457 -0400] conn=23 fd=103 slot=103 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:07:12:13.684231843 -0400] conn=23 TLS1.2 128-bit AES-GCM [23/Oct/2020:07:12:13.685087831 -0400] conn=23 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [23/Oct/2020:07:12:13.685478906 -0400] conn=23 op=0 RESULT err=0 tag=97 nentries=0 etime=0.044995726 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [23/Oct/2020:07:12:13.686411703 -0400] conn=23 op=1 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(|(member=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan)(member=grant))\" attrs=\"entryuuid cn\" [23/Oct/2020:07:12:13.686675968 -0400] conn=23 op=1 RESULT err=0 tag=101 nentries=2 etime=0.000324070 [23/Oct/2020:07:12:13.687691917 -0400] conn=23 op=2 UNBIND [23/Oct/2020:07:12:13.687704782 -0400] conn=23 op=2 fd=103 closed - U1 sed -i -e \"s/NAME 'ipaUniqueID'/NAME ('ipaUniqueID' 'entryUUID')/\" /etc/dirsrv/slapd-*/schema/60basev2.ldif ipa-ldap-updater -u --schema-file=$(ls /etc/dirsrv/slapd-*/schema/60basev2.ldif) After making the above modification I now get: [23/Oct/2020:08:16:51.891366602 -0400] conn=30 fd=101 slot=101 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:08:16:51.938289338 -0400] conn=30 TLS1.2 128-bit AES-GCM [23/Oct/2020:08:16:51.939209205 -0400] conn=30 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [23/Oct/2020:08:16:51.965507560 -0400] conn=30 op=0 RESULT err=49 tag=97 nentries=0 etime=0.073775627 - Invalid credentials [23/Oct/2020:08:16:51.966077916 -0400] conn=30 op=-1 fd=101 closed - B1 [23/Oct/2020:08:16:51.970300516 -0400] conn=31 fd=101 slot=101 SSL connection from 192.168.1.93 to 192.168.1.95 [23/Oct/2020:08:16:52.015244484 -0400] conn=31 TLS1.2 128-bit AES-GCM [23/Oct/2020:08:16:52.015949382 -0400] conn=31 op=0 BIND dn=\"\" method=128 version=3 [23/Oct/2020:08:16:52.016032928 -0400] conn=31 op=0 RESULT err=0 tag=97 nentries=0 etime=0.045312604 dn=\"\" [23/Oct/2020:08:16:52.017337373 -0400] conn=31 op=1 SRCH base=\"cn=accounts,dc=grant,dc=lan\" scope=2 filter=\"(|(member=null)(member=grant))\" attrs=\"ipaUniqueID cn\" [23/Oct/2020:08:16:52.017436879 -0400] conn=31 op=1 RESULT err=0 tag=101 nentries=0 etime=0.000150394 [23/Oct/2020:08:16:52.018338463 -0400] conn=31 op=2 UNBIND [23/Oct/2020:08:16:52.018350155 -0400] conn=31 op=2 fd=101 closed - U1 [23/Oct/2020:08:20:26.725516663 -0400] conn=21 op=2 SRCH base=\"ou=sessions,ou=Security Domain,o=ipaca\" scope=2 filter=\"(objectClass=securityDomainSessionEntry)\" attrs=\"cn\" [23/Oct/2020:08:20:26.725732986 -0400] conn=21 op=2 RESULT err=32 tag=101 nentries=0 etime=0.000316769","title":"Update FreeIPA Schema"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/","text":"Setting Up OpenLDAP with OpenManage My Environment CentOS Version CentOS Linux release 8.2.2004 (Core) NAME=\"CentOS Linux\" VERSION=\"8 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"8\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"CentOS Linux 8 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:8\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-8\" CENTOS_MANTISBT_PROJECT_VERSION=\"8\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8\" CentOS Linux release 8.2.2004 (Core) CentOS Linux release 8.2.2004 (Core) IPA Version [root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235 OpenManage Version Version 3.5.0 (Build 60) Helpful Resources Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN OpenManage User's Guide Install Instructions Install CentOS8 1.I installed CentOS minimal 2.Make sure NTP is working correctly Install OpenManage For the OpenLDAP setup I followed Install and Setup OpenLDAP on CentOS 8 by koromicha I want the current version of OpenLDAP so I'll be building it from source. Install dependencies with dnf install -y cyrus-sasl-devel make libtool autoconf libtool-ltdl-devel openssl-devel libdb-devel tar gcc perl perl-devel wget vim Create non privileged system user: useradd -r -M -d /var/lib/openldap -u 55 -s /usr/sbin/nologin ldap Pull tarball wget https://www.openldap.org/software/download/OpenLDAP/openldap-release/openldap-2.4.54.tgz && tar xzf openldap-2.4.54.tgz && cd openldap-2.4.54 Build and install OpenLDAP ./configure --prefix=/usr --sysconfdir=/etc --disable-static --enable-debug --with-tls=openssl --with-cyrus-sasl --enable-dynamic --enable-crypt --enable-spasswd --enable-slapd --enable-modules --enable-rlookups --enable-backends=mod --disable-ndb --disable-sql --disable-shell --disable-bdb --disable-hdb --enable-overlays=mod && make depend && make -j2 && make install Configure OpenLDAP mkdir /var/lib/openldap /etc/openldap/slapd.d && chown -R ldap:ldap /var/lib/openldap && chown root:ldap /etc/openldap/slapd.conf Add an OpenLDAP systemd service vim /etc/systemd/system/slapd.service [Unit] Description=OpenLDAP Server Daemon After=syslog.target network-online.target Documentation=man:slapd Documentation=man:slapd-mdb [Service] Type=forking PIDFile=/var/lib/openldap/slapd.pid Environment=\"SLAPD_URLS=ldap:/// ldapi:/// ldaps:///\" Environment=\"SLAPD_OPTIONS=-F /etc/openldap/slapd.d\" ExecStart=/usr/libexec/slapd -u ldap -g ldap -h ${SLAPD_URLS} $SLAPD_OPTIONS [Install] WantedBy=multi-user.target Check if your version of sudo supports lday with sudo -V | grep -i \"ldap\" and confirm the below lines are present: ldap.conf path: /etc/sudo-ldap.conf ldap.secret path: /etc/ldap.secret Make sure LDAP sudo schema is available with rpm -ql sudo | grep -i schema.openldap . You should see /usr/share/doc/sudo/schema.OpenLDAP Run: cp /usr/share/doc/sudo/schema.OpenLDAP /etc/openldap/schema/sudo.schema cat << 'EOL' > /etc/openldap/schema/sudo.ldif dn: cn=sudo,cn=schema,cn=config objectClass: olcSchemaConfig cn: sudo olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.1 NAME 'sudoUser' DESC 'User(s) who may run sudo' EQUALITY caseExactIA5Match SUBSTR caseExactIA5SubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.2 NAME 'sudoHost' DESC 'Host(s) who may run sudo' EQUALITY caseExactIA5Match SUBSTR caseExactIA5SubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.3 NAME 'sudoCommand' DESC 'Command(s) to be executed by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.4 NAME 'sudoRunAs' DESC 'User(s) impersonated by sudo (deprecated)' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.5 NAME 'sudoOption' DESC 'Options(s) followed by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.6 NAME 'sudoRunAsUser' DESC 'User(s) impersonated by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.7 NAME 'sudoRunAsGroup' DESC 'Group(s) impersonated by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcObjectClasses: ( 1.3.6.1.4.1.15953.9.2.1 NAME 'sudoRole' SUP top STRUCTURAL DESC 'Sudoer Entries' MUST ( cn ) MAY ( sudoUser $ sudoHost $ sudoCommand $ sudoRunAs $ sudoRunAsUser $ sudoRunAsGroup $ sudoOption $ description ) ) EOL mv /etc/openldap/slapd.ldif /etc/openldap/slapd.ldif.bak vim /etc/openldap/slapd.ldif dn: cn=config objectClass: olcGlobal cn: config olcArgsFile: /var/lib/openldap/slapd.args olcPidFile: /var/lib/openldap/slapd.pid dn: cn=schema,cn=config objectClass: olcSchemaConfig cn: schema dn: cn=module,cn=config objectClass: olcModuleList cn: module olcModulepath: /usr/libexec/openldap olcModuleload: back_mdb.la include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/cosine.ldif include: file:///etc/openldap/schema/nis.ldif include: file:///etc/openldap/schema/inetorgperson.ldif include: file:///etc/openldap/schema/ppolicy.ldif include: file:///etc/openldap/schema/sudo.ldif dn: olcDatabase=frontend,cn=config objectClass: olcDatabaseConfig objectClass: olcFrontendConfig olcDatabase: frontend olcAccess: to dn.base=\"cn=Subschema\" by * read olcAccess: to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\" manage by * none dn: olcDatabase=config,cn=config objectClass: olcDatabaseConfig olcDatabase: config olcRootDN: cn=config olcAccess: to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\" manage by * none Make sure slapadd -n 0 -F /etc/openldap/slapd.d -l /etc/openldap/slapd.ldif -u runs without error Run slapadd -n 0 -F /etc/openldap/slapd.d -l /etc/openldap/slapd.ldif && chown -R ldap:ldap /etc/openldap/slapd.d/* && systemctl daemon-reload && systemctl enable --now slapd && systemctl status slapd SLAPD LOGGING NOT WORKING Run slappasswd and note the hash output. Helpful Commands To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status .","title":"Setting Up OpenLDAP with OpenManage"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#setting-up-openldap-with-openmanage","text":"","title":"Setting Up OpenLDAP with OpenManage"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#my-environment","text":"","title":"My Environment"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#centos-version","text":"CentOS Linux release 8.2.2004 (Core) NAME=\"CentOS Linux\" VERSION=\"8 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"8\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"CentOS Linux 8 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:8\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-8\" CENTOS_MANTISBT_PROJECT_VERSION=\"8\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8\" CentOS Linux release 8.2.2004 (Core) CentOS Linux release 8.2.2004 (Core)","title":"CentOS Version"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#ipa-version","text":"[root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235","title":"IPA Version"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#openmanage-version","text":"Version 3.5.0 (Build 60)","title":"OpenManage Version"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#helpful-resources","text":"Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN OpenManage User's Guide","title":"Helpful Resources"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#install-instructions","text":"Install CentOS8 1.I installed CentOS minimal 2.Make sure NTP is working correctly Install OpenManage For the OpenLDAP setup I followed Install and Setup OpenLDAP on CentOS 8 by koromicha I want the current version of OpenLDAP so I'll be building it from source. Install dependencies with dnf install -y cyrus-sasl-devel make libtool autoconf libtool-ltdl-devel openssl-devel libdb-devel tar gcc perl perl-devel wget vim Create non privileged system user: useradd -r -M -d /var/lib/openldap -u 55 -s /usr/sbin/nologin ldap Pull tarball wget https://www.openldap.org/software/download/OpenLDAP/openldap-release/openldap-2.4.54.tgz && tar xzf openldap-2.4.54.tgz && cd openldap-2.4.54 Build and install OpenLDAP ./configure --prefix=/usr --sysconfdir=/etc --disable-static --enable-debug --with-tls=openssl --with-cyrus-sasl --enable-dynamic --enable-crypt --enable-spasswd --enable-slapd --enable-modules --enable-rlookups --enable-backends=mod --disable-ndb --disable-sql --disable-shell --disable-bdb --disable-hdb --enable-overlays=mod && make depend && make -j2 && make install Configure OpenLDAP mkdir /var/lib/openldap /etc/openldap/slapd.d && chown -R ldap:ldap /var/lib/openldap && chown root:ldap /etc/openldap/slapd.conf Add an OpenLDAP systemd service vim /etc/systemd/system/slapd.service [Unit] Description=OpenLDAP Server Daemon After=syslog.target network-online.target Documentation=man:slapd Documentation=man:slapd-mdb [Service] Type=forking PIDFile=/var/lib/openldap/slapd.pid Environment=\"SLAPD_URLS=ldap:/// ldapi:/// ldaps:///\" Environment=\"SLAPD_OPTIONS=-F /etc/openldap/slapd.d\" ExecStart=/usr/libexec/slapd -u ldap -g ldap -h ${SLAPD_URLS} $SLAPD_OPTIONS [Install] WantedBy=multi-user.target Check if your version of sudo supports lday with sudo -V | grep -i \"ldap\" and confirm the below lines are present: ldap.conf path: /etc/sudo-ldap.conf ldap.secret path: /etc/ldap.secret Make sure LDAP sudo schema is available with rpm -ql sudo | grep -i schema.openldap . You should see /usr/share/doc/sudo/schema.OpenLDAP Run: cp /usr/share/doc/sudo/schema.OpenLDAP /etc/openldap/schema/sudo.schema cat << 'EOL' > /etc/openldap/schema/sudo.ldif dn: cn=sudo,cn=schema,cn=config objectClass: olcSchemaConfig cn: sudo olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.1 NAME 'sudoUser' DESC 'User(s) who may run sudo' EQUALITY caseExactIA5Match SUBSTR caseExactIA5SubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.2 NAME 'sudoHost' DESC 'Host(s) who may run sudo' EQUALITY caseExactIA5Match SUBSTR caseExactIA5SubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.3 NAME 'sudoCommand' DESC 'Command(s) to be executed by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.4 NAME 'sudoRunAs' DESC 'User(s) impersonated by sudo (deprecated)' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.5 NAME 'sudoOption' DESC 'Options(s) followed by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.6 NAME 'sudoRunAsUser' DESC 'User(s) impersonated by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcAttributeTypes: ( 1.3.6.1.4.1.15953.9.1.7 NAME 'sudoRunAsGroup' DESC 'Group(s) impersonated by sudo' EQUALITY caseExactIA5Match SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 ) olcObjectClasses: ( 1.3.6.1.4.1.15953.9.2.1 NAME 'sudoRole' SUP top STRUCTURAL DESC 'Sudoer Entries' MUST ( cn ) MAY ( sudoUser $ sudoHost $ sudoCommand $ sudoRunAs $ sudoRunAsUser $ sudoRunAsGroup $ sudoOption $ description ) ) EOL mv /etc/openldap/slapd.ldif /etc/openldap/slapd.ldif.bak vim /etc/openldap/slapd.ldif dn: cn=config objectClass: olcGlobal cn: config olcArgsFile: /var/lib/openldap/slapd.args olcPidFile: /var/lib/openldap/slapd.pid dn: cn=schema,cn=config objectClass: olcSchemaConfig cn: schema dn: cn=module,cn=config objectClass: olcModuleList cn: module olcModulepath: /usr/libexec/openldap olcModuleload: back_mdb.la include: file:///etc/openldap/schema/core.ldif include: file:///etc/openldap/schema/cosine.ldif include: file:///etc/openldap/schema/nis.ldif include: file:///etc/openldap/schema/inetorgperson.ldif include: file:///etc/openldap/schema/ppolicy.ldif include: file:///etc/openldap/schema/sudo.ldif dn: olcDatabase=frontend,cn=config objectClass: olcDatabaseConfig objectClass: olcFrontendConfig olcDatabase: frontend olcAccess: to dn.base=\"cn=Subschema\" by * read olcAccess: to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\" manage by * none dn: olcDatabase=config,cn=config objectClass: olcDatabaseConfig olcDatabase: config olcRootDN: cn=config olcAccess: to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\" manage by * none Make sure slapadd -n 0 -F /etc/openldap/slapd.d -l /etc/openldap/slapd.ldif -u runs without error Run slapadd -n 0 -F /etc/openldap/slapd.d -l /etc/openldap/slapd.ldif && chown -R ldap:ldap /etc/openldap/slapd.d/* && systemctl daemon-reload && systemctl enable --now slapd && systemctl status slapd SLAPD LOGGING NOT WORKING Run slappasswd and note the hash output.","title":"Install Instructions"},{"location":"LDAP%20with%20OpenManage/README-CentOS-OpenLDAP/#helpful-commands","text":"To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status .","title":"Helpful Commands"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/","text":"Setting Up FreeIPA with OpenManage Conclusion: Currently FreeIPA isn't supported or tested against OpenManage. See the User's Guide page 137. I'm going to try it with OpenLDAP My Environment CentOS Version CentOS Linux release 8.2.2004 (Core) NAME=\"CentOS Linux\" VERSION=\"8 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"8\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"CentOS Linux 8 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:8\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-8\" CENTOS_MANTISBT_PROJECT_VERSION=\"8\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8\" CentOS Linux release 8.2.2004 (Core) CentOS Linux release 8.2.2004 (Core) FreeIPA Version [root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235 OpenManage Version Version 3.4.1 (Build 24) Helpful Resources Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN Install Instructions Install CentOS8 1.I installed CentOS minimal 2.Make sure NTP is working correctly Install OpenManage Install the idm system module with dnf install -y @idm:DL1 freeipa-server Configure your DNS server ( /etc/hosts did not work for me) with a record for the hostname of your FreeIPA server. I added a record for centos.grant.lan . Run ipa-server-install 1.If you have any DNS failures edit the file /tmp/ipa.system.records.tu5qyl09.db (you may have to change the name) and add the record centos.grant.lan 86400 IN A 192.168.1.92 (adjust accordingly). Afterwards run ipa dns-update-system-records Run kinit admin Open firewall ports firewall-cmd --add-port=80/tcp --permanent --zone=public firewall-cmd --add-port=443/tcp --permanent --zone=public firewall-cmd --add-port=389/tcp --permanent --zone=public firewall-cmd --add-port=636/tcp --permanent --zone=public firewall-cmd --add-port=88/tcp --permanent --zone=public firewall-cmd --add-port=464/tcp --permanent --zone=public firewall-cmd --add-port=88/udp --permanent --zone=public firewall-cmd --add-port=464/udp --permanent --zone=public firewall-cmd --add-port=123/udp --permanent --zone=public firewall-cmd --reload Log into FreeIPA server at https://centos.grant.lan . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Under Active users I added an admin user. Go to Users and then directory services in OpenManage. I used the following: Note: You can get the Bind DN by running ldapsearch from the command line. Helpful Commands To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status . Testing Scenario 1 This got me a working test connection: Output [15/Oct/2020:14:09:18.440103345 -0400] conn=107 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:18.484254084 -0400] conn=107 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:18.484862509 -0400] conn=107 op=0 BIND dn=\"\" method=128 version=3 [15/Oct/2020:14:09:18.485048511 -0400] conn=107 op=0 RESULT err=0 tag=97 nentries=0 etime=0.044677059 dn=\"\" [15/Oct/2020:14:09:18.485743204 -0400] conn=107 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:14:09:18.487440884 -0400] conn=107 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001795760 [15/Oct/2020:14:09:18.488143502 -0400] conn=107 op=2 UNBIND [15/Oct/2020:14:09:18.488159848 -0400] conn=107 op=2 fd=74 closed - U1 [15/Oct/2020:14:09:18.491313979 -0400] conn=108 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:18.536590087 -0400] conn=108 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:18.537372005 -0400] conn=108 op=0 BIND dn=\"uid=grant,cn=users,cn=compat,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:14:09:18.538144502 -0400] conn=108 op=0 RESULT err=0 tag=97 nentries=0 etime=0.046223517 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:14:09:18.538536207 -0400] conn=108 op=1 UNBIND [15/Oct/2020:14:09:18.538566004 -0400] conn=108 op=1 fd=74 closed - U1 [15/Oct/2020:14:09:28.961238173 -0400] conn=109 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:29.005228025 -0400] conn=109 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:29.005755286 -0400] conn=109 op=0 BIND dn=\"\" method=128 version=3 [15/Oct/2020:14:09:29.005931161 -0400] conn=109 op=0 RESULT err=0 tag=97 nentries=0 etime=0.044397507 dn=\"\" [15/Oct/2020:14:09:29.006898618 -0400] conn=109 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:14:09:29.008536186 -0400] conn=109 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001740822 [15/Oct/2020:14:09:29.009182689 -0400] conn=109 op=2 UNBIND [15/Oct/2020:14:09:29.009196697 -0400] conn=109 op=2 fd=74 closed - U1 [15/Oct/2020:14:09:29.012428320 -0400] conn=110 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:29.057469132 -0400] conn=110 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:29.058084024 -0400] conn=110 op=0 BIND dn=\"uid=grant,cn=users,cn=compat,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:14:09:29.058825635 -0400] conn=110 op=0 RESULT err=0 tag=97 nentries=0 etime=0.046016675 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:14:09:29.059166870 -0400] conn=110 op=1 UNBIND [15/Oct/2020:14:09:29.059195118 -0400] conn=110 op=1 fd=74 closed - U1 Scenario 2 When I added a Bind DN as shown in this video I get a failure. Error Message Log Output [15/Oct/2020:14:12:07.504942397 -0400] conn=112 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:12:07.550456498 -0400] conn=112 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:12:07.551077266 -0400] conn=112 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:14:12:07.551767359 -0400] conn=112 op=0 RESULT err=0 tag=97 nentries=0 etime=0.046428458 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:14:12:07.552283396 -0400] conn=112 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:14:12:07.553922212 -0400] conn=112 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001752227 [15/Oct/2020:14:12:07.555518270 -0400] conn=112 op=2 UNBIND [15/Oct/2020:14:12:07.555534158 -0400] conn=112 op=2 fd=74 closed - U1 Scenario 3 - Current Sticking Point Using the settings from scenario 1, I continued. When trying to add a group though, no groups are displayed in available groups. Output [15/Oct/2020:15:19:49.806462707 -0400] conn=169 fd=103 slot=103 SSL connection from 192.168.1.18 to 192.168.1.92 [15/Oct/2020:15:19:49.856773316 -0400] conn=169 TLS1.2 128-bit AES-GCM [15/Oct/2020:15:19:49.858681446 -0400] conn=169 op=0 BIND dn=\"\" method=128 version=3 [15/Oct/2020:15:19:49.858906917 -0400] conn=169 op=0 RESULT err=0 tag=97 nentries=0 etime=0.051584941 dn=\"\" [15/Oct/2020:15:19:49.864335125 -0400] conn=169 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:15:19:49.866001831 -0400] conn=169 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001790286 [15/Oct/2020:15:19:49.867368889 -0400] conn=169 op=2 UNBIND [15/Oct/2020:15:19:49.867386461 -0400] conn=169 op=2 fd=103 closed - U1 [15/Oct/2020:15:19:49.873375865 -0400] conn=170 fd=103 slot=103 SSL connection from 192.168.1.18 to 192.168.1.92 [15/Oct/2020:15:19:49.925956643 -0400] conn=170 TLS1.2 128-bit AES-GCM [15/Oct/2020:15:19:49.928180447 -0400] conn=170 op=0 BIND dn=\"uid=grant,cn=users,cn=compat,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:15:19:49.928993026 -0400] conn=170 op=0 RESULT err=0 tag=97 nentries=0 etime=0.053916831 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:15:19:49.934942058 -0400] conn=170 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(&(cn=grantgroup*)(uniqueMember=*))\" attrs=\"cn entryuuid\" [15/Oct/2020:15:19:49.935438340 -0400] conn=170 op=1 RESULT err=0 tag=101 nentries=0 etime=0.000639539 [15/Oct/2020:15:19:49.936729725 -0400] conn=170 op=2 UNBIND [15/Oct/2020:15:19:49.936744908 -0400] conn=170 op=2 fd=103 closed - U1","title":"Setting Up FreeIPA with OpenManage"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#setting-up-freeipa-with-openmanage","text":"Conclusion: Currently FreeIPA isn't supported or tested against OpenManage. See the User's Guide page 137. I'm going to try it with OpenLDAP","title":"Setting Up FreeIPA with OpenManage"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#my-environment","text":"","title":"My Environment"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#centos-version","text":"CentOS Linux release 8.2.2004 (Core) NAME=\"CentOS Linux\" VERSION=\"8 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"8\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"CentOS Linux 8 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:8\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-8\" CENTOS_MANTISBT_PROJECT_VERSION=\"8\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8\" CentOS Linux release 8.2.2004 (Core) CentOS Linux release 8.2.2004 (Core)","title":"CentOS Version"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#freeipa-version","text":"[root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235","title":"FreeIPA Version"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#openmanage-version","text":"Version 3.4.1 (Build 24)","title":"OpenManage Version"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#helpful-resources","text":"Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN","title":"Helpful Resources"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#install-instructions","text":"Install CentOS8 1.I installed CentOS minimal 2.Make sure NTP is working correctly Install OpenManage Install the idm system module with dnf install -y @idm:DL1 freeipa-server Configure your DNS server ( /etc/hosts did not work for me) with a record for the hostname of your FreeIPA server. I added a record for centos.grant.lan . Run ipa-server-install 1.If you have any DNS failures edit the file /tmp/ipa.system.records.tu5qyl09.db (you may have to change the name) and add the record centos.grant.lan 86400 IN A 192.168.1.92 (adjust accordingly). Afterwards run ipa dns-update-system-records Run kinit admin Open firewall ports firewall-cmd --add-port=80/tcp --permanent --zone=public firewall-cmd --add-port=443/tcp --permanent --zone=public firewall-cmd --add-port=389/tcp --permanent --zone=public firewall-cmd --add-port=636/tcp --permanent --zone=public firewall-cmd --add-port=88/tcp --permanent --zone=public firewall-cmd --add-port=464/tcp --permanent --zone=public firewall-cmd --add-port=88/udp --permanent --zone=public firewall-cmd --add-port=464/udp --permanent --zone=public firewall-cmd --add-port=123/udp --permanent --zone=public firewall-cmd --reload Log into FreeIPA server at https://centos.grant.lan . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Under Active users I added an admin user. Go to Users and then directory services in OpenManage. I used the following: Note: You can get the Bind DN by running ldapsearch from the command line.","title":"Install Instructions"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#helpful-commands","text":"To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status .","title":"Helpful Commands"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#testing","text":"","title":"Testing"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#scenario-1","text":"This got me a working test connection:","title":"Scenario 1"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#output","text":"[15/Oct/2020:14:09:18.440103345 -0400] conn=107 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:18.484254084 -0400] conn=107 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:18.484862509 -0400] conn=107 op=0 BIND dn=\"\" method=128 version=3 [15/Oct/2020:14:09:18.485048511 -0400] conn=107 op=0 RESULT err=0 tag=97 nentries=0 etime=0.044677059 dn=\"\" [15/Oct/2020:14:09:18.485743204 -0400] conn=107 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:14:09:18.487440884 -0400] conn=107 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001795760 [15/Oct/2020:14:09:18.488143502 -0400] conn=107 op=2 UNBIND [15/Oct/2020:14:09:18.488159848 -0400] conn=107 op=2 fd=74 closed - U1 [15/Oct/2020:14:09:18.491313979 -0400] conn=108 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:18.536590087 -0400] conn=108 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:18.537372005 -0400] conn=108 op=0 BIND dn=\"uid=grant,cn=users,cn=compat,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:14:09:18.538144502 -0400] conn=108 op=0 RESULT err=0 tag=97 nentries=0 etime=0.046223517 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:14:09:18.538536207 -0400] conn=108 op=1 UNBIND [15/Oct/2020:14:09:18.538566004 -0400] conn=108 op=1 fd=74 closed - U1 [15/Oct/2020:14:09:28.961238173 -0400] conn=109 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:29.005228025 -0400] conn=109 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:29.005755286 -0400] conn=109 op=0 BIND dn=\"\" method=128 version=3 [15/Oct/2020:14:09:29.005931161 -0400] conn=109 op=0 RESULT err=0 tag=97 nentries=0 etime=0.044397507 dn=\"\" [15/Oct/2020:14:09:29.006898618 -0400] conn=109 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:14:09:29.008536186 -0400] conn=109 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001740822 [15/Oct/2020:14:09:29.009182689 -0400] conn=109 op=2 UNBIND [15/Oct/2020:14:09:29.009196697 -0400] conn=109 op=2 fd=74 closed - U1 [15/Oct/2020:14:09:29.012428320 -0400] conn=110 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:09:29.057469132 -0400] conn=110 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:09:29.058084024 -0400] conn=110 op=0 BIND dn=\"uid=grant,cn=users,cn=compat,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:14:09:29.058825635 -0400] conn=110 op=0 RESULT err=0 tag=97 nentries=0 etime=0.046016675 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:14:09:29.059166870 -0400] conn=110 op=1 UNBIND [15/Oct/2020:14:09:29.059195118 -0400] conn=110 op=1 fd=74 closed - U1","title":"Output"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#scenario-2","text":"When I added a Bind DN as shown in this video I get a failure.","title":"Scenario 2"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#error-message","text":"","title":"Error Message"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#log-output","text":"[15/Oct/2020:14:12:07.504942397 -0400] conn=112 fd=74 slot=74 SSL connection from 192.168.1.93 to 192.168.1.92 [15/Oct/2020:14:12:07.550456498 -0400] conn=112 TLS1.2 128-bit AES-GCM [15/Oct/2020:14:12:07.551077266 -0400] conn=112 op=0 BIND dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:14:12:07.551767359 -0400] conn=112 op=0 RESULT err=0 tag=97 nentries=0 etime=0.046428458 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:14:12:07.552283396 -0400] conn=112 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:14:12:07.553922212 -0400] conn=112 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001752227 [15/Oct/2020:14:12:07.555518270 -0400] conn=112 op=2 UNBIND [15/Oct/2020:14:12:07.555534158 -0400] conn=112 op=2 fd=74 closed - U1","title":"Log Output"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#scenario-3-current-sticking-point","text":"Using the settings from scenario 1, I continued. When trying to add a group though, no groups are displayed in available groups.","title":"Scenario 3 - Current Sticking Point"},{"location":"LDAP%20with%20OpenManage/README-FreeIPA-CENTOS/#output_1","text":"[15/Oct/2020:15:19:49.806462707 -0400] conn=169 fd=103 slot=103 SSL connection from 192.168.1.18 to 192.168.1.92 [15/Oct/2020:15:19:49.856773316 -0400] conn=169 TLS1.2 128-bit AES-GCM [15/Oct/2020:15:19:49.858681446 -0400] conn=169 op=0 BIND dn=\"\" method=128 version=3 [15/Oct/2020:15:19:49.858906917 -0400] conn=169 op=0 RESULT err=0 tag=97 nentries=0 etime=0.051584941 dn=\"\" [15/Oct/2020:15:19:49.864335125 -0400] conn=169 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(uid=grant)\" attrs=ALL [15/Oct/2020:15:19:49.866001831 -0400] conn=169 op=1 RESULT err=0 tag=101 nentries=1 etime=0.001790286 [15/Oct/2020:15:19:49.867368889 -0400] conn=169 op=2 UNBIND [15/Oct/2020:15:19:49.867386461 -0400] conn=169 op=2 fd=103 closed - U1 [15/Oct/2020:15:19:49.873375865 -0400] conn=170 fd=103 slot=103 SSL connection from 192.168.1.18 to 192.168.1.92 [15/Oct/2020:15:19:49.925956643 -0400] conn=170 TLS1.2 128-bit AES-GCM [15/Oct/2020:15:19:49.928180447 -0400] conn=170 op=0 BIND dn=\"uid=grant,cn=users,cn=compat,dc=grant,dc=lan\" method=128 version=3 [15/Oct/2020:15:19:49.928993026 -0400] conn=170 op=0 RESULT err=0 tag=97 nentries=0 etime=0.053916831 dn=\"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" [15/Oct/2020:15:19:49.934942058 -0400] conn=170 op=1 SRCH base=\"dc=grant,dc=lan\" scope=2 filter=\"(&(cn=grantgroup*)(uniqueMember=*))\" attrs=\"cn entryuuid\" [15/Oct/2020:15:19:49.935438340 -0400] conn=170 op=1 RESULT err=0 tag=101 nentries=0 etime=0.000639539 [15/Oct/2020:15:19:49.936729725 -0400] conn=170 op=2 UNBIND [15/Oct/2020:15:19:49.936744908 -0400] conn=170 op=2 fd=103 closed - U1","title":"Output"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/","text":"Setting Up OpenLDAP with OpenManage My Environment OpenManage Version Version 3.5.0 (Build 60) Helpful Resources Dell Tutorial LDAP Result Codes Helpful Post on Bind DN OpenManage User's Guide Fix This base cannot be created with PLA in phpldapadmin Turnkey OpenLDAP Instructions Download OpenLDAP appliance from here 1.Alternatively, you can build it yourself. [This tutorial](https://medium.com/@benjamin.dronen/installing-openldap-and-phpldapadmin-on-ubuntu-20-04-lts-7ef3ca40dc00 is helpful however you will have to add LDAPS for it to work with OpenManage Enterprise. Helpful Commands/Things Run slapd in Foreground sudo slapd -d 256 -d 128 View Database Configuration The database configuration for OpenLDAP is stored at /etc/ldap/slapd.d You can find a config your interested in with grep -R <THING> * . For example my user config was at cn\\=config/olcDatabase\\=\\{1\\}mdb.ldif . phpldapadmin Config Location /etc/phpldapadmin/config.php Line 300 has login stuff Use a SRV record for Discovery If you use DNS for Domain Controller Lookup when setting up LDAP what it will do is use a SRV record lookup to find your LDAP server. If you want discovery to happen this way, you just need to add the appropriate SRV record to your DNS server. I was using PFSense so I added the following in Custom options: server: local-data: \"_ldap._tcp.ubuntuldap.grant.lan 3600 IN SRV 0 100 389 ubuntuldap.grant.lan\" Potential Bug? When testing LDAP on OpenManage I noticed it would issue the message \"Unable to connect to the LDAP or AD server because the entered credentials are invalid.\" However, while watching Wireshark I noted this coincided with a failed DNS query. This error message appears to be a erroneous.","title":"Setting Up OpenLDAP with OpenManage"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#setting-up-openldap-with-openmanage","text":"","title":"Setting Up OpenLDAP with OpenManage"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#my-environment","text":"","title":"My Environment"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#openmanage-version","text":"Version 3.5.0 (Build 60)","title":"OpenManage Version"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#helpful-resources","text":"Dell Tutorial LDAP Result Codes Helpful Post on Bind DN OpenManage User's Guide Fix This base cannot be created with PLA in phpldapadmin Turnkey OpenLDAP","title":"Helpful Resources"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#instructions","text":"Download OpenLDAP appliance from here 1.Alternatively, you can build it yourself. [This tutorial](https://medium.com/@benjamin.dronen/installing-openldap-and-phpldapadmin-on-ubuntu-20-04-lts-7ef3ca40dc00 is helpful however you will have to add LDAPS for it to work with OpenManage Enterprise.","title":"Instructions"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#helpful-commandsthings","text":"","title":"Helpful Commands/Things"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#run-slapd-in-foreground","text":"sudo slapd -d 256 -d 128","title":"Run slapd in Foreground"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#view-database-configuration","text":"The database configuration for OpenLDAP is stored at /etc/ldap/slapd.d You can find a config your interested in with grep -R <THING> * . For example my user config was at cn\\=config/olcDatabase\\=\\{1\\}mdb.ldif .","title":"View Database Configuration"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#phpldapadmin-config-location","text":"/etc/phpldapadmin/config.php Line 300 has login stuff","title":"phpldapadmin Config Location"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#use-a-srv-record-for-discovery","text":"If you use DNS for Domain Controller Lookup when setting up LDAP what it will do is use a SRV record lookup to find your LDAP server. If you want discovery to happen this way, you just need to add the appropriate SRV record to your DNS server. I was using PFSense so I added the following in Custom options: server: local-data: \"_ldap._tcp.ubuntuldap.grant.lan 3600 IN SRV 0 100 389 ubuntuldap.grant.lan\"","title":"Use a SRV record for Discovery"},{"location":"LDAP%20with%20OpenManage/README-Turnkey-Linux/#potential-bug","text":"When testing LDAP on OpenManage I noticed it would issue the message \"Unable to connect to the LDAP or AD server because the entered credentials are invalid.\" However, while watching Wireshark I noted this coincided with a failed DNS query. This error message appears to be a erroneous.","title":"Potential Bug?"},{"location":"LDAP%20with%20OpenManage/keycloak/","text":"Some people like this: https://www.keycloak.org/","title":"Keycloak"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/","text":"Setting Up FreeIPA with OpenManage My Environment RHEL Version NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.2 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.2\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.2 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.2\" Red Hat Enterprise Linux release 8.2 (Ootpa) Red Hat Enterprise Linux release 8.2 (Ootpa) FreeIPA Version [root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235 OpenManage Version Version 3.4.1 (Build 24) Helpful Resources Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN Install Instructions Install RHEL Change hostname 1. hostname freeipa.grant.lan && hostnamectl set-hostname freeipa.grant.lan 2.Change in /etc/hostname 3.Configure DNS to return for this hostname. Double check with dig +short freeipa.grant.lan A && dig +short -x 192.168.1.95 Follow RHEL's instructions 1.I used Chapter 5 for primary installation Run kinit admin - this allows you to use the command line tools otherwise they'll complain about kerberos. Log into FreeIPA server at https://<your_hostname> . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Go to Users and then directory services in OpenManage. I used the following: Note: You can get the Bind DN by running ldapsearch from the command line. Create a new user and new group in the UI and assign the new user to the new group. Install OpenManage Go to Application Settings -> Directory Services Substitute with your values and then click test. I wasn't able to get this to work with the generic admin user. In the test screen I used that new user to connect to directory services Helpful Commands To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status . Bug I used the settings defined here: When I went to import the users from a group I received the following: The code in question: Below was the value of u at runtime: [ { \"userTypeId\":2, \"objectGuid\":null, \"objectSid\":null, \"directoryServiceId\":13483, \"name\":\"grantgroup\", \"password\":\"\", \"userName\":\"grantgroup\", \"roleId\":\"10\", \"locked\":false, \"isBuiltin\":false, \"enabled\":true } ] Error in logs [ERROR] 2020-10-22 07:33:08.392 [ajp-bio-8009-exec-2] BaseController - com.dell.enterprise.exception.ui.ConsoleException: error.general_known_error_occurred com.dell.enterprise.exception.ui.ConsoleException: error.general_known_error_occurred at com.dell.enterprise.controller.console.ADController.importGroups(ADController.java:400) ~[UI.ADPlugin-0.0.1-SNAPSHOT.jar:?] at sun.reflect.GeneratedMethodAccessor824.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_262] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_262] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:854) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:765) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:650) [tomcat-servlet-3.0-api.jar:?] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:731) [tomcat-servlet-3.0-api.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat7-websocket.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at com.dell.enterprise.filter.ui.CacheControlFilter.doFilterInternal(CacheControlFilter.java:23) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.catalina.filters.SetCharacterEncodingFilter.doFilter(SetCharacterEncodingFilter.java:108) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.6.0.jar:1.6.0] at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.6.0.jar:1.6.0] at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) [shiro-core-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.6.0.jar:1.6.0] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at com.dell.enterprise.core.integration.lib.common.filter.RequestFilter.doFilter(RequestFilter.java:103) [common-0.0.1-SNAPSHOT.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110) [catalina.jar:7.0.76] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:498) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169) [catalina.jar:7.0.76] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) [catalina.jar:7.0.76] at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) [catalina.jar:7.0.76] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445) [catalina.jar:7.0.76] at org.apache.coyote.ajp.AjpProcessor.process(AjpProcessor.java:190) [tomcat-coyote.jar:7.0.76] at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637) [tomcat-coyote.jar:7.0.76] at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316) [tomcat-coyote.jar:7.0.76] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_262] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_262] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-coyote.jar:7.0.76] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_262] Further Explanation The URI endpoint is: https://192.168.1.93/core/api/Console/import-groups This is the JSON returned from the call. {severity: \"IGNORE\", message: \"error.general_known_error_occurred\",\u2026} debug: false details: {error: {code: \"Base.1.0.GeneralError\",\u2026}} error: {code: \"Base.1.0.GeneralError\",\u2026} @Message.ExtendedInfo: [{MessageId: \"CGEN1004\", RelatedProperties: [],\u2026}] code: \"Base.1.0.GeneralError\" message: \"A general error has occurred. See ExtendedInfo for more information.\" message: \"error.general_known_error_occurred\" severity: \"IGNORE\" timestamp: \"2020-10-21T14:43:44.385-0500\" The errors occurs at: M.send(y(u) ? null : u) See here for a description of Javascript's ternary operator. In this case it is saying if y(u) is true then the value is set to null, otherwise it is set to u . The y function is: function y(e) { return \"undefined\" == typeof e } It is just a basic check to see if u is defined or not. M is an instance of XMLHttpRequest . We can see M being called with open M.open(i, s, !0) where i is \"POST\" and s is \"/core/api/Console/import-groups\". The problem occurs because objectGuid and objectSid are set to null. Resolution See duplicate_bug.py for a replication of the problem. Replace the payload: { \"userTypeId\":2, \"objectGuid\":null, \"objectSid\":null, \"directoryServiceId\":13483, \"name\":\"grantgroup\", \"password\":\"\", \"userName\":\"grantgroup\", \"roleId\":\"10\", \"locked\":false, \"isBuiltin\":false, \"enabled\":true } with the data from your instance. I grabbed this out of the javascript debugger. To fix the problem, you have to lookup the uid/gid (which correspond to objectSid and objectGuid respectively) on your LDAP server and replace the null values. I used ldapsearch to find mine: # grant, users, compat, grant.lan dn: uid=grant,cn=users,cn=compat,dc=grant,dc=lan objectClass: posixAccount objectClass: ipaOverrideTarget objectClass: top gecos: Grant Curell cn: Grant Curell uidNumber: 1314600001 gidNumber: 1314600001 loginShell: /bin/sh homeDirectory: /home/grant ipaAnchorUUID:: OklQQTpncmFudC5sYW46OWIzOTYwNDQtMTNhZS0xMWViLTllNzctMDA1MDU2Ym U4NGIw uid: grant You can see the uidNumber and gidNumber fields. Change the payload out in duplicate_bug.py and it will correctly import the group. test_payload = [ { \"userTypeId\": 2, \"objectGuid\": 1314600001, \"objectSid\": 1314600001, \"directoryServiceId\": 13483, \"name\": \"grantgroup\", \"password\": \"\", \"userName\": \"grant\", \"roleId\": \"10\", \"locked\": False, \"isBuiltin\": False, \"enabled\": True } ]","title":"Setting Up FreeIPA with OpenManage"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#setting-up-freeipa-with-openmanage","text":"","title":"Setting Up FreeIPA with OpenManage"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#my-environment","text":"","title":"My Environment"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#rhel-version","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.2 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.2\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.2 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.2\" Red Hat Enterprise Linux release 8.2 (Ootpa) Red Hat Enterprise Linux release 8.2 (Ootpa)","title":"RHEL Version"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#freeipa-version","text":"[root@centos ~]# ipa --version VERSION: 4.8.4, API_VERSION: 2.235","title":"FreeIPA Version"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#openmanage-version","text":"Version 3.4.1 (Build 24)","title":"OpenManage Version"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#helpful-resources","text":"Dell Tutorial Logs Explained LDAP Result Codes Helpful Post on Bind DN","title":"Helpful Resources"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#install-instructions","text":"Install RHEL Change hostname 1. hostname freeipa.grant.lan && hostnamectl set-hostname freeipa.grant.lan 2.Change in /etc/hostname 3.Configure DNS to return for this hostname. Double check with dig +short freeipa.grant.lan A && dig +short -x 192.168.1.95 Follow RHEL's instructions 1.I used Chapter 5 for primary installation Run kinit admin - this allows you to use the command line tools otherwise they'll complain about kerberos. Log into FreeIPA server at https://<your_hostname> . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Go to Users and then directory services in OpenManage. I used the following: Note: You can get the Bind DN by running ldapsearch from the command line. Create a new user and new group in the UI and assign the new user to the new group. Install OpenManage Go to Application Settings -> Directory Services Substitute with your values and then click test. I wasn't able to get this to work with the generic admin user. In the test screen I used that new user to connect to directory services","title":"Install Instructions"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#helpful-commands","text":"To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status .","title":"Helpful Commands"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#bug","text":"I used the settings defined here: When I went to import the users from a group I received the following: The code in question: Below was the value of u at runtime: [ { \"userTypeId\":2, \"objectGuid\":null, \"objectSid\":null, \"directoryServiceId\":13483, \"name\":\"grantgroup\", \"password\":\"\", \"userName\":\"grantgroup\", \"roleId\":\"10\", \"locked\":false, \"isBuiltin\":false, \"enabled\":true } ] Error in logs [ERROR] 2020-10-22 07:33:08.392 [ajp-bio-8009-exec-2] BaseController - com.dell.enterprise.exception.ui.ConsoleException: error.general_known_error_occurred com.dell.enterprise.exception.ui.ConsoleException: error.general_known_error_occurred at com.dell.enterprise.controller.console.ADController.importGroups(ADController.java:400) ~[UI.ADPlugin-0.0.1-SNAPSHOT.jar:?] at sun.reflect.GeneratedMethodAccessor824.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_262] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_262] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:854) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:765) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:650) [tomcat-servlet-3.0-api.jar:?] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.3.28.RELEASE.jar:4.3.28.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:731) [tomcat-servlet-3.0-api.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat7-websocket.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at com.dell.enterprise.filter.ui.CacheControlFilter.doFilterInternal(CacheControlFilter.java:23) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.catalina.filters.SetCharacterEncodingFilter.doFilter(SetCharacterEncodingFilter.java:108) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.6.0.jar:1.6.0] at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.6.0.jar:1.6.0] at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) [shiro-core-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [shiro-web-1.6.0.jar:1.6.0] at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.6.0.jar:1.6.0] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) [spring-web-4.3.28.RELEASE.jar:4.3.28.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at com.dell.enterprise.core.integration.lib.common.filter.RequestFilter.doFilter(RequestFilter.java:103) [common-0.0.1-SNAPSHOT.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) [catalina.jar:7.0.76] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110) [catalina.jar:7.0.76] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:498) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169) [catalina.jar:7.0.76] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) [catalina.jar:7.0.76] at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962) [catalina.jar:7.0.76] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) [catalina.jar:7.0.76] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445) [catalina.jar:7.0.76] at org.apache.coyote.ajp.AjpProcessor.process(AjpProcessor.java:190) [tomcat-coyote.jar:7.0.76] at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637) [tomcat-coyote.jar:7.0.76] at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316) [tomcat-coyote.jar:7.0.76] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_262] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_262] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-coyote.jar:7.0.76] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_262]","title":"Bug"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#further-explanation","text":"The URI endpoint is: https://192.168.1.93/core/api/Console/import-groups This is the JSON returned from the call. {severity: \"IGNORE\", message: \"error.general_known_error_occurred\",\u2026} debug: false details: {error: {code: \"Base.1.0.GeneralError\",\u2026}} error: {code: \"Base.1.0.GeneralError\",\u2026} @Message.ExtendedInfo: [{MessageId: \"CGEN1004\", RelatedProperties: [],\u2026}] code: \"Base.1.0.GeneralError\" message: \"A general error has occurred. See ExtendedInfo for more information.\" message: \"error.general_known_error_occurred\" severity: \"IGNORE\" timestamp: \"2020-10-21T14:43:44.385-0500\" The errors occurs at: M.send(y(u) ? null : u) See here for a description of Javascript's ternary operator. In this case it is saying if y(u) is true then the value is set to null, otherwise it is set to u . The y function is: function y(e) { return \"undefined\" == typeof e } It is just a basic check to see if u is defined or not. M is an instance of XMLHttpRequest . We can see M being called with open M.open(i, s, !0) where i is \"POST\" and s is \"/core/api/Console/import-groups\". The problem occurs because objectGuid and objectSid are set to null.","title":"Further Explanation"},{"location":"LDAP%20with%20OpenManage/LDAP%20Group%20Import%20Bug/#resolution","text":"See duplicate_bug.py for a replication of the problem. Replace the payload: { \"userTypeId\":2, \"objectGuid\":null, \"objectSid\":null, \"directoryServiceId\":13483, \"name\":\"grantgroup\", \"password\":\"\", \"userName\":\"grantgroup\", \"roleId\":\"10\", \"locked\":false, \"isBuiltin\":false, \"enabled\":true } with the data from your instance. I grabbed this out of the javascript debugger. To fix the problem, you have to lookup the uid/gid (which correspond to objectSid and objectGuid respectively) on your LDAP server and replace the null values. I used ldapsearch to find mine: # grant, users, compat, grant.lan dn: uid=grant,cn=users,cn=compat,dc=grant,dc=lan objectClass: posixAccount objectClass: ipaOverrideTarget objectClass: top gecos: Grant Curell cn: Grant Curell uidNumber: 1314600001 gidNumber: 1314600001 loginShell: /bin/sh homeDirectory: /home/grant ipaAnchorUUID:: OklQQTpncmFudC5sYW46OWIzOTYwNDQtMTNhZS0xMWViLTllNzctMDA1MDU2Ym U4NGIw uid: grant You can see the uidNumber and gidNumber fields. Change the payload out in duplicate_bug.py and it will correctly import the group. test_payload = [ { \"userTypeId\": 2, \"objectGuid\": 1314600001, \"objectSid\": 1314600001, \"directoryServiceId\": 13483, \"name\": \"grantgroup\", \"password\": \"\", \"userName\": \"grant\", \"roleId\": \"10\", \"locked\": False, \"isBuiltin\": False, \"enabled\": True } ]","title":"Resolution"},{"location":"LLMs%20Explained/","text":"LLMs Explained The Math Behind GPT Models (Rough Draft) The Math Behind GPT Models (Rough Draft) Overview How Transformers Work 1 - Input Sequence to Encoder Embeddings 1.5 Position Encoding Input Embedding: \"You are welcome\" Output Embedding: \" de nada\" Adding Them Together Encoder Stack Processing Self Attention A Concrete Example Attention Heads and Multi Attention Heads Layer Normalization Feed Forward Neural Net Prepare and Embed Target Sequence for Decoder Decoder Stack Processing with Encoder Output Output Layer for Word Probabilities Loss Function and Back-Propagation Generative Pre-Trained Transformer (GPT) What's so different about GPT models? Going Through an Example Input Representation: Embedding and Positional Encoding: Masked Self-Attention Feed Forward and Layer Norm Output Training GPT Time Complexity Retrieval Augmented Generation (RAG) Nearest Neighbor Search The General Idea Algorithms for Nearest Neighbor Searches: Supplemental Information Word Embeddings Weight Matrices Softmax Matrix Multiplication Calculating Y Calculate Attention Score Calculate Multi-Attention Head Output Calculate Layer Normalization Linear Regression Code Plot XOR XOR Example Using Rectified Linear Units (ReLU) Math for FFN Decoder Attention Heads Calculate Encoder-Decoder Output What is Cross Entropy Loss Other Sources Overview The purpose of this whitepaper is to explain at a low level how LLMs work such that we can make informed decisions about their performance and architectural decisions. I had trouble finding a single source that walked through all the pieces at a sufficient level of detail so this is more a literature review that further explains the following: GPT: Origin, Theory, Application, and Future The Deep Learning Book Transformers Explained Visually Google's Original Paper - Attention is All You Need How Transformers Work We start by covering how transformers work. Transformers are the core of an LLM model. Below we discover the traditional transformer architecture. GPT-style models do not use the encoders and have what is called a decoder only architecture, but it is difficult to understand that architecture without understanding where it comes from so for this section we cover how the encoder works as well as the decoder. This article series does a fantastic job of explaining the overarching LLM learning process but there were several parts I didn't immediately understand and moreover it did not provide concrete mathematical examples to illustrate the concepts. I go through and explain the pieces of the article which didn't make sense to me and I have added concrete examples to illustrate the process mathematically. The below image is an overview model learning and inference process. There are some minor differences between the two processes which I will explain below but at this level they are the same. To illustrate how LLMs work, we will use the example of asking an LLM to translate, \"You are welcome\" to \"De Nada\". Image Source These are the high level steps which must take place. The input sequence is converted into Embeddings (with Position Encoding) and fed to the Encoder. The stack of Encoders processes this and produces an encoded representation of the input sequence. The target sequence is prepended with a start-of-sentence token, converted into Embeddings (with Position Encoding), and fed to the Decoder. The stack of Decoders processes this along with the Encoder stack\u2019s encoded representation to produce an encoded representation of the target sequence. The Output layer converts it into word probabilities and the final output sequence. The Transformer\u2019s Loss function compares this output sequence with the target sequence from the training data. This loss is used to generate gradients to train the Transformer during back-propagation. This overview was taken from here 1 - Input Sequence to Encoder Embeddings Let's assume you have a word embedding model that maps each word in the sentence \"You are welcome\" to a 4-dimensional vector. I use arbitrary numbers for demonstration. Tokenization : The sentence \"You are welcome\" is tokenized into ['You', 'are', 'welcome'] . Word Embeddings : See Word Embeddings for an explanation of how these work. Assume the embedding model maps 'You' to $[0.1, 0.2, -0.1, 0.4]$. 'are' is mapped to $[-0.3, 0.5, 0.1, -0.2]$. 'welcome' is mapped to $[0.4, -0.3, 0.2, 0.1]$. Input Matrix (X) : The vectors are stacked to form the input matrix (X): $$ X = \\begin{pmatrix} 0.1 & 0.2 & -0.1 & 0.4 \\\\ -0.3 & 0.5 & 0.1 & -0.2 \\\\ 0.4 & -0.3 & 0.2 & 0.1 \\end{pmatrix} $$ This (X) matrix serves as the input to the neural network, and each row corresponds to the embedding of a word in the sentence \"You are welcome\". Now we need to do the same thing for the output embedding. In many sequence-to-sequence models like Transformers used for tasks like machine translation, a special start token (often denoted as <s> , <start> , or [START] ) and sometimes an end token (e.g., <e> , <end> , or [END] ) are added to sequences. These tokens provide signals for the beginning and end of sequences and help in the generation process. Tokenization with Start Token : The phrase \"de nada\" becomes ['<start>', 'de', 'nada'] . Word Embeddings : Assume our embedding model maps <start> to $[0.0, 0.0, 0.0, 0.0]$ (just as a placeholder; in practice, it would have a unique representation). 'de' is mapped to $[-0.2, 0.4, 0.3, 0.1]$. 'nada' is mapped to $[0.5, -0.1, -0.4, 0.3]$. Output Matrix (Y) with the start token: $$ Y = \\begin{pmatrix} 0.0 & 0.0 & 0.0 & 0.0 \\\\ -0.2 & 0.4 & 0.3 & 0.1 \\\\ 0.5 & -0.1 & -0.4 & 0.3 \\end{pmatrix} $$ The inclusion of the start token helps the model recognize the beginning of the output sequence. If there's an end token, it can similarly indicate the end of the sequence, especially useful in generation tasks. What I don't show here is a padding but in the actual models you would likely also have a pad. Ex: ['<start>', 'de', 'nada', '<pad>', '<pad>'] to make sure that the input sequences are the same size. This is a feature of the traditional transformer model but will not appear in the GPT-style models. 1.5 Position Encoding In previous models (Recurrent Neural Networks [RNNs] typically), the position of words in a sentence and their mathematical importance were fixed by virtue of the fact that those models operated on each word sequentially. Transformers on the other hand process all words in a batch at the same time drastically reducing training/inference time. This presents a problem because word order matters. Ex: \"The cat sat on the mat.\" is not the same as \"The mat sat on the cat.\" It is important for us to include the position within the sentence as a value within our framework. To remedy this, Transformers incorporate a mechanism called Position Encoding. This mechanism is designed to infuse the sequence with positional information, ensuring the model can distinguish between \"cat sat on the mat\" and \"mat sat on the cat\". Just as there was an embedding layer for input and output there are also position encoding layers for both input and output. Importantly, the Position Encoding doesn't rely on the specific words in a sequence. Instead, it assigns a unique encoding to each possible position in the sequence. These encodings are predetermined and consistent across all sequences. These encodings are generated using the following formulas: $$ PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) $$ $$ PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) $$ where sin is used for even positions and cos is used for odd positions. $pos$: Position of the word in the sequence $d_{\\text{model}}$: Dimensionality of the embeddings $i$: Index for the dimension ranging from 0 to $d_{\\text{model}}/2 - 1$ The brilliance of this design lies in its ability to provide rich positional context without being tied to the content of the sequence. This ensures that no matter what words are present, the Transformer always understands their order. To continue our other examples: Alright, let's compute the position encodings using the given equations for both input and output embeddings. Given: - $d_{\\text{model}}$ is the dimension of the model, which in our case from the earlier examples is 4. - The $pos$ variable represents the position of the word in the sequence. - The $i$ variable ranges from 0 to $d_{\\text{model}}/2-1$. Since $d_{\\text{model}}$ is 4, $i$ will range from 0 to 1. Input Embedding: \"You are welcome\" For the input sequence, we have 3 words, so the positions are $pos = 0, 1, 2$. Using the given equations: For $pos = 0$: $$ PE_{(0, 0)} = \\sin\\left(\\frac{0}{10000^{2(0)/4}}\\right) = 0\\space,\\space PE_{(0, 1)} = \\cos\\left(\\frac{0}{10000^{2(0+1)/4}}\\right) = 1\\space,\\space PE_{(0, 2)} = \\sin\\left(\\frac{0}{10000^{2(1)/4}}\\right) = 0\\space,\\space PE_{(0, 3)} = \\cos\\left(\\frac{0}{10000^{2(1+1)/4}}\\right) = 1\\space,\\space $$ To break that down further: $pos = 0$ $d_{\\text{model}} = 4$ For $PE_{(0,0)}$ Using the formula for even indices (2i): $$i = 0$$ $$PE_{(0, 2(0))} = \\sin\\left(\\frac{0}{10000^{2(0)/4}}\\right)$$ Since $\\sin(0)$ is 0, the value is 0. For $PE_{(0,1)}$ Using the formula for odd indices (2i+1): $$i = 0$$ $$PE_{(0, 2(0)+1)} = \\cos\\left(\\frac{0}{10000^{2(0+1)/4}}\\right)$$ Since $\\cos(0)$ is 1, the value is 1. For $PE_{(0,2)}$ Using the formula for even indices (2i): $$i = 1$$ $$PE_{(0, 2(1))} = \\sin\\left(\\frac{0}{10000^{2(1)/4}}\\right)$$ Again, since $\\sin(0)$ is 0, the value is 0. For $PE_{(0,3)}$ Using the formula for odd indices (2i+1): $$i = 1$$ $$PE_{(0, 2(1)+1)} = \\cos\\left(\\frac{0}{10000^{2(1+1)/4}}\\right)$$ Once more, since $\\cos(0)$ is 1, the value is 1. Following the same pattern for $pos = 1$ and $pos = 2$, we get: $$ PE_{\\text{input}} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ \\sin\\left(\\frac{1}{10000^0}\\right) & \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & \\sin\\left(\\frac{1}{10000^2}\\right) & \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ \\sin\\left(\\frac{2}{10000^0}\\right) & \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & \\sin\\left(\\frac{2}{10000^2}\\right) & \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 0.8415 & 0.99995 & 0.0001 & 1 \\\\ 0.9093 & 0.9998 & 0.0002 & 1 \\end{pmatrix} $$ Output Embedding: \" de nada\" For the output sequence, we also have 3 words/tokens. The positions again are $pos = 0, 1, 2$. Using the equations similarly: $$ PE_{\\text{output}} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ \\sin\\left(\\frac{1}{10000^0}\\right) & \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & \\sin\\left(\\frac{1}{10000^2}\\right) & \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ \\sin\\left(\\frac{2}{10000^0}\\right) & \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & \\sin\\left(\\frac{2}{10000^2}\\right) & \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 0.8415 & 0.99995 & 0.0001 & 1 \\\\ 0.9093 & 0.9998 & 0.0002 & 1 \\end{pmatrix} $$ Finally, to incorporate these position encodings into our embeddings, you would simply add the corresponding position encoding to each row of the embedding matrices $X$ and $Y$. Adding Them Together Given: $$ X = \\begin{pmatrix} 0.1 & 0.2 & -0.1 & 0.4 \\\\ -0.3 & 0.5 & 0.1 & -0.2 \\\\ 0.4 & -0.3 & 0.2 & 0.1 \\end{pmatrix} $$ $$ Y = \\begin{pmatrix} 0.0 & 0.0 & 0.0 & 0.0 \\\\ -0.2 & 0.4 & 0.3 & 0.1 \\\\ 0.5 & -0.1 & -0.4 & 0.3 \\end{pmatrix} $$ $$ PE_{\\text{input/output}} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 0.8415 & 0.99995 & 0.0001 & 1 \\\\ 0.9093 & 0.9998 & 0.0002 & 1 \\end{pmatrix} $$ $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ 0.5415 & 1.49995 & 0.1001 & 0.8 \\\\ 1.3093 & 0.6998 & 0.2002 & 1.1 \\end{pmatrix} $$ $$ Y + PE_{\\text{output}} = \\begin{pmatrix} 0.0 & 1.0 & 0.0 & 1.0 \\\\ 0.6415 & 1.39995 & 0.3001 & 1.1 \\\\ 1.4093 & 0.8998 & -0.3998 & 1.3 \\end{pmatrix} $$ Adding position encodings to $Y$: $$ Y + PE_{\\text{output}} = \\begin{pmatrix} 0.0 + 0 & 0.0 + 1 & 0.0 + 0 & 0.0 + 1 \\\\ -0.2 + 0.8415 & 0.4 + 0.99995 & 0.3 + 0.0001 & 0.1 + 1 \\\\ 0.5 + 0.9093 & -0.1 + 0.9998 & -0.4 + 0.0002 & 0.3 + 1 \\end{pmatrix} = \\begin{pmatrix} 0.0 & 1.0 & 0.0 & 1.0 \\\\ 0.6415 & 1.39995 & 0.3001 & 1.1 \\\\ 1.4093 & 0.8998 & -0.3998 & 1.3 \\end{pmatrix} $$ These new matrices incorporate both the embeddings and the position information, and they will be used as input to subsequent layers of the Transformer model. One more thing you should take from this is that the contents of the input are independent of the position embedding. The only thing that matters is the position of the word for the position embedding. What we now have is a matrix that contains information on both the relationships of the word and its position in the sentence. This is visualized well in this post It's worth noting in our example we are only showing a single line of text but in reality you would batch multiple sets of text together in the traditional transformer model. The shape of the matrix will remain unchanged until we reach the final output layer. The other bit of complexity you see in the figure above that we don't here is that realistically the word vector matrix describing the word's relationships would be multidimensional but here we used a basic, two dimensional, matrix. Now we are ready to move onto encoding. Encoder Stack Processing The encoding process looks like this at a high level as illustrated here : At a high level this is what each component does: Self-Attention : This mechanism allows the model to weigh the importance of different words in the sequence relative to each other. It outputs a matrix of the same size which is a combination of input vectors based on their attention scores. Layer Norm : After the self-attention mechanism, the output undergoes a layer normalization to stabilize the activations and assist with training. Feed-forward : The normalized output is passed through a feed-forward neural network. This is present in each transformer block and helps in further transformation of the data. One of the things that wasn't immediately obvious to me was why this exists. It does a couple of things. First, this is where most of the \"learning\" happens. It is in the feedforward network that the complex relationships between different tokens (words) and general ideas are really stored. Each word is independently transformed by some linear transformation (IE: a matrix operation of some variety be it addition, subtraction, multiplication, division). Secondly, it introduces non-linearity. If you aren't heavy into math it may not be immediately obvious why you care about this. If you have a linear model its performance ends up being roughly the same as some sort of linear regression. That's fine for basic statistical analysis but that's what we have been doing for decades and is hardly going to do anything earth shattering for you. By making the model non-linear it allows it to create a function which more closely approximates complex relationships. Said in a non-mathy way, it is the juice that gets you the cider that is something as fantastic as ChatGPT. Third, it provides depth. What is depth is the question I first had immediately following this explanation. Imagine your model is evaluating pictures. The lowest level might learn rough outlines, maybe some colors or textures, but that's it. Maybe the picture is of a face and at the moderate levels of depth it starts to learn what an eye or a nose look like. Finally, at the deepest levels the model figures out who the picture is of or identifies whether the person is happy or sad. Layer Norm : Post feed-forward operation, another layer normalization is performed. Self Attention Image source The purpose of the self attention portion of the algorithm is explained fantastically in this paper by Troy Wang . Self-attention is one of the key differentiating characteristics of the transformer model. It is a critical component that enables the Transformer to comprehend language contexts intelligently [VSP+17]. The objective of attention can be clearly illustrated by a simple example. Given an input such as \u201cProfessor Marcus gave some really good advice to Troy, one of his students, because he has extensive experiences in the academia.\u201d For a human reader, it is clear that the word \u201che\u201d in the second half of the sentence refers to \u201cProfessor Marcus,\u201d instead of his student. But for a computer program, it\u2019s not so apparent. There are many such circumstances where grammatical ambiguities legally exist, such that rule-based and hard-coded logic would not be sufficient for effective language analysis and comprehension [VSP+17][Alammar18]. This is where self-attention comes into play. When the model processes each token input, self- attention enables the model to associate the meaning of the current token with other tokens, such as associating \u201che\u201d with \u201cProfessor Marcus\u201d in our previous example, in order to gain better knowledge of this current input. In other words, the transformer model learns how to pay attention to the context thanks to the self-attention mechanism. It turns out that natural language has a lot of sequential dependencies, and thus the ability to incorporate information from previous words in the input sequence is critical to comprehending the input [VSP+17][Alammar18]. The actual math of this is a bit confusing so I found it was best to read it first from our friend Troy Wang and then I'll provide a more detailed explanation where I really break down what he is saying. Now, let's breakdown the process of computing self-attention. Before computing self-attention, each individual input token is first being converted into a vector using the embedding algorithm that we discussed earlier. Then, for each embedding, we calculate its query vector ($\\mathbf{Q}$), key vector ($\\mathbf{K}$), and value vector ($\\mathbf{V}$) by multiplying the embedding vector with three pre-trained matrices $\\mathbf{W_Q}$, $\\mathbf{W_K}$, $\\mathbf{W_V}$ intended for calculating the three matrices respectively. Notice that the three vectors all have the same dimension, and it does not have to be equal with the dimension of the embedding vectors. The dimensions of the three matrices are the same, and they are all length of the embedding vectors by the length of the ($\\mathbf{Q}$), ($\\mathbf{K}$), and ($\\mathbf{V}$) vectors. Then, for each input embedding, we dot multiply its own $\\mathbf{Q}$ vector with every other input embedding's $\\mathbf{K}$ vector. At this point, for every input embedding, we have calculated a set of score corresponding to each and every embedding in the input sequence, including itself. Then for each of the embedding, we divide all its scores by the square root of the dimension of the key vectors for more stable gradients and pass the scores through the softmax function for normalization. After this, we multiply each $\\mathbf{V}$ vector in the input sequence with its respective softmax score, and finally add up those weighted value vectors. This resulting sum vector is the self-attention of this particular input embedding [VSP+17] [Alammar18][IYA16]. Although we described the process in terms of vectors, in practice it is implemented by means of matrices. This is because the computation process for each vector independent and identical. We would stack our input embeddings as rows in an input matrix, multiply this matrix with learned weight matrices $W_Q$, $W_K$, $W_V$ and get $(Q)$, $(K)$, and $(V)$ vectors respectively, feed the three resulting matrices into the softmax function as: $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V$$ Image source Ok, let's start with explaining what exactly are Q, K, and V because that wasn't immediately obvious to me when I read Wang's paper. Of course! Let's dive deeper into the roles of the Query (Q), Key (K), and Value (V) matrices in the self-attention mechanism: Query (Q) : Purpose : The Query matrix is used to represent the current word or token we are focusing on. Think of it as asking a question: \"Which words in the sequence are most relevant to this one?\" Function : In the self-attention mechanism, the Q vector of a token is used to score how much other tokens should be attended to. By taking the dot product of Q with every K (explained below), we obtain a score that determines how much focus each token in the sequence should have in relation to the current token. Key (K) : Purpose : The Key matrix represents all the tokens that we will check our current token against to determine their level of similarity or relevance. Function : The K vectors are matched against the Q vector to produce attention scores. The intuition is that if a Q vector has a high dot product with a K vector, then the corresponding tokens are relevant to each other. This score indicates the weight or level of attention the model should give to the token represented by that particular K when considering the token represented by Q. Value (V) : Purpose : The Value matrix represents the actual content of the tokens. While Q and K are used to determine the relationships and relevance among tokens, V provides the content we want to extract based on those relationships. Function : Once we have our attention scores (from the Q-K dot products), these scores determine how much of each V vector we take into the final output. If a token is deemed highly relevant, its V vector contributes more to the final representation of the current token. An Analogy : Imagine you're a spy in a room with multiple people having conversations. You're eavesdropping on one person (the \"query\"), but you also want to gather context from what everyone else (the \"keys\") are saying to understand as much as you can. The Q (Query) is you asking: \"Who in this room is relevant to what the target (query) is saying?\" The K (Keys) are the topics each person in the room is talking about. By comparing your query to each topic (taking the dot product of Q and K), you determine who is talking about things most relevant to the person you're focusing on. The V (Values) are the actual words or content of what each person is saying. Once you've identified the most relevant people based on your query and keys, you take a weighted sum of their words (the V vectors) to get the complete context. The self-attention mechanism uses this approach to weigh the importance of different tokens in a sequence relative to a particular token, resulting in a rich contextual representation for each token in the input. Ok, now that we better understand Q, K, and V let's look at the total process from beginning to end and go through an example. $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V$$ Calculating Q, K, and V : What happens : Each embedding vector gets transformed into three different vectors: Query (Q), Key (K), and Value (V). How it happens : Multiply the embedding vector with three distinct pre-trained matrices ($W_Q$, $W_K$, and $W_V$). Why it matters : These vectors serve distinct purposes. Q is used to fetch the attention score, K provides a set of keys to match against, and V serves as a pool of values to fetch from based on those scores. Relationship to equation : This step produces the Q, K, and V vectors which are central elements in the equation. Dot Product between Q and K : What happens : Each Q vector is dot-multiplied with every K vector. How it happens : This is simple vector multiplication between Q of a particular token and the K of every other token, resulting in a score. Why it matters : This score represents how much attention should be paid to other tokens when encoding information about a particular token. Relationship to equation : This step corresponds to the $Q \\times K^T$ part of the equation. Scaling the Scores : What happens : The scores from the previous step are scaled down. How it happens : Each score is divided by the square root of the dimension of the K vectors. Why it matters : This step ensures stable gradients. Without this scaling, the gradients could be too small for effective learning, especially when the dimensionality (or depth) of the keys is large. Relationship to equation : This step is represented by the division by $\\sqrt{d_k}$ in the equation. Applying Softmax : What happens : The scores for each token are turned into a probability distribution using the softmax function. How it happens : Softmax normalizes the scores so they're between 0 and 1 and sum up to 1. Why it matters : This provides a clear set of attention \"weights\" for each token. The higher the softmax output, the more attention the model pays to the corresponding token. Relationship to equation : This step is captured by the $\\text{softmax}(\\cdot)$ operation in the equation. Calculating Weighted Values : What happens : The V vectors are multiplied by the softmax scores. How it happens : Each token's V vector is weighted by the token's respective softmax score from the previous step. Why it matters : This step essentially picks out values from the V vectors proportional to the attention scores. Tokens deemed more relevant contribute more to the final output. Relationship to equation : This step corresponds to the $\\times V$ at the end of the equation, where the weighted values from the softmax operation are combined with V. Summing Weighted Values : What happens : The weighted V vectors are summed up. How it happens : A simple vector summation. Why it matters : The resulting vector is the final output for a particular token, which is a combination of features from other tokens based on the attention scores. Relationship to equation : This summation is implied in the matrix multiplication in the equation. The result of the $\\text{softmax}(\\cdot) \\times V$ operation is the summed attention output for each token. Matrix Computations in Practice : What happens : The operations described above, while explained using vectors, are in practice executed using matrices. How it happens : Instead of processing tokens one-by-one, all tokens are processed simultaneously by stacking embeddings into a matrix and using matrix multiplication for efficiency. Why it matters : Matrix operations are highly optimized and parallelizable, making the computations significantly faster, especially on hardware like GPUs. Relationship to equation : The use of Q, K, and V in the equation reflects these matrix computations. The Attention Output : The equation one last time: $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V $$ This formula captures the essence of the self-attention mechanism. The product of Q and $K^T$ gives attention scores, which after scaling and softmax, are used to weigh the V values. A Concrete Example Given the above steps for calculating self-attention, let's break it down: 1. Create Query (Q), Key (K), and Value (V) Matrices : We obtain these by multiplying the input embeddings (with position encodings) with the weight matrices $W_Q$, $W_K$, and $W_V$ respectively. For the sake of this example, we will assume these weight matrices are: $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ $$ W_K = \\begin{pmatrix} 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\end{pmatrix} $$ $$ W_V = \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\end{pmatrix} $$ Compute Q, K, and V : Multiply the input matrix $X$ with these weights: $$ Q = X \\times W_Q $$ $$ K = X \\times W_K $$ $$ V = X \\times W_V $$ Calculate Attention Scores : This is done by multiplying $Q$ with $K^T$, then dividing by the square root of the dimension of the key vectors $d_k$. In our example, $d_k$ is 4. $$ Score = \\frac{Q \\times K^T}{\\sqrt{d_k}} $$ Apply Softmax to the Scores : This will give each word's attention score. $$ SoftmaxScore = \\text{softmax}(Score) $$ Multiply Softmax Score with V : This will give the weighted representation of the input with respect to other words in the sentence. $$ AttentionOutput = SoftmaxScore \\times V $$ Let's calculate the matrices Q, K, V, Score, SoftmaxScore, and AttentionOutput: To begin, we will compute the $Q$, $K$, and $V$ matrices. Using: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ Given the weight matrices: $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ $$ W_K = \\begin{pmatrix} 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\end{pmatrix} $$ $$ W_V = \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\end{pmatrix} $$ Compute $Q$: $$ Q = (X + PE_{\\text{input}}) \\times W_Q $$ Compute $K$: $$ K = (X + PE_{\\text{input}}) \\times W_K $$ Compute $V$: $$ V = (X + PE_{\\text{input}}) \\times W_V $$ Let's calculate these values: First, let's compute the Q matrix using our input matrix ( X + PE_{\\text{input}} ) and the ( W_Q ) matrix: $$ Q = (X + PE_{\\text{input}}) \\times W_Q $$ Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ When you multiply the above matrices, you get: $$ Q = \\begin{pmatrix} 1.5 & 1.1 & 2.6 & 0 \\\\ 1.3415 & 1.6 & 2.3 & 0.6415 \\\\ 2.4093 & 0.8998 & 1.7998 & 1.5093 \\end{pmatrix} $$ If your matrix multiplication is rusty see the matrix math behind this calculation . We compute the $K$ matrix using our input matrix $X + PE_{\\text{input}}$ and the $W_K$ matrix: $$ K = (X + PE_{\\text{input}}) \\times W_K $$ Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ When you multiply the above matrices, you get: $$ Q = \\begin{pmatrix} 1.5 & 1.1 & 2.6 & 0 \\\\ 1.3415 & 1.6 & 2.3 & 0.6415 \\\\ 2.4093 & 0.8998 & 1.7998 & 1.5093 \\end{pmatrix} $$ Finally we do the math for $V$. $X + PE_{\\text{input}}$ and the $W_V$ matrix: $$ V = (X + PE_{\\text{input}}) \\times W_V $$ Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_V = \\begin{pmatrix} 0 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ Multiplying the matrices, we get: $$ V = \\begin{pmatrix} 1.5 & 0 & 1.1 & 2.6 \\\\ 1.3415 & 0.6416 & 1.6001 & 2.3 \\\\ 2.4093 & 1.5095 & 0.9 & 1.7998 \\end{pmatrix} $$ We perform the same calculations for $Y$. Here are the results: $$ \\text{Q} = \\begin{pmatrix} 1 & 1 & 2 & 0 \\\\ 1.7415 & 1.7001 & 2.5 & 0.9416 \\\\ 2.7093 & 0.5 & 2.1998 & 1.0095 \\end{pmatrix} $$ $$ \\text{K} = \\begin{pmatrix} 1 & 1 & 0 & 2 \\\\ 1.7001 & 1.7415 & 0.9416 & 2.5 \\\\ 0.5 & 2.7093 & 1.0095 & 2.1998 \\end{pmatrix} $$ $$ \\text{V} = \\begin{pmatrix} 1 & 0 & 1 & 2 \\\\ 1.7415 & 0.9416 & 1.7001 & 2.5 \\\\ 2.7093 & 1.0095 & 0.5 & 2.1998 \\end{pmatrix} $$ This gives us the $V$ matrix. With $Q$, $K$, and $V$ matrices in hand, you're ready to compute the attention scores and proceed with the self-attention mechanism. Next we need to calculate the attention score with: $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V$$ I did this with this python code : $$ \\text{Attention}(Q, K, V) = \\begin{pmatrix} 2.11372594 & 1.21488963 & 1.06582258 & 1.96465889 \\\\ 2.10729705 & 1.1957622 & 1.06288922 & 1.97442407 \\\\ 1.82115196 & 0.90157546 & 1.21880742 & 2.13838393 \\end{pmatrix} $$ It's worth mentioning that the result of this portion of the equation (before we multiply by $V$): $$\\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right)$$ the result is: $$\\begin{pmatrix} 0.07057112 & 0.21671075 & 0.71271813 \\ 0.08861574 & 0.2073653 & 0.70401897 \\ 0.16858447 & 0.40724309 & 0.42417243 \\end{pmatrix}$$ Notice how, as we expected with softmax, each row of the matrix adds to one. This is what is creating our probability distribution. Attention Heads and Multi Attention Heads I will not do all the math here as it is an exact repeat of what we have above, but the actual models will use multiple attention heads. Each attention head \"pays attention\" to different parts of the sentence. The goal being to avoid a few tokens (words) having an outsized impact on the output. We want to pay attention to the totality of the sentence. Consider a sentence like \"Jane, who recently graduated from Harvard, is starting her new job at Google.\" In this sentence, the words \"Harvard\" and \"Google\" are likely to have high attention scores because they are proper nouns and often important in text. Single-Head Attention : If you're using single-head attention to find out where Jane is starting her job, the model might give high attention to both \"Harvard\" and \"Google\". This could be misleading because the word \"Harvard\" isn't relevant to the query about Jane's new job, even though it's generally an important token. Multi-Head Attention : In contrast, one head could focus on \"Jane\" and \"job,\" while another head could focus on \"Harvard\" and \"Google,\" and yet another head could focus on \"recently graduated\" and \"starting.\" This way, the model can capture both the important context provided by \"Harvard\" and the fact that \"Google\" is where she is starting her new job, without letting the importance of \"Harvard\" overshadow the relevance of \"Google\" to the query. Returning to Troy Wang's paper : One problem of the self-attention layer is that by only using a single set of trained matrices ( Q, K, ) and ( V ), the self-attention could be dominated by just one or a few tokens, and thereby not being able to pay attention to multiple places that might be meaningful. Therefore, by using multi-heads, we aim to linearly combine the results of many independent self-attention computations, and thereby expand the self-attention layer's ability to focus on different positions [VSP+17] [Alammar18]. More concretely, we use multiple sets of mutually independent ( (Q), (K), ) and ( (V) ) matrices, each being randomly initialized and independently trained. With multiple ( (Q), (K), ) and ( (V) ) matrices, we end up with multiple resulting vectors for every input token vector. Nonetheless, the feedforward neural network in the next step is designed to only accept one vector per word input. In order to combine those vectors, we concatenate them into a single vector and then multiply it with another weight vector which is trained simultaneously. Formally, this multi-head attention is defined as $$ MultiHead(Q, K, V) = Concat(head_1, ..., head_h) W_O $$ where $head_i = Attention(Q W_i^Q, K W_i^K, V W_i^V)$ What this would actually look like. Here we just make up some matrix and assume that it is the output from head 2; it would have been generated exactly as we did the output from the first head. Compute for Head 2 : First, let's assume the output of the second attention head ( head_2 ) is: $$ \\text{Attention}_2(Q, K, V) = \\begin{pmatrix} 1.5 & 0.8 & 1.2 & 2.0 \\\\ 1.6 & 0.9 & 1.1 & 2.1 \\\\ 1.4 & 0.7 & 1.3 & 1.9 \\end{pmatrix} $$ Concatenate Outputs : Now, we concatenate the outputs of head_1 and head_2 : $$ \\text{Concat}(\\text{Attention}_1, \\text{Attention}_2) = \\begin{pmatrix} 2.11372594 & 1.21488963 & 1.06582258 & 1.96465889 & 1.5 & 0.8 & 1.2 & 2.0 \\\\ 2.10729705 & 1.1957622 & 1.06288922 & 1.97442407 & 1.6 & 0.9 & 1.1 & 2.1 \\\\ 1.82115196 & 0.90157546 & 1.21880742 & 2.13838393 & 1.4 & 0.7 & 1.3 & 1.9 \\end{pmatrix} $$ Final Linear Projection : Finally, we multiply the concatenated matrix with a learned projection matrix $W_O$. For the sake of simplicity in this example, let's assume $W_O$ is an 8x4 matrix filled with 0.5. In a real-world scenario, this matrix would have learned values. I generated random values for $W_O$ but in reality this would start random and the model would train these values over time. $$ W_O = \\begin{pmatrix} 0.37738326 & 0.83274845 & 0.37280978 & 0.14584743 \\\\ 0.28706851 & 0.29072609 & 0.69116998 & 0.20106682 \\\\ 0.26764653 & 0.12058646 & 0.82634382 & 0.60818759 \\\\ 0.44329703 & 0.4425581 & 0.89811744 & 0.24551412 \\\\ 0.9186323 & 0.40029736 & 0.17636762 & 0.06896409 \\\\ 0.41921272 & 0.0495383 & 0.77792527 & 0.4354529 \\\\ 0.14791365 & 0.66822966 & 0.48313699 & 0.94127396 \\\\ 0.11604641 & 0.51794357 & 0.62942357 & 0.76420883 \\end{pmatrix} $$ Multiply the two together: The final multi-head attention output will be: $$ \\text{Concat}(\\text{Attention}_1, \\text{Attention}_2) = \\begin{pmatrix} 2.11372594 & 1.21488963 & 1.06582258 & 1.96465889 & 1.5 & 0.8 & 1.2 & 2.0 \\\\ 2.10729705 & 1.1957622 & 1.06288922 & 1.97442407 & 1.6 & 0.9 & 1.1 & 2.1 \\\\ 1.82115196 & 0.90157546 & 1.21880742 & 2.13838393 & 1.4 & 0.7 & 1.3 & 1.9 \\end{pmatrix} $$ I don't want to get too into the weeds on this, but it is worth making a brief note on why this is better than RNN. The short version is it's faster. For starters, all the calculations for each attention head can run in parallel completely independently. The other great part is that the calculation is independent of input length. You could feed in 1000 words or 500 and the attention calculation runs at the same speed. Layer Normalization As the model trains itself, problems frequently arise. For example: Without layer normalization, the model could suffer from issues related to the internal covariate shift. Here's a simple example: Let's say we have a neural network for binary classification and a layer that takes two features $x_1$ and $x_2$ as input. Initially, $x_1$ and $x_2$ are both in the range of [0, 1]. First Epoch : The model learns some weights and biases based on $x_1$ and $x_2$. Second Epoch : We add new features, or the features themselves change distribution, such that $x_1$ is now in the range of [0, 1000] while $x_2$ remains in [0, 1]. Without layer normalization, this change in feature scale will make the previously learned weights and biases less useful, and the model may need a lot of time to adjust to this new scale. It might even diverge and fail to train. In contrast, if we use layer normalization, the inputs are rescaled to have zero mean and unit variance, making it easier for the model to adapt to the new data distribution. Layer normalization keeps the scales consistent, making training more stable. After layer normalization is applied the results won't be restricted to a specific range like [0, 1] or [-1, 1] as in the case of some other normalization techniques. Instead, layer normalization will center the data around zero and will scale based on the standard deviation, but there's no hard constraint on the range of the output values. However, after layer normalization, the mean of each row (or each example, in the context of a neural network) will be approximately 0, and the standard deviation will be approximately 1. The actual values can be positive or negative and can exceed the range of [-1, 1], depending on the original data and its distribution. Layer normalization is applied to each data point within a given example, rather than across examples in the dataset (which is what batch normalization does). Given matrix $M$: $$ M = \\begin{pmatrix} 4.42554033 & 5.589241 & 6.99844643 & 4.79288192 \\\\ 4.55176485 & 5.6122494 & 7.09923364 & 4.82144704 \\\\ 4.21254506 & 5.31988824 & 6.84520426 & 4.79017392 \\end{pmatrix} $$ The layer normalization for each row (example) in $M$ is calculated as: $$ \\text{LN}(x_i) = \\gamma \\times \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta $$ $x_i$ is the input vector (a row in $M$ in our case). $\\mu$ is the mean of $x_i$. $\\sigma^2$ is the variance of $x_i$. $\\gamma$ and $\\beta$ are learnable parameters, which can be set to 1 and 0 respectively for simplification. $\\epsilon$ is a small constant added for numerical stability (can be set to $1e-6$ or similar). I don't show the breakdown of applying the formula here but what really matters is understanding what the formula does. See this python code for how I got the results. $$ \\text{LN}(x_i) = \\begin{pmatrix} -1.03927142 & 0.13949668 & 1.56694829 & -0.66717355 \\\\ -0.97825977 & 0.09190721 & 1.59246789 & -0.70611533 \\\\ -1.10306273 & 0.02854757 & 1.58729045 & -0.51277529 \\end{pmatrix} $$ The whole process from beginning to end: Image Source Feed Forward Neural Net Finally we reach the feed forward network - the piece at the heart of most AI models. So much of AI is based on these things I think it's worth spending a bit of time explaining how they work. The book Deep Learning (2017, MIT), by Ian Goodfellow, Yoshua Bengio, and Aaron Courville does a really good job of explaining this along with some common terms from deep learning so I will just quote it here. Deep feedforward networks , also often called feedforward neural networks , or multilayer perceptrons (MLPs) , are the quintessential deep learning models. The goal of a feedforward network is to approximate some function $f^ $. For example, for a classifier, $y = f^ (x)$ maps an input $x$ to a category $y$. A feedforward network defines a mapping $y = f(x; \\theta)$ and learns the value of the parameters $\\theta$ that result in the best function approximation. These models are called feedforward because information flows through the function being evaluated from $x$, through the intermediate computations used to define $f$, and finally to the output $y$. There are no feedback connections in which outputs of the model are fed back into itself. When feedforward neural networks are extended to include feedback connections, they are called recurrent neural networks , presented in chapter 10. Feedforward networks are of extreme importance to machine learning practitioners. They form the basis of many important commercial applications. For example, the convolutional networks used for object recognition from photos are a specialized kind of feedforward network. Feedforward networks are a conceptual stepping stone on the path to recurrent networks, which power many natural language applications. Feedforward neural networks are called networks because they are typically represented by composing together many different functions. The model is associated with a directed acyclic graph describing how the functions are composed together. For example, we might have three functions $f^{(1)}, f^{(2)},$ and $f^{(3)}$ connected in a chain, to form $f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$. These chain structures are the most commonly used structures of neural networks. In this case, $f^{(1)}$ is called the first layer of the network, $f^{(2)}$ is called the second layer, and so on. The overall length of the chain gives the depth of the model. It is from this terminology that the name \"deep learning\" arises. The final layer of a feedforward network is called the output layer . During neural network training, we drive $f(x)$ to match $f^ (x)$. The training data provides us with noisy, approximate examples of $f^ (x)$ evaluated at different training points. Each example $x$ is accompanied by a label $y \\approx f^ (x)$. The training examples specify directly what the output layer must do at each point $x$; it must produce a value that is close to $y$. The behavior of the other layers is not directly specified by the training data. The learning algorithm must decide how to use those layers to produce the desired output, but the training data does not say what each individual layer should do. Instead, the learning algorithm must decide how to use these layers to best implement an approximation of $f^ $. Because the training data does not show the desired output for each of these layers, these layers are called hidden layers . Finally, these networks are called neural because they are loosely inspired by neuroscience. Each hidden layer of the network is typically vector-valued. The dimensionality of these hidden layers determines the width of the model. Each element of the vector may be interpreted as playing a role analogous to a neuron. Rather than thinking of the layer as representing a single vector-to-vector function, we can also think of the layer as consisting of many units that act in parallel, each representing a vector-to-scalar function. Each unit resembles a neuron in the sense that it receives input from many other units and computes its own activation value. The idea of using many layers of vector-valued representation is drawn from neuroscience. The choice of the functions $f^{(i)}(x)$ used to compute these representations is also loosely guided by neuroscientific observations about the functions that biological neurons compute. However, modern neural network research is guided by many mathematical and engineering disciplines, and the goal of neural networks is not to perfectly model the brain. It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we know about the brain, rather than as models of brain function. You might be asking yourself what the difference between all this and a linear regression. The Deep Learning book gets into this on page 165. I leave out this discussion and instead provide a simple picture below which displays some true function that we are trying to approximate and allows you to compare the two graphs: I used this code to generate the plot using tensor flow. What's cool about that plot is that it is a real machine learning problem and that is the real performance of the two models. As the Deep Learning book points out, there isn't even a way to approximate something as simple as the XOR function with linear regression. Here is a plot of what XOR looks like: There is an example of how an XOR model works . Going back to the paper from Troy Wang Feed-Forward Neural Net feeds its output, an $n$ by 1 vector for each input token where $n$ is the dimension of the embedding, to the neural network layer. Each neural network layer consists of two pretrained matrices, the first one having dimension $n \\times 4n$, and the second $4n \\times n$. The input vector relayed from the self-attention layer is first multiplied with the first matrix in the neural network $W1$, resulting in a $(1 \\times 4n)$ matrix, which is then multiplied with the second matrix $W2$, resulting in a $(1 \\times n)$ matrix. This is equivalent to a vector with dimension $n$, which is uncoincidentally the same as the original input of the neural network. Note that the hyperparameter of 4 is rather arbitrary. The developers of the transformer model did not explain the reason for picking this particular hyperparameter [VSP+17]. Below is the formal representation of the feed-forward neural network that we just discussed. Note that there is also a ReLU activation in between the two multiplications. $FFN(x) = max(0, xW1 + b1) W2 + b2$ This transformation is the same across different positions in the same layer, yet each layer has its own unique parameters [VSP+17]. Let's walk through what that means in terms of our case. Input Vector Dimension $(n \\times 1)$ : In the Transformer model, for each token, the output from the self-attention layer is a vector of dimension $n$, which is fed into the FFNN layer. In our layer normalization example, each row represents a token and the number of columns represents the dimensionality ($n=4$). First Matrix $(n \\times 4n)$ : This expansion of dimensions by a factor of 4 is specific to the Transformer's FFNN layer. It's a design choice, and while there's no explicit reasoning in the original paper, it can be thought of as allowing the network more capacity to combine features before projecting them back to the original size. In our example, we expanded to 6 dimensions just for demonstration. In the Transformer, it would be 16 (4 times 4). ReLU Activation : After multiplying by the first matrix $W_1$ and adding the bias $b_1$, a ReLU (Rectified Linear Unit) activation function is applied element-wise. This introduces non-linearity, which is essential for the network to model complex patterns. This was demonstrated in our example as well with the line a1 = np.maximum(0, z1) Second Matrix $(4n \\times n)$ : The activated output from the previous step is then multiplied by a second matrix $W_2$ to bring the dimension back to $n$. In our example, this was done to bring it back to 4 dimensions. In the Transformer, it would bring it back to the original size of the embeddings. Result : The output is again a vector with dimension $n$ for each input token, ready to be processed by subsequent layers or to produce final outputs. This matches with the example where our final matrix $z2$ had rows with 4 dimensions, just like our original input. Layer-Wise Unique Parameters : The FFNN layers across positions share parameters, meaning every token goes through the same FFNN transformation within a single layer. However, each FFNN in different Transformer layers has its own set of parameters, allowing it to learn different transformations at different depths of the network. So taking it to our example. Given we start with this output from the layer normalization: $$ \\text{LN}(x_i) = \\begin{pmatrix} -1.03927142 & 0.13949668 & 1.56694829 & -0.66717355 \\\\ -0.97825977 & 0.09190721 & 1.59246789 & -0.70611533 \\\\ -1.10306273 & 0.02854757 & 1.58729045 & -0.51277529 \\end{pmatrix} $$ Now, let's pass this through a simple FFNN. We will assume: We project the data up to 6 dimensions (just for demonstration purposes) and then project it back to 4 dimensions. We use a ReLU activation function between the two linear transformations. Given this: The weight matrices will be $W_1$ of size $[4 \\times 6]$ and $W_2$ of size $[6 \\times 4]$. The bias vectors will be $b_1$ of size $[6]$ and $b_2$ of size $[4]$. Let's randomly initialize these parameters for the demonstration: $$W_1 = \\begin{pmatrix} 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 \\\\ 0.7 & 0.8 & 0.9 & 1.0 & 1.1 & 1.2 \\\\ 1.3 & 1.4 & 1.5 & 1.6 & 1.7 & 1.8 \\\\ 1.9 & 2.0 & 2.1 & 2.2 & 2.3 & 2.4 \\end{pmatrix}$$ $$b_1 = \\begin{pmatrix} 0.01 \\\\ 0.02 \\\\ 0.03 \\\\ 0.04 \\\\ 0.05 \\\\ 0.06 \\end{pmatrix}$$ $$W_2 = \\begin{pmatrix} 0.1 & 0.7 & 1.3 & 1.9 \\\\ 0.2 & 0.8 & 1.4 & 2.0 \\\\ 0.3 & 0.9 & 1.5 & 2.1 \\\\ 0.4 & 1.0 & 1.6 & 2.2 \\\\ 0.5 & 1.1 & 1.7 & 2.3 \\\\ 0.6 & 1.2 & 1.8 & 2.4 \\end{pmatrix}$$ $$b_2 = \\begin{pmatrix} 0.01 \\\\ 0.02 \\\\ 0.03 \\\\ 0.04 \\end{pmatrix}$$ Applying the FFNN: First linear transformation: $z_1 = \\text{LN}(x_i) \\times W_1 + b_1$ Apply ReLU activation: $a_1 = \\text{ReLU}(z_1)$ Second linear transformation: $z_2 = a_1 \\times W_2 + b_2$ Final output $z_2$ will be of size [3x4] representing the transformed data. When you run this process through Python you get: $$\\text{FFN}(x)=\\begin{pmatrix} 1.70355949 & 4.58680433 & 7.47004916 & 10.353294 \\\\ 1.56070622 & 4.19905974 & 6.83741326 & 9.47576678 \\\\ 2.19865128 & 5.93062489 & 9.66259851 & 13.39457212 \\end{pmatrix}$$ Now we rerun layer normalization against that result using exactly the same process as before for the final output of our encoder. $$\\text{LN}(x_o) = \\begin{pmatrix} -1.34164072 & -0.44721357 & 0.44721357 & 1.34164072 \\\\ -1.34164071 & -0.44721357 & 0.44721357 & 1.34164071 \\\\ -1.34164075 & -0.44721358 & 0.44721358 & 1.34164075 \\end{pmatrix}$$ Our resulting columns are coincidentally the same because the FNN values are scalar multiples ($\\times 3$) due to the way I arbitrarily set this up. This wouldn't happen in the scope of billions of variables. Prepare and Embed Target Sequence for Decoder Recall, this is the overview of our decoder process. Source Image here From this article Coming to the Decoder stack, the target sequence is fed to the Output Embedding and Position Encoding, which produces an encoded representation for each word in the target sequence that captures the meaning and position of each word. This is fed to all three parameters, Query, Key, and Value in the Self-Attention in the first Decoder which then also produces an encoded representation for each word in the target sequence, which now incorporates the attention scores for each word as well. After passing through the Layer Norm, this is fed to the Query parameter in the Encoder-Decoder Attention in the first Decoder The first thing we have to do is take out output embedding and calculate self attention on it just as we did for the input embedding . Our output embedding was: $$ Y + PE_{\\text{output}} = \\begin{pmatrix} 0.0 + 0 & 0.0 + 1 & 0.0 + 0 & 0.0 + 1 \\\\ -0.2 + 0.8415 & 0.4 + 0.99995 & 0.3 + 0.0001 & 0.1 + 1 \\\\ 0.5 + 0.9093 & -0.1 + 0.9998 & -0.4 + 0.0002 & 0.3 + 1 \\end{pmatrix} = \\begin{pmatrix} 0.0 & 1.0 & 0.0 & 1.0 \\\\ 0.6415 & 1.39995 & 0.3001 & 1.1 \\\\ 1.4093 & 0.8998 & -0.3998 & 1.3 \\end{pmatrix} $$ The math for the attention head on the decoder is the same as it was for the input stack so I do not show it here. The Python I used to generate the example is here . The result of the process is: $$\\text{Attention}_2(Q, K, V) = \\begin{pmatrix} 2.82896639 & 2.49151229 & 3.27935978 & 3.36785616 \\\\ 2.93697775 & 2.57919015 & 3.42996786 & 3.49210994 \\\\ 2.95810782 & 2.60399936 & 3.43836135 & 3.51718943 \\end{pmatrix}$$ Likewise, the math for layer normalization remains the same as it was for the input . The result here is: $$\\text{LN}(x_o) = \\begin{pmatrix} -0.46049196 & -1.4140849 & 0.81224991 & 1.06232694 \\\\ -0.46121408 & -1.41736871 & 0.85625689 & 1.02232591 \\\\ -0.46146504 & -1.41536061 & 0.83223948 & 1.04458616 \\end{pmatrix}$$ Attention Masking One thing I don't describe here that the article does describe is attention masking. Recall how at the beginning we had start padding? We do not want our model to pay attention to that start padding so we actually mask that out. We also mask out future characters in the decode process because remember, we've given the decoder exactly the right answer. We don't want it to look ahead at the answer and guess it exactly, we want it to try to guess it. So we also mask out future words at each stage of the process. I have done that in the Python code but I haven't gone through the math here. Decoder Stack Processing with Encoder Output The same post describes the encoder-decoder attention block. The Encoder-Decoder Attention takes its input from two sources. Therefore, unlike the Encoder Self-Attention, which computes the interaction between each input word with other input words, and Decoder Self-Attention which computes the interaction between each target word with other target words, the Encoder-Decoder Attention computes the interaction between each target word with each input word. So what does that look like: Compute the Queries (Q) from the Decoder's Output : For the encoder-decoder attention, the queries are derived from the decoder, while the keys and values are derived from the encoder. Using the decoder's output $\\text{LN}(x_o)$ and the decoder's weight matrix $W_Q$: $$ Q = \\text{LN}(x_o) \\times W_Q $$ Compute the Keys (K) and Values (V) from the Encoder's Output : Using the encoder's output and the encoder's weight matrices $W_K$ and $W_V$: $$ K = \\text{LN}(x_e) \\times W_K $$ $$ V = \\text{LN}(x_e) \\times W_V $$ Compute the Attention Scores : This is done by multiplying the queries and keys, and then dividing by the square root of the depth of the keys (in this case, the number of columns in our matrices, which is 4): $$ \\text{Scores} = \\frac{Q \\times K^T}{\\sqrt{4}} $$ Apply Masking : As with before we need to mask out future words. Compute the Attention Weights : $$ \\text{Attention Weights} = \\text{Softmax}(\\text{Scores}) $$ Compute the Output of the Attention Mechanism : This is done by multiplying the attention weights with the values: $$ \\text{Attention Output} = \\text{Attention Weights} \\times V $$ Putting that all into Python you get: $$\\begin{pmatrix} -1.7888543 & 1.7888543 & 0. & 0. \\\\ -1.7888543 & 1.7888543 & 0. & 0. \\\\ -1.7888543 & 1.7888543 & 0. & 0. \\end{pmatrix}$$ Since this is a toy example the values are effectively nonsense. Output Layer for Word Probabilities With this output you would then do the following: To get from the output of Decoder-2 to the words \"de nada\", you would have to follow several steps, based on the provided diagram: Linear Transformation : The output of Decoder-2 is passed through a linear layer. This involves multiplying the output by a learned weight matrix. The purpose of this step is to transform the output dimensions to match the size of the vocabulary. Suppose your vocabulary has $V$ words. The weight matrix for the linear layer will have dimensions suitable to project the decoder's output into a shape like (sequence_length, V) , where sequence_length is the number of words/tokens in the output sequence. For simplicity, let's assume you have a small vocabulary of 10,000 words (including \"de\" and \"nada\"). The transformation will convert the 4-dimensional output of each sequence element into a 10,000-dimensional vector. Softmax Activation : After the linear transformation, the output values are passed through a softmax function to convert them into probabilities. The softmax function ensures that the values are between 0 and 1 and that they sum to 1 across the vocabulary for each sequence position. This will give you a probability distribution over all words in the vocabulary for each position in the output sequence. Selecting the Word : For each position in the output sequence, you would pick the word in the vocabulary with the highest probability. This is often done using an argmax function. So, for the first position, if the word \"de\" has the highest probability, it's selected. For the second position, if \"nada\" has the highest probability, it's selected, and so on. Final Output : Concatenate the chosen words together based on their sequence position to get the final output, which in this case would be \"de nada\". In practice, especially during training, the process might involve more complexities like teacher forcing, beam search during inference, etc., to improve the quality of the translations. But the above steps are the basic ones to go from Decoder-2's output to the final translated words. And that's it, our transformer output is complete! Loss Function and Back-Propagation Ok, so we've talked through how we get output... but now how do we actually train? I struggled to decide how to write this because in reality this gets very complex. The Deep Learning book has an entire chapter dedicated to stochastic gradient descent. What I settled on is showing how we take the transformer output as described above and transform that to a probability distribution. Let's first go through the process in broad terms. Cross-Entropy Loss Calculation : The transformer generates logits, which are the outputs of the model's final linear layer before applying the softmax function. These logits represent the unnormalized log probabilities of each word in the model's vocabulary. We then apply the softmax function to the logits to obtain a probability distribution over the vocabulary (predicted probabilities). Cross-entropy loss is then calculated between the predicted probabilities and the true distribution, which is typically represented as a one-hot encoded vector indicating the true next word in the sequence. Gradient Computation : To improve the model, we need to know how to adjust the parameters to reduce the loss. This is done by computing the gradient of the loss with respect to each parameter. In the context of a transformer, this means calculating the derivatives of the loss with respect to each element in the weight matrices and biases throughout the network. The gradients indicate the direction in which we should adjust our parameters to reduce the loss; a positive gradient suggests that increasing the parameter would increase the loss, while a negative gradient suggests that increasing the parameter would decrease the loss. Weight Update : Once we have the gradients, we use them to update the model\u2019s weights. This is done by subtracting a fraction of the gradient from the current weights. This fraction is determined by the learning rate\u2014a hyperparameter that controls how big a step we take during optimization. Backpropagation Through Time (BPTT) : Because transformers process sequences, we need to consider not just the immediate outputs but also how a change in weights affects the subsequent parts of the sequence. Backpropagation through time is a method of applying the chain rule to unroll the sequence and calculate the impact of weights on loss at each time step. Iteration and Convergence : This entire process is repeated for many iterations\u2014each iteration is an opportunity to adjust the weights slightly to reduce the loss. Over many iterations, this process is designed to converge on a set of weights that minimizes the loss, making the model's predictions as accurate as possible. Regularization and Optimization Techniques : In practice, additional techniques such as dropout, layer normalization, and advanced optimizers like Adam or RMSprop are used to improve training stability, avoid overfitting, and ensure that the optimization process converges efficiently. Each of these steps is carefully monitored using validation sets to ensure that the model is learning generalizable patterns and not just memorizing the training data. Let's take a look at a concrete example. Let's look at a concrete example: Sure, let's consider a simple example involving a language model that is training to predict the next word in a sentence. Let's say our model's current task is to predict the word following \"The cat sat on the ___.\" For simplicity, imagine our model's vocabulary only consists of four words: {mat, hat, bat, rat}, each represented by a one-hot encoded vector: $\\text{mat} = [1, 0, 0, 0]$ $\\text{hat} = [0, 1, 0, 0]$ $\\text{bat} = [0, 0, 1, 0]$ $\\text{rat} = [0, 0, 0, 1]$ The true next word in our training example is \"mat\", so the true probability distribution (one-hot encoded) for this example is: $$ y = [1, 0, 0, 0] $$ Now, let's say our model predicts the probabilities for each word as follows: $$\\begin{pmatrix} \\text{mat} & \\text{hat} & \\text{bat} & \\text{rat} \\ 0.7 & 0.1 & 0.1 & 0.1 \\end{pmatrix}$$ where .7 is the model's confidence that the next word is \"mat\". The predicted probability distribution is: $$ P = [0.7, 0.1, 0.1, 0.1] $$ We then calculate the cross-entropy loss for this single example as: $$ L = -\\sum_{i=1}^4 y_i \\log(p_i) \\ L = -(1 \\cdot \\log(0.7) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1)) \\ L = -(\\log(0.7)) \\ L \\approx 0.357 $$ In this case, the loss is relatively low because the model's prediction was quite close to the true distribution, with a high probability assigned to the correct word \"mat\". If the model were very wrong, say it predicted: $$ P = [0.1, 0.1, 0.1, 0.7] $$ The cross-entropy loss would then be: $$ L = -\\sum_{i=1}^4 y_i \\log(p_i) \\ L = -(1 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.7)) \\ L = -(\\log(0.1)) \\ L \\approx 2.303 $$ The loss is now much higher, reflecting the poor quality of the prediction. By backpropagating this loss and updating the model's weights accordingly, the model is trained to make better predictions over time. Let's say we wanted to fix that that second scenario. How do we do that? We do it with gradient descent. A real description of gradient descent is too long to describe here. The aforementioned deep learning book has a lengthy discussion on it. To compute the gradient of the cross-entropy loss with respect to the model's predictions (which are the inputs to the softmax function, the aforementioned logits), we need to differentiate the loss with respect to each logit for each class. Given the true distribution $y = [1, 0, 0, 0]$ and the model's predicted probabilities $P = [0.1, 0.1, 0.1, 0.7]$, the loss $L$ for this incorrect prediction was calculated as approximately 2.303. Now, we'll compute the gradient of $L$ with respect to the logits, which are the inputs to the softmax function that produced $P$. If $Z$ are the logits and $P$ is obtained by applying the softmax function to $Z$, then for the softmax output for class $i$, we have: $$P_i = \\frac{e^{Z_i}}{\\sum_{k=1}^{V} e^{Z_k}}$$ The gradient of the cross-entropy loss $L$ with respect to the logits $Z$ can be simplified to: $$\\frac{\\partial L}{\\partial Z_i} = P_i - y_i$$ The expression represents the partial derivative of the cross-entropy loss function $L$ with respect to the logit $Z_i$ for class $i$. Here's what's being differentiated: Loss Function $L$ : The cross-entropy loss function measures the difference between the model's predicted probabilities for each class (given by the softmax function) and the actual distribution of the labels (typically a one-hot encoded vector in classification tasks). A single class here being a possible next word. Logits $Z$ : The logits are the outputs of the model that are fed into the softmax function. They are the raw, unnormalized scores that the model believes each class deserves based on the input data. When we differentiate $L$ with respect to $Z_i$, we are calculating how a small change in the logit $Z_i$ for any class $i$ will affect the overall loss $L$. This gradient is crucial because it provides the information needed to adjust the model parameters (weights and biases) during the training process to minimize the loss. This process is what allows the model to learn from data. Given our predicted probabilities and the true labels, the gradient for each class would be: For the \"mat\" class (class 1): $\\frac{\\partial L}{\\partial Z_{\\text{mat}}} = P_{\\text{mat}} - y_{\\text{mat}} = 0.1 - 1 = -0.9$ For the \"hat\" class (class 2): $\\frac{\\partial L}{\\partial Z_{\\text{hat}}} = P_{\\text{hat}} - y_{\\text{hat}} = 0.1 - 0 = 0.1$ For the \"bat\" class (class 3): $\\frac{\\partial L}{\\partial Z_{\\text{bat}}} = P_{\\text{bat}} - y_{\\text{bat}} = 0.1 - 0 = 0.1$ For the \"rat\" class (class 4): $\\frac{\\partial L}{\\partial Z_{\\text{rat}}} = P_{\\text{rat}} - y_{\\text{rat}} = 0.7 - 0 = 0.7$ These gradients tell us how much we need to adjust each logit to reduce the loss. A negative gradient for \"mat\" indicates that we need to increase the corresponding logit value to increase the probability of the correct class, while a positive gradient for the other classes indicates that we need to decrease those logit values to reduce their probabilities. The gradient values indicate the direction and magnitude of change needed to reduce the loss with respect to each class's logit (unnormalized log probabilities before softmax). For the \"mat\" class (class 1): $\\frac{\\partial L}{\\partial Z_{\\text{mat}}} = -0.9$ The true class was \"mat\" (since $y_{\\text{mat}} = 1$), but the model predicted a low probability (0.1). The negative gradient (-0.9) indicates the model should increase the logit for \"mat\" to increase its probability upon the next iteration. For the \"hat\" class (class 2): $\\frac{\\partial L}{\\partial Z_{\\text{hat}}} = 0.1$ The model incorrectly assigned a small probability to \"hat\", which wasn't the true class. The positive gradient suggests the model should decrease the logit for \"hat\" to reduce its probability next time. For the \"bat\" class (class 3): $\\frac{\\partial L}{\\partial Z_{\\text{bat}}} = 0.1$ Similar to \"hat\", \"bat\" is not the true class, and it also received a small probability. Again, the model should decrease the logit for \"bat\". For the \"rat\" class (class 4): $\\frac{\\partial L}{\\partial Z_{\\text{rat}}} = 0.7$ \"Rat\" is not the true class, but the model assigned it a high probability (0.7). The large positive gradient value indicates a strong need to decrease the logit for \"rat\" to correct this error. In essence, the gradient tells you how to tweak the logits to reduce the loss in the next training step: - Negative gradients imply an increase in the respective logit value is needed (to increase the probability of the true class). - Positive gradients imply a decrease in the respective logit value is needed (to reduce the probability of incorrect classes). So now we take that information and use it to update the weights: Gradient Descent Step : The weights $W$ are updated by subtracting the product of the learning rate $\\alpha$ and the gradient: $$ W_i = W_i - \\alpha \\cdot \\frac{\\partial L}{\\partial Z_i} $$ where $W_i$ is the weight corresponding to class $i$ and the learning rate is a hyperparameter. So for our example you would get: $$ Z[0] = Z[0] - 0.1 \\times (-0.9) \\ Z[1] = Z[1] - 0.1 \\times 0.1 \\ Z[2] = Z[2] - 0.1 \\times 0.1 \\ Z[3] = Z[3] - 0.1 \\times 0.7 $$ Given a learning rate $\\alpha = 0.1$, the updated probabilities after one iteration would be: For the \"mat\" class, since the gradient was -0.9: $P_{\\text{mat}} = 0.1 + 0.1 \\times 0.9 = 0.1 + 0.09 = 0.19$ For the \"hat\", \"bat\", and \"rat\" classes, since the gradients were 0.1 and 0.7 respectively: $P_{\\text{hat}} = P_{\\text{bat}} = 0.1 - 0.1 \\times 0.1 = 0.1 - 0.01 = 0.09$ $P_{\\text{rat}} = 0.7 - 0.1 \\times 0.7 = 0.7 - 0.07 = 0.63$ After the first update, the probabilities would be: - $P_{\\text{mat}} = 0.19$ - $P_{\\text{hat}} = P_{\\text{bat}} = 0.09$ - $P_{\\text{rat}} = 0.63$ However, we need to re-normalize these probabilities because they won't sum up to 1 after the update. This is usually done by passing the updated weights $Z$ through a softmax function to get the new probabilities $P$. If we were working with the logits $Z$ directly, we would subtract the gradients scaled by the learning rate from the logits, and then apply the softmax to get the next set of probabilities. Here is a Python script which performs the work: import numpy as np # Define the initial weights weights = np.array([0.1, 0.1, 0.1, 0.7]) # True class index true_class = 0 # Define the learning rate learning_rate = 0.01 # Number of iterations iterations = 2000 # Apply gradient descent for i in range(iterations): # Compute the probabilities using softmax # Softmax formula: P(class_i) = e^(Z_i) / sum(e^(Z_j) for j in classes) exp_weights = np.exp(weights) probabilities = exp_weights / np.sum(exp_weights) # Compute the gradient for each class # Gradient for true class: (P(class_i) - 1) # Gradient for other classes: P(class_i) gradients = probabilities.copy() gradients[true_class] -= 1 # Update the weights with the gradients # Weight update formula: W_i = W_i - learning_rate * gradient_i weights -= learning_rate * gradients # Print the weights and probabilities at each 10th step if i % 10 == 0: print(f\"Iteration {i}: Weights: {weights}\") print(f\"Iteration {i}: Probabilities: {probabilities}\") # Calculate final probabilities using the updated weights final_probabilities = np.exp(weights) / np.sum(np.exp(weights)) print(\"\\nFinal probabilities: \", final_probabilities) Here is what the ouput looks like: Iteration 0: Weights: [0.10792622 0.09792622 0.09792622 0.69622133] Iteration 0: Probabilities: [0.20737772 0.20737772 0.20737772 0.37786684] ...SNIP... Iteration 1990: Weights: [ 3.41207767 -0.86673008 -0.86673008 -0.6786175 ] Iteration 1990: Probabilities: [0.95742224 0.0132765 0.0132765 0.01602477] Final probabilities: [0.95765298 0.01320591 0.01320591 0.0159352 ] Now imagine that this is instead done over the totality of a language with a massive vocabulary instead of four words. That's what a real LLM is doing. With all of that learned, we are finally ready to go to the main event - GPT. Generative Pre-Trained Transformer (GPT) What's so different about GPT models? The most obvious problem with the above is the same problem everyone has... you have to have training data. Creating training data is tedious, error prone, and generally difficult. So what makes GPT models special? They work on unlabeled text. You can point them at a huge corpus of text and they can train themselves. Even better, you can feed in labeled data to enhance a GPT model for domain-specific tasks. As Troy Wang points out though In fact, in the case of GPT3 (the third generation of GPT), its parameters and training corpus are so large, and its task-agnostic performance is so good, such that fine-tuning is no longer essential. Instead, providing a few examples in the input prompt, which is also called few-shots in-context learning, is sufficient for most tasks [BMR+20]. I'll also cite him again to describe the next big point: Another architectural difference between GPT and traditional transformers is that instead of relying on both encoders and decoders, GPT gets rid of the encoders and instead derives its performance from stacking many decoders. Additionally, the sheer scale of GPT models is groundbreaking in itself. GPT models have exponentially more parameters and use exponentially larger training sets than the original transformer model. The original version of GPT comes with 150 million parameters [RNS+18]. GPT2 has 1.5 billion parameters, while GPT3, the latest version of the GPT series models, has a mind blowing 175 billion parameters [RWC+19] [BMR+20]. This is what the GPT model in contrast to what we saw in the original transformer. Source Image Going Through an Example Input Representation: Suppose we have a sentence: \"I love AI,\" which we tokenize as $[\"I\", \"love\", \"AI\"]$. Here are our randomly selected embeddings: $$ U = { \\text{\"I\"}: [0.12, 0.87], \\text{\"love\"}: [0.56, 0.32], \\text{\"AI\"}: [0.74, 0.51] } $$ For our positional encoding matrix (W_p), we use: $$ W_p = \\left[ 0.02, 0.04, 0.03, 0.07, 0.05, 0.09 \\right] $$ Embedding and Positional Encoding: Combining our embeddings with our positional encodings, we get: $$ h_0 = U + W_p $$ For \"I\": $$ h_0(\\text{\"I\"}) = \\left[ 0.14, 0.91 \\right] $$ For \"love\": $$ h_0(\\text{\"love\"}) = \\left[ 0.59, 0.39 \\right] $$ For \"AI\": $$ h_0(\\text{\"AI\"}) = \\left[ 0.79, 0.60 \\right] $$ Masked Self-Attention The math for the self attention mechanism remain the same as they were in this section The difference is that the output of: $$ Score = \\frac{Q \\times K^T}{\\sqrt{d_k}} $$ is multiplied by: $$ \\text{Mask} = \\begin{pmatrix} 0 & -\\infty & -\\infty \\ 0 & 0 & -\\infty \\ 0 & 0 & 0 \\end{pmatrix} $$ This has the effect of masking out future tokens so that the model is only able to use the information from previous tokens to predict the future tokens. Visually this appears as: Image Source Suppose for our masked self-attention, the attention weights (for the word \"love\") give 0.1 importance to the word \"I\" and 0.9 to itself. The word \"AI\" hasn't appeared yet, so it gets 0 importance. Hence, the attention output for \"love\" will be: $$ h_1(\\text{\"love\"}) = 0.1 \\times h_0(\\text{\"I\"}) + 0.9 \\times h_0(\\text{\"love\"}) = \\left[ 0.155, 0.458 \\right] $$ Feed Forward and Layer Norm Let's use a simplified feed-forward mechanism. Assuming a linear transformation with a weight matrix (W): $$ W = \\left[ 0.2, 0.3, 0.4, 0.5 \\right] $$ The output for the word \"love\" will be: $$ h_2(\\text{\"love\"}) = h_1(\\text{\"love\"}) \\times W = \\left[ 0.1753, 0.309 \\right] $$ Output This remains the same as before . Training Model Objective: The primary goal during pre-training is to maximize the likelihood of a particular token given its preceding tokens. For a model being trained, it tries to predict the next word in a sequence using the context provided by the preceding words. Context Window: For \"I love AI,\" if we were to use a context window of two words, the model would be given \"I love\" and would try to predict \"AI.\" Tokenizing and Embeddings: The passage mentions breaking down input into embeddings. In the case of \"I love AI,\" the words \"I,\" \"love,\" and \"AI\" are tokenized and then converted into dense vectors or embeddings. These embeddings capture semantic meanings and relationships between words. Maximizing Likelihood: As the formula $L_1(U) = \\Sigma_i \\log P(u_i|u_{i-k}, ..., u_{i-1})$ suggests, the model tries to maximize the probability (or likelihood) of observing the token $u_i$ given its previous k tokens. For our example \"I love AI,\" if you feed \"I love\" into the model, it should assign a high probability to \"AI\" being the next word, assuming \"I love AI\" is a frequent phrase in the training data. Unsupervised Nature: The term \"unsupervised\" implies that there's no explicit label provided to the model for training. Instead, the model uses the context (preceding words) as input and tries to predict the next word. The correct answer (or \"label\") is just the next word in the sequence. So, the data itself provides both the input and the \"label.\" GPT Time Complexity Self-Attention Mechanism: The self-attention mechanism calculates attention scores between each pair of tokens in the input. Thus, if you have an input sequence of length $n$, you'd need to compute scores for every pair, leading to $n^2$ pairwise computations. Matrix Multiplication: For each of the pairwise computations, we perform matrix multiplication with the Query, Key, and Value matrices. If $d$ represents the dimensionality of the embeddings (or the size of the model), then this matrix multiplication step has a time complexity of $O(d)$. Aggregating Time Complexity: Taking both of the above steps into account, the overall time complexity for the self-attention mechanism becomes $O(n^2 \\times d)$. Number of Layers: GPT models, like all transformer-based models, consist of multiple layers (blocks). If $l$ is the number of layers, then the time complexity considering all layers becomes $O(l \\times n^2 \\times d)$. Other Components: Apart from the self-attention mechanism, there are feed-forward neural networks and layer normalization in each layer of the transformer. However, the operations associated with these components are linear with respect to the sequence length and do not significantly alter the quadratic nature of the transformer's time complexity. The primary bottleneck in terms of time complexity for GPT models is the self-attention mechanism, which has a time complexity of the aforementioned $O(l \\times n^2 \\times d)$. The quadratic dependence on the sequence length $n$ means that as the input gets longer, the time taken for computation increases quadratically. This is one of the reasons why there's usually a limit on the maximum sequence length that transformer models can handle. It's also worth noting that while the theoretical time complexity gives us an understanding of how computation grows with the size of input and model, in practice, optimizations, hardware accelerations, and efficient implementations will have a huge impact on the performance of the model. To provide a rough order of magnitude, GPT3 has 175 layers and d is often set to a value like 1024 in a large model. Retrieval Augmented Generation (RAG) RAG is a technique used to take an existing model and extend it with new information. Input Processing : Question : Take a question as input. For example, \"What are the health benefits of green tea?\" Embedding : Convert this question into a vector using the same transformer model used for encoding the documents in the database. Retrieval Phase : Approximate Nearest Neighbor Search : Using the embedded question, perform an ANN search in the database to retrieve the most relevant documents. Let's say we retrieve 'N' documents. Document Vectors : These documents are represented by their respective embedding vectors, say $([D_1, D_2, ..., D_N])$. Combining Retrieved Knowledge with LLM : Contextual Integration : The LLM is provided with both the original question and the retrieved documents to generate an answer. Attention Mechanism : The model uses a cross-attention mechanism between the question and each of the retrieved documents to understand the context better. Generating the Answer : Sequence Generation : The LLM generates the answer token by token. For each token: It computes a probability distribution over the vocabulary. The probability is conditioned on the input question and the retrieved documents. The model chooses the token with the highest probability at each step. Example : The model might start with \"Green tea is known for its...\", incorporating information from both the question and the content of the retrieved documents. Loss Calculation and Training : Training : During training, the model's parameters are adjusted to minimize the difference between the generated answer and the correct answer. Loss Function : A common choice is the cross-entropy loss between the predicted and actual answers. Joint Training : Both the retrieval component and the generation model are trained jointly to improve the coherence between retrieved documents and generated answers. Mathematical Representation Question Embedding : ( Q = \\text{Transformer}( \\text{\"What are the health benefits of green tea?\"} ) ) Document Retrieval : ( [D_1, D_2, ..., D_N] = \\text{ANN_Search}(Q) ) Generation Probability : ( P(\\text{word} | Q, D_1, D_2, ..., D_N) ) Answer Generation : ( \\text{Answer} = \\arg\\max \\prod P(\\text{word} i | \\text{word} {<i}, Q, D_1, D_2, ..., D_N) ) Nearest Neighbor Search A nearest neighbor search (NNS) is an algorithm used to find the closest or most similar data points to a given query point in a dataset. The General Idea Dataset : Consider a dataset comprising a collection of points. These points could represent anything depending on the application - for instance, they could be vectors encoding the features of images, text, or any type of numerical data. Query Point : You have a query point (or a search point), and you want to find the point(s) in your dataset that are closest to this query point. Distance Metric : A distance metric is used to measure the closeness or similarity between points. Common metrics include Euclidean distance, Manhattan distance, cosine similarity, and others, depending on the nature of the data and the application. Algorithms for Nearest Neighbor Searches: What matters: Scalability : ANN algorithms are designed to handle very large datasets efficiently, which is crucial for RAG models as they often involve searching through extensive collections of documents or embeddings. Speed : Exact NNS can be computationally intensive and time-consuming, especially in high-dimensional spaces (like text embeddings). ANN provides a good balance between accuracy and computational efficiency. Dimensionality : Text data, when converted into embeddings (vector representations), typically reside in high-dimensional space. ANN algorithms are more adept at handling the curse of dimensionality than exact NNS methods. Common Algorithms Locality-Sensitive Hashing (LSH) : LSH is a method of performing probabilistic dimension reduction of high-dimensional data. It hashes input items so that similar items map to the same \u201cbuckets\u201d with high probability. Hierarchical Navigable Small World Graphs (HNSW) : HNSW is known for its high efficiency and accuracy, especially in high-dimensional data. It builds a layered graph structure that allows for faster query times. Faiss (Facebook AI Similarity Search) : Developed by Facebook AI, Faiss is a library for efficient similarity search and clustering of dense vectors. It contains implementations of several ANN algorithms and is optimized for use with GPUs. Annoy (Approximate Nearest Neighbors Oh Yeah) : Annoy is a C++ library with Python bindings to search for points in space that are close to a given query point. It's particularly useful for large datasets and is used by Spotify for music recommendation. Common problems and solutions: Curse of Dimensionality : As the number of dimensions (features) of the data increases, finding the nearest neighbor becomes computationally intensive. This is because the volume of the space increases exponentially with each additional dimension, making the data points sparse. Approximate Nearest Neighbor (ANN) : To counter the computational challenges, especially in high-dimensional spaces, approximate methods are used. These methods do not always guarantee the exact nearest neighbor but can find an approximation much faster. Indexing Structures : Data structures like KD-trees, Ball trees, and Hash tables are used to optimize NNS, making searches faster than a brute-force search that compares the query point with every point in the dataset. Parallelization and Distributed Computing : Leveraging multiple processors or distributed systems can significantly speed up nearest neighbor searches in large datasets. Supplemental Information Word Embeddings The first question(s) I asked when I saw these matrices is, \"Where do these values come from and what are they?\" What followed soon after was, \"Why do they exist?\" Why they exist lends context to where do they come from and what are they. Why do they exist The article Large language models, explained with a minimum of math and jargon does a fantastic job of answering this in a non-mathematical way. The goal here is that we want to describe mathematically the relationship between some given word and other words because this will then allow us to more accurately predict what words should go in the answers our LLM produces. Words that are similar should have similar vector values. This concept was pioneered at Google in a paper called Word2vec . You can see this visually at this website . For example, I wanted to see what airplanes are likely to be related to airplanes: The percentage similarity to \"airplane\": aeroplane : NOUN, 0.8153 aircraft : NOUN, 0.7992 plane : NOUN, 0.7429 airliner : NOUN, 0.7398 helicopter : NOUN, 0.7006 aircraave : NOUN, 0.6568 biplane : NOUN, 0.6540 airship : NOUN, 0.6404 dc-3 : NOUN, 0.6297 seaplane : NOUN, 0.6271 Where do these values come from? The answer is it depends. There are three potential places these values may originate from at first: Random Initialization: Here, the embeddings are initialized with small random values. These values then get adjusted during training to capture semantic meanings. Pre-trained Embeddings: Instead of starting with random values, it's common to initialize the embeddings with vectors from pre-trained models like Word2Vec, GloVe, or FastText. These embeddings are trained on vast corpora and capture general language semantics. Depending on the task and the dataset, these pre-trained embeddings can either be kept static during training or be fine-tuned. Training from Scratch: In some cases, especially when the domain-specific language is very different from general language (e.g., medical texts or legal documents), embeddings might be trained from scratch along with the rest of the model. The values in the embedding are updated during the training phase. Most models today will start with one of the sets of values defined above so you aren't starting from scratch. That also gets you a much more accurate model much faster. What are they? Realistic answer? We don't really fully understand. We understand parts, but the simple answer is that the model learns values it \"thinks\" are sensible. There are entire papers written to explain just fractions of the relationships. Weight Matrices The weight matrices $W_Q$, $W_K$, and $W_V$ are learned parameters in the self-attention mechanism of the transformer model. Here's a more detailed explanation: 1. Initialization : At the beginning of the training process, these matrices are usually initialized with small random values. This can be achieved through various initialization techniques, such as Xavier or He initialization. 2. Training : During the training process, the transformer model is fed with input data, and it tries to minimize the difference between its predictions and the actual output (this difference is often measured using a loss function like cross-entropy for classification tasks). As the model is trained using optimization algorithms like stochastic gradient descent (SGD) or its variants (e.g., Adam, RMSprop), these weight matrices get updated iteratively. The updates are done in a direction that reduces the loss. 3. Role of Backpropagation : The updating of these matrices is governed by backpropagation, a fundamental technique in training deep neural networks. Gradients are computed for the loss with respect to each element of these matrices, which indicates how much a small change in that element would affect the overall loss. These gradients are then used to adjust the matrices in the direction that minimizes the loss. 4. Final Model : After many iterations (epochs) of training, these matrices converge to values that allow the transformer model to effectively compute self-attention over the input data. In other words, through training, the model learns the best values for these matrices to perform the task at hand, whether it's language translation, text classification, or any other NLP task. Softmax Let's say we have a neural network that is trying to classify an input into one of three categories. The final layer of the network produces a vector of logits (raw prediction scores) for each category: $$ x = [2.0, 1.0, 0.2] $$ Here: - The first value (2.0) corresponds to the prediction score for Category A. - The second value (1.0) is for Category B. - The third value (0.2) is for Category C. To interpret these scores as probabilities, we use the softmax function. Applying softmax: $$ \\text{softmax}(x)_i = \\frac{e^{x_i}}{{\\sum e^{x_j}}} $$ $$ \\text{softmax}(x)_i = \\frac{e^{x_i}}{{\\sum e^{x_j}}} $$ For each component: $$ \\text{softmax}(x)_A = \\frac{e^{2.0}}{e^{2.0} + e^{1.0} + e^{0.2}} $$ $$ \\text{softmax}(x)_B = \\frac{e^{1.0}}{e^{2.0} + e^{1.0} + e^{0.2}} $$ $$ \\text{softmax}(x)_C = \\frac{e^{0.2}}{e^{2.0} + e^{1.0} + e^{0.2}} $$ Computing these, we might get something like: $$ \\text{softmax}(x) = [0.65, 0.24, 0.11] $$ The results are probabilities: - Category A: 65% - Category B: 24% - Category C: 11% The values sum up to 1, and the largest logit (2.0 for Category A) corresponds to the largest probability (65%). Why do we use softmax for self attention? Normalization : The raw logits can be any set of values, positive or negative. Softmax ensures that we get a proper probability distribution where values are between 0 and 1 and sum up to 1. Emphasizing Differences : Even subtle differences in logits can be emphasized. In our example, the difference between 2.0 and 1.0 becomes a difference between 65% and 24% in probabilities. Self-attention mechanism : In the context of Transformers and self-attention, softmax is applied to the scores (results of Q and K dot products) to determine the weight or attention each input should get. By turning these scores into probabilities, the model decides which parts of the input sequence are most relevant for each position, effectively weighting the contribution of each input's value (from the V matrix) when producing the output. Matrix Multiplication Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ First row of $Q$: Multiply each element of the first row of $(X + PE_{\\text{input}})$ with the corresponding element of each column in $W_Q$, then sum them up. $$ Q[1,1] = (0.1 \\times 1) + (1.2 \\times 0) + (-0.1 \\times 0) + (1.4 \\times 1) = 0.1 + 0 + 0 + 1.4 = 1.5 $$ $$ Q[1,2] = (0.1 \\times 0) + (1.2 \\times 1) + (-0.1 \\times 1) + (1.4 \\times 0) = 0 + 1.2 - 0.1 + 0 = 1.1 $$ $$ Q[1,3] = (0.1 \\times 0) + (1.2 \\times 1) + (-0.1 \\times 0) + (1.4 \\times 1) = 0 + 1.2 + 0 + 0 = 1.2 $$ $$ Q[1,4] = (0.1 \\times 1) + (1.2 \\times 0) + (-0.1 \\times 1) + (1.4 \\times 0) = 0.1 + 0 - 0.1 + 0 = 0 $$ Second row of $Q$ $$ Q[2,1] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 1 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 0 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 0 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[2,2] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 0 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 1 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 1 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 0 $$ $$ Q[2,3] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 0 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 1 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 0 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[2,4] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 1 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 0 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 1 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 0 $$ Third row of $Q$ $$ Q[3,1] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 1 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 0 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 0 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[3,2] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 0 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 1 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 1 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 0 $$ $$ Q[3,3] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 0 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 1 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 0 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[3,4] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 1 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 0 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 1 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 0 $$ Plug that into some Python: import numpy as np X_PE_input = np.array([ [0.1, 1.2, -0.1, 1.4], [-0.3 + np.sin(1), 0.5 + np.cos(1/10000**0.5), 0.1 + np.sin(1/10000**2), -0.2 + np.cos(1/10000**2.5)], [0.4 + np.sin(2), -0.3 + np.cos(2/10000**0.5), 0.2 + np.sin(2/10000**2), 0.1 + np.cos(2/10000**2.5)] ]) W_Q = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) Q = X_PE_input.dot(W_Q) print(Q) that will get you: [[1.5 1.1 2.6 0. ] [1.34147098 1.59995001 2.29995 0.64147099] [2.40929743 0.89980003 1.79980001 1.50929745]] Printed nicely out to four decimal places: $$ \\begin{pmatrix} 1.5 & 1.1 & 2.6 & 0 \\\\ 1.3415 & 1.6 & 2.3 & 0.6415 \\\\ 2.4093 & 0.8998 & 1.7998 & 1.5093 \\end{pmatrix} $$ You can get all three matrices with: import numpy as np # Input matrix X = np.array([ [0.1, 1.2, -0.1, 1.4], [0.5415, 1.49995, 0.1001, 0.8], [1.3093, 0.6998, 0.2002, 1.1] ]) # Weight matrices W_Q = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) W_K = np.array([ [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1] ]) W_V = np.array([ [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 1, 0], [1, 0, 0, 1] ]) # Matrix multiplication Q = np.dot(X, W_Q) K = np.dot(X, W_K) V = np.dot(X, W_V) print(\"Q:\") print(Q) print(\"\\nK:\") print(K) print(\"\\nV:\") print(V) Output Q: [[1.5 1.1 2.6 0. ] [1.3415 1.60005 2.29995 0.6416 ] [2.4093 0.9 1.7998 1.5095 ]] K: [[1.1 1.5 0. 2.6 ] [1.60005 1.3415 0.6416 2.29995] [0.9 2.4093 1.5095 1.7998 ]] V: [[1.5 0. 1.1 2.6 ] [1.3415 0.6416 1.60005 2.29995] [2.4093 1.5095 0.9 1.7998 ]] > Calculating Y Calculate for $Y$: import numpy as np # Input matrix X X = np.array([ [0.0, 1.0, 0.0, 1.0], [0.6415, 1.39995, 0.3001, 1.1], [1.4093, 0.8998, -0.3998, 1.3] ]) # Weight matrices W_Q, W_K, W_V W_Q = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) W_K = np.array([ [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1] ]) W_V = np.array([ [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 1, 0], [1, 0, 0, 1] ]) # Calculate Q, K, V matrices Q = np.dot(X, W_Q) K = np.dot(X, W_K) V = np.dot(X, W_V) print(\"Q matrix:\") print(Q) print(\"K matrix:\") print(K) print(\"V matrix:\") print(V) Output: Q matrix: [[1. 1. 2. 0. ] [1.7415 1.70005 2.49995 0.9416 ] [2.7093 0.5 2.1998 1.0095 ]] K matrix: [[1. 1. 0. 2. ] [1.70005 1.7415 0.9416 2.49995] [0.5 2.7093 1.0095 2.1998 ]] V matrix: [[1. 0. 1. 2. ] [1.7415 0.9416 1.70005 2.49995] [2.7093 1.0095 0.5 2.1998 ]] Calculate Attention Score import numpy as np from scipy.special import softmax def attention(Q, K, V): d_k = Q.shape[-1] matmul_qk = np.dot(Q, K.T) # Scale the matrix multiplication scaled_attention_logits = matmul_qk / np.sqrt(d_k) # Apply softmax attention_weights = softmax(scaled_attention_logits, axis=-1) # Multiply by the Value matrix output = np.dot(attention_weights, V) return output # Given matrices Q = np.array([[1.5, 1.1, 2.6, 0.], [1.3415, 1.60005, 2.29995, 0.6416], [2.4093, 0.9, 1.7998, 1.5095]]) K = np.array([[1.1, 1.5, 0., 2.6], [1.60005, 1.3415, 0.6416, 2.29995], [0.9, 2.4093, 1.5095, 1.7998]]) V = np.array([[1.5, 0., 1.1, 2.6], [1.3415, 0.6416, 1.60005, 2.29995], [2.4093, 1.5095, 0.9, 1.7998]]) result = attention(Q, K, V) print(\"Attention(Q, K, V) = \") print(result) Output: Attention(Q, K, V) = [[2.11372594 1.21488963 1.06582258 1.96465889] [2.10729705 1.1957622 1.06288922 1.97442407] [1.82115196 0.90157546 1.21880742 2.13838393]] Calculate Multi-Attention Head Output import numpy as np # Given attention outputs Attention1 = np.array([ [2.11372594, 1.21488963, 1.06582258, 1.96465889], [2.10729705, 1.1957622, 1.06288922, 1.97442407], [1.82115196, 0.90157546, 1.21880742, 2.13838393] ]) Attention2 = np.array([ [1.5, 0.8, 1.2, 2.0], [1.6, 0.9, 1.1, 2.1], [1.4, 0.7, 1.3, 1.9] ]) # Concatenate the attention outputs concat_attention = np.concatenate([Attention1, Attention2], axis=1) # Given W_O matrix W_O = np.array([ [0.37738326, 0.83274845, 0.37280978, 0.14584743], [0.28706851, 0.29072609, 0.69116998, 0.20106682], [0.26764653, 0.12058646, 0.82634382, 0.60818759], [0.44329703, 0.4425581, 0.89811744, 0.24551412], [0.9186323, 0.40029736, 0.17636762, 0.06896409], [0.41921272, 0.0495383, 0.77792527, 0.4354529 ], [0.14791365, 0.66822966, 0.48313699, 0.94127396], [0.11604641, 0.51794357, 0.62942357, 0.76420883] ]) # Multiply concatenated output with W_O multihead_output = concat_attention.dot(W_O) print(multihead_output) Output: [[4.42554033 5.589241 6.99844643 4.79288192] [4.55176485 5.6122494 7.09923364 4.82144704] [4.21254506 5.31988824 6.84520426 4.79017392]] Calculate Layer Normalization import numpy as np # Define matrix M M = np.array([ [4.42554033, 5.589241, 6.99844643, 4.79288192], [4.55176485, 5.6122494, 7.09923364, 4.82144704], [4.21254506, 5.31988824, 6.84520426, 4.79017392] ]) # Initialize epsilon for numerical stability epsilon = 1e-6 # Calculate mean and variance for each row mean = np.mean(M, axis=1, keepdims=True) variance = np.var(M, axis=1, keepdims=True) # Compute layer normalization LN_M = (M - mean) / np.sqrt(variance + epsilon) print(LN_M) Output: [[-1.03927142 0.13949668 1.56694829 -0.66717355] [-0.97825977 0.09190721 1.59246789 -0.70611533] [-1.10306273 0.02854757 1.58729045 -0.51277529]] Linear Regression Code import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression import tensorflow as tf # Generate data X = np.linspace(-10, 10, 100).reshape(-1, 1) y = np.sin(X) # Create and train the linear model linear_model = LinearRegression() linear_model.fit(X, y) # Predict with linear model y_linear_pred = linear_model.predict(X) # Create and train the neural network model nn_model = tf.keras.Sequential([ tf.keras.layers.Dense(10, input_shape=(1,), activation='relu'), tf.keras.layers.Dense(10, activation='relu'), tf.keras.layers.Dense(1) ]) nn_model.compile(optimizer='adam', loss='mean_squared_error') nn_model.fit(X, y, epochs=1000, verbose=0) # Predict with neural network model y_nn_pred = nn_model.predict(X) # Plotting fig, axs = plt.subplots(1, 2, figsize=(12, 6)) # Linear model plot axs[0].scatter(X, y, label='True Function', color='blue') axs[0].plot(X, y_linear_pred, label='Linear Model', color='red') axs[0].legend() axs[0].set_title('Linear Model') # Deep Feedforward Network plot axs[1].scatter(X, y, label='True Function', color='blue') axs[1].plot(X, y_nn_pred, label='Deep Network', color='green') axs[1].legend() axs[1].set_title('Deep Feedforward Network') plt.show() Output: Plot XOR import matplotlib.pyplot as plt def plot_xor(): # Coordinates for the points x = [0, 1, 0, 1] y = [0, 0, 1, 1] # XOR values for the points colors = [0, 1, 1, 0] # Plot the points plt.scatter(x, y, c=colors, s=100, cmap=\"gray\", edgecolors=\"black\", linewidth=1.5) # Set axis labels and title plt.xlabel(\"$x_1$\") plt.ylabel(\"$x_2$\") plt.title(\"Original $x$ space\") # Adjust axis limits plt.xlim(-0.1, 1.1) plt.ylim(-0.1, 1.1) # Show grid plt.grid(True, which='both', linestyle='--', linewidth=0.5) # Set equal aspect ratio plt.gca().set_aspect('equal', adjustable='box') plt.show() plot_xor() Output: XOR Example 1. Dataset for XOR: $x_1$ $x_2$ XOR 0 0 0 0 1 1 1 0 1 1 1 0 2. Architecture: - A 2-layer feedforward network - Input layer has 2 neurons (for $x_1$ and $x_2$) - Hidden layer has 2 neurons - Output layer has 1 neuron 3. Forward Pass: Suppose we have the following weights and biases: For the hidden layer: $$ W = \\begin{bmatrix} 20 & 20 \\ -20 & -20 \\end{bmatrix} $$ $$ c = \\begin{bmatrix} -10 \\ 30 \\end{bmatrix} $$ For the output layer: $$ w = \\begin{bmatrix} 20 \\ 20 \\end{bmatrix} $$ $$ b = -30 $$ We'll use the sigmoid function as our non-linearity: $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$ 4. Computing for each Input: For input $x = [0, 0]$: Hidden layer outputs: $$ h_1 = \\sigma(0 \\times 20 + 0 \\times 20 - 10) = \\sigma(-10) \\approx 0 $$ $$ h_2 = \\sigma(0 \\times -20 + 0 \\times -20 + 30) = \\sigma(30) \\approx 1 $$ Output layer: $$ y = \\sigma(0 \\times 20 + 1 \\times 20 - 30) = \\sigma(-10) \\approx 0 $$ This matches the XOR output for [0, 0], which is 0. Similar computations for the other inputs will provide the respective XOR outputs, illustrating that the network can represent the XOR function. The hidden layer effectively captures the regions of the input space where the XOR function is 1, and the output layer then combines these regions to produce the final XOR result. Using Rectified Linear Units (ReLU) ReLU is the most common activation function for deep learning so I figured I'd rewrite the example to use it just to compare and contrast. 1. Dataset for XOR remains the same: $x_1$ $x_2$ XOR 0 0 0 0 1 1 1 0 1 1 1 0 2. Architecture: - A 2-layer feedforward network - Input layer has 2 neurons (for $x_1$ and $x_2$) - Hidden layer has 2 neurons - Output layer has 1 neuron ReLU Function: $$ \\text{ReLU}(z) = \\max(0, z) $$ 3. Forward Pass: To ensure that the ReLU activations work for the XOR problem, we will need to choose weights and biases that divide the space in a way that can be combined to represent the XOR function. For the hidden layer: $$ W = \\begin{bmatrix} 1 & -1 \\ -1 & 1 \\end{bmatrix} $$ $$ c = \\begin{bmatrix} 0 \\ 0 \\end{bmatrix} $$ For the output layer: $$ w = \\begin{bmatrix} 1 \\ 1 \\end{bmatrix} $$ $$ b = -0.5 $$ 4. Computing for each Input: For input $x = [0, 0]$: Hidden layer outputs: $$ h_1 = \\text{ReLU}(0 \\times 1 + 0 \\times -1 + 0) = 0 $$ $$ h_2 = \\text{ReLU}(0 \\times -1 + 0 \\times 1 + 0) = 0 $$ Output layer: $$ y = \\text{ReLU}(0 \\times 1 + 0 \\times 1 - 0.5) = 0 $$ This matches the XOR output for [0, 0], which is 0. For the input $x = [0, 1]$: Hidden layer outputs: $$ h_1 = \\text{ReLU}(0 \\times 1 + 1 \\times -1 + 0) = 0 $$ $$ h_2 = \\text{ReLU}(0 \\times -1 + 1 \\times 1 + 0) = 1 $$ Output layer: $$ y = \\text{ReLU}(0 \\times 1 + 1 \\times 1 - 0.5) = 0.5 $$ For XOR, we can threshold the output at $0.5$, such that $y \\geq 0.5$ outputs 1, else outputs 0. Following this thresholding, the output is 1, matching the XOR for [0, 1]. Similarly, you can compute the outputs for the other inputs $[1, 0]$ and $[1, 1]$, and they will match the expected XOR outputs with threshold at 0.5. A quick Python program to prove this out: import numpy as np def relu(z): return max(0, z) def forward_pass(x): # Hidden Layer W = np.array([[1, -1], [-1, 1]]) c = np.array([0, 0]) h = np.vectorize(relu)(np.dot(x, W) + c) # Output Layer w = np.array([1, 1]) b = -0.5 y = relu(np.dot(h, w) + b) # Thresholding at 0.5 for XOR if y >= 0.5: return 1 else: return 0 inputs = [[0, 0], [0, 1], [1, 0], [1, 1]] outputs = [] for x in inputs: outputs.append(forward_pass(x)) print(\"Inputs:\", inputs) print(\"Outputs:\", outputs) Outputs: Inputs: [[0, 0], [0, 1], [1, 0], [1, 1]] Outputs: [0, 1, 1, 0] Math for FFN import numpy as np # Layer Normalized Data LN_xi = np.array([ [-1.03927142, 0.13949668, 1.56694829, -0.66717355], [-0.97825977, 0.09190721, 1.59246789, -0.70611533], [-1.10306273, 0.02854757, 1.58729045, -0.51277529] ]) # Parameters W1 = np.array([ [0.1, 0.2, 0.3, 0.4, 0.5, 0.6], [0.7, 0.8, 0.9, 1.0, 1.1, 1.2], [1.3, 1.4, 1.5, 1.6, 1.7, 1.8], [1.9, 2.0, 2.1, 2.2, 2.3, 2.4] ]) b1 = np.array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06]) W2 = np.array([ [0.1, 0.7, 1.3, 1.9], [0.2, 0.8, 1.4, 2.0], [0.3, 0.9, 1.5, 2.1], [0.4, 1.0, 1.6, 2.2], [0.5, 1.1, 1.7, 2.3], [0.6, 1.2, 1.8, 2.4] ]) b2 = np.array([0.01, 0.02, 0.03, 0.04]) # First linear transformation z1 = np.dot(LN_xi, W1) + b1 # Apply ReLU activation a1 = np.maximum(0, z1) # Second linear transformation z2 = np.dot(a1, W2) + b2 print(z2) If you want to see the first row, first column calculated separately: import numpy as np # Layer Normalized Data for the first row LN_xi_row1 = np.array([-1.03927142, 0.13949668, 1.56694829, -0.66717355]) # Parameters W1 = np.array([ [0.1, 0.2, 0.3, 0.4, 0.5, 0.6], [0.7, 0.8, 0.9, 1.0, 1.1, 1.2], [1.3, 1.4, 1.5, 1.6, 1.7, 1.8], [1.9, 2.0, 2.1, 2.2, 2.3, 2.4] ]) b1 = np.array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06]) W2_col1 = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6]) b2_col1 = 0.01 # First linear transformation for the first row z1_row1 = np.dot(LN_xi_row1, W1) + b1 # Apply ReLU activation for the first row a1_row1 = np.maximum(0, z1_row1) # Second linear transformation for the first column z2_row1_col1 = np.dot(a1_row1, W2_col1) + b2_col1 print(z2_row1_col1) Decoder Attention Heads I used this code to generate the results for the decoder attention heads. import numpy as np # Define the position encoding matrix for the output PE_output = np.array([[0.0, 1.0, 0.0, 1.0], [0.6415, 1.39995, 0.3001, 1.1], [1.4093, 0.8998, -0.3998, 1.3]]) # Generate random matrices for weights np.random.seed(42) # Setting seed for reproducibility d_model = 4 # The dimensionality of the input and output d_k = d_model d_v = d_model W_q = np.random.rand(d_model, d_k) W_k = np.random.rand(d_model, d_k) W_v = np.random.rand(d_model, d_v) W_o = np.random.rand(d_k, d_model) # Compute Q, K, V matrices Q = PE_output @ W_q K = PE_output @ W_k V = PE_output @ W_v # Compute the attention weights attention_weights = np.exp(Q @ K.T) / np.sum(np.exp(Q @ K.T), axis=-1, keepdims=True) # Compute the output of the self-attention mechanism output = attention_weights @ V # Project the output back to the original dimensionality output = output @ W_o # Layer Normalization mean = np.mean(output, axis=-1, keepdims=True) std = np.std(output, axis=-1, keepdims=True) eps = 1e-6 normalized_output = (output - mean) / (std + eps) print(\"Self Attention Output:\") print(output) print(\"\\nLayer Normalized Output:\") print(normalized_output) Output: Self Attention Output: [[2.82896639 2.49151229 3.27935978 3.36785616] [2.93697775 2.57919015 3.42996786 3.49210994] [2.95810782 2.60399936 3.43836135 3.51718943]] Layer Normalized Output: [[-0.46049196 -1.4140849 0.81224991 1.06232694] [-0.46121408 -1.41736871 0.85625689 1.02232591] [-0.46146504 -1.41536061 0.83223948 1.04458616]] Calculate Encoder-Decoder Output import numpy as np # Encoder Output Encoder_Output = np.array([ [-1.34164072, -0.44721357, 0.44721357, 1.34164072], [-1.34164071, -0.44721357, 0.44721357, 1.34164071], [-1.34164075, -0.44721358, 0.44721358, 1.34164075] ]) # Decoder Output Decoder_Output = np.array([ [-0.46049196, -1.4140849, 0.81224991, 1.06232694], [-0.46121408, -1.41736871, 0.85625689, 1.02232591], [-0.46146504, -1.41536061, 0.83223948, 1.04458616] ]) # Encoder Weights W_Q_enc = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) W_K_enc = np.array([ [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1] ]) W_V_enc = np.array([ [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 1, 0], [1, 0, 0, 1] ]) # Decoder Weights W_Q_dec = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) # Compute Queries, Keys, and Values for Encoder Q_enc = Encoder_Output.dot(W_Q_enc.T) K_enc = Encoder_Output.dot(W_K_enc.T) V_enc = Encoder_Output.dot(W_V_enc.T) # Compute Queries for Decoder Q_dec = Decoder_Output.dot(W_Q_dec.T) # Attention Scores Scores = Q_dec.dot(K_enc.T) / np.sqrt(3) def softmax(x): e_x = np.exp(x - np.max(x)) return e_x / e_x.sum(axis=-1, keepdims=True) # Compute attention weights Attention_Weights = softmax(Scores) # Compute Weighted sum of Values Attention_Output = Attention_Weights.dot(V_enc) print(\"Attention Weights:\") print(Attention_Weights) print(\"\\nAttention Output:\") print(Attention_Output) Output: Attention Weights: [[0.33333333 0.33333333 0.33333334] [0.33333333 0.33333333 0.33333334] [0.33333333 0.33333333 0.33333334]] Attention Output: [[-1.7888543 1.7888543 0. 0. ] [-1.7888543 1.7888543 0. 0. ] [-1.7888543 1.7888543 0. 0. ]] What is Cross Entropy Loss Cross-entropy loss in the context of LLMs such as transformers is a measure of the difference between the model's predicted probability distribution over the vocabulary and the true distribution, typically represented as a one-hot encoded vector for the actual next token in the sequence. For a single prediction, it's calculated as: $$ L = -\\sum_{i=1}^V y_i \\log(p_i) $$ where $V$ is the size of the vocabulary, $y_i$ is the one-hot encoding of the true token (1 for the true token and 0 for all others), and $p_i$ is the predicted probability of the $i$-th token. Why Do We Use It? Comparing Probability Distributions : Cross-entropy is inherently a measure for comparing two probability distributions, making it well-suited for tasks where the output is a set of probabilities\u2014such as predicting the next token in a sequence. Gradient Optimization : It enables efficient training of neural networks through gradient-based optimization techniques. In LLMs, the gradients can be efficiently computed for backpropagation to adjust the model's parameters. Logarithmic Scaling : This feature of cross-entropy provides a natural and strong gradient signal for learning, which is especially important for models dealing with a large output space, such as the vocabularies in LLMs. Direct Feedback for Probability Prediction : Cross-entropy directly penalizes the model based on how divergent its probability predictions are from the actual distribution, which in the case of LLMs is crucial for generating coherent text sequences. Information Theoretic Interpretation : It stems from information theory, where it measures the number of extra bits needed due to the inefficiency of assuming the predicted distribution instead of the true distribution. In training LLMs, cross-entropy loss is pivotal in guiding the model to adjust its internal parameters. By minimizing this loss, a model learns to increase the probability it assigns to the actual next token and decrease the probabilities of all other tokens, thus aligning the predicted distribution closer to the true distribution, token by token. This is key to generating text that closely follows the human language patterns. You can verify this yourself with this Python code: import numpy as np # True label y_true = np.array([1, 0, 0, 0]) # The correct word is 'mat' # Predictions predictions_1 = np.array([0.7, 0.1, 0.1, 0.1]) # Model's prediction is good predictions_2 = np.array([0.1, 0.1, 0.1, 0.7]) # Model's prediction is poor # Function to calculate cross-entropy loss def cross_entropy(y_true, predictions): return -np.sum(y_true * np.log(predictions)) # Calculate loss loss_1 = cross_entropy(y_true, predictions_1) loss_2 = cross_entropy(y_true, predictions_2) print(f\"Loss for first prediction: {loss_1:.3f}\") print(f\"Loss for second prediction: {loss_2:.3f}\") Output: Loss for first prediction: 0.357 Loss for second prediction: 2.303 Other Sources Retrieval-Augmented Generation for Knowledge Intensive NLP Tasks Nvidia - AI Chatbot with Retrieval Augmented Generation","title":"LLMs Explained"},{"location":"LLMs%20Explained/#llms-explained","text":"","title":"LLMs Explained"},{"location":"LLMs%20Explained/#the-math-behind-gpt-models-rough-draft","text":"The Math Behind GPT Models (Rough Draft) Overview How Transformers Work 1 - Input Sequence to Encoder Embeddings 1.5 Position Encoding Input Embedding: \"You are welcome\" Output Embedding: \" de nada\" Adding Them Together Encoder Stack Processing Self Attention A Concrete Example Attention Heads and Multi Attention Heads Layer Normalization Feed Forward Neural Net Prepare and Embed Target Sequence for Decoder Decoder Stack Processing with Encoder Output Output Layer for Word Probabilities Loss Function and Back-Propagation Generative Pre-Trained Transformer (GPT) What's so different about GPT models? Going Through an Example Input Representation: Embedding and Positional Encoding: Masked Self-Attention Feed Forward and Layer Norm Output Training GPT Time Complexity Retrieval Augmented Generation (RAG) Nearest Neighbor Search The General Idea Algorithms for Nearest Neighbor Searches: Supplemental Information Word Embeddings Weight Matrices Softmax Matrix Multiplication Calculating Y Calculate Attention Score Calculate Multi-Attention Head Output Calculate Layer Normalization Linear Regression Code Plot XOR XOR Example Using Rectified Linear Units (ReLU) Math for FFN Decoder Attention Heads Calculate Encoder-Decoder Output What is Cross Entropy Loss Other Sources","title":"The Math Behind GPT Models (Rough Draft)"},{"location":"LLMs%20Explained/#overview","text":"The purpose of this whitepaper is to explain at a low level how LLMs work such that we can make informed decisions about their performance and architectural decisions. I had trouble finding a single source that walked through all the pieces at a sufficient level of detail so this is more a literature review that further explains the following: GPT: Origin, Theory, Application, and Future The Deep Learning Book Transformers Explained Visually Google's Original Paper - Attention is All You Need","title":"Overview"},{"location":"LLMs%20Explained/#how-transformers-work","text":"We start by covering how transformers work. Transformers are the core of an LLM model. Below we discover the traditional transformer architecture. GPT-style models do not use the encoders and have what is called a decoder only architecture, but it is difficult to understand that architecture without understanding where it comes from so for this section we cover how the encoder works as well as the decoder. This article series does a fantastic job of explaining the overarching LLM learning process but there were several parts I didn't immediately understand and moreover it did not provide concrete mathematical examples to illustrate the concepts. I go through and explain the pieces of the article which didn't make sense to me and I have added concrete examples to illustrate the process mathematically. The below image is an overview model learning and inference process. There are some minor differences between the two processes which I will explain below but at this level they are the same. To illustrate how LLMs work, we will use the example of asking an LLM to translate, \"You are welcome\" to \"De Nada\". Image Source These are the high level steps which must take place. The input sequence is converted into Embeddings (with Position Encoding) and fed to the Encoder. The stack of Encoders processes this and produces an encoded representation of the input sequence. The target sequence is prepended with a start-of-sentence token, converted into Embeddings (with Position Encoding), and fed to the Decoder. The stack of Decoders processes this along with the Encoder stack\u2019s encoded representation to produce an encoded representation of the target sequence. The Output layer converts it into word probabilities and the final output sequence. The Transformer\u2019s Loss function compares this output sequence with the target sequence from the training data. This loss is used to generate gradients to train the Transformer during back-propagation. This overview was taken from here","title":"How Transformers Work"},{"location":"LLMs%20Explained/#1-input-sequence-to-encoder-embeddings","text":"Let's assume you have a word embedding model that maps each word in the sentence \"You are welcome\" to a 4-dimensional vector. I use arbitrary numbers for demonstration. Tokenization : The sentence \"You are welcome\" is tokenized into ['You', 'are', 'welcome'] . Word Embeddings : See Word Embeddings for an explanation of how these work. Assume the embedding model maps 'You' to $[0.1, 0.2, -0.1, 0.4]$. 'are' is mapped to $[-0.3, 0.5, 0.1, -0.2]$. 'welcome' is mapped to $[0.4, -0.3, 0.2, 0.1]$. Input Matrix (X) : The vectors are stacked to form the input matrix (X): $$ X = \\begin{pmatrix} 0.1 & 0.2 & -0.1 & 0.4 \\\\ -0.3 & 0.5 & 0.1 & -0.2 \\\\ 0.4 & -0.3 & 0.2 & 0.1 \\end{pmatrix} $$ This (X) matrix serves as the input to the neural network, and each row corresponds to the embedding of a word in the sentence \"You are welcome\". Now we need to do the same thing for the output embedding. In many sequence-to-sequence models like Transformers used for tasks like machine translation, a special start token (often denoted as <s> , <start> , or [START] ) and sometimes an end token (e.g., <e> , <end> , or [END] ) are added to sequences. These tokens provide signals for the beginning and end of sequences and help in the generation process. Tokenization with Start Token : The phrase \"de nada\" becomes ['<start>', 'de', 'nada'] . Word Embeddings : Assume our embedding model maps <start> to $[0.0, 0.0, 0.0, 0.0]$ (just as a placeholder; in practice, it would have a unique representation). 'de' is mapped to $[-0.2, 0.4, 0.3, 0.1]$. 'nada' is mapped to $[0.5, -0.1, -0.4, 0.3]$. Output Matrix (Y) with the start token: $$ Y = \\begin{pmatrix} 0.0 & 0.0 & 0.0 & 0.0 \\\\ -0.2 & 0.4 & 0.3 & 0.1 \\\\ 0.5 & -0.1 & -0.4 & 0.3 \\end{pmatrix} $$ The inclusion of the start token helps the model recognize the beginning of the output sequence. If there's an end token, it can similarly indicate the end of the sequence, especially useful in generation tasks. What I don't show here is a padding but in the actual models you would likely also have a pad. Ex: ['<start>', 'de', 'nada', '<pad>', '<pad>'] to make sure that the input sequences are the same size. This is a feature of the traditional transformer model but will not appear in the GPT-style models.","title":"1 - Input Sequence to Encoder Embeddings"},{"location":"LLMs%20Explained/#15-position-encoding","text":"In previous models (Recurrent Neural Networks [RNNs] typically), the position of words in a sentence and their mathematical importance were fixed by virtue of the fact that those models operated on each word sequentially. Transformers on the other hand process all words in a batch at the same time drastically reducing training/inference time. This presents a problem because word order matters. Ex: \"The cat sat on the mat.\" is not the same as \"The mat sat on the cat.\" It is important for us to include the position within the sentence as a value within our framework. To remedy this, Transformers incorporate a mechanism called Position Encoding. This mechanism is designed to infuse the sequence with positional information, ensuring the model can distinguish between \"cat sat on the mat\" and \"mat sat on the cat\". Just as there was an embedding layer for input and output there are also position encoding layers for both input and output. Importantly, the Position Encoding doesn't rely on the specific words in a sequence. Instead, it assigns a unique encoding to each possible position in the sequence. These encodings are predetermined and consistent across all sequences. These encodings are generated using the following formulas: $$ PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) $$ $$ PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) $$ where sin is used for even positions and cos is used for odd positions. $pos$: Position of the word in the sequence $d_{\\text{model}}$: Dimensionality of the embeddings $i$: Index for the dimension ranging from 0 to $d_{\\text{model}}/2 - 1$ The brilliance of this design lies in its ability to provide rich positional context without being tied to the content of the sequence. This ensures that no matter what words are present, the Transformer always understands their order. To continue our other examples: Alright, let's compute the position encodings using the given equations for both input and output embeddings. Given: - $d_{\\text{model}}$ is the dimension of the model, which in our case from the earlier examples is 4. - The $pos$ variable represents the position of the word in the sequence. - The $i$ variable ranges from 0 to $d_{\\text{model}}/2-1$. Since $d_{\\text{model}}$ is 4, $i$ will range from 0 to 1.","title":"1.5 Position Encoding"},{"location":"LLMs%20Explained/#input-embedding-you-are-welcome","text":"For the input sequence, we have 3 words, so the positions are $pos = 0, 1, 2$. Using the given equations: For $pos = 0$: $$ PE_{(0, 0)} = \\sin\\left(\\frac{0}{10000^{2(0)/4}}\\right) = 0\\space,\\space PE_{(0, 1)} = \\cos\\left(\\frac{0}{10000^{2(0+1)/4}}\\right) = 1\\space,\\space PE_{(0, 2)} = \\sin\\left(\\frac{0}{10000^{2(1)/4}}\\right) = 0\\space,\\space PE_{(0, 3)} = \\cos\\left(\\frac{0}{10000^{2(1+1)/4}}\\right) = 1\\space,\\space $$ To break that down further: $pos = 0$ $d_{\\text{model}} = 4$ For $PE_{(0,0)}$ Using the formula for even indices (2i): $$i = 0$$ $$PE_{(0, 2(0))} = \\sin\\left(\\frac{0}{10000^{2(0)/4}}\\right)$$ Since $\\sin(0)$ is 0, the value is 0. For $PE_{(0,1)}$ Using the formula for odd indices (2i+1): $$i = 0$$ $$PE_{(0, 2(0)+1)} = \\cos\\left(\\frac{0}{10000^{2(0+1)/4}}\\right)$$ Since $\\cos(0)$ is 1, the value is 1. For $PE_{(0,2)}$ Using the formula for even indices (2i): $$i = 1$$ $$PE_{(0, 2(1))} = \\sin\\left(\\frac{0}{10000^{2(1)/4}}\\right)$$ Again, since $\\sin(0)$ is 0, the value is 0. For $PE_{(0,3)}$ Using the formula for odd indices (2i+1): $$i = 1$$ $$PE_{(0, 2(1)+1)} = \\cos\\left(\\frac{0}{10000^{2(1+1)/4}}\\right)$$ Once more, since $\\cos(0)$ is 1, the value is 1. Following the same pattern for $pos = 1$ and $pos = 2$, we get: $$ PE_{\\text{input}} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ \\sin\\left(\\frac{1}{10000^0}\\right) & \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & \\sin\\left(\\frac{1}{10000^2}\\right) & \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ \\sin\\left(\\frac{2}{10000^0}\\right) & \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & \\sin\\left(\\frac{2}{10000^2}\\right) & \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 0.8415 & 0.99995 & 0.0001 & 1 \\\\ 0.9093 & 0.9998 & 0.0002 & 1 \\end{pmatrix} $$","title":"Input Embedding: \"You are welcome\""},{"location":"LLMs%20Explained/#output-embedding-de-nada","text":"For the output sequence, we also have 3 words/tokens. The positions again are $pos = 0, 1, 2$. Using the equations similarly: $$ PE_{\\text{output}} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ \\sin\\left(\\frac{1}{10000^0}\\right) & \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & \\sin\\left(\\frac{1}{10000^2}\\right) & \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ \\sin\\left(\\frac{2}{10000^0}\\right) & \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & \\sin\\left(\\frac{2}{10000^2}\\right) & \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 0.8415 & 0.99995 & 0.0001 & 1 \\\\ 0.9093 & 0.9998 & 0.0002 & 1 \\end{pmatrix} $$ Finally, to incorporate these position encodings into our embeddings, you would simply add the corresponding position encoding to each row of the embedding matrices $X$ and $Y$.","title":"Output Embedding: \" de nada\""},{"location":"LLMs%20Explained/#adding-them-together","text":"Given: $$ X = \\begin{pmatrix} 0.1 & 0.2 & -0.1 & 0.4 \\\\ -0.3 & 0.5 & 0.1 & -0.2 \\\\ 0.4 & -0.3 & 0.2 & 0.1 \\end{pmatrix} $$ $$ Y = \\begin{pmatrix} 0.0 & 0.0 & 0.0 & 0.0 \\\\ -0.2 & 0.4 & 0.3 & 0.1 \\\\ 0.5 & -0.1 & -0.4 & 0.3 \\end{pmatrix} $$ $$ PE_{\\text{input/output}} = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 0.8415 & 0.99995 & 0.0001 & 1 \\\\ 0.9093 & 0.9998 & 0.0002 & 1 \\end{pmatrix} $$ $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ 0.5415 & 1.49995 & 0.1001 & 0.8 \\\\ 1.3093 & 0.6998 & 0.2002 & 1.1 \\end{pmatrix} $$ $$ Y + PE_{\\text{output}} = \\begin{pmatrix} 0.0 & 1.0 & 0.0 & 1.0 \\\\ 0.6415 & 1.39995 & 0.3001 & 1.1 \\\\ 1.4093 & 0.8998 & -0.3998 & 1.3 \\end{pmatrix} $$ Adding position encodings to $Y$: $$ Y + PE_{\\text{output}} = \\begin{pmatrix} 0.0 + 0 & 0.0 + 1 & 0.0 + 0 & 0.0 + 1 \\\\ -0.2 + 0.8415 & 0.4 + 0.99995 & 0.3 + 0.0001 & 0.1 + 1 \\\\ 0.5 + 0.9093 & -0.1 + 0.9998 & -0.4 + 0.0002 & 0.3 + 1 \\end{pmatrix} = \\begin{pmatrix} 0.0 & 1.0 & 0.0 & 1.0 \\\\ 0.6415 & 1.39995 & 0.3001 & 1.1 \\\\ 1.4093 & 0.8998 & -0.3998 & 1.3 \\end{pmatrix} $$ These new matrices incorporate both the embeddings and the position information, and they will be used as input to subsequent layers of the Transformer model. One more thing you should take from this is that the contents of the input are independent of the position embedding. The only thing that matters is the position of the word for the position embedding. What we now have is a matrix that contains information on both the relationships of the word and its position in the sentence. This is visualized well in this post It's worth noting in our example we are only showing a single line of text but in reality you would batch multiple sets of text together in the traditional transformer model. The shape of the matrix will remain unchanged until we reach the final output layer. The other bit of complexity you see in the figure above that we don't here is that realistically the word vector matrix describing the word's relationships would be multidimensional but here we used a basic, two dimensional, matrix. Now we are ready to move onto encoding.","title":"Adding Them Together"},{"location":"LLMs%20Explained/#encoder-stack-processing","text":"The encoding process looks like this at a high level as illustrated here : At a high level this is what each component does: Self-Attention : This mechanism allows the model to weigh the importance of different words in the sequence relative to each other. It outputs a matrix of the same size which is a combination of input vectors based on their attention scores. Layer Norm : After the self-attention mechanism, the output undergoes a layer normalization to stabilize the activations and assist with training. Feed-forward : The normalized output is passed through a feed-forward neural network. This is present in each transformer block and helps in further transformation of the data. One of the things that wasn't immediately obvious to me was why this exists. It does a couple of things. First, this is where most of the \"learning\" happens. It is in the feedforward network that the complex relationships between different tokens (words) and general ideas are really stored. Each word is independently transformed by some linear transformation (IE: a matrix operation of some variety be it addition, subtraction, multiplication, division). Secondly, it introduces non-linearity. If you aren't heavy into math it may not be immediately obvious why you care about this. If you have a linear model its performance ends up being roughly the same as some sort of linear regression. That's fine for basic statistical analysis but that's what we have been doing for decades and is hardly going to do anything earth shattering for you. By making the model non-linear it allows it to create a function which more closely approximates complex relationships. Said in a non-mathy way, it is the juice that gets you the cider that is something as fantastic as ChatGPT. Third, it provides depth. What is depth is the question I first had immediately following this explanation. Imagine your model is evaluating pictures. The lowest level might learn rough outlines, maybe some colors or textures, but that's it. Maybe the picture is of a face and at the moderate levels of depth it starts to learn what an eye or a nose look like. Finally, at the deepest levels the model figures out who the picture is of or identifies whether the person is happy or sad. Layer Norm : Post feed-forward operation, another layer normalization is performed.","title":"Encoder Stack Processing"},{"location":"LLMs%20Explained/#self-attention","text":"Image source The purpose of the self attention portion of the algorithm is explained fantastically in this paper by Troy Wang . Self-attention is one of the key differentiating characteristics of the transformer model. It is a critical component that enables the Transformer to comprehend language contexts intelligently [VSP+17]. The objective of attention can be clearly illustrated by a simple example. Given an input such as \u201cProfessor Marcus gave some really good advice to Troy, one of his students, because he has extensive experiences in the academia.\u201d For a human reader, it is clear that the word \u201che\u201d in the second half of the sentence refers to \u201cProfessor Marcus,\u201d instead of his student. But for a computer program, it\u2019s not so apparent. There are many such circumstances where grammatical ambiguities legally exist, such that rule-based and hard-coded logic would not be sufficient for effective language analysis and comprehension [VSP+17][Alammar18]. This is where self-attention comes into play. When the model processes each token input, self- attention enables the model to associate the meaning of the current token with other tokens, such as associating \u201che\u201d with \u201cProfessor Marcus\u201d in our previous example, in order to gain better knowledge of this current input. In other words, the transformer model learns how to pay attention to the context thanks to the self-attention mechanism. It turns out that natural language has a lot of sequential dependencies, and thus the ability to incorporate information from previous words in the input sequence is critical to comprehending the input [VSP+17][Alammar18]. The actual math of this is a bit confusing so I found it was best to read it first from our friend Troy Wang and then I'll provide a more detailed explanation where I really break down what he is saying. Now, let's breakdown the process of computing self-attention. Before computing self-attention, each individual input token is first being converted into a vector using the embedding algorithm that we discussed earlier. Then, for each embedding, we calculate its query vector ($\\mathbf{Q}$), key vector ($\\mathbf{K}$), and value vector ($\\mathbf{V}$) by multiplying the embedding vector with three pre-trained matrices $\\mathbf{W_Q}$, $\\mathbf{W_K}$, $\\mathbf{W_V}$ intended for calculating the three matrices respectively. Notice that the three vectors all have the same dimension, and it does not have to be equal with the dimension of the embedding vectors. The dimensions of the three matrices are the same, and they are all length of the embedding vectors by the length of the ($\\mathbf{Q}$), ($\\mathbf{K}$), and ($\\mathbf{V}$) vectors. Then, for each input embedding, we dot multiply its own $\\mathbf{Q}$ vector with every other input embedding's $\\mathbf{K}$ vector. At this point, for every input embedding, we have calculated a set of score corresponding to each and every embedding in the input sequence, including itself. Then for each of the embedding, we divide all its scores by the square root of the dimension of the key vectors for more stable gradients and pass the scores through the softmax function for normalization. After this, we multiply each $\\mathbf{V}$ vector in the input sequence with its respective softmax score, and finally add up those weighted value vectors. This resulting sum vector is the self-attention of this particular input embedding [VSP+17] [Alammar18][IYA16]. Although we described the process in terms of vectors, in practice it is implemented by means of matrices. This is because the computation process for each vector independent and identical. We would stack our input embeddings as rows in an input matrix, multiply this matrix with learned weight matrices $W_Q$, $W_K$, $W_V$ and get $(Q)$, $(K)$, and $(V)$ vectors respectively, feed the three resulting matrices into the softmax function as: $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V$$ Image source Ok, let's start with explaining what exactly are Q, K, and V because that wasn't immediately obvious to me when I read Wang's paper. Of course! Let's dive deeper into the roles of the Query (Q), Key (K), and Value (V) matrices in the self-attention mechanism: Query (Q) : Purpose : The Query matrix is used to represent the current word or token we are focusing on. Think of it as asking a question: \"Which words in the sequence are most relevant to this one?\" Function : In the self-attention mechanism, the Q vector of a token is used to score how much other tokens should be attended to. By taking the dot product of Q with every K (explained below), we obtain a score that determines how much focus each token in the sequence should have in relation to the current token. Key (K) : Purpose : The Key matrix represents all the tokens that we will check our current token against to determine their level of similarity or relevance. Function : The K vectors are matched against the Q vector to produce attention scores. The intuition is that if a Q vector has a high dot product with a K vector, then the corresponding tokens are relevant to each other. This score indicates the weight or level of attention the model should give to the token represented by that particular K when considering the token represented by Q. Value (V) : Purpose : The Value matrix represents the actual content of the tokens. While Q and K are used to determine the relationships and relevance among tokens, V provides the content we want to extract based on those relationships. Function : Once we have our attention scores (from the Q-K dot products), these scores determine how much of each V vector we take into the final output. If a token is deemed highly relevant, its V vector contributes more to the final representation of the current token. An Analogy : Imagine you're a spy in a room with multiple people having conversations. You're eavesdropping on one person (the \"query\"), but you also want to gather context from what everyone else (the \"keys\") are saying to understand as much as you can. The Q (Query) is you asking: \"Who in this room is relevant to what the target (query) is saying?\" The K (Keys) are the topics each person in the room is talking about. By comparing your query to each topic (taking the dot product of Q and K), you determine who is talking about things most relevant to the person you're focusing on. The V (Values) are the actual words or content of what each person is saying. Once you've identified the most relevant people based on your query and keys, you take a weighted sum of their words (the V vectors) to get the complete context. The self-attention mechanism uses this approach to weigh the importance of different tokens in a sequence relative to a particular token, resulting in a rich contextual representation for each token in the input. Ok, now that we better understand Q, K, and V let's look at the total process from beginning to end and go through an example. $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V$$ Calculating Q, K, and V : What happens : Each embedding vector gets transformed into three different vectors: Query (Q), Key (K), and Value (V). How it happens : Multiply the embedding vector with three distinct pre-trained matrices ($W_Q$, $W_K$, and $W_V$). Why it matters : These vectors serve distinct purposes. Q is used to fetch the attention score, K provides a set of keys to match against, and V serves as a pool of values to fetch from based on those scores. Relationship to equation : This step produces the Q, K, and V vectors which are central elements in the equation. Dot Product between Q and K : What happens : Each Q vector is dot-multiplied with every K vector. How it happens : This is simple vector multiplication between Q of a particular token and the K of every other token, resulting in a score. Why it matters : This score represents how much attention should be paid to other tokens when encoding information about a particular token. Relationship to equation : This step corresponds to the $Q \\times K^T$ part of the equation. Scaling the Scores : What happens : The scores from the previous step are scaled down. How it happens : Each score is divided by the square root of the dimension of the K vectors. Why it matters : This step ensures stable gradients. Without this scaling, the gradients could be too small for effective learning, especially when the dimensionality (or depth) of the keys is large. Relationship to equation : This step is represented by the division by $\\sqrt{d_k}$ in the equation. Applying Softmax : What happens : The scores for each token are turned into a probability distribution using the softmax function. How it happens : Softmax normalizes the scores so they're between 0 and 1 and sum up to 1. Why it matters : This provides a clear set of attention \"weights\" for each token. The higher the softmax output, the more attention the model pays to the corresponding token. Relationship to equation : This step is captured by the $\\text{softmax}(\\cdot)$ operation in the equation. Calculating Weighted Values : What happens : The V vectors are multiplied by the softmax scores. How it happens : Each token's V vector is weighted by the token's respective softmax score from the previous step. Why it matters : This step essentially picks out values from the V vectors proportional to the attention scores. Tokens deemed more relevant contribute more to the final output. Relationship to equation : This step corresponds to the $\\times V$ at the end of the equation, where the weighted values from the softmax operation are combined with V. Summing Weighted Values : What happens : The weighted V vectors are summed up. How it happens : A simple vector summation. Why it matters : The resulting vector is the final output for a particular token, which is a combination of features from other tokens based on the attention scores. Relationship to equation : This summation is implied in the matrix multiplication in the equation. The result of the $\\text{softmax}(\\cdot) \\times V$ operation is the summed attention output for each token. Matrix Computations in Practice : What happens : The operations described above, while explained using vectors, are in practice executed using matrices. How it happens : Instead of processing tokens one-by-one, all tokens are processed simultaneously by stacking embeddings into a matrix and using matrix multiplication for efficiency. Why it matters : Matrix operations are highly optimized and parallelizable, making the computations significantly faster, especially on hardware like GPUs. Relationship to equation : The use of Q, K, and V in the equation reflects these matrix computations. The Attention Output : The equation one last time: $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V $$ This formula captures the essence of the self-attention mechanism. The product of Q and $K^T$ gives attention scores, which after scaling and softmax, are used to weigh the V values.","title":"Self Attention"},{"location":"LLMs%20Explained/#a-concrete-example","text":"Given the above steps for calculating self-attention, let's break it down: 1. Create Query (Q), Key (K), and Value (V) Matrices : We obtain these by multiplying the input embeddings (with position encodings) with the weight matrices $W_Q$, $W_K$, and $W_V$ respectively. For the sake of this example, we will assume these weight matrices are: $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ $$ W_K = \\begin{pmatrix} 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\end{pmatrix} $$ $$ W_V = \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\end{pmatrix} $$ Compute Q, K, and V : Multiply the input matrix $X$ with these weights: $$ Q = X \\times W_Q $$ $$ K = X \\times W_K $$ $$ V = X \\times W_V $$ Calculate Attention Scores : This is done by multiplying $Q$ with $K^T$, then dividing by the square root of the dimension of the key vectors $d_k$. In our example, $d_k$ is 4. $$ Score = \\frac{Q \\times K^T}{\\sqrt{d_k}} $$ Apply Softmax to the Scores : This will give each word's attention score. $$ SoftmaxScore = \\text{softmax}(Score) $$ Multiply Softmax Score with V : This will give the weighted representation of the input with respect to other words in the sentence. $$ AttentionOutput = SoftmaxScore \\times V $$ Let's calculate the matrices Q, K, V, Score, SoftmaxScore, and AttentionOutput: To begin, we will compute the $Q$, $K$, and $V$ matrices. Using: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ Given the weight matrices: $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ $$ W_K = \\begin{pmatrix} 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\end{pmatrix} $$ $$ W_V = \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\end{pmatrix} $$ Compute $Q$: $$ Q = (X + PE_{\\text{input}}) \\times W_Q $$ Compute $K$: $$ K = (X + PE_{\\text{input}}) \\times W_K $$ Compute $V$: $$ V = (X + PE_{\\text{input}}) \\times W_V $$ Let's calculate these values: First, let's compute the Q matrix using our input matrix ( X + PE_{\\text{input}} ) and the ( W_Q ) matrix: $$ Q = (X + PE_{\\text{input}}) \\times W_Q $$ Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ When you multiply the above matrices, you get: $$ Q = \\begin{pmatrix} 1.5 & 1.1 & 2.6 & 0 \\\\ 1.3415 & 1.6 & 2.3 & 0.6415 \\\\ 2.4093 & 0.8998 & 1.7998 & 1.5093 \\end{pmatrix} $$ If your matrix multiplication is rusty see the matrix math behind this calculation . We compute the $K$ matrix using our input matrix $X + PE_{\\text{input}}$ and the $W_K$ matrix: $$ K = (X + PE_{\\text{input}}) \\times W_K $$ Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ When you multiply the above matrices, you get: $$ Q = \\begin{pmatrix} 1.5 & 1.1 & 2.6 & 0 \\\\ 1.3415 & 1.6 & 2.3 & 0.6415 \\\\ 2.4093 & 0.8998 & 1.7998 & 1.5093 \\end{pmatrix} $$ Finally we do the math for $V$. $X + PE_{\\text{input}}$ and the $W_V$ matrix: $$ V = (X + PE_{\\text{input}}) \\times W_V $$ Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_V = \\begin{pmatrix} 0 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ Multiplying the matrices, we get: $$ V = \\begin{pmatrix} 1.5 & 0 & 1.1 & 2.6 \\\\ 1.3415 & 0.6416 & 1.6001 & 2.3 \\\\ 2.4093 & 1.5095 & 0.9 & 1.7998 \\end{pmatrix} $$ We perform the same calculations for $Y$. Here are the results: $$ \\text{Q} = \\begin{pmatrix} 1 & 1 & 2 & 0 \\\\ 1.7415 & 1.7001 & 2.5 & 0.9416 \\\\ 2.7093 & 0.5 & 2.1998 & 1.0095 \\end{pmatrix} $$ $$ \\text{K} = \\begin{pmatrix} 1 & 1 & 0 & 2 \\\\ 1.7001 & 1.7415 & 0.9416 & 2.5 \\\\ 0.5 & 2.7093 & 1.0095 & 2.1998 \\end{pmatrix} $$ $$ \\text{V} = \\begin{pmatrix} 1 & 0 & 1 & 2 \\\\ 1.7415 & 0.9416 & 1.7001 & 2.5 \\\\ 2.7093 & 1.0095 & 0.5 & 2.1998 \\end{pmatrix} $$ This gives us the $V$ matrix. With $Q$, $K$, and $V$ matrices in hand, you're ready to compute the attention scores and proceed with the self-attention mechanism. Next we need to calculate the attention score with: $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right) \\times V$$ I did this with this python code : $$ \\text{Attention}(Q, K, V) = \\begin{pmatrix} 2.11372594 & 1.21488963 & 1.06582258 & 1.96465889 \\\\ 2.10729705 & 1.1957622 & 1.06288922 & 1.97442407 \\\\ 1.82115196 & 0.90157546 & 1.21880742 & 2.13838393 \\end{pmatrix} $$ It's worth mentioning that the result of this portion of the equation (before we multiply by $V$): $$\\text{softmax}\\left(\\frac{Q \\times K^T}{\\sqrt{d_k}}\\right)$$ the result is: $$\\begin{pmatrix} 0.07057112 & 0.21671075 & 0.71271813 \\ 0.08861574 & 0.2073653 & 0.70401897 \\ 0.16858447 & 0.40724309 & 0.42417243 \\end{pmatrix}$$ Notice how, as we expected with softmax, each row of the matrix adds to one. This is what is creating our probability distribution.","title":"A Concrete Example"},{"location":"LLMs%20Explained/#attention-heads-and-multi-attention-heads","text":"I will not do all the math here as it is an exact repeat of what we have above, but the actual models will use multiple attention heads. Each attention head \"pays attention\" to different parts of the sentence. The goal being to avoid a few tokens (words) having an outsized impact on the output. We want to pay attention to the totality of the sentence. Consider a sentence like \"Jane, who recently graduated from Harvard, is starting her new job at Google.\" In this sentence, the words \"Harvard\" and \"Google\" are likely to have high attention scores because they are proper nouns and often important in text. Single-Head Attention : If you're using single-head attention to find out where Jane is starting her job, the model might give high attention to both \"Harvard\" and \"Google\". This could be misleading because the word \"Harvard\" isn't relevant to the query about Jane's new job, even though it's generally an important token. Multi-Head Attention : In contrast, one head could focus on \"Jane\" and \"job,\" while another head could focus on \"Harvard\" and \"Google,\" and yet another head could focus on \"recently graduated\" and \"starting.\" This way, the model can capture both the important context provided by \"Harvard\" and the fact that \"Google\" is where she is starting her new job, without letting the importance of \"Harvard\" overshadow the relevance of \"Google\" to the query. Returning to Troy Wang's paper : One problem of the self-attention layer is that by only using a single set of trained matrices ( Q, K, ) and ( V ), the self-attention could be dominated by just one or a few tokens, and thereby not being able to pay attention to multiple places that might be meaningful. Therefore, by using multi-heads, we aim to linearly combine the results of many independent self-attention computations, and thereby expand the self-attention layer's ability to focus on different positions [VSP+17] [Alammar18]. More concretely, we use multiple sets of mutually independent ( (Q), (K), ) and ( (V) ) matrices, each being randomly initialized and independently trained. With multiple ( (Q), (K), ) and ( (V) ) matrices, we end up with multiple resulting vectors for every input token vector. Nonetheless, the feedforward neural network in the next step is designed to only accept one vector per word input. In order to combine those vectors, we concatenate them into a single vector and then multiply it with another weight vector which is trained simultaneously. Formally, this multi-head attention is defined as $$ MultiHead(Q, K, V) = Concat(head_1, ..., head_h) W_O $$ where $head_i = Attention(Q W_i^Q, K W_i^K, V W_i^V)$ What this would actually look like. Here we just make up some matrix and assume that it is the output from head 2; it would have been generated exactly as we did the output from the first head. Compute for Head 2 : First, let's assume the output of the second attention head ( head_2 ) is: $$ \\text{Attention}_2(Q, K, V) = \\begin{pmatrix} 1.5 & 0.8 & 1.2 & 2.0 \\\\ 1.6 & 0.9 & 1.1 & 2.1 \\\\ 1.4 & 0.7 & 1.3 & 1.9 \\end{pmatrix} $$ Concatenate Outputs : Now, we concatenate the outputs of head_1 and head_2 : $$ \\text{Concat}(\\text{Attention}_1, \\text{Attention}_2) = \\begin{pmatrix} 2.11372594 & 1.21488963 & 1.06582258 & 1.96465889 & 1.5 & 0.8 & 1.2 & 2.0 \\\\ 2.10729705 & 1.1957622 & 1.06288922 & 1.97442407 & 1.6 & 0.9 & 1.1 & 2.1 \\\\ 1.82115196 & 0.90157546 & 1.21880742 & 2.13838393 & 1.4 & 0.7 & 1.3 & 1.9 \\end{pmatrix} $$ Final Linear Projection : Finally, we multiply the concatenated matrix with a learned projection matrix $W_O$. For the sake of simplicity in this example, let's assume $W_O$ is an 8x4 matrix filled with 0.5. In a real-world scenario, this matrix would have learned values. I generated random values for $W_O$ but in reality this would start random and the model would train these values over time. $$ W_O = \\begin{pmatrix} 0.37738326 & 0.83274845 & 0.37280978 & 0.14584743 \\\\ 0.28706851 & 0.29072609 & 0.69116998 & 0.20106682 \\\\ 0.26764653 & 0.12058646 & 0.82634382 & 0.60818759 \\\\ 0.44329703 & 0.4425581 & 0.89811744 & 0.24551412 \\\\ 0.9186323 & 0.40029736 & 0.17636762 & 0.06896409 \\\\ 0.41921272 & 0.0495383 & 0.77792527 & 0.4354529 \\\\ 0.14791365 & 0.66822966 & 0.48313699 & 0.94127396 \\\\ 0.11604641 & 0.51794357 & 0.62942357 & 0.76420883 \\end{pmatrix} $$ Multiply the two together: The final multi-head attention output will be: $$ \\text{Concat}(\\text{Attention}_1, \\text{Attention}_2) = \\begin{pmatrix} 2.11372594 & 1.21488963 & 1.06582258 & 1.96465889 & 1.5 & 0.8 & 1.2 & 2.0 \\\\ 2.10729705 & 1.1957622 & 1.06288922 & 1.97442407 & 1.6 & 0.9 & 1.1 & 2.1 \\\\ 1.82115196 & 0.90157546 & 1.21880742 & 2.13838393 & 1.4 & 0.7 & 1.3 & 1.9 \\end{pmatrix} $$ I don't want to get too into the weeds on this, but it is worth making a brief note on why this is better than RNN. The short version is it's faster. For starters, all the calculations for each attention head can run in parallel completely independently. The other great part is that the calculation is independent of input length. You could feed in 1000 words or 500 and the attention calculation runs at the same speed.","title":"Attention Heads and Multi Attention Heads"},{"location":"LLMs%20Explained/#layer-normalization","text":"As the model trains itself, problems frequently arise. For example: Without layer normalization, the model could suffer from issues related to the internal covariate shift. Here's a simple example: Let's say we have a neural network for binary classification and a layer that takes two features $x_1$ and $x_2$ as input. Initially, $x_1$ and $x_2$ are both in the range of [0, 1]. First Epoch : The model learns some weights and biases based on $x_1$ and $x_2$. Second Epoch : We add new features, or the features themselves change distribution, such that $x_1$ is now in the range of [0, 1000] while $x_2$ remains in [0, 1]. Without layer normalization, this change in feature scale will make the previously learned weights and biases less useful, and the model may need a lot of time to adjust to this new scale. It might even diverge and fail to train. In contrast, if we use layer normalization, the inputs are rescaled to have zero mean and unit variance, making it easier for the model to adapt to the new data distribution. Layer normalization keeps the scales consistent, making training more stable. After layer normalization is applied the results won't be restricted to a specific range like [0, 1] or [-1, 1] as in the case of some other normalization techniques. Instead, layer normalization will center the data around zero and will scale based on the standard deviation, but there's no hard constraint on the range of the output values. However, after layer normalization, the mean of each row (or each example, in the context of a neural network) will be approximately 0, and the standard deviation will be approximately 1. The actual values can be positive or negative and can exceed the range of [-1, 1], depending on the original data and its distribution. Layer normalization is applied to each data point within a given example, rather than across examples in the dataset (which is what batch normalization does). Given matrix $M$: $$ M = \\begin{pmatrix} 4.42554033 & 5.589241 & 6.99844643 & 4.79288192 \\\\ 4.55176485 & 5.6122494 & 7.09923364 & 4.82144704 \\\\ 4.21254506 & 5.31988824 & 6.84520426 & 4.79017392 \\end{pmatrix} $$ The layer normalization for each row (example) in $M$ is calculated as: $$ \\text{LN}(x_i) = \\gamma \\times \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta $$ $x_i$ is the input vector (a row in $M$ in our case). $\\mu$ is the mean of $x_i$. $\\sigma^2$ is the variance of $x_i$. $\\gamma$ and $\\beta$ are learnable parameters, which can be set to 1 and 0 respectively for simplification. $\\epsilon$ is a small constant added for numerical stability (can be set to $1e-6$ or similar). I don't show the breakdown of applying the formula here but what really matters is understanding what the formula does. See this python code for how I got the results. $$ \\text{LN}(x_i) = \\begin{pmatrix} -1.03927142 & 0.13949668 & 1.56694829 & -0.66717355 \\\\ -0.97825977 & 0.09190721 & 1.59246789 & -0.70611533 \\\\ -1.10306273 & 0.02854757 & 1.58729045 & -0.51277529 \\end{pmatrix} $$ The whole process from beginning to end: Image Source","title":"Layer Normalization"},{"location":"LLMs%20Explained/#feed-forward-neural-net","text":"Finally we reach the feed forward network - the piece at the heart of most AI models. So much of AI is based on these things I think it's worth spending a bit of time explaining how they work. The book Deep Learning (2017, MIT), by Ian Goodfellow, Yoshua Bengio, and Aaron Courville does a really good job of explaining this along with some common terms from deep learning so I will just quote it here. Deep feedforward networks , also often called feedforward neural networks , or multilayer perceptrons (MLPs) , are the quintessential deep learning models. The goal of a feedforward network is to approximate some function $f^ $. For example, for a classifier, $y = f^ (x)$ maps an input $x$ to a category $y$. A feedforward network defines a mapping $y = f(x; \\theta)$ and learns the value of the parameters $\\theta$ that result in the best function approximation. These models are called feedforward because information flows through the function being evaluated from $x$, through the intermediate computations used to define $f$, and finally to the output $y$. There are no feedback connections in which outputs of the model are fed back into itself. When feedforward neural networks are extended to include feedback connections, they are called recurrent neural networks , presented in chapter 10. Feedforward networks are of extreme importance to machine learning practitioners. They form the basis of many important commercial applications. For example, the convolutional networks used for object recognition from photos are a specialized kind of feedforward network. Feedforward networks are a conceptual stepping stone on the path to recurrent networks, which power many natural language applications. Feedforward neural networks are called networks because they are typically represented by composing together many different functions. The model is associated with a directed acyclic graph describing how the functions are composed together. For example, we might have three functions $f^{(1)}, f^{(2)},$ and $f^{(3)}$ connected in a chain, to form $f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$. These chain structures are the most commonly used structures of neural networks. In this case, $f^{(1)}$ is called the first layer of the network, $f^{(2)}$ is called the second layer, and so on. The overall length of the chain gives the depth of the model. It is from this terminology that the name \"deep learning\" arises. The final layer of a feedforward network is called the output layer . During neural network training, we drive $f(x)$ to match $f^ (x)$. The training data provides us with noisy, approximate examples of $f^ (x)$ evaluated at different training points. Each example $x$ is accompanied by a label $y \\approx f^ (x)$. The training examples specify directly what the output layer must do at each point $x$; it must produce a value that is close to $y$. The behavior of the other layers is not directly specified by the training data. The learning algorithm must decide how to use those layers to produce the desired output, but the training data does not say what each individual layer should do. Instead, the learning algorithm must decide how to use these layers to best implement an approximation of $f^ $. Because the training data does not show the desired output for each of these layers, these layers are called hidden layers . Finally, these networks are called neural because they are loosely inspired by neuroscience. Each hidden layer of the network is typically vector-valued. The dimensionality of these hidden layers determines the width of the model. Each element of the vector may be interpreted as playing a role analogous to a neuron. Rather than thinking of the layer as representing a single vector-to-vector function, we can also think of the layer as consisting of many units that act in parallel, each representing a vector-to-scalar function. Each unit resembles a neuron in the sense that it receives input from many other units and computes its own activation value. The idea of using many layers of vector-valued representation is drawn from neuroscience. The choice of the functions $f^{(i)}(x)$ used to compute these representations is also loosely guided by neuroscientific observations about the functions that biological neurons compute. However, modern neural network research is guided by many mathematical and engineering disciplines, and the goal of neural networks is not to perfectly model the brain. It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we know about the brain, rather than as models of brain function. You might be asking yourself what the difference between all this and a linear regression. The Deep Learning book gets into this on page 165. I leave out this discussion and instead provide a simple picture below which displays some true function that we are trying to approximate and allows you to compare the two graphs: I used this code to generate the plot using tensor flow. What's cool about that plot is that it is a real machine learning problem and that is the real performance of the two models. As the Deep Learning book points out, there isn't even a way to approximate something as simple as the XOR function with linear regression. Here is a plot of what XOR looks like: There is an example of how an XOR model works . Going back to the paper from Troy Wang Feed-Forward Neural Net feeds its output, an $n$ by 1 vector for each input token where $n$ is the dimension of the embedding, to the neural network layer. Each neural network layer consists of two pretrained matrices, the first one having dimension $n \\times 4n$, and the second $4n \\times n$. The input vector relayed from the self-attention layer is first multiplied with the first matrix in the neural network $W1$, resulting in a $(1 \\times 4n)$ matrix, which is then multiplied with the second matrix $W2$, resulting in a $(1 \\times n)$ matrix. This is equivalent to a vector with dimension $n$, which is uncoincidentally the same as the original input of the neural network. Note that the hyperparameter of 4 is rather arbitrary. The developers of the transformer model did not explain the reason for picking this particular hyperparameter [VSP+17]. Below is the formal representation of the feed-forward neural network that we just discussed. Note that there is also a ReLU activation in between the two multiplications. $FFN(x) = max(0, xW1 + b1) W2 + b2$ This transformation is the same across different positions in the same layer, yet each layer has its own unique parameters [VSP+17]. Let's walk through what that means in terms of our case. Input Vector Dimension $(n \\times 1)$ : In the Transformer model, for each token, the output from the self-attention layer is a vector of dimension $n$, which is fed into the FFNN layer. In our layer normalization example, each row represents a token and the number of columns represents the dimensionality ($n=4$). First Matrix $(n \\times 4n)$ : This expansion of dimensions by a factor of 4 is specific to the Transformer's FFNN layer. It's a design choice, and while there's no explicit reasoning in the original paper, it can be thought of as allowing the network more capacity to combine features before projecting them back to the original size. In our example, we expanded to 6 dimensions just for demonstration. In the Transformer, it would be 16 (4 times 4). ReLU Activation : After multiplying by the first matrix $W_1$ and adding the bias $b_1$, a ReLU (Rectified Linear Unit) activation function is applied element-wise. This introduces non-linearity, which is essential for the network to model complex patterns. This was demonstrated in our example as well with the line a1 = np.maximum(0, z1) Second Matrix $(4n \\times n)$ : The activated output from the previous step is then multiplied by a second matrix $W_2$ to bring the dimension back to $n$. In our example, this was done to bring it back to 4 dimensions. In the Transformer, it would bring it back to the original size of the embeddings. Result : The output is again a vector with dimension $n$ for each input token, ready to be processed by subsequent layers or to produce final outputs. This matches with the example where our final matrix $z2$ had rows with 4 dimensions, just like our original input. Layer-Wise Unique Parameters : The FFNN layers across positions share parameters, meaning every token goes through the same FFNN transformation within a single layer. However, each FFNN in different Transformer layers has its own set of parameters, allowing it to learn different transformations at different depths of the network. So taking it to our example. Given we start with this output from the layer normalization: $$ \\text{LN}(x_i) = \\begin{pmatrix} -1.03927142 & 0.13949668 & 1.56694829 & -0.66717355 \\\\ -0.97825977 & 0.09190721 & 1.59246789 & -0.70611533 \\\\ -1.10306273 & 0.02854757 & 1.58729045 & -0.51277529 \\end{pmatrix} $$ Now, let's pass this through a simple FFNN. We will assume: We project the data up to 6 dimensions (just for demonstration purposes) and then project it back to 4 dimensions. We use a ReLU activation function between the two linear transformations. Given this: The weight matrices will be $W_1$ of size $[4 \\times 6]$ and $W_2$ of size $[6 \\times 4]$. The bias vectors will be $b_1$ of size $[6]$ and $b_2$ of size $[4]$. Let's randomly initialize these parameters for the demonstration: $$W_1 = \\begin{pmatrix} 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 \\\\ 0.7 & 0.8 & 0.9 & 1.0 & 1.1 & 1.2 \\\\ 1.3 & 1.4 & 1.5 & 1.6 & 1.7 & 1.8 \\\\ 1.9 & 2.0 & 2.1 & 2.2 & 2.3 & 2.4 \\end{pmatrix}$$ $$b_1 = \\begin{pmatrix} 0.01 \\\\ 0.02 \\\\ 0.03 \\\\ 0.04 \\\\ 0.05 \\\\ 0.06 \\end{pmatrix}$$ $$W_2 = \\begin{pmatrix} 0.1 & 0.7 & 1.3 & 1.9 \\\\ 0.2 & 0.8 & 1.4 & 2.0 \\\\ 0.3 & 0.9 & 1.5 & 2.1 \\\\ 0.4 & 1.0 & 1.6 & 2.2 \\\\ 0.5 & 1.1 & 1.7 & 2.3 \\\\ 0.6 & 1.2 & 1.8 & 2.4 \\end{pmatrix}$$ $$b_2 = \\begin{pmatrix} 0.01 \\\\ 0.02 \\\\ 0.03 \\\\ 0.04 \\end{pmatrix}$$ Applying the FFNN: First linear transformation: $z_1 = \\text{LN}(x_i) \\times W_1 + b_1$ Apply ReLU activation: $a_1 = \\text{ReLU}(z_1)$ Second linear transformation: $z_2 = a_1 \\times W_2 + b_2$ Final output $z_2$ will be of size [3x4] representing the transformed data. When you run this process through Python you get: $$\\text{FFN}(x)=\\begin{pmatrix} 1.70355949 & 4.58680433 & 7.47004916 & 10.353294 \\\\ 1.56070622 & 4.19905974 & 6.83741326 & 9.47576678 \\\\ 2.19865128 & 5.93062489 & 9.66259851 & 13.39457212 \\end{pmatrix}$$ Now we rerun layer normalization against that result using exactly the same process as before for the final output of our encoder. $$\\text{LN}(x_o) = \\begin{pmatrix} -1.34164072 & -0.44721357 & 0.44721357 & 1.34164072 \\\\ -1.34164071 & -0.44721357 & 0.44721357 & 1.34164071 \\\\ -1.34164075 & -0.44721358 & 0.44721358 & 1.34164075 \\end{pmatrix}$$ Our resulting columns are coincidentally the same because the FNN values are scalar multiples ($\\times 3$) due to the way I arbitrarily set this up. This wouldn't happen in the scope of billions of variables.","title":"Feed Forward Neural Net"},{"location":"LLMs%20Explained/#prepare-and-embed-target-sequence-for-decoder","text":"Recall, this is the overview of our decoder process. Source Image here From this article Coming to the Decoder stack, the target sequence is fed to the Output Embedding and Position Encoding, which produces an encoded representation for each word in the target sequence that captures the meaning and position of each word. This is fed to all three parameters, Query, Key, and Value in the Self-Attention in the first Decoder which then also produces an encoded representation for each word in the target sequence, which now incorporates the attention scores for each word as well. After passing through the Layer Norm, this is fed to the Query parameter in the Encoder-Decoder Attention in the first Decoder The first thing we have to do is take out output embedding and calculate self attention on it just as we did for the input embedding . Our output embedding was: $$ Y + PE_{\\text{output}} = \\begin{pmatrix} 0.0 + 0 & 0.0 + 1 & 0.0 + 0 & 0.0 + 1 \\\\ -0.2 + 0.8415 & 0.4 + 0.99995 & 0.3 + 0.0001 & 0.1 + 1 \\\\ 0.5 + 0.9093 & -0.1 + 0.9998 & -0.4 + 0.0002 & 0.3 + 1 \\end{pmatrix} = \\begin{pmatrix} 0.0 & 1.0 & 0.0 & 1.0 \\\\ 0.6415 & 1.39995 & 0.3001 & 1.1 \\\\ 1.4093 & 0.8998 & -0.3998 & 1.3 \\end{pmatrix} $$ The math for the attention head on the decoder is the same as it was for the input stack so I do not show it here. The Python I used to generate the example is here . The result of the process is: $$\\text{Attention}_2(Q, K, V) = \\begin{pmatrix} 2.82896639 & 2.49151229 & 3.27935978 & 3.36785616 \\\\ 2.93697775 & 2.57919015 & 3.42996786 & 3.49210994 \\\\ 2.95810782 & 2.60399936 & 3.43836135 & 3.51718943 \\end{pmatrix}$$ Likewise, the math for layer normalization remains the same as it was for the input . The result here is: $$\\text{LN}(x_o) = \\begin{pmatrix} -0.46049196 & -1.4140849 & 0.81224991 & 1.06232694 \\\\ -0.46121408 & -1.41736871 & 0.85625689 & 1.02232591 \\\\ -0.46146504 & -1.41536061 & 0.83223948 & 1.04458616 \\end{pmatrix}$$ Attention Masking One thing I don't describe here that the article does describe is attention masking. Recall how at the beginning we had start padding? We do not want our model to pay attention to that start padding so we actually mask that out. We also mask out future characters in the decode process because remember, we've given the decoder exactly the right answer. We don't want it to look ahead at the answer and guess it exactly, we want it to try to guess it. So we also mask out future words at each stage of the process. I have done that in the Python code but I haven't gone through the math here.","title":"Prepare and Embed Target Sequence for Decoder"},{"location":"LLMs%20Explained/#decoder-stack-processing-with-encoder-output","text":"The same post describes the encoder-decoder attention block. The Encoder-Decoder Attention takes its input from two sources. Therefore, unlike the Encoder Self-Attention, which computes the interaction between each input word with other input words, and Decoder Self-Attention which computes the interaction between each target word with other target words, the Encoder-Decoder Attention computes the interaction between each target word with each input word. So what does that look like: Compute the Queries (Q) from the Decoder's Output : For the encoder-decoder attention, the queries are derived from the decoder, while the keys and values are derived from the encoder. Using the decoder's output $\\text{LN}(x_o)$ and the decoder's weight matrix $W_Q$: $$ Q = \\text{LN}(x_o) \\times W_Q $$ Compute the Keys (K) and Values (V) from the Encoder's Output : Using the encoder's output and the encoder's weight matrices $W_K$ and $W_V$: $$ K = \\text{LN}(x_e) \\times W_K $$ $$ V = \\text{LN}(x_e) \\times W_V $$ Compute the Attention Scores : This is done by multiplying the queries and keys, and then dividing by the square root of the depth of the keys (in this case, the number of columns in our matrices, which is 4): $$ \\text{Scores} = \\frac{Q \\times K^T}{\\sqrt{4}} $$ Apply Masking : As with before we need to mask out future words. Compute the Attention Weights : $$ \\text{Attention Weights} = \\text{Softmax}(\\text{Scores}) $$ Compute the Output of the Attention Mechanism : This is done by multiplying the attention weights with the values: $$ \\text{Attention Output} = \\text{Attention Weights} \\times V $$ Putting that all into Python you get: $$\\begin{pmatrix} -1.7888543 & 1.7888543 & 0. & 0. \\\\ -1.7888543 & 1.7888543 & 0. & 0. \\\\ -1.7888543 & 1.7888543 & 0. & 0. \\end{pmatrix}$$ Since this is a toy example the values are effectively nonsense.","title":"Decoder Stack Processing with Encoder Output"},{"location":"LLMs%20Explained/#output-layer-for-word-probabilities","text":"With this output you would then do the following: To get from the output of Decoder-2 to the words \"de nada\", you would have to follow several steps, based on the provided diagram: Linear Transformation : The output of Decoder-2 is passed through a linear layer. This involves multiplying the output by a learned weight matrix. The purpose of this step is to transform the output dimensions to match the size of the vocabulary. Suppose your vocabulary has $V$ words. The weight matrix for the linear layer will have dimensions suitable to project the decoder's output into a shape like (sequence_length, V) , where sequence_length is the number of words/tokens in the output sequence. For simplicity, let's assume you have a small vocabulary of 10,000 words (including \"de\" and \"nada\"). The transformation will convert the 4-dimensional output of each sequence element into a 10,000-dimensional vector. Softmax Activation : After the linear transformation, the output values are passed through a softmax function to convert them into probabilities. The softmax function ensures that the values are between 0 and 1 and that they sum to 1 across the vocabulary for each sequence position. This will give you a probability distribution over all words in the vocabulary for each position in the output sequence. Selecting the Word : For each position in the output sequence, you would pick the word in the vocabulary with the highest probability. This is often done using an argmax function. So, for the first position, if the word \"de\" has the highest probability, it's selected. For the second position, if \"nada\" has the highest probability, it's selected, and so on. Final Output : Concatenate the chosen words together based on their sequence position to get the final output, which in this case would be \"de nada\". In practice, especially during training, the process might involve more complexities like teacher forcing, beam search during inference, etc., to improve the quality of the translations. But the above steps are the basic ones to go from Decoder-2's output to the final translated words. And that's it, our transformer output is complete!","title":"Output Layer for Word Probabilities"},{"location":"LLMs%20Explained/#loss-function-and-back-propagation","text":"Ok, so we've talked through how we get output... but now how do we actually train? I struggled to decide how to write this because in reality this gets very complex. The Deep Learning book has an entire chapter dedicated to stochastic gradient descent. What I settled on is showing how we take the transformer output as described above and transform that to a probability distribution. Let's first go through the process in broad terms. Cross-Entropy Loss Calculation : The transformer generates logits, which are the outputs of the model's final linear layer before applying the softmax function. These logits represent the unnormalized log probabilities of each word in the model's vocabulary. We then apply the softmax function to the logits to obtain a probability distribution over the vocabulary (predicted probabilities). Cross-entropy loss is then calculated between the predicted probabilities and the true distribution, which is typically represented as a one-hot encoded vector indicating the true next word in the sequence. Gradient Computation : To improve the model, we need to know how to adjust the parameters to reduce the loss. This is done by computing the gradient of the loss with respect to each parameter. In the context of a transformer, this means calculating the derivatives of the loss with respect to each element in the weight matrices and biases throughout the network. The gradients indicate the direction in which we should adjust our parameters to reduce the loss; a positive gradient suggests that increasing the parameter would increase the loss, while a negative gradient suggests that increasing the parameter would decrease the loss. Weight Update : Once we have the gradients, we use them to update the model\u2019s weights. This is done by subtracting a fraction of the gradient from the current weights. This fraction is determined by the learning rate\u2014a hyperparameter that controls how big a step we take during optimization. Backpropagation Through Time (BPTT) : Because transformers process sequences, we need to consider not just the immediate outputs but also how a change in weights affects the subsequent parts of the sequence. Backpropagation through time is a method of applying the chain rule to unroll the sequence and calculate the impact of weights on loss at each time step. Iteration and Convergence : This entire process is repeated for many iterations\u2014each iteration is an opportunity to adjust the weights slightly to reduce the loss. Over many iterations, this process is designed to converge on a set of weights that minimizes the loss, making the model's predictions as accurate as possible. Regularization and Optimization Techniques : In practice, additional techniques such as dropout, layer normalization, and advanced optimizers like Adam or RMSprop are used to improve training stability, avoid overfitting, and ensure that the optimization process converges efficiently. Each of these steps is carefully monitored using validation sets to ensure that the model is learning generalizable patterns and not just memorizing the training data. Let's take a look at a concrete example. Let's look at a concrete example: Sure, let's consider a simple example involving a language model that is training to predict the next word in a sentence. Let's say our model's current task is to predict the word following \"The cat sat on the ___.\" For simplicity, imagine our model's vocabulary only consists of four words: {mat, hat, bat, rat}, each represented by a one-hot encoded vector: $\\text{mat} = [1, 0, 0, 0]$ $\\text{hat} = [0, 1, 0, 0]$ $\\text{bat} = [0, 0, 1, 0]$ $\\text{rat} = [0, 0, 0, 1]$ The true next word in our training example is \"mat\", so the true probability distribution (one-hot encoded) for this example is: $$ y = [1, 0, 0, 0] $$ Now, let's say our model predicts the probabilities for each word as follows: $$\\begin{pmatrix} \\text{mat} & \\text{hat} & \\text{bat} & \\text{rat} \\ 0.7 & 0.1 & 0.1 & 0.1 \\end{pmatrix}$$ where .7 is the model's confidence that the next word is \"mat\". The predicted probability distribution is: $$ P = [0.7, 0.1, 0.1, 0.1] $$ We then calculate the cross-entropy loss for this single example as: $$ L = -\\sum_{i=1}^4 y_i \\log(p_i) \\ L = -(1 \\cdot \\log(0.7) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1)) \\ L = -(\\log(0.7)) \\ L \\approx 0.357 $$ In this case, the loss is relatively low because the model's prediction was quite close to the true distribution, with a high probability assigned to the correct word \"mat\". If the model were very wrong, say it predicted: $$ P = [0.1, 0.1, 0.1, 0.7] $$ The cross-entropy loss would then be: $$ L = -\\sum_{i=1}^4 y_i \\log(p_i) \\ L = -(1 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.1) + 0 \\cdot \\log(0.7)) \\ L = -(\\log(0.1)) \\ L \\approx 2.303 $$ The loss is now much higher, reflecting the poor quality of the prediction. By backpropagating this loss and updating the model's weights accordingly, the model is trained to make better predictions over time. Let's say we wanted to fix that that second scenario. How do we do that? We do it with gradient descent. A real description of gradient descent is too long to describe here. The aforementioned deep learning book has a lengthy discussion on it. To compute the gradient of the cross-entropy loss with respect to the model's predictions (which are the inputs to the softmax function, the aforementioned logits), we need to differentiate the loss with respect to each logit for each class. Given the true distribution $y = [1, 0, 0, 0]$ and the model's predicted probabilities $P = [0.1, 0.1, 0.1, 0.7]$, the loss $L$ for this incorrect prediction was calculated as approximately 2.303. Now, we'll compute the gradient of $L$ with respect to the logits, which are the inputs to the softmax function that produced $P$. If $Z$ are the logits and $P$ is obtained by applying the softmax function to $Z$, then for the softmax output for class $i$, we have: $$P_i = \\frac{e^{Z_i}}{\\sum_{k=1}^{V} e^{Z_k}}$$ The gradient of the cross-entropy loss $L$ with respect to the logits $Z$ can be simplified to: $$\\frac{\\partial L}{\\partial Z_i} = P_i - y_i$$ The expression represents the partial derivative of the cross-entropy loss function $L$ with respect to the logit $Z_i$ for class $i$. Here's what's being differentiated: Loss Function $L$ : The cross-entropy loss function measures the difference between the model's predicted probabilities for each class (given by the softmax function) and the actual distribution of the labels (typically a one-hot encoded vector in classification tasks). A single class here being a possible next word. Logits $Z$ : The logits are the outputs of the model that are fed into the softmax function. They are the raw, unnormalized scores that the model believes each class deserves based on the input data. When we differentiate $L$ with respect to $Z_i$, we are calculating how a small change in the logit $Z_i$ for any class $i$ will affect the overall loss $L$. This gradient is crucial because it provides the information needed to adjust the model parameters (weights and biases) during the training process to minimize the loss. This process is what allows the model to learn from data. Given our predicted probabilities and the true labels, the gradient for each class would be: For the \"mat\" class (class 1): $\\frac{\\partial L}{\\partial Z_{\\text{mat}}} = P_{\\text{mat}} - y_{\\text{mat}} = 0.1 - 1 = -0.9$ For the \"hat\" class (class 2): $\\frac{\\partial L}{\\partial Z_{\\text{hat}}} = P_{\\text{hat}} - y_{\\text{hat}} = 0.1 - 0 = 0.1$ For the \"bat\" class (class 3): $\\frac{\\partial L}{\\partial Z_{\\text{bat}}} = P_{\\text{bat}} - y_{\\text{bat}} = 0.1 - 0 = 0.1$ For the \"rat\" class (class 4): $\\frac{\\partial L}{\\partial Z_{\\text{rat}}} = P_{\\text{rat}} - y_{\\text{rat}} = 0.7 - 0 = 0.7$ These gradients tell us how much we need to adjust each logit to reduce the loss. A negative gradient for \"mat\" indicates that we need to increase the corresponding logit value to increase the probability of the correct class, while a positive gradient for the other classes indicates that we need to decrease those logit values to reduce their probabilities. The gradient values indicate the direction and magnitude of change needed to reduce the loss with respect to each class's logit (unnormalized log probabilities before softmax). For the \"mat\" class (class 1): $\\frac{\\partial L}{\\partial Z_{\\text{mat}}} = -0.9$ The true class was \"mat\" (since $y_{\\text{mat}} = 1$), but the model predicted a low probability (0.1). The negative gradient (-0.9) indicates the model should increase the logit for \"mat\" to increase its probability upon the next iteration. For the \"hat\" class (class 2): $\\frac{\\partial L}{\\partial Z_{\\text{hat}}} = 0.1$ The model incorrectly assigned a small probability to \"hat\", which wasn't the true class. The positive gradient suggests the model should decrease the logit for \"hat\" to reduce its probability next time. For the \"bat\" class (class 3): $\\frac{\\partial L}{\\partial Z_{\\text{bat}}} = 0.1$ Similar to \"hat\", \"bat\" is not the true class, and it also received a small probability. Again, the model should decrease the logit for \"bat\". For the \"rat\" class (class 4): $\\frac{\\partial L}{\\partial Z_{\\text{rat}}} = 0.7$ \"Rat\" is not the true class, but the model assigned it a high probability (0.7). The large positive gradient value indicates a strong need to decrease the logit for \"rat\" to correct this error. In essence, the gradient tells you how to tweak the logits to reduce the loss in the next training step: - Negative gradients imply an increase in the respective logit value is needed (to increase the probability of the true class). - Positive gradients imply a decrease in the respective logit value is needed (to reduce the probability of incorrect classes). So now we take that information and use it to update the weights: Gradient Descent Step : The weights $W$ are updated by subtracting the product of the learning rate $\\alpha$ and the gradient: $$ W_i = W_i - \\alpha \\cdot \\frac{\\partial L}{\\partial Z_i} $$ where $W_i$ is the weight corresponding to class $i$ and the learning rate is a hyperparameter. So for our example you would get: $$ Z[0] = Z[0] - 0.1 \\times (-0.9) \\ Z[1] = Z[1] - 0.1 \\times 0.1 \\ Z[2] = Z[2] - 0.1 \\times 0.1 \\ Z[3] = Z[3] - 0.1 \\times 0.7 $$ Given a learning rate $\\alpha = 0.1$, the updated probabilities after one iteration would be: For the \"mat\" class, since the gradient was -0.9: $P_{\\text{mat}} = 0.1 + 0.1 \\times 0.9 = 0.1 + 0.09 = 0.19$ For the \"hat\", \"bat\", and \"rat\" classes, since the gradients were 0.1 and 0.7 respectively: $P_{\\text{hat}} = P_{\\text{bat}} = 0.1 - 0.1 \\times 0.1 = 0.1 - 0.01 = 0.09$ $P_{\\text{rat}} = 0.7 - 0.1 \\times 0.7 = 0.7 - 0.07 = 0.63$ After the first update, the probabilities would be: - $P_{\\text{mat}} = 0.19$ - $P_{\\text{hat}} = P_{\\text{bat}} = 0.09$ - $P_{\\text{rat}} = 0.63$ However, we need to re-normalize these probabilities because they won't sum up to 1 after the update. This is usually done by passing the updated weights $Z$ through a softmax function to get the new probabilities $P$. If we were working with the logits $Z$ directly, we would subtract the gradients scaled by the learning rate from the logits, and then apply the softmax to get the next set of probabilities. Here is a Python script which performs the work: import numpy as np # Define the initial weights weights = np.array([0.1, 0.1, 0.1, 0.7]) # True class index true_class = 0 # Define the learning rate learning_rate = 0.01 # Number of iterations iterations = 2000 # Apply gradient descent for i in range(iterations): # Compute the probabilities using softmax # Softmax formula: P(class_i) = e^(Z_i) / sum(e^(Z_j) for j in classes) exp_weights = np.exp(weights) probabilities = exp_weights / np.sum(exp_weights) # Compute the gradient for each class # Gradient for true class: (P(class_i) - 1) # Gradient for other classes: P(class_i) gradients = probabilities.copy() gradients[true_class] -= 1 # Update the weights with the gradients # Weight update formula: W_i = W_i - learning_rate * gradient_i weights -= learning_rate * gradients # Print the weights and probabilities at each 10th step if i % 10 == 0: print(f\"Iteration {i}: Weights: {weights}\") print(f\"Iteration {i}: Probabilities: {probabilities}\") # Calculate final probabilities using the updated weights final_probabilities = np.exp(weights) / np.sum(np.exp(weights)) print(\"\\nFinal probabilities: \", final_probabilities) Here is what the ouput looks like: Iteration 0: Weights: [0.10792622 0.09792622 0.09792622 0.69622133] Iteration 0: Probabilities: [0.20737772 0.20737772 0.20737772 0.37786684] ...SNIP... Iteration 1990: Weights: [ 3.41207767 -0.86673008 -0.86673008 -0.6786175 ] Iteration 1990: Probabilities: [0.95742224 0.0132765 0.0132765 0.01602477] Final probabilities: [0.95765298 0.01320591 0.01320591 0.0159352 ] Now imagine that this is instead done over the totality of a language with a massive vocabulary instead of four words. That's what a real LLM is doing. With all of that learned, we are finally ready to go to the main event - GPT.","title":"Loss Function and Back-Propagation"},{"location":"LLMs%20Explained/#generative-pre-trained-transformer-gpt","text":"","title":"Generative Pre-Trained Transformer (GPT)"},{"location":"LLMs%20Explained/#whats-so-different-about-gpt-models","text":"The most obvious problem with the above is the same problem everyone has... you have to have training data. Creating training data is tedious, error prone, and generally difficult. So what makes GPT models special? They work on unlabeled text. You can point them at a huge corpus of text and they can train themselves. Even better, you can feed in labeled data to enhance a GPT model for domain-specific tasks. As Troy Wang points out though In fact, in the case of GPT3 (the third generation of GPT), its parameters and training corpus are so large, and its task-agnostic performance is so good, such that fine-tuning is no longer essential. Instead, providing a few examples in the input prompt, which is also called few-shots in-context learning, is sufficient for most tasks [BMR+20]. I'll also cite him again to describe the next big point: Another architectural difference between GPT and traditional transformers is that instead of relying on both encoders and decoders, GPT gets rid of the encoders and instead derives its performance from stacking many decoders. Additionally, the sheer scale of GPT models is groundbreaking in itself. GPT models have exponentially more parameters and use exponentially larger training sets than the original transformer model. The original version of GPT comes with 150 million parameters [RNS+18]. GPT2 has 1.5 billion parameters, while GPT3, the latest version of the GPT series models, has a mind blowing 175 billion parameters [RWC+19] [BMR+20]. This is what the GPT model in contrast to what we saw in the original transformer. Source Image","title":"What's so different about GPT models?"},{"location":"LLMs%20Explained/#going-through-an-example","text":"","title":"Going Through an Example"},{"location":"LLMs%20Explained/#input-representation","text":"Suppose we have a sentence: \"I love AI,\" which we tokenize as $[\"I\", \"love\", \"AI\"]$. Here are our randomly selected embeddings: $$ U = { \\text{\"I\"}: [0.12, 0.87], \\text{\"love\"}: [0.56, 0.32], \\text{\"AI\"}: [0.74, 0.51] } $$ For our positional encoding matrix (W_p), we use: $$ W_p = \\left[ 0.02, 0.04, 0.03, 0.07, 0.05, 0.09 \\right] $$","title":"Input Representation:"},{"location":"LLMs%20Explained/#embedding-and-positional-encoding","text":"Combining our embeddings with our positional encodings, we get: $$ h_0 = U + W_p $$ For \"I\": $$ h_0(\\text{\"I\"}) = \\left[ 0.14, 0.91 \\right] $$ For \"love\": $$ h_0(\\text{\"love\"}) = \\left[ 0.59, 0.39 \\right] $$ For \"AI\": $$ h_0(\\text{\"AI\"}) = \\left[ 0.79, 0.60 \\right] $$","title":"Embedding and Positional Encoding:"},{"location":"LLMs%20Explained/#masked-self-attention","text":"The math for the self attention mechanism remain the same as they were in this section The difference is that the output of: $$ Score = \\frac{Q \\times K^T}{\\sqrt{d_k}} $$ is multiplied by: $$ \\text{Mask} = \\begin{pmatrix} 0 & -\\infty & -\\infty \\ 0 & 0 & -\\infty \\ 0 & 0 & 0 \\end{pmatrix} $$ This has the effect of masking out future tokens so that the model is only able to use the information from previous tokens to predict the future tokens. Visually this appears as: Image Source Suppose for our masked self-attention, the attention weights (for the word \"love\") give 0.1 importance to the word \"I\" and 0.9 to itself. The word \"AI\" hasn't appeared yet, so it gets 0 importance. Hence, the attention output for \"love\" will be: $$ h_1(\\text{\"love\"}) = 0.1 \\times h_0(\\text{\"I\"}) + 0.9 \\times h_0(\\text{\"love\"}) = \\left[ 0.155, 0.458 \\right] $$","title":"Masked Self-Attention"},{"location":"LLMs%20Explained/#feed-forward-and-layer-norm","text":"Let's use a simplified feed-forward mechanism. Assuming a linear transformation with a weight matrix (W): $$ W = \\left[ 0.2, 0.3, 0.4, 0.5 \\right] $$ The output for the word \"love\" will be: $$ h_2(\\text{\"love\"}) = h_1(\\text{\"love\"}) \\times W = \\left[ 0.1753, 0.309 \\right] $$","title":"Feed Forward and Layer Norm"},{"location":"LLMs%20Explained/#output","text":"This remains the same as before .","title":"Output"},{"location":"LLMs%20Explained/#training","text":"Model Objective: The primary goal during pre-training is to maximize the likelihood of a particular token given its preceding tokens. For a model being trained, it tries to predict the next word in a sequence using the context provided by the preceding words. Context Window: For \"I love AI,\" if we were to use a context window of two words, the model would be given \"I love\" and would try to predict \"AI.\" Tokenizing and Embeddings: The passage mentions breaking down input into embeddings. In the case of \"I love AI,\" the words \"I,\" \"love,\" and \"AI\" are tokenized and then converted into dense vectors or embeddings. These embeddings capture semantic meanings and relationships between words. Maximizing Likelihood: As the formula $L_1(U) = \\Sigma_i \\log P(u_i|u_{i-k}, ..., u_{i-1})$ suggests, the model tries to maximize the probability (or likelihood) of observing the token $u_i$ given its previous k tokens. For our example \"I love AI,\" if you feed \"I love\" into the model, it should assign a high probability to \"AI\" being the next word, assuming \"I love AI\" is a frequent phrase in the training data. Unsupervised Nature: The term \"unsupervised\" implies that there's no explicit label provided to the model for training. Instead, the model uses the context (preceding words) as input and tries to predict the next word. The correct answer (or \"label\") is just the next word in the sequence. So, the data itself provides both the input and the \"label.\"","title":"Training"},{"location":"LLMs%20Explained/#gpt-time-complexity","text":"Self-Attention Mechanism: The self-attention mechanism calculates attention scores between each pair of tokens in the input. Thus, if you have an input sequence of length $n$, you'd need to compute scores for every pair, leading to $n^2$ pairwise computations. Matrix Multiplication: For each of the pairwise computations, we perform matrix multiplication with the Query, Key, and Value matrices. If $d$ represents the dimensionality of the embeddings (or the size of the model), then this matrix multiplication step has a time complexity of $O(d)$. Aggregating Time Complexity: Taking both of the above steps into account, the overall time complexity for the self-attention mechanism becomes $O(n^2 \\times d)$. Number of Layers: GPT models, like all transformer-based models, consist of multiple layers (blocks). If $l$ is the number of layers, then the time complexity considering all layers becomes $O(l \\times n^2 \\times d)$. Other Components: Apart from the self-attention mechanism, there are feed-forward neural networks and layer normalization in each layer of the transformer. However, the operations associated with these components are linear with respect to the sequence length and do not significantly alter the quadratic nature of the transformer's time complexity. The primary bottleneck in terms of time complexity for GPT models is the self-attention mechanism, which has a time complexity of the aforementioned $O(l \\times n^2 \\times d)$. The quadratic dependence on the sequence length $n$ means that as the input gets longer, the time taken for computation increases quadratically. This is one of the reasons why there's usually a limit on the maximum sequence length that transformer models can handle. It's also worth noting that while the theoretical time complexity gives us an understanding of how computation grows with the size of input and model, in practice, optimizations, hardware accelerations, and efficient implementations will have a huge impact on the performance of the model. To provide a rough order of magnitude, GPT3 has 175 layers and d is often set to a value like 1024 in a large model.","title":"GPT Time Complexity"},{"location":"LLMs%20Explained/#retrieval-augmented-generation-rag","text":"RAG is a technique used to take an existing model and extend it with new information. Input Processing : Question : Take a question as input. For example, \"What are the health benefits of green tea?\" Embedding : Convert this question into a vector using the same transformer model used for encoding the documents in the database. Retrieval Phase : Approximate Nearest Neighbor Search : Using the embedded question, perform an ANN search in the database to retrieve the most relevant documents. Let's say we retrieve 'N' documents. Document Vectors : These documents are represented by their respective embedding vectors, say $([D_1, D_2, ..., D_N])$. Combining Retrieved Knowledge with LLM : Contextual Integration : The LLM is provided with both the original question and the retrieved documents to generate an answer. Attention Mechanism : The model uses a cross-attention mechanism between the question and each of the retrieved documents to understand the context better. Generating the Answer : Sequence Generation : The LLM generates the answer token by token. For each token: It computes a probability distribution over the vocabulary. The probability is conditioned on the input question and the retrieved documents. The model chooses the token with the highest probability at each step. Example : The model might start with \"Green tea is known for its...\", incorporating information from both the question and the content of the retrieved documents. Loss Calculation and Training : Training : During training, the model's parameters are adjusted to minimize the difference between the generated answer and the correct answer. Loss Function : A common choice is the cross-entropy loss between the predicted and actual answers. Joint Training : Both the retrieval component and the generation model are trained jointly to improve the coherence between retrieved documents and generated answers. Mathematical Representation Question Embedding : ( Q = \\text{Transformer}( \\text{\"What are the health benefits of green tea?\"} ) ) Document Retrieval : ( [D_1, D_2, ..., D_N] = \\text{ANN_Search}(Q) ) Generation Probability : ( P(\\text{word} | Q, D_1, D_2, ..., D_N) ) Answer Generation : ( \\text{Answer} = \\arg\\max \\prod P(\\text{word} i | \\text{word} {<i}, Q, D_1, D_2, ..., D_N) )","title":"Retrieval Augmented Generation (RAG)"},{"location":"LLMs%20Explained/#nearest-neighbor-search","text":"A nearest neighbor search (NNS) is an algorithm used to find the closest or most similar data points to a given query point in a dataset.","title":"Nearest Neighbor Search"},{"location":"LLMs%20Explained/#the-general-idea","text":"Dataset : Consider a dataset comprising a collection of points. These points could represent anything depending on the application - for instance, they could be vectors encoding the features of images, text, or any type of numerical data. Query Point : You have a query point (or a search point), and you want to find the point(s) in your dataset that are closest to this query point. Distance Metric : A distance metric is used to measure the closeness or similarity between points. Common metrics include Euclidean distance, Manhattan distance, cosine similarity, and others, depending on the nature of the data and the application.","title":"The General Idea"},{"location":"LLMs%20Explained/#algorithms-for-nearest-neighbor-searches","text":"What matters: Scalability : ANN algorithms are designed to handle very large datasets efficiently, which is crucial for RAG models as they often involve searching through extensive collections of documents or embeddings. Speed : Exact NNS can be computationally intensive and time-consuming, especially in high-dimensional spaces (like text embeddings). ANN provides a good balance between accuracy and computational efficiency. Dimensionality : Text data, when converted into embeddings (vector representations), typically reside in high-dimensional space. ANN algorithms are more adept at handling the curse of dimensionality than exact NNS methods. Common Algorithms Locality-Sensitive Hashing (LSH) : LSH is a method of performing probabilistic dimension reduction of high-dimensional data. It hashes input items so that similar items map to the same \u201cbuckets\u201d with high probability. Hierarchical Navigable Small World Graphs (HNSW) : HNSW is known for its high efficiency and accuracy, especially in high-dimensional data. It builds a layered graph structure that allows for faster query times. Faiss (Facebook AI Similarity Search) : Developed by Facebook AI, Faiss is a library for efficient similarity search and clustering of dense vectors. It contains implementations of several ANN algorithms and is optimized for use with GPUs. Annoy (Approximate Nearest Neighbors Oh Yeah) : Annoy is a C++ library with Python bindings to search for points in space that are close to a given query point. It's particularly useful for large datasets and is used by Spotify for music recommendation. Common problems and solutions: Curse of Dimensionality : As the number of dimensions (features) of the data increases, finding the nearest neighbor becomes computationally intensive. This is because the volume of the space increases exponentially with each additional dimension, making the data points sparse. Approximate Nearest Neighbor (ANN) : To counter the computational challenges, especially in high-dimensional spaces, approximate methods are used. These methods do not always guarantee the exact nearest neighbor but can find an approximation much faster. Indexing Structures : Data structures like KD-trees, Ball trees, and Hash tables are used to optimize NNS, making searches faster than a brute-force search that compares the query point with every point in the dataset. Parallelization and Distributed Computing : Leveraging multiple processors or distributed systems can significantly speed up nearest neighbor searches in large datasets.","title":"Algorithms for Nearest Neighbor Searches:"},{"location":"LLMs%20Explained/#supplemental-information","text":"","title":"Supplemental Information"},{"location":"LLMs%20Explained/#word-embeddings","text":"The first question(s) I asked when I saw these matrices is, \"Where do these values come from and what are they?\" What followed soon after was, \"Why do they exist?\" Why they exist lends context to where do they come from and what are they. Why do they exist The article Large language models, explained with a minimum of math and jargon does a fantastic job of answering this in a non-mathematical way. The goal here is that we want to describe mathematically the relationship between some given word and other words because this will then allow us to more accurately predict what words should go in the answers our LLM produces. Words that are similar should have similar vector values. This concept was pioneered at Google in a paper called Word2vec . You can see this visually at this website . For example, I wanted to see what airplanes are likely to be related to airplanes: The percentage similarity to \"airplane\": aeroplane : NOUN, 0.8153 aircraft : NOUN, 0.7992 plane : NOUN, 0.7429 airliner : NOUN, 0.7398 helicopter : NOUN, 0.7006 aircraave : NOUN, 0.6568 biplane : NOUN, 0.6540 airship : NOUN, 0.6404 dc-3 : NOUN, 0.6297 seaplane : NOUN, 0.6271 Where do these values come from? The answer is it depends. There are three potential places these values may originate from at first: Random Initialization: Here, the embeddings are initialized with small random values. These values then get adjusted during training to capture semantic meanings. Pre-trained Embeddings: Instead of starting with random values, it's common to initialize the embeddings with vectors from pre-trained models like Word2Vec, GloVe, or FastText. These embeddings are trained on vast corpora and capture general language semantics. Depending on the task and the dataset, these pre-trained embeddings can either be kept static during training or be fine-tuned. Training from Scratch: In some cases, especially when the domain-specific language is very different from general language (e.g., medical texts or legal documents), embeddings might be trained from scratch along with the rest of the model. The values in the embedding are updated during the training phase. Most models today will start with one of the sets of values defined above so you aren't starting from scratch. That also gets you a much more accurate model much faster. What are they? Realistic answer? We don't really fully understand. We understand parts, but the simple answer is that the model learns values it \"thinks\" are sensible. There are entire papers written to explain just fractions of the relationships.","title":"Word Embeddings"},{"location":"LLMs%20Explained/#weight-matrices","text":"The weight matrices $W_Q$, $W_K$, and $W_V$ are learned parameters in the self-attention mechanism of the transformer model. Here's a more detailed explanation: 1. Initialization : At the beginning of the training process, these matrices are usually initialized with small random values. This can be achieved through various initialization techniques, such as Xavier or He initialization. 2. Training : During the training process, the transformer model is fed with input data, and it tries to minimize the difference between its predictions and the actual output (this difference is often measured using a loss function like cross-entropy for classification tasks). As the model is trained using optimization algorithms like stochastic gradient descent (SGD) or its variants (e.g., Adam, RMSprop), these weight matrices get updated iteratively. The updates are done in a direction that reduces the loss. 3. Role of Backpropagation : The updating of these matrices is governed by backpropagation, a fundamental technique in training deep neural networks. Gradients are computed for the loss with respect to each element of these matrices, which indicates how much a small change in that element would affect the overall loss. These gradients are then used to adjust the matrices in the direction that minimizes the loss. 4. Final Model : After many iterations (epochs) of training, these matrices converge to values that allow the transformer model to effectively compute self-attention over the input data. In other words, through training, the model learns the best values for these matrices to perform the task at hand, whether it's language translation, text classification, or any other NLP task.","title":"Weight Matrices"},{"location":"LLMs%20Explained/#softmax","text":"Let's say we have a neural network that is trying to classify an input into one of three categories. The final layer of the network produces a vector of logits (raw prediction scores) for each category: $$ x = [2.0, 1.0, 0.2] $$ Here: - The first value (2.0) corresponds to the prediction score for Category A. - The second value (1.0) is for Category B. - The third value (0.2) is for Category C. To interpret these scores as probabilities, we use the softmax function. Applying softmax: $$ \\text{softmax}(x)_i = \\frac{e^{x_i}}{{\\sum e^{x_j}}} $$ $$ \\text{softmax}(x)_i = \\frac{e^{x_i}}{{\\sum e^{x_j}}} $$ For each component: $$ \\text{softmax}(x)_A = \\frac{e^{2.0}}{e^{2.0} + e^{1.0} + e^{0.2}} $$ $$ \\text{softmax}(x)_B = \\frac{e^{1.0}}{e^{2.0} + e^{1.0} + e^{0.2}} $$ $$ \\text{softmax}(x)_C = \\frac{e^{0.2}}{e^{2.0} + e^{1.0} + e^{0.2}} $$ Computing these, we might get something like: $$ \\text{softmax}(x) = [0.65, 0.24, 0.11] $$ The results are probabilities: - Category A: 65% - Category B: 24% - Category C: 11% The values sum up to 1, and the largest logit (2.0 for Category A) corresponds to the largest probability (65%). Why do we use softmax for self attention? Normalization : The raw logits can be any set of values, positive or negative. Softmax ensures that we get a proper probability distribution where values are between 0 and 1 and sum up to 1. Emphasizing Differences : Even subtle differences in logits can be emphasized. In our example, the difference between 2.0 and 1.0 becomes a difference between 65% and 24% in probabilities. Self-attention mechanism : In the context of Transformers and self-attention, softmax is applied to the scores (results of Q and K dot products) to determine the weight or attention each input should get. By turning these scores into probabilities, the model decides which parts of the input sequence are most relevant for each position, effectively weighting the contribution of each input's value (from the V matrix) when producing the output.","title":"Softmax"},{"location":"LLMs%20Explained/#matrix-multiplication","text":"Given: $$ X + PE_{\\text{input}} = \\begin{pmatrix} 0.1 & 1.2 & -0.1 & 1.4 \\\\ -0.3 + \\sin\\left(\\frac{1}{10000^0}\\right) & 0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right) & 0.1 + \\sin\\left(\\frac{1}{10000^2}\\right) & -0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right) \\\\ 0.4 + \\sin\\left(\\frac{2}{10000^0}\\right) & -0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right) & 0.2 + \\sin\\left(\\frac{2}{10000^2}\\right) & 0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right) \\end{pmatrix} $$ $$ W_Q = \\begin{pmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$ First row of $Q$: Multiply each element of the first row of $(X + PE_{\\text{input}})$ with the corresponding element of each column in $W_Q$, then sum them up. $$ Q[1,1] = (0.1 \\times 1) + (1.2 \\times 0) + (-0.1 \\times 0) + (1.4 \\times 1) = 0.1 + 0 + 0 + 1.4 = 1.5 $$ $$ Q[1,2] = (0.1 \\times 0) + (1.2 \\times 1) + (-0.1 \\times 1) + (1.4 \\times 0) = 0 + 1.2 - 0.1 + 0 = 1.1 $$ $$ Q[1,3] = (0.1 \\times 0) + (1.2 \\times 1) + (-0.1 \\times 0) + (1.4 \\times 1) = 0 + 1.2 + 0 + 0 = 1.2 $$ $$ Q[1,4] = (0.1 \\times 1) + (1.2 \\times 0) + (-0.1 \\times 1) + (1.4 \\times 0) = 0.1 + 0 - 0.1 + 0 = 0 $$ Second row of $Q$ $$ Q[2,1] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 1 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 0 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 0 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[2,2] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 0 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 1 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 1 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 0 $$ $$ Q[2,3] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 0 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 1 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 0 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[2,4] = (-0.3 + \\sin\\left(\\frac{1}{10000^0}\\right)) \\times 1 + (0.5 + \\cos\\left(\\frac{1}{10000^{0.5}}\\right)) \\times 0 + (0.1 + \\sin\\left(\\frac{1}{10000^2}\\right)) \\times 1 + (-0.2 + \\cos\\left(\\frac{1}{10000^{2.5}}\\right)) \\times 0 $$ Third row of $Q$ $$ Q[3,1] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 1 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 0 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 0 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[3,2] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 0 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 1 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 1 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 0 $$ $$ Q[3,3] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 0 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 1 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 0 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 1 $$ $$ Q[3,4] = (0.4 + \\sin\\left(\\frac{2}{10000^0}\\right)) \\times 1 + (-0.3 + \\cos\\left(\\frac{2}{10000^{0.5}}\\right)) \\times 0 + (0.2 + \\sin\\left(\\frac{2}{10000^2}\\right)) \\times 1 + (0.1 + \\cos\\left(\\frac{2}{10000^{2.5}}\\right)) \\times 0 $$ Plug that into some Python: import numpy as np X_PE_input = np.array([ [0.1, 1.2, -0.1, 1.4], [-0.3 + np.sin(1), 0.5 + np.cos(1/10000**0.5), 0.1 + np.sin(1/10000**2), -0.2 + np.cos(1/10000**2.5)], [0.4 + np.sin(2), -0.3 + np.cos(2/10000**0.5), 0.2 + np.sin(2/10000**2), 0.1 + np.cos(2/10000**2.5)] ]) W_Q = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) Q = X_PE_input.dot(W_Q) print(Q) that will get you: [[1.5 1.1 2.6 0. ] [1.34147098 1.59995001 2.29995 0.64147099] [2.40929743 0.89980003 1.79980001 1.50929745]] Printed nicely out to four decimal places: $$ \\begin{pmatrix} 1.5 & 1.1 & 2.6 & 0 \\\\ 1.3415 & 1.6 & 2.3 & 0.6415 \\\\ 2.4093 & 0.8998 & 1.7998 & 1.5093 \\end{pmatrix} $$ You can get all three matrices with: import numpy as np # Input matrix X = np.array([ [0.1, 1.2, -0.1, 1.4], [0.5415, 1.49995, 0.1001, 0.8], [1.3093, 0.6998, 0.2002, 1.1] ]) # Weight matrices W_Q = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) W_K = np.array([ [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1] ]) W_V = np.array([ [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 1, 0], [1, 0, 0, 1] ]) # Matrix multiplication Q = np.dot(X, W_Q) K = np.dot(X, W_K) V = np.dot(X, W_V) print(\"Q:\") print(Q) print(\"\\nK:\") print(K) print(\"\\nV:\") print(V) Output Q: [[1.5 1.1 2.6 0. ] [1.3415 1.60005 2.29995 0.6416 ] [2.4093 0.9 1.7998 1.5095 ]] K: [[1.1 1.5 0. 2.6 ] [1.60005 1.3415 0.6416 2.29995] [0.9 2.4093 1.5095 1.7998 ]] V: [[1.5 0. 1.1 2.6 ] [1.3415 0.6416 1.60005 2.29995] [2.4093 1.5095 0.9 1.7998 ]] >","title":"Matrix Multiplication"},{"location":"LLMs%20Explained/#calculating-y","text":"Calculate for $Y$: import numpy as np # Input matrix X X = np.array([ [0.0, 1.0, 0.0, 1.0], [0.6415, 1.39995, 0.3001, 1.1], [1.4093, 0.8998, -0.3998, 1.3] ]) # Weight matrices W_Q, W_K, W_V W_Q = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) W_K = np.array([ [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1] ]) W_V = np.array([ [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 1, 0], [1, 0, 0, 1] ]) # Calculate Q, K, V matrices Q = np.dot(X, W_Q) K = np.dot(X, W_K) V = np.dot(X, W_V) print(\"Q matrix:\") print(Q) print(\"K matrix:\") print(K) print(\"V matrix:\") print(V) Output: Q matrix: [[1. 1. 2. 0. ] [1.7415 1.70005 2.49995 0.9416 ] [2.7093 0.5 2.1998 1.0095 ]] K matrix: [[1. 1. 0. 2. ] [1.70005 1.7415 0.9416 2.49995] [0.5 2.7093 1.0095 2.1998 ]] V matrix: [[1. 0. 1. 2. ] [1.7415 0.9416 1.70005 2.49995] [2.7093 1.0095 0.5 2.1998 ]]","title":"Calculating Y"},{"location":"LLMs%20Explained/#calculate-attention-score","text":"import numpy as np from scipy.special import softmax def attention(Q, K, V): d_k = Q.shape[-1] matmul_qk = np.dot(Q, K.T) # Scale the matrix multiplication scaled_attention_logits = matmul_qk / np.sqrt(d_k) # Apply softmax attention_weights = softmax(scaled_attention_logits, axis=-1) # Multiply by the Value matrix output = np.dot(attention_weights, V) return output # Given matrices Q = np.array([[1.5, 1.1, 2.6, 0.], [1.3415, 1.60005, 2.29995, 0.6416], [2.4093, 0.9, 1.7998, 1.5095]]) K = np.array([[1.1, 1.5, 0., 2.6], [1.60005, 1.3415, 0.6416, 2.29995], [0.9, 2.4093, 1.5095, 1.7998]]) V = np.array([[1.5, 0., 1.1, 2.6], [1.3415, 0.6416, 1.60005, 2.29995], [2.4093, 1.5095, 0.9, 1.7998]]) result = attention(Q, K, V) print(\"Attention(Q, K, V) = \") print(result) Output: Attention(Q, K, V) = [[2.11372594 1.21488963 1.06582258 1.96465889] [2.10729705 1.1957622 1.06288922 1.97442407] [1.82115196 0.90157546 1.21880742 2.13838393]]","title":"Calculate Attention Score"},{"location":"LLMs%20Explained/#calculate-multi-attention-head-output","text":"import numpy as np # Given attention outputs Attention1 = np.array([ [2.11372594, 1.21488963, 1.06582258, 1.96465889], [2.10729705, 1.1957622, 1.06288922, 1.97442407], [1.82115196, 0.90157546, 1.21880742, 2.13838393] ]) Attention2 = np.array([ [1.5, 0.8, 1.2, 2.0], [1.6, 0.9, 1.1, 2.1], [1.4, 0.7, 1.3, 1.9] ]) # Concatenate the attention outputs concat_attention = np.concatenate([Attention1, Attention2], axis=1) # Given W_O matrix W_O = np.array([ [0.37738326, 0.83274845, 0.37280978, 0.14584743], [0.28706851, 0.29072609, 0.69116998, 0.20106682], [0.26764653, 0.12058646, 0.82634382, 0.60818759], [0.44329703, 0.4425581, 0.89811744, 0.24551412], [0.9186323, 0.40029736, 0.17636762, 0.06896409], [0.41921272, 0.0495383, 0.77792527, 0.4354529 ], [0.14791365, 0.66822966, 0.48313699, 0.94127396], [0.11604641, 0.51794357, 0.62942357, 0.76420883] ]) # Multiply concatenated output with W_O multihead_output = concat_attention.dot(W_O) print(multihead_output) Output: [[4.42554033 5.589241 6.99844643 4.79288192] [4.55176485 5.6122494 7.09923364 4.82144704] [4.21254506 5.31988824 6.84520426 4.79017392]]","title":"Calculate Multi-Attention Head Output"},{"location":"LLMs%20Explained/#calculate-layer-normalization","text":"import numpy as np # Define matrix M M = np.array([ [4.42554033, 5.589241, 6.99844643, 4.79288192], [4.55176485, 5.6122494, 7.09923364, 4.82144704], [4.21254506, 5.31988824, 6.84520426, 4.79017392] ]) # Initialize epsilon for numerical stability epsilon = 1e-6 # Calculate mean and variance for each row mean = np.mean(M, axis=1, keepdims=True) variance = np.var(M, axis=1, keepdims=True) # Compute layer normalization LN_M = (M - mean) / np.sqrt(variance + epsilon) print(LN_M) Output: [[-1.03927142 0.13949668 1.56694829 -0.66717355] [-0.97825977 0.09190721 1.59246789 -0.70611533] [-1.10306273 0.02854757 1.58729045 -0.51277529]]","title":"Calculate Layer Normalization"},{"location":"LLMs%20Explained/#linear-regression-code","text":"import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression import tensorflow as tf # Generate data X = np.linspace(-10, 10, 100).reshape(-1, 1) y = np.sin(X) # Create and train the linear model linear_model = LinearRegression() linear_model.fit(X, y) # Predict with linear model y_linear_pred = linear_model.predict(X) # Create and train the neural network model nn_model = tf.keras.Sequential([ tf.keras.layers.Dense(10, input_shape=(1,), activation='relu'), tf.keras.layers.Dense(10, activation='relu'), tf.keras.layers.Dense(1) ]) nn_model.compile(optimizer='adam', loss='mean_squared_error') nn_model.fit(X, y, epochs=1000, verbose=0) # Predict with neural network model y_nn_pred = nn_model.predict(X) # Plotting fig, axs = plt.subplots(1, 2, figsize=(12, 6)) # Linear model plot axs[0].scatter(X, y, label='True Function', color='blue') axs[0].plot(X, y_linear_pred, label='Linear Model', color='red') axs[0].legend() axs[0].set_title('Linear Model') # Deep Feedforward Network plot axs[1].scatter(X, y, label='True Function', color='blue') axs[1].plot(X, y_nn_pred, label='Deep Network', color='green') axs[1].legend() axs[1].set_title('Deep Feedforward Network') plt.show() Output:","title":"Linear Regression Code"},{"location":"LLMs%20Explained/#plot-xor","text":"import matplotlib.pyplot as plt def plot_xor(): # Coordinates for the points x = [0, 1, 0, 1] y = [0, 0, 1, 1] # XOR values for the points colors = [0, 1, 1, 0] # Plot the points plt.scatter(x, y, c=colors, s=100, cmap=\"gray\", edgecolors=\"black\", linewidth=1.5) # Set axis labels and title plt.xlabel(\"$x_1$\") plt.ylabel(\"$x_2$\") plt.title(\"Original $x$ space\") # Adjust axis limits plt.xlim(-0.1, 1.1) plt.ylim(-0.1, 1.1) # Show grid plt.grid(True, which='both', linestyle='--', linewidth=0.5) # Set equal aspect ratio plt.gca().set_aspect('equal', adjustable='box') plt.show() plot_xor() Output:","title":"Plot XOR"},{"location":"LLMs%20Explained/#xor-example","text":"1. Dataset for XOR: $x_1$ $x_2$ XOR 0 0 0 0 1 1 1 0 1 1 1 0 2. Architecture: - A 2-layer feedforward network - Input layer has 2 neurons (for $x_1$ and $x_2$) - Hidden layer has 2 neurons - Output layer has 1 neuron 3. Forward Pass: Suppose we have the following weights and biases: For the hidden layer: $$ W = \\begin{bmatrix} 20 & 20 \\ -20 & -20 \\end{bmatrix} $$ $$ c = \\begin{bmatrix} -10 \\ 30 \\end{bmatrix} $$ For the output layer: $$ w = \\begin{bmatrix} 20 \\ 20 \\end{bmatrix} $$ $$ b = -30 $$ We'll use the sigmoid function as our non-linearity: $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$ 4. Computing for each Input: For input $x = [0, 0]$: Hidden layer outputs: $$ h_1 = \\sigma(0 \\times 20 + 0 \\times 20 - 10) = \\sigma(-10) \\approx 0 $$ $$ h_2 = \\sigma(0 \\times -20 + 0 \\times -20 + 30) = \\sigma(30) \\approx 1 $$ Output layer: $$ y = \\sigma(0 \\times 20 + 1 \\times 20 - 30) = \\sigma(-10) \\approx 0 $$ This matches the XOR output for [0, 0], which is 0. Similar computations for the other inputs will provide the respective XOR outputs, illustrating that the network can represent the XOR function. The hidden layer effectively captures the regions of the input space where the XOR function is 1, and the output layer then combines these regions to produce the final XOR result.","title":"XOR Example"},{"location":"LLMs%20Explained/#using-rectified-linear-units-relu","text":"ReLU is the most common activation function for deep learning so I figured I'd rewrite the example to use it just to compare and contrast. 1. Dataset for XOR remains the same: $x_1$ $x_2$ XOR 0 0 0 0 1 1 1 0 1 1 1 0 2. Architecture: - A 2-layer feedforward network - Input layer has 2 neurons (for $x_1$ and $x_2$) - Hidden layer has 2 neurons - Output layer has 1 neuron ReLU Function: $$ \\text{ReLU}(z) = \\max(0, z) $$ 3. Forward Pass: To ensure that the ReLU activations work for the XOR problem, we will need to choose weights and biases that divide the space in a way that can be combined to represent the XOR function. For the hidden layer: $$ W = \\begin{bmatrix} 1 & -1 \\ -1 & 1 \\end{bmatrix} $$ $$ c = \\begin{bmatrix} 0 \\ 0 \\end{bmatrix} $$ For the output layer: $$ w = \\begin{bmatrix} 1 \\ 1 \\end{bmatrix} $$ $$ b = -0.5 $$ 4. Computing for each Input: For input $x = [0, 0]$: Hidden layer outputs: $$ h_1 = \\text{ReLU}(0 \\times 1 + 0 \\times -1 + 0) = 0 $$ $$ h_2 = \\text{ReLU}(0 \\times -1 + 0 \\times 1 + 0) = 0 $$ Output layer: $$ y = \\text{ReLU}(0 \\times 1 + 0 \\times 1 - 0.5) = 0 $$ This matches the XOR output for [0, 0], which is 0. For the input $x = [0, 1]$: Hidden layer outputs: $$ h_1 = \\text{ReLU}(0 \\times 1 + 1 \\times -1 + 0) = 0 $$ $$ h_2 = \\text{ReLU}(0 \\times -1 + 1 \\times 1 + 0) = 1 $$ Output layer: $$ y = \\text{ReLU}(0 \\times 1 + 1 \\times 1 - 0.5) = 0.5 $$ For XOR, we can threshold the output at $0.5$, such that $y \\geq 0.5$ outputs 1, else outputs 0. Following this thresholding, the output is 1, matching the XOR for [0, 1]. Similarly, you can compute the outputs for the other inputs $[1, 0]$ and $[1, 1]$, and they will match the expected XOR outputs with threshold at 0.5. A quick Python program to prove this out: import numpy as np def relu(z): return max(0, z) def forward_pass(x): # Hidden Layer W = np.array([[1, -1], [-1, 1]]) c = np.array([0, 0]) h = np.vectorize(relu)(np.dot(x, W) + c) # Output Layer w = np.array([1, 1]) b = -0.5 y = relu(np.dot(h, w) + b) # Thresholding at 0.5 for XOR if y >= 0.5: return 1 else: return 0 inputs = [[0, 0], [0, 1], [1, 0], [1, 1]] outputs = [] for x in inputs: outputs.append(forward_pass(x)) print(\"Inputs:\", inputs) print(\"Outputs:\", outputs) Outputs: Inputs: [[0, 0], [0, 1], [1, 0], [1, 1]] Outputs: [0, 1, 1, 0]","title":"Using Rectified Linear Units (ReLU)"},{"location":"LLMs%20Explained/#math-for-ffn","text":"import numpy as np # Layer Normalized Data LN_xi = np.array([ [-1.03927142, 0.13949668, 1.56694829, -0.66717355], [-0.97825977, 0.09190721, 1.59246789, -0.70611533], [-1.10306273, 0.02854757, 1.58729045, -0.51277529] ]) # Parameters W1 = np.array([ [0.1, 0.2, 0.3, 0.4, 0.5, 0.6], [0.7, 0.8, 0.9, 1.0, 1.1, 1.2], [1.3, 1.4, 1.5, 1.6, 1.7, 1.8], [1.9, 2.0, 2.1, 2.2, 2.3, 2.4] ]) b1 = np.array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06]) W2 = np.array([ [0.1, 0.7, 1.3, 1.9], [0.2, 0.8, 1.4, 2.0], [0.3, 0.9, 1.5, 2.1], [0.4, 1.0, 1.6, 2.2], [0.5, 1.1, 1.7, 2.3], [0.6, 1.2, 1.8, 2.4] ]) b2 = np.array([0.01, 0.02, 0.03, 0.04]) # First linear transformation z1 = np.dot(LN_xi, W1) + b1 # Apply ReLU activation a1 = np.maximum(0, z1) # Second linear transformation z2 = np.dot(a1, W2) + b2 print(z2) If you want to see the first row, first column calculated separately: import numpy as np # Layer Normalized Data for the first row LN_xi_row1 = np.array([-1.03927142, 0.13949668, 1.56694829, -0.66717355]) # Parameters W1 = np.array([ [0.1, 0.2, 0.3, 0.4, 0.5, 0.6], [0.7, 0.8, 0.9, 1.0, 1.1, 1.2], [1.3, 1.4, 1.5, 1.6, 1.7, 1.8], [1.9, 2.0, 2.1, 2.2, 2.3, 2.4] ]) b1 = np.array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06]) W2_col1 = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6]) b2_col1 = 0.01 # First linear transformation for the first row z1_row1 = np.dot(LN_xi_row1, W1) + b1 # Apply ReLU activation for the first row a1_row1 = np.maximum(0, z1_row1) # Second linear transformation for the first column z2_row1_col1 = np.dot(a1_row1, W2_col1) + b2_col1 print(z2_row1_col1)","title":"Math for FFN"},{"location":"LLMs%20Explained/#decoder-attention-heads","text":"I used this code to generate the results for the decoder attention heads. import numpy as np # Define the position encoding matrix for the output PE_output = np.array([[0.0, 1.0, 0.0, 1.0], [0.6415, 1.39995, 0.3001, 1.1], [1.4093, 0.8998, -0.3998, 1.3]]) # Generate random matrices for weights np.random.seed(42) # Setting seed for reproducibility d_model = 4 # The dimensionality of the input and output d_k = d_model d_v = d_model W_q = np.random.rand(d_model, d_k) W_k = np.random.rand(d_model, d_k) W_v = np.random.rand(d_model, d_v) W_o = np.random.rand(d_k, d_model) # Compute Q, K, V matrices Q = PE_output @ W_q K = PE_output @ W_k V = PE_output @ W_v # Compute the attention weights attention_weights = np.exp(Q @ K.T) / np.sum(np.exp(Q @ K.T), axis=-1, keepdims=True) # Compute the output of the self-attention mechanism output = attention_weights @ V # Project the output back to the original dimensionality output = output @ W_o # Layer Normalization mean = np.mean(output, axis=-1, keepdims=True) std = np.std(output, axis=-1, keepdims=True) eps = 1e-6 normalized_output = (output - mean) / (std + eps) print(\"Self Attention Output:\") print(output) print(\"\\nLayer Normalized Output:\") print(normalized_output) Output: Self Attention Output: [[2.82896639 2.49151229 3.27935978 3.36785616] [2.93697775 2.57919015 3.42996786 3.49210994] [2.95810782 2.60399936 3.43836135 3.51718943]] Layer Normalized Output: [[-0.46049196 -1.4140849 0.81224991 1.06232694] [-0.46121408 -1.41736871 0.85625689 1.02232591] [-0.46146504 -1.41536061 0.83223948 1.04458616]]","title":"Decoder Attention Heads"},{"location":"LLMs%20Explained/#calculate-encoder-decoder-output","text":"import numpy as np # Encoder Output Encoder_Output = np.array([ [-1.34164072, -0.44721357, 0.44721357, 1.34164072], [-1.34164071, -0.44721357, 0.44721357, 1.34164071], [-1.34164075, -0.44721358, 0.44721358, 1.34164075] ]) # Decoder Output Decoder_Output = np.array([ [-0.46049196, -1.4140849, 0.81224991, 1.06232694], [-0.46121408, -1.41736871, 0.85625689, 1.02232591], [-0.46146504, -1.41536061, 0.83223948, 1.04458616] ]) # Encoder Weights W_Q_enc = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) W_K_enc = np.array([ [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1] ]) W_V_enc = np.array([ [1, 1, 0, 0], [0, 0, 1, 1], [0, 1, 1, 0], [1, 0, 0, 1] ]) # Decoder Weights W_Q_dec = np.array([ [1, 0, 0, 1], [0, 1, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0] ]) # Compute Queries, Keys, and Values for Encoder Q_enc = Encoder_Output.dot(W_Q_enc.T) K_enc = Encoder_Output.dot(W_K_enc.T) V_enc = Encoder_Output.dot(W_V_enc.T) # Compute Queries for Decoder Q_dec = Decoder_Output.dot(W_Q_dec.T) # Attention Scores Scores = Q_dec.dot(K_enc.T) / np.sqrt(3) def softmax(x): e_x = np.exp(x - np.max(x)) return e_x / e_x.sum(axis=-1, keepdims=True) # Compute attention weights Attention_Weights = softmax(Scores) # Compute Weighted sum of Values Attention_Output = Attention_Weights.dot(V_enc) print(\"Attention Weights:\") print(Attention_Weights) print(\"\\nAttention Output:\") print(Attention_Output) Output: Attention Weights: [[0.33333333 0.33333333 0.33333334] [0.33333333 0.33333333 0.33333334] [0.33333333 0.33333333 0.33333334]] Attention Output: [[-1.7888543 1.7888543 0. 0. ] [-1.7888543 1.7888543 0. 0. ] [-1.7888543 1.7888543 0. 0. ]]","title":"Calculate Encoder-Decoder Output"},{"location":"LLMs%20Explained/#what-is-cross-entropy-loss","text":"Cross-entropy loss in the context of LLMs such as transformers is a measure of the difference between the model's predicted probability distribution over the vocabulary and the true distribution, typically represented as a one-hot encoded vector for the actual next token in the sequence. For a single prediction, it's calculated as: $$ L = -\\sum_{i=1}^V y_i \\log(p_i) $$ where $V$ is the size of the vocabulary, $y_i$ is the one-hot encoding of the true token (1 for the true token and 0 for all others), and $p_i$ is the predicted probability of the $i$-th token. Why Do We Use It? Comparing Probability Distributions : Cross-entropy is inherently a measure for comparing two probability distributions, making it well-suited for tasks where the output is a set of probabilities\u2014such as predicting the next token in a sequence. Gradient Optimization : It enables efficient training of neural networks through gradient-based optimization techniques. In LLMs, the gradients can be efficiently computed for backpropagation to adjust the model's parameters. Logarithmic Scaling : This feature of cross-entropy provides a natural and strong gradient signal for learning, which is especially important for models dealing with a large output space, such as the vocabularies in LLMs. Direct Feedback for Probability Prediction : Cross-entropy directly penalizes the model based on how divergent its probability predictions are from the actual distribution, which in the case of LLMs is crucial for generating coherent text sequences. Information Theoretic Interpretation : It stems from information theory, where it measures the number of extra bits needed due to the inefficiency of assuming the predicted distribution instead of the true distribution. In training LLMs, cross-entropy loss is pivotal in guiding the model to adjust its internal parameters. By minimizing this loss, a model learns to increase the probability it assigns to the actual next token and decrease the probabilities of all other tokens, thus aligning the predicted distribution closer to the true distribution, token by token. This is key to generating text that closely follows the human language patterns. You can verify this yourself with this Python code: import numpy as np # True label y_true = np.array([1, 0, 0, 0]) # The correct word is 'mat' # Predictions predictions_1 = np.array([0.7, 0.1, 0.1, 0.1]) # Model's prediction is good predictions_2 = np.array([0.1, 0.1, 0.1, 0.7]) # Model's prediction is poor # Function to calculate cross-entropy loss def cross_entropy(y_true, predictions): return -np.sum(y_true * np.log(predictions)) # Calculate loss loss_1 = cross_entropy(y_true, predictions_1) loss_2 = cross_entropy(y_true, predictions_2) print(f\"Loss for first prediction: {loss_1:.3f}\") print(f\"Loss for second prediction: {loss_2:.3f}\") Output: Loss for first prediction: 0.357 Loss for second prediction: 2.303","title":"What is Cross Entropy Loss"},{"location":"LLMs%20Explained/#other-sources","text":"Retrieval-Augmented Generation for Knowledge Intensive NLP Tasks Nvidia - AI Chatbot with Retrieval Augmented Generation","title":"Other Sources"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/","text":"Load Balance Testing on 4112F-ON w/OS10 See: Test Case 1 Test Case 2 Test Case 3 Test Case 4","title":"Load Balance Testing on 4112F-ON w/OS10"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/#load-balance-testing-on-4112f-on-wos10","text":"See: Test Case 1 Test Case 2 Test Case 3 Test Case 4","title":"Load Balance Testing on 4112F-ON w/OS10"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/","text":"Dell OS10 Load Balancing with LAG Config In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. Helpful Links ONIE Network Install Process Overview Dell OS10 Manual My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OS 10 Version OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39 Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Management Interface See Configure Management Interface on Dell OS10 Configure Device for Reverse LAG Physical Configuration I used the following SFPs 1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/9) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output I used the following optics: Input Port Output Ports LAG Configuration Enable LAG Ports and Input Port Verify All Interfaces are Running at the Same Speed All interfaces must be the same speed in a LAG. In my case, the fiber interface was running at 10Gb/s so I brought that down to 1Gb/s by doing the following: OS10(config)# interface ethernet 1/1/12 OS10(conf-if-eth1/1/12)# speed 1000 OS10(conf-if-eth1/1/12)# <165>1 2019-10-28T19:10:22.616888+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IFM_OSTATE_DN: Interface operational state is down :ethernet1/1/12 OS10(conf-if-eth1/1/12)# OS10(conf-if-eth1/1/12)# <165>1 2019-10-28T19:10:29.591467+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IFM_OSTATE_UP: Interface operational state is up :ethernet1/1/12 Add Interfaces to the Port Channel Group OS10(config)# interface port-channel 1 OS10(conf-if-po-1)# exit OS10(config)# interface ethernet 1/1/5 OS10(conf-if-eth1/1/5)# channel-group 1 mode on OS10(conf-if-eth1/1/5)# <165>1 2019-10-28T19:17:33.746593+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IFM_OSTATE_UP: Interface operational state is up :port-channel1 OS10(conf-if-eth1/1/5)# exit OS10(config)# interface ethernet 1/1/9 OS10(conf-if-eth1/1/9)# channel-group 1 mode on OS10(conf-if-eth1/1/9)# exit OS10(config)# interface ethernet 1/1/12 OS10(conf-if-eth1/1/12)# channel-group 1 mode on Configure the Port Channel Hash Algorithm We want to load balance on the standard network 5 tuple. You can configure this with OS10(config)# load-balancing ip-selection destination-ip source-ip protocol l4-destination-port l4-source-port Configure Mirror Port Session from Source to LAG Interface Next we need to send all the traffic from our \"TAP\" input interface to our port channel to be load balanced out to all of our listening devices. OS10(config)# monitor session 1 OS10(conf-mon-local-1)# source interface ethernet 1/1/1 OS10(conf-mon-local-1)# destination interface port-channel 1 OS10(conf-mon-local-1)# no shut Final Configuration OS10# show running-configuration ! Version 10.5.0.2 ! Last configuration change at Oct 29 14:53:37 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password XXXXX username admin password XXXXX role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown channel-group 1 no switchport flowcontrol receive on ! interface ethernet1/1/10 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/11 no shutdown no switchport flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry Findings The reverse LAG strategy will load balance traffic, but there is a critical problem. The hash algorithm is sensitive to the order of the fields. This means that in a standard TCP conversation as the IP/TCP/UDP source and destinations reverse for inbound and outbound traffic they will always go to different hosts on a five tuple hash. For example, see the below: Host 1 Host 2 Host 3 If you look at host 1 and host 3 you can see that both sides of the traffic consistently landed on different sessions. Without modifying the guts of how the algorithm itself is implemented, there isn't a way to fix this. IE: The idea isn't going to work. The reason for this is that security sensors like Bro and Suricata require the complete conversation be sent to a single instance. That is to say, a single instance of Bro or Suricata must see the entire conversation. The configuration above will cause an instance to see only one side of any given conversation. Other Notes The default VLAN on our OS10 switch is VLAN 1 and is untagged. The default configuration of a port is Switchport access vlan 1 on all ports (factory default) All ports will show in vlan 1, and vlan 1 will be labeled as the default vlan using command \u201csho vlan\u201d If you change the default vlan using the command \u201cdefault vlan-id\u201d it will change the switchport access vlan on all interfaces that were in the default vlan to the new specified default vlan. default vlan-id 3 all vlan 1 ports get changed to vlan 3 ports automatically (vlan 3 is the new default vlan), and the interfaces will sho Switchport access vlan 3 If you want any port to be in a different untagged vlan other the default vlan, you must change it via the command \u201cswitchport access vlan \u201d On a trunk port, the default vlan is the native vlan. If you want to change the native vlan on trunk port, then you use the command \u201cswitchport access vlan \u201d So in my example I sent earlier The default vlan is vlan 1 on all ports except the trunk port. sho run will sho Switchport access vlan 1 on all interfaces except the trunk port because I changed it. I specified vlan 2 as the native vlan for the trunk port only. Untagged VLAN ==> switchport access vlan 2 Tagged VLAN ==> switchport trunk allowed vlan 1612-1615,3939 Example: interface ethernet1/1/17 description Node1_Port1 switchport mode trunk switchport access vlan 2 switchport trunk allowed vlan 1612-1615,3939 spanning-tree port type edge no shutdown","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#dell-os10-load-balancing-with-lag-config","text":"In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors.","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#helpful-links","text":"ONIE Network Install Process Overview Dell OS10 Manual","title":"Helpful Links"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#my-configuration","text":"","title":"My Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#os-10-version","text":"OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39","title":"OS 10 Version"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#configure-management-interface","text":"See Configure Management Interface on Dell OS10","title":"Configure Management Interface"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#configure-device-for-reverse-lag","text":"","title":"Configure Device for Reverse LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#physical-configuration","text":"I used the following SFPs 1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/9) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output I used the following optics:","title":"Physical Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#input-port","text":"","title":"Input Port"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#output-ports","text":"","title":"Output Ports"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#lag-configuration","text":"","title":"LAG Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#enable-lag-ports-and-input-port","text":"","title":"Enable LAG Ports and Input Port"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#verify-all-interfaces-are-running-at-the-same-speed","text":"All interfaces must be the same speed in a LAG. In my case, the fiber interface was running at 10Gb/s so I brought that down to 1Gb/s by doing the following: OS10(config)# interface ethernet 1/1/12 OS10(conf-if-eth1/1/12)# speed 1000 OS10(conf-if-eth1/1/12)# <165>1 2019-10-28T19:10:22.616888+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IFM_OSTATE_DN: Interface operational state is down :ethernet1/1/12 OS10(conf-if-eth1/1/12)# OS10(conf-if-eth1/1/12)# <165>1 2019-10-28T19:10:29.591467+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IFM_OSTATE_UP: Interface operational state is up :ethernet1/1/12","title":"Verify All Interfaces are Running at the Same Speed"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#add-interfaces-to-the-port-channel-group","text":"OS10(config)# interface port-channel 1 OS10(conf-if-po-1)# exit OS10(config)# interface ethernet 1/1/5 OS10(conf-if-eth1/1/5)# channel-group 1 mode on OS10(conf-if-eth1/1/5)# <165>1 2019-10-28T19:17:33.746593+00:00 OS10 dn_alm 669 - - Node.1-Unit.1:PRI [event], Dell EMC (OS10) %IFM_OSTATE_UP: Interface operational state is up :port-channel1 OS10(conf-if-eth1/1/5)# exit OS10(config)# interface ethernet 1/1/9 OS10(conf-if-eth1/1/9)# channel-group 1 mode on OS10(conf-if-eth1/1/9)# exit OS10(config)# interface ethernet 1/1/12 OS10(conf-if-eth1/1/12)# channel-group 1 mode on","title":"Add Interfaces to the Port Channel Group"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#configure-the-port-channel-hash-algorithm","text":"We want to load balance on the standard network 5 tuple. You can configure this with OS10(config)# load-balancing ip-selection destination-ip source-ip protocol l4-destination-port l4-source-port","title":"Configure the Port Channel Hash Algorithm"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#configure-mirror-port-session-from-source-to-lag-interface","text":"Next we need to send all the traffic from our \"TAP\" input interface to our port channel to be load balanced out to all of our listening devices. OS10(config)# monitor session 1 OS10(conf-mon-local-1)# source interface ethernet 1/1/1 OS10(conf-mon-local-1)# destination interface port-channel 1 OS10(conf-mon-local-1)# no shut","title":"Configure Mirror Port Session from Source to LAG Interface"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#final-configuration","text":"OS10# show running-configuration ! Version 10.5.0.2 ! Last configuration change at Oct 29 14:53:37 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password XXXXX username admin password XXXXX role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown channel-group 1 no switchport flowcontrol receive on ! interface ethernet1/1/10 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/11 no shutdown no switchport flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry","title":"Final Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#findings","text":"The reverse LAG strategy will load balance traffic, but there is a critical problem. The hash algorithm is sensitive to the order of the fields. This means that in a standard TCP conversation as the IP/TCP/UDP source and destinations reverse for inbound and outbound traffic they will always go to different hosts on a five tuple hash. For example, see the below:","title":"Findings"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#host-1","text":"","title":"Host 1"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#host-2","text":"","title":"Host 2"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#host-3","text":"If you look at host 1 and host 3 you can see that both sides of the traffic consistently landed on different sessions. Without modifying the guts of how the algorithm itself is implemented, there isn't a way to fix this. IE: The idea isn't going to work. The reason for this is that security sensors like Bro and Suricata require the complete conversation be sent to a single instance. That is to say, a single instance of Bro or Suricata must see the entire conversation. The configuration above will cause an instance to see only one side of any given conversation.","title":"Host 3"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%201/#other-notes","text":"The default VLAN on our OS10 switch is VLAN 1 and is untagged. The default configuration of a port is Switchport access vlan 1 on all ports (factory default) All ports will show in vlan 1, and vlan 1 will be labeled as the default vlan using command \u201csho vlan\u201d If you change the default vlan using the command \u201cdefault vlan-id\u201d it will change the switchport access vlan on all interfaces that were in the default vlan to the new specified default vlan. default vlan-id 3 all vlan 1 ports get changed to vlan 3 ports automatically (vlan 3 is the new default vlan), and the interfaces will sho Switchport access vlan 3 If you want any port to be in a different untagged vlan other the default vlan, you must change it via the command \u201cswitchport access vlan \u201d On a trunk port, the default vlan is the native vlan. If you want to change the native vlan on trunk port, then you use the command \u201cswitchport access vlan \u201d So in my example I sent earlier The default vlan is vlan 1 on all ports except the trunk port. sho run will sho Switchport access vlan 1 on all interfaces except the trunk port because I changed it. I specified vlan 2 as the native vlan for the trunk port only. Untagged VLAN ==> switchport access vlan 2 Tagged VLAN ==> switchport trunk allowed vlan 1612-1615,3939 Example: interface ethernet1/1/17 description Node1_Port1 switchport mode trunk switchport access vlan 2 switchport trunk allowed vlan 1612-1615,3939 spanning-tree port type edge no shutdown","title":"Other Notes"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/","text":"Dell OS10 Load Balancing with LAG Config In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. This test case was a duplicate of test 1 except with 1 port unplugged to see how it affected the algorithm. Helpful Links ONIE Network Install Process Overview Dell OS10 Manual My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OS 10 Version OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39 Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Management Interface See Configure Management Interface on Dell OS10 Configure Device for LAG Physical Configuration 1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 1, 1Gb/s copper SFPs (Ethernet 1/1/5) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output MAJOR DIFFERENCE WITH TEST 1 : In this test Ethernet 1/1/9 was disconnected. I actually did this by accident originally. I discovered VMWare autonegotiates to 10Gb/s and if you leave the interface at 1Gb/s the interface will not come up. Configuration - Same as Test 1 Except with Ethernet 1/1/9 Unplugged OS10(config)# do show ip interface brief Interface Name IP-Address OK Method Status Protocol ========================================================================================= Ethernet 1/1/1 unassigned YES unset up up Ethernet 1/1/2 unassigned NO unset up down Ethernet 1/1/3 unassigned NO unset up down Ethernet 1/1/4 unassigned NO unset up down Ethernet 1/1/5 unassigned YES unset up up Ethernet 1/1/6 unassigned NO unset up down Ethernet 1/1/7 unassigned NO unset up down Ethernet 1/1/8 unassigned NO unset up down Ethernet 1/1/9 unassigned NO unset up down Ethernet 1/1/10 unassigned NO unset up down Ethernet 1/1/11 unassigned NO unset up down Ethernet 1/1/12 unassigned YES unset up up Ethernet 1/1/13 unassigned NO unset up down Ethernet 1/1/14 unassigned NO unset up down Ethernet 1/1/15 unassigned NO unset up down Management 1/1/1 192.168.1.20/24 YES manual up up Vlan 1 unassigned YES unset up up Port-channel 1 unassigned YES unset up up OS10(config)# do show running-configuration ! Version 10.5.0.2 ! Last configuration change at Nov 01 01:09:30 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password $6$5DdOHYg5$JCE1vMSmkQOrbh31U74PIPv7lyOgRmba1IxhkYibppMXs1KM4Y.gbTPcxyMP/PHUkMc5rdk/ZLv9Sfv3ALtB61 username admin password $6$q9QBeYjZ$jfxzVqGhkxX3smxJSH9DDz7/3OJc6m5wjF8nnLD7/VKx8SloIhp4NoGZs0I/UNwh8WVuxwfd9q4pWIgNs5BKH. role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/10 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/11 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry Findings ~~I noticed in this configuration traffic appears to balance correctly. Will need to sit down and think on the math.~~ I am no longer convinced these results are valid. See test case 3. After further examination it looks like on the surface it is working when in reality it may not be. Interface 1/1/9 was down because ESXi was set to 10Gb/s and I had set the speed on 9 manually to 1Gb/s causing it to go down. Host 1 Host 2","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#dell-os10-load-balancing-with-lag-config","text":"In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. This test case was a duplicate of test 1 except with 1 port unplugged to see how it affected the algorithm.","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#helpful-links","text":"ONIE Network Install Process Overview Dell OS10 Manual","title":"Helpful Links"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#my-configuration","text":"","title":"My Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#os-10-version","text":"OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39","title":"OS 10 Version"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#configure-management-interface","text":"See Configure Management Interface on Dell OS10","title":"Configure Management Interface"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#configure-device-for-lag","text":"","title":"Configure Device for LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#physical-configuration","text":"1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 1, 1Gb/s copper SFPs (Ethernet 1/1/5) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output MAJOR DIFFERENCE WITH TEST 1 : In this test Ethernet 1/1/9 was disconnected. I actually did this by accident originally. I discovered VMWare autonegotiates to 10Gb/s and if you leave the interface at 1Gb/s the interface will not come up.","title":"Physical Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#configuration-same-as-test-1-except-with-ethernet-119-unplugged","text":"OS10(config)# do show ip interface brief Interface Name IP-Address OK Method Status Protocol ========================================================================================= Ethernet 1/1/1 unassigned YES unset up up Ethernet 1/1/2 unassigned NO unset up down Ethernet 1/1/3 unassigned NO unset up down Ethernet 1/1/4 unassigned NO unset up down Ethernet 1/1/5 unassigned YES unset up up Ethernet 1/1/6 unassigned NO unset up down Ethernet 1/1/7 unassigned NO unset up down Ethernet 1/1/8 unassigned NO unset up down Ethernet 1/1/9 unassigned NO unset up down Ethernet 1/1/10 unassigned NO unset up down Ethernet 1/1/11 unassigned NO unset up down Ethernet 1/1/12 unassigned YES unset up up Ethernet 1/1/13 unassigned NO unset up down Ethernet 1/1/14 unassigned NO unset up down Ethernet 1/1/15 unassigned NO unset up down Management 1/1/1 192.168.1.20/24 YES manual up up Vlan 1 unassigned YES unset up up Port-channel 1 unassigned YES unset up up OS10(config)# do show running-configuration ! Version 10.5.0.2 ! Last configuration change at Nov 01 01:09:30 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password $6$5DdOHYg5$JCE1vMSmkQOrbh31U74PIPv7lyOgRmba1IxhkYibppMXs1KM4Y.gbTPcxyMP/PHUkMc5rdk/ZLv9Sfv3ALtB61 username admin password $6$q9QBeYjZ$jfxzVqGhkxX3smxJSH9DDz7/3OJc6m5wjF8nnLD7/VKx8SloIhp4NoGZs0I/UNwh8WVuxwfd9q4pWIgNs5BKH. role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/10 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/11 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry","title":"Configuration - Same as Test 1 Except with Ethernet 1/1/9 Unplugged"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#findings","text":"~~I noticed in this configuration traffic appears to balance correctly. Will need to sit down and think on the math.~~ I am no longer convinced these results are valid. See test case 3. After further examination it looks like on the surface it is working when in reality it may not be. Interface 1/1/9 was down because ESXi was set to 10Gb/s and I had set the speed on 9 manually to 1Gb/s causing it to go down.","title":"Findings"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#host-1","text":"","title":"Host 1"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%202/#host-2","text":"","title":"Host 2"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/","text":"Dell OS10 Load Balancing with LAG Config In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. This is a duplicate of test 1 to verify my results. I began questioning myself after looking more closely at the data. Helpful Links ONIE Network Install Process Overview Dell OS10 Manual My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OS 10 Version OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39 Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Management Interface See Configure Management Interface on Dell OS10 Configure Device for LAG Physical Configuration 1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/10) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output Configuration - Same as Test 1 The only change was I moved from port 9 to port 10. ! Version 10.5.0.2 ! Last configuration change at Nov 01 01:52:29 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password $6$5DdOHYg5$JCE1vMSmkQOrbh31U74PIPv7lyOgRmba1IxhkYibppMXs1KM4Y.gbTPcxyMP/PHUkMc5rdk/ZLv9Sfv3ALtB61 username admin password $6$q9QBeYjZ$jfxzVqGhkxX3smxJSH9DDz7/3OJc6m5wjF8nnLD7/VKx8SloIhp4NoGZs0I/UNwh8WVuxwfd9q4pWIgNs5BKH. role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown switchport access vlan 1 speed 1000 flowcontrol receive on ! interface ethernet1/1/10 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/11 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry Findings I confirmed that the traffic did indeed go to different simulated sensors. This time I stopped the traffic generator, reset all the Wireshark sessions and then restarted the traffic generator. I set the filter on Wireshark to 13.107.42.12 ahead of time on all three before examining a specific stream more closely as seen on host 3. On host 3 you can see the synchronize packet go out with sequence number 3195700332 and you notice that the SYN, ACK response is missing. Look at host 2 and you can see the SYN, ACK with the expected response of 3195700333. Host 1 Host 2 Host 3","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#dell-os10-load-balancing-with-lag-config","text":"In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. This is a duplicate of test 1 to verify my results. I began questioning myself after looking more closely at the data.","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#helpful-links","text":"ONIE Network Install Process Overview Dell OS10 Manual","title":"Helpful Links"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#my-configuration","text":"","title":"My Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#os-10-version","text":"OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39","title":"OS 10 Version"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#configure-management-interface","text":"See Configure Management Interface on Dell OS10","title":"Configure Management Interface"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#configure-device-for-lag","text":"","title":"Configure Device for LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#physical-configuration","text":"1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/10) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output","title":"Physical Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#configuration-same-as-test-1","text":"The only change was I moved from port 9 to port 10. ! Version 10.5.0.2 ! Last configuration change at Nov 01 01:52:29 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password $6$5DdOHYg5$JCE1vMSmkQOrbh31U74PIPv7lyOgRmba1IxhkYibppMXs1KM4Y.gbTPcxyMP/PHUkMc5rdk/ZLv9Sfv3ALtB61 username admin password $6$q9QBeYjZ$jfxzVqGhkxX3smxJSH9DDz7/3OJc6m5wjF8nnLD7/VKx8SloIhp4NoGZs0I/UNwh8WVuxwfd9q4pWIgNs5BKH. role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown switchport access vlan 1 speed 1000 flowcontrol receive on ! interface ethernet1/1/10 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/11 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry","title":"Configuration - Same as Test 1"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#findings","text":"I confirmed that the traffic did indeed go to different simulated sensors. This time I stopped the traffic generator, reset all the Wireshark sessions and then restarted the traffic generator. I set the filter on Wireshark to 13.107.42.12 ahead of time on all three before examining a specific stream more closely as seen on host 3. On host 3 you can see the synchronize packet go out with sequence number 3195700332 and you notice that the SYN, ACK response is missing. Look at host 2 and you can see the SYN, ACK with the expected response of 3195700333.","title":"Findings"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#host-1","text":"","title":"Host 1"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#host-2","text":"","title":"Host 2"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%203/#host-3","text":"","title":"Host 3"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/","text":"Dell OS10 Load Balancing with LAG Config In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. After test 3 I added the command: OS10(config)# enhanced-hashing resilient-hashing lag Helpful Links ONIE Network Install Process Overview Dell OS10 Manual My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OS 10 Version OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39 Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Management Interface See Configure Management Interface on Dell OS10 Configure Device for LAG Physical Configuration 1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/10) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output Configuration ! Version 10.5.0.2 ! Last configuration change at Nov 01 02:25:00 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password $6$5DdOHYg5$JCE1vMSmkQOrbh31U74PIPv7lyOgRmba1IxhkYibppMXs1KM4Y.gbTPcxyMP/PHUkMc5rdk/ZLv9Sfv3ALtB61 enhanced-hashing resilient-hashing lag username admin password $6$q9QBeYjZ$jfxzVqGhkxX3smxJSH9DDz7/3OJc6m5wjF8nnLD7/VKx8SloIhp4NoGZs0I/UNwh8WVuxwfd9q4pWIgNs5BKH. role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown switchport access vlan 1 speed 1000 flowcontrol receive on ! interface ethernet1/1/10 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/11 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry Findings This time traffic still went to different Wireshark sessions as you can see in the below. On host 3 you can see the synchronize packet go out with sequence number 3195700332 and you notice that the SYN, ACK response is missing. Look at host 2 and you can see the SYN, ACK with the expected response of 3195700333. Traffic to Different Wireshark Sessions However a session on host 1 seems to work correctly. Host 1 Session with Correct Output A More Definitive Test I wanted to be sure of my findings so I crafted a new PCAP. This time, I started a capture on my desktop and opened a new connection to vCenter knowing this should generate several new streams. I then closed the browser entirely to ensure those same sessions would close. I saved the capture off and sent it to my traffic replay system. I then played it back with tcpreplay . I then grabbed a random stream from the sequence to confirm whether I could see the entire three way hand shake on one host or not. As suspected the initial syn hit one Wireshark session and the response went to a separate Wireshark session. Host 1 Host 3","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#dell-os10-load-balancing-with-lag-config","text":"In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. After test 3 I added the command: OS10(config)# enhanced-hashing resilient-hashing lag","title":"Dell OS10 Load Balancing with LAG Config"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#helpful-links","text":"ONIE Network Install Process Overview Dell OS10 Manual","title":"Helpful Links"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#my-configuration","text":"","title":"My Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 10.5.0.2 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#os-10-version","text":"OS10# show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:39","title":"OS 10 Version"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#configure-management-interface","text":"See Configure Management Interface on Dell OS10","title":"Configure Management Interface"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#configure-device-for-lag","text":"","title":"Configure Device for LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#physical-configuration","text":"1, 1Gb/s copper SFP (Ethernet 1/1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/10) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output","title":"Physical Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#configuration","text":"! Version 10.5.0.2 ! Last configuration change at Nov 01 02:25:00 2019 ! ip vrf default ! interface breakout 1/1/13 map 100g-1x interface breakout 1/1/14 map 100g-1x interface breakout 1/1/15 map 100g-1x iscsi enable iscsi target port 860 iscsi target port 3260 system-user linuxadmin password $6$5DdOHYg5$JCE1vMSmkQOrbh31U74PIPv7lyOgRmba1IxhkYibppMXs1KM4Y.gbTPcxyMP/PHUkMc5rdk/ZLv9Sfv3ALtB61 enhanced-hashing resilient-hashing lag username admin password $6$q9QBeYjZ$jfxzVqGhkxX3smxJSH9DDz7/3OJc6m5wjF8nnLD7/VKx8SloIhp4NoGZs0I/UNwh8WVuxwfd9q4pWIgNs5BKH. role sysadmin priv-lvl 15 aaa authentication login default local aaa authentication login console local ! class-map type application class-iscsi ! policy-map type application policy-iscsi ! interface vlan1 no shutdown ! interface port-channel1 no shutdown switchport access vlan 1 ! interface mgmt1/1/1 no shutdown no ip address dhcp ip address 192.168.1.20/24 ipv6 address autoconfig ! interface ethernet1/1/1 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/2 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/3 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/4 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/5 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/6 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/7 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/8 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/9 no shutdown switchport access vlan 1 speed 1000 flowcontrol receive on ! interface ethernet1/1/10 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/11 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/12 no shutdown channel-group 1 no switchport speed 1000 flowcontrol receive on ! interface ethernet1/1/13 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/14 no shutdown switchport access vlan 1 flowcontrol receive on ! interface ethernet1/1/15 no shutdown switchport access vlan 1 flowcontrol receive on ! monitor session 1 destination interface port-channel1 source interface ethernet1/1/1 no shut ! snmp-server contact \"Contact Support\" ! telemetry","title":"Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#findings","text":"This time traffic still went to different Wireshark sessions as you can see in the below. On host 3 you can see the synchronize packet go out with sequence number 3195700332 and you notice that the SYN, ACK response is missing. Look at host 2 and you can see the SYN, ACK with the expected response of 3195700333.","title":"Findings"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#traffic-to-different-wireshark-sessions","text":"However a session on host 1 seems to work correctly.","title":"Traffic to Different Wireshark Sessions"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#host-1-session-with-correct-output","text":"","title":"Host 1 Session with Correct Output"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#a-more-definitive-test","text":"I wanted to be sure of my findings so I crafted a new PCAP. This time, I started a capture on my desktop and opened a new connection to vCenter knowing this should generate several new streams. I then closed the browser entirely to ensure those same sessions would close. I saved the capture off and sent it to my traffic replay system. I then played it back with tcpreplay . I then grabbed a random stream from the sequence to confirm whether I could see the entire three way hand shake on one host or not. As suspected the initial syn hit one Wireshark session and the response went to a separate Wireshark session.","title":"A More Definitive Test"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#host-1","text":"","title":"Host 1"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OS10/Test%20Case%204/#host-3","text":"","title":"Host 3"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/","text":"Load Balancing with LAG OPX In this test case the goal is to create a simple packet broker using a reverse LAG port. Helpful Links ONIE Network Install Process Overview OPX Install Instructions for Dell EMC Equipment OPX Tools Source Code OPX Command Reference OPX LAG Command Documenattion OPX Docs Home List of Supported Hardware Helpful Debug Commands cps_get_oid.py -qua target base-switch/switching-entities/switching-entity cps_model_info base-switch/switching-entities/switching-entity cps_set_oid.py -qua target base-switch/switching-entities/switching-entity name=lag-hash-fields attr=src-ip,dest-ip,l4-dest-port,l4-src-port,ip-protocol My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OpenSwitch version PKGS_OPX-3.2.0-installer-x86_64 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OPX Version OS_NAME=\"OPX\" OS_VERSION=\"unstable\" PLATFORM=\"S4112F-ON\" ARCHITECTURE=\"x86_64\" INTERNAL_BUILD_ID=\"OpenSwitch blueprint for Dell 1.0.0\" BUILD_VERSION=\"unstable.0-stretch\" BUILD_DATE=\"2019-06-21T19:04:22+0000\" INSTALL_DATE=\"2019-10-23T23:16:10+00:00\" SYSTEM_UPTIME= 1 day, 5 minutes SYSTEM_STATE= running UPGRADED_PACKAGES=no ALTERED_PACKAGES=yes Wasn't sure why I got the unstable version after installation. It didn't cause any problems for testing so I just left it as is. Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Device for Reverse LAG Physical Configuration I used the following SFPs 1, 1Gb/s copper SFP (e101-001-0) for input 2, 1Gb/s copper SFPs (e101-005-0/e101-009-0) and 1, 10Gb/s, fiber SFP (e101-012-0) for output Input Port Output Ports LAG Configuration Enable LAG Ports and Input Port root@OPX:~# ip link set e101-001-0 up root@OPX:~# ip link set e101-005-0 up root@OPX:~# ip link set e101-009-0 up root@OPX:~# ip link set e101-012-0 up root@OPX:~# opx-show-interface --summary Port | Enabled | Operational status | Supported speed ----------------------------------------------------------- e101-001-0 | yes | up | 1G 10G e101-002-0 | no | down | 1G 10G e101-003-0 | no | down | 1G 10G e101-004-0 | no | down | 1G 10G e101-005-0 | yes | up | 1G 10G e101-006-0 | no | down | 1G 10G e101-007-0 | no | down | 1G 10G e101-008-0 | no | down | 1G 10G e101-009-0 | yes | up | 1G 10G e101-010-0 | no | down | 1G 10G e101-011-0 | no | down | 1G 10G e101-012-0 | yes | up | 1G 10G e101-013-0 | no | down | 100G e101-014-0 | no | down | 100G e101-015-0 | no | down | 100G eth0 | yes | UNKNOWN | UNKNOWN Configure LAG Configure LAG Algorithm You can see the switch's global paramters with the opx-show-global-switch command: root@OPX:~# opx-show-global-switch Switch id 0 ACL entry max priority: 2147483647 ACL entry min priority: 0 ACL table max priority: 11 ACL table min priority: 0 Bridge table size: 147456 BST enable: off BST tracking mode: current Counter refresh interval: 5 s Default mac address: 88:6f:d4:98:b7:80 ECMP group size: 256 ECMP hash algorithm: crc ECMP hash seed value: 0 Egress buffer pool num: 4 Ingress buffer pool num: 4 IPv6 extended prefix routes: 0 IPv6 extended prefix routes lpm block size: 1024 L3 nexthop table size: 32768 LAG hash algorithm: crc LAG hash seed value: 0 MAC address aging timer: 1800 s Max ECMP entries per group: 0 Max IPv6 extended prefix routes: 3072 Max MTU: 9216 Max VXLAN overlay nexthops: 4096 Max VXLAN overlay rifs: 2048 Number of multicast queues per port: 10 Number of queues cpu port: 43 Number of queues per port: 20 Number of unicast queues per port: 10 QoS rate adjust: 0 RIF table size: 12288 Switch mode: store and forward Temperature: 49 deg. C Total buffer size: 12188 UFT mode: default UFT host table size: 135168 UFT L2 mac table size: 147456 UFT L3 route table size: 16384 VXLAN riot enable: on If you want to change the hash algorithm you can do so with opx-config-global-switch --lag-hash-alg <crc | random | xor> I went ahead and left mine are CRC. This article from Dell can be helpful in deciding. Configure LAG Fields More imporantly you will probably want to configure what fields are used to determine the hash. The options are: src-mac: The source MAC address of the frame dest-mac: The destination MAC of the frame vlan-id: The VLAN ID listed in the frame ethertype: The ethertype of the frame ip-protocol: The IP protocol field in the IPv4 header src-ip: The packet source IP dest-ip: The destination IP of the packet l4-dest-port: The destination port of the segment l4-src-port: The source port of the segment in-port: The port from which the packet entered. It is unlikely you would want to use this for a reverse LAG I will use a standard 5-tuple configuration (src/dst IP, src/dest port, protocol #) Create LAG opx-config-lag create --name reverse_lag --unblockedports e101-005-0,e101-009-0,e101-012-0 --enable Results I wasn't able to complete the config. There is a bug in OPX preventing you from being able to set the fields on which the LAG will hash. I spent about a day working my way through the problem. See current status on this bug ticket","title":"Load Balancing with LAG OPX"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#load-balancing-with-lag-opx","text":"In this test case the goal is to create a simple packet broker using a reverse LAG port.","title":"Load Balancing with LAG OPX"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#helpful-links","text":"ONIE Network Install Process Overview OPX Install Instructions for Dell EMC Equipment OPX Tools Source Code OPX Command Reference OPX LAG Command Documenattion OPX Docs Home List of Supported Hardware","title":"Helpful Links"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#helpful-debug-commands","text":"cps_get_oid.py -qua target base-switch/switching-entities/switching-entity cps_model_info base-switch/switching-entities/switching-entity cps_set_oid.py -qua target base-switch/switching-entities/switching-entity name=lag-hash-fields attr=src-ip,dest-ip,l4-dest-port,l4-src-port,ip-protocol","title":"Helpful Debug Commands"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#my-configuration","text":"","title":"My Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OpenSwitch version PKGS_OPX-3.2.0-installer-x86_64 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#opx-version","text":"OS_NAME=\"OPX\" OS_VERSION=\"unstable\" PLATFORM=\"S4112F-ON\" ARCHITECTURE=\"x86_64\" INTERNAL_BUILD_ID=\"OpenSwitch blueprint for Dell 1.0.0\" BUILD_VERSION=\"unstable.0-stretch\" BUILD_DATE=\"2019-06-21T19:04:22+0000\" INSTALL_DATE=\"2019-10-23T23:16:10+00:00\" SYSTEM_UPTIME= 1 day, 5 minutes SYSTEM_STATE= running UPGRADED_PACKAGES=no ALTERED_PACKAGES=yes Wasn't sure why I got the unstable version after installation. It didn't cause any problems for testing so I just left it as is.","title":"OPX Version"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#configure-device-for-reverse-lag","text":"","title":"Configure Device for Reverse LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#physical-configuration","text":"I used the following SFPs 1, 1Gb/s copper SFP (e101-001-0) for input 2, 1Gb/s copper SFPs (e101-005-0/e101-009-0) and 1, 10Gb/s, fiber SFP (e101-012-0) for output","title":"Physical Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#input-port","text":"","title":"Input Port"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#output-ports","text":"","title":"Output Ports"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#lag-configuration","text":"","title":"LAG Configuration"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#enable-lag-ports-and-input-port","text":"root@OPX:~# ip link set e101-001-0 up root@OPX:~# ip link set e101-005-0 up root@OPX:~# ip link set e101-009-0 up root@OPX:~# ip link set e101-012-0 up root@OPX:~# opx-show-interface --summary Port | Enabled | Operational status | Supported speed ----------------------------------------------------------- e101-001-0 | yes | up | 1G 10G e101-002-0 | no | down | 1G 10G e101-003-0 | no | down | 1G 10G e101-004-0 | no | down | 1G 10G e101-005-0 | yes | up | 1G 10G e101-006-0 | no | down | 1G 10G e101-007-0 | no | down | 1G 10G e101-008-0 | no | down | 1G 10G e101-009-0 | yes | up | 1G 10G e101-010-0 | no | down | 1G 10G e101-011-0 | no | down | 1G 10G e101-012-0 | yes | up | 1G 10G e101-013-0 | no | down | 100G e101-014-0 | no | down | 100G e101-015-0 | no | down | 100G eth0 | yes | UNKNOWN | UNKNOWN","title":"Enable LAG Ports and Input Port"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#configure-lag","text":"","title":"Configure LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#configure-lag-algorithm","text":"You can see the switch's global paramters with the opx-show-global-switch command: root@OPX:~# opx-show-global-switch Switch id 0 ACL entry max priority: 2147483647 ACL entry min priority: 0 ACL table max priority: 11 ACL table min priority: 0 Bridge table size: 147456 BST enable: off BST tracking mode: current Counter refresh interval: 5 s Default mac address: 88:6f:d4:98:b7:80 ECMP group size: 256 ECMP hash algorithm: crc ECMP hash seed value: 0 Egress buffer pool num: 4 Ingress buffer pool num: 4 IPv6 extended prefix routes: 0 IPv6 extended prefix routes lpm block size: 1024 L3 nexthop table size: 32768 LAG hash algorithm: crc LAG hash seed value: 0 MAC address aging timer: 1800 s Max ECMP entries per group: 0 Max IPv6 extended prefix routes: 3072 Max MTU: 9216 Max VXLAN overlay nexthops: 4096 Max VXLAN overlay rifs: 2048 Number of multicast queues per port: 10 Number of queues cpu port: 43 Number of queues per port: 20 Number of unicast queues per port: 10 QoS rate adjust: 0 RIF table size: 12288 Switch mode: store and forward Temperature: 49 deg. C Total buffer size: 12188 UFT mode: default UFT host table size: 135168 UFT L2 mac table size: 147456 UFT L3 route table size: 16384 VXLAN riot enable: on If you want to change the hash algorithm you can do so with opx-config-global-switch --lag-hash-alg <crc | random | xor> I went ahead and left mine are CRC. This article from Dell can be helpful in deciding.","title":"Configure LAG Algorithm"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#configure-lag-fields","text":"More imporantly you will probably want to configure what fields are used to determine the hash. The options are: src-mac: The source MAC address of the frame dest-mac: The destination MAC of the frame vlan-id: The VLAN ID listed in the frame ethertype: The ethertype of the frame ip-protocol: The IP protocol field in the IPv4 header src-ip: The packet source IP dest-ip: The destination IP of the packet l4-dest-port: The destination port of the segment l4-src-port: The source port of the segment in-port: The port from which the packet entered. It is unlikely you would want to use this for a reverse LAG I will use a standard 5-tuple configuration (src/dst IP, src/dest port, protocol #)","title":"Configure LAG Fields"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#create-lag","text":"opx-config-lag create --name reverse_lag --unblockedports e101-005-0,e101-009-0,e101-012-0 --enable","title":"Create LAG"},{"location":"Load%20Balance%20Testing%20on%204112F-ON/OpenSwitch%20%28OPX%29/#results","text":"I wasn't able to complete the config. There is a bug in OPX preventing you from being able to set the fields on which the LAG will hash. I spent about a day working my way through the problem. See current status on this bug ticket","title":"Results"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/","text":"Load Balance Testing with OpenVSwitch From tutorial ovs-conntrack Testing performed on OS10 v Setup ip netns add left ip netns add right ip link add veth_l0 type veth peer name veth_l1 ip link set veth_l1 netns left ip link add veth_r0 type veth peer name veth_r1 ip link set veth_r1 netns right ovs-vsctl add-br br0 ip a s | less ovs-vsctl add-port br0 veth_l0 ovs-vsctl add-port br0 veth_r0 ip netns exec left sudo ip link set lo up ip netns exec right sudo ip link set lo up Generate TCP segments ip netns exec left sudo `which scapy` ip netns exec right sudo `which scapy` Matching TCP packets Simple flows for port to port ovs-ofctl add-flow br0 \"table=0, priority=10, in_port=veth_l0, actions=veth_r0\" ovs-ofctl add-flow br0 \"table=0, priority=10, in_port=veth_r0, actions=veth_l0\" Flow matching ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=-trk, tcp, in_port=veth_l0, actions=ct(table=0)\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=+trk+new, tcp, in_port=veth_l0, actions=ct(commit),veth_r0\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=-trk, tcp, in_port=veth_r0, actions=ct(table=0)\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=+trk+est, tcp, in_port=veth_r0, actions=veth_l0\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=+trk+est, tcp, in_port=veth_l0, actions=veth_r0\" End result You can do cool stuff, but it won't work/wouldn't be a great way to do this.","title":"Load Balance Testing with OpenVSwitch"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#load-balance-testing-with-openvswitch","text":"From tutorial ovs-conntrack Testing performed on OS10 v","title":"Load Balance Testing with OpenVSwitch"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#setup","text":"ip netns add left ip netns add right ip link add veth_l0 type veth peer name veth_l1 ip link set veth_l1 netns left ip link add veth_r0 type veth peer name veth_r1 ip link set veth_r1 netns right ovs-vsctl add-br br0 ip a s | less ovs-vsctl add-port br0 veth_l0 ovs-vsctl add-port br0 veth_r0 ip netns exec left sudo ip link set lo up ip netns exec right sudo ip link set lo up","title":"Setup"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#generate-tcp-segments","text":"ip netns exec left sudo `which scapy` ip netns exec right sudo `which scapy`","title":"Generate TCP segments"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#matching-tcp-packets","text":"","title":"Matching TCP packets"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#simple-flows-for-port-to-port","text":"ovs-ofctl add-flow br0 \"table=0, priority=10, in_port=veth_l0, actions=veth_r0\" ovs-ofctl add-flow br0 \"table=0, priority=10, in_port=veth_r0, actions=veth_l0\"","title":"Simple flows for port to port"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#flow-matching","text":"ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=-trk, tcp, in_port=veth_l0, actions=ct(table=0)\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=+trk+new, tcp, in_port=veth_l0, actions=ct(commit),veth_r0\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=-trk, tcp, in_port=veth_r0, actions=ct(table=0)\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=+trk+est, tcp, in_port=veth_r0, actions=veth_l0\" ovs-ofctl add-flow br0 \"table=0, priority=50, ct_state=+trk+est, tcp, in_port=veth_l0, actions=veth_r0\"","title":"Flow matching"},{"location":"Load%20Balance%20Testing%20with%20OpenVSwitch/#end-result","text":"You can do cool stuff, but it won't work/wouldn't be a great way to do this.","title":"End result"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/","text":"Load Balancing on Mellanox Switches In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors. Version Info mellanox.lan [standalone: master] # show version Product name: Onyx Product release: 3.8.2004 Build ID: #1-dev Build date: 2019-09-23 14:19:47 Target arch: x86_64 Target hw: x86_64 Built by: jenkins@7ae5fd122b61 Version summary: X86_64 3.8.2004 2019-09-23 14:19:47 x86_64 Product model: x86onie Host ID: B8599FD560BE System serial num: MT1940T00588 System UUID: 5f4c5ed2-e60b-11e9-8000-b8599f7f6f40 Uptime: 17h 27m 36.480s CPU load averages: 3.17 / 3.17 / 3.11 Number of CPUs: 4 System memory: 2738 MB used / 5065 MB free / 7803 MB total Swap: 0 MB used / 0 MB free / 0 MB total Connect to the Console Port and Management Ethernet Port Plug in both the management Ethernet cable and the serial cable. The console port is the bottom port and the ethernet management port is the top port. I had to plug the console cable into a specific USB slot on the server. It didn't work in the first one I tried. See picture below. This likely has nothing to do with the Mellanox switch itself, but as a note for those that come after you may want to try different USB ports if you find you aren't getting output on the first one you try and are confident you have the correct settings. I used the following console configuration: Baud Rate: 115200 Data Bits: 8 Stop Bits: 1 Parity: None Flow Control: None Update to Latest Version of MLNX-OS I pulled updates here The system uses a web server target for updates. I had Apache running on a RHEL 8 box. Download the update file and then upload it to your web server's root directory. On the switch itself (over a console port) do the following: switch > enable switch # configure terminal switch (config) # show images # Delete the old image if it exists. It will be under # \"Images available to be installed\" switch (config) # image delete <old_image> Download the new image from your web server with mellanox.lan [standalone: master] # image fetch http://rhel8.lan/onyx-X86_64-3.8.2004.img 100.0% [################################################################################################################################################################################################################################################################] Next install the updated OS with: mellanox.lan [standalone: master] # image install onyx-X86_64-3.8.2004.img location 2 progress track verify check-sig Step 1 of 4: Verify Image 100.0% [#################################################################] Step 2 of 4: Uncompress Image 100.0% [#################################################################] Step 3 of 4: Create Filesystems 100.0% [#################################################################] Step 4 of 4: Extract Image 98.6% [################################################################ ] 100.0% [#################################################################] Now set the switch to load from the new operating system and reload: mellanox.lan [standalone: master] # image boot next mellanox.lan [standalone: master] # reload Physical Configuration I used the following port configuration: 1, 1Gb/s copper SFP (Eth1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/9) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output I used the following optics: Connect the input port to port 1. I connected my output ports in the following way: Bringing the Interfaces Up Mellanox does not perform testing with 3rd party NICs. During testing we found that autonegotiation of speed will not work on standard Dell SFPs. Use the below command on each interface to set the speed manually: mellanox.lan [standalone: master] (config interface ethernet 1/1) # speed 1G Configure the LAG Initial Configuration mellanox.lan [standalone: master] (config) # port-channel load-balance ethernet source-destination-mac source-destination-ip source-destination-port symmetric mellanox.lan [standalone: master] (config) # interface port-channel 1 mellanox.lan [standalone: master] (config interface port-channel 1) # switchport mode hybrid mellanox.lan [standalone: master] (config interface port-channel 1) # description load balance group mellanox.lan [standalone: master] (config interface port-channel 1) # no shut mellanox.lan [standalone: master] (config interface port-channel 1) # mtu 9000 force mellanox.lan [standalone: master] (config interface port-channel 1) # exit mellanox.lan [standalone: master] (config) # interface ethernet 1/5 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/9 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/12 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/1 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/1 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/5 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/9 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/12 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/5 channel-group 1 mode on mellanox.lan [standalone: master] (config) # interface ethernet 1/9 channel-group 1 mode on mellanox.lan [standalone: master] (config) # interface ethernet 1/12 channel-group 1 mode on Problem Using Port Mirroring Originally my plan was to use a mirror port to send all the traffic from port 1 to our LAG interface. In contrast to OS10, MLNX-OS will not allow you to do this. The problem is that MLNX-OS will not allow you to create a mirror session from interface 1 to the LAG port which prevents this configuration from working. Moreover you cannot access the Linux command line to use a utility like tc to perform the config either. Configure OpenFlow Instead of using port mirroring to send the traffic from interface one we can instead use a static OpenFlow configuration to redirect the traffic. mellanox.lan [standalone: master] (config) # interface ethernet 1/1 openflow mode hybrid mellanox.lan [standalone: master] (config) # interface port-channel 1 openflow mode hybrid mellanox.lan [standalone: master] (config) # openflow add-flows 1000 priority=50,in_port=Eth1/1,actions=output:Po1 Findings The Mellanox SN2010 works correctly and will appropriately load balance full sessions across each member of the LAG. See below for screenshots. Host 1 Host 2 Host 3","title":"Load Balancing on Mellanox Switches"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#load-balancing-on-mellanox-switches","text":"In this test case the goal is to create a simple load balancer using a reverse LAG port. The idea is to have one input port which is then mirrored to a logical LAG port and at the other end of the LAG port is a number of security sensors.","title":"Load Balancing on Mellanox Switches"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#version-info","text":"mellanox.lan [standalone: master] # show version Product name: Onyx Product release: 3.8.2004 Build ID: #1-dev Build date: 2019-09-23 14:19:47 Target arch: x86_64 Target hw: x86_64 Built by: jenkins@7ae5fd122b61 Version summary: X86_64 3.8.2004 2019-09-23 14:19:47 x86_64 Product model: x86onie Host ID: B8599FD560BE System serial num: MT1940T00588 System UUID: 5f4c5ed2-e60b-11e9-8000-b8599f7f6f40 Uptime: 17h 27m 36.480s CPU load averages: 3.17 / 3.17 / 3.11 Number of CPUs: 4 System memory: 2738 MB used / 5065 MB free / 7803 MB total Swap: 0 MB used / 0 MB free / 0 MB total","title":"Version Info"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#connect-to-the-console-port-and-management-ethernet-port","text":"Plug in both the management Ethernet cable and the serial cable. The console port is the bottom port and the ethernet management port is the top port. I had to plug the console cable into a specific USB slot on the server. It didn't work in the first one I tried. See picture below. This likely has nothing to do with the Mellanox switch itself, but as a note for those that come after you may want to try different USB ports if you find you aren't getting output on the first one you try and are confident you have the correct settings. I used the following console configuration: Baud Rate: 115200 Data Bits: 8 Stop Bits: 1 Parity: None Flow Control: None","title":"Connect to the Console Port and Management Ethernet Port"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#update-to-latest-version-of-mlnx-os","text":"I pulled updates here The system uses a web server target for updates. I had Apache running on a RHEL 8 box. Download the update file and then upload it to your web server's root directory. On the switch itself (over a console port) do the following: switch > enable switch # configure terminal switch (config) # show images # Delete the old image if it exists. It will be under # \"Images available to be installed\" switch (config) # image delete <old_image> Download the new image from your web server with mellanox.lan [standalone: master] # image fetch http://rhel8.lan/onyx-X86_64-3.8.2004.img 100.0% [################################################################################################################################################################################################################################################################] Next install the updated OS with: mellanox.lan [standalone: master] # image install onyx-X86_64-3.8.2004.img location 2 progress track verify check-sig Step 1 of 4: Verify Image 100.0% [#################################################################] Step 2 of 4: Uncompress Image 100.0% [#################################################################] Step 3 of 4: Create Filesystems 100.0% [#################################################################] Step 4 of 4: Extract Image 98.6% [################################################################ ] 100.0% [#################################################################] Now set the switch to load from the new operating system and reload: mellanox.lan [standalone: master] # image boot next mellanox.lan [standalone: master] # reload","title":"Update to Latest Version of MLNX-OS"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#physical-configuration","text":"I used the following port configuration: 1, 1Gb/s copper SFP (Eth1/1) for input 2, 1Gb/s copper SFPs (Ethernet 1/1/5/Ethernet 1/1/9) and 1, 1Gb/s, fiber SFP (Ethernet 1/1/12) for output I used the following optics: Connect the input port to port 1. I connected my output ports in the following way:","title":"Physical Configuration"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#bringing-the-interfaces-up","text":"Mellanox does not perform testing with 3rd party NICs. During testing we found that autonegotiation of speed will not work on standard Dell SFPs. Use the below command on each interface to set the speed manually: mellanox.lan [standalone: master] (config interface ethernet 1/1) # speed 1G","title":"Bringing the Interfaces Up"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#configure-the-lag","text":"","title":"Configure the LAG"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#initial-configuration","text":"mellanox.lan [standalone: master] (config) # port-channel load-balance ethernet source-destination-mac source-destination-ip source-destination-port symmetric mellanox.lan [standalone: master] (config) # interface port-channel 1 mellanox.lan [standalone: master] (config interface port-channel 1) # switchport mode hybrid mellanox.lan [standalone: master] (config interface port-channel 1) # description load balance group mellanox.lan [standalone: master] (config interface port-channel 1) # no shut mellanox.lan [standalone: master] (config interface port-channel 1) # mtu 9000 force mellanox.lan [standalone: master] (config interface port-channel 1) # exit mellanox.lan [standalone: master] (config) # interface ethernet 1/5 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/9 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/12 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/1 switchport mode hybrid mellanox.lan [standalone: master] (config) # interface ethernet 1/1 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/5 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/9 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/12 mtu 9000 force mellanox.lan [standalone: master] (config) # interface ethernet 1/5 channel-group 1 mode on mellanox.lan [standalone: master] (config) # interface ethernet 1/9 channel-group 1 mode on mellanox.lan [standalone: master] (config) # interface ethernet 1/12 channel-group 1 mode on","title":"Initial Configuration"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#problem-using-port-mirroring","text":"Originally my plan was to use a mirror port to send all the traffic from port 1 to our LAG interface. In contrast to OS10, MLNX-OS will not allow you to do this. The problem is that MLNX-OS will not allow you to create a mirror session from interface 1 to the LAG port which prevents this configuration from working. Moreover you cannot access the Linux command line to use a utility like tc to perform the config either.","title":"Problem Using Port Mirroring"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#configure-openflow","text":"Instead of using port mirroring to send the traffic from interface one we can instead use a static OpenFlow configuration to redirect the traffic. mellanox.lan [standalone: master] (config) # interface ethernet 1/1 openflow mode hybrid mellanox.lan [standalone: master] (config) # interface port-channel 1 openflow mode hybrid mellanox.lan [standalone: master] (config) # openflow add-flows 1000 priority=50,in_port=Eth1/1,actions=output:Po1","title":"Configure OpenFlow"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#findings","text":"The Mellanox SN2010 works correctly and will appropriately load balance full sessions across each member of the LAG. See below for screenshots.","title":"Findings"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#host-1","text":"","title":"Host 1"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#host-2","text":"","title":"Host 2"},{"location":"Load%20Balancing%20on%20Mellanox%20Switches/#host-3","text":"","title":"Host 3"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/","text":"Load Balancing with LAG on 5112F-ON Load Balancing with LAG on 5112F-ON Version/Hardware Information The Test Environment Configure Devices Configure 5212F-ON Configure RHEL 8 Test Results Version/Hardware Information Note This requires at least 10.5.3.0 and is only supported on switches with the Trident proc OS10(config)# do show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2021 by Dell Inc. All Rights Reserved. OS Version: 10.5.3.0 Build Version: 10.5.3.0.44 Build Time: 2021-10-06T23:03:55+0000 System Type: S5212F-ON Architecture: x86_64 Up Time: 00:03:27 The Test Environment I used a RHEL box to generate traffic inbound to the switch on port ethernet 1/1/5:1 which I then expected to load balance across ports ethernet 1/1/1:1 and 1/1/4:1. I used source and dest IP and source and dest port as the criteria for load balancing. Traffic was captured with a single laptop which was directly connected to the two independent receiving interfaces. A single Wireshark monitor session was established for each of the individual interfaces to ensure that they received independent, mutually-exclusive, session load balancing. The traffic was a session I generated by using a laptop that was serving as a virtual web gateway along with being used as an end user device. Configure Devices Configure 5212F-ON configure terminal load-balancing ip-selection source-ip destination-ip l4-destination-port l4-source-port port-group 1/1/1 mode eth 10g-4x interface port-channel 1 no shutdown no switchport exit interface ethernet 1/1/1:1 no shut channel-group 1 speed 1000 exit interface ethernet 1/1/4:1 no shut channel-group 1 speed 1000 exit monitor session 1 destination interface port-channel 1 source interface ethernet 1/1/5:1 no shut exit Your listening source captures traffic be that a tap, span, Linux host, etc Traffic is pushed into a physical interface (ethernet 1/1/5:1) on the 5212 Traffic is mirrored from the physical interface (Ethernet 1/1/5:1) to the virtual port group interface The port group interface is tied to two physical interfaces and set to perform load balancing The virtual port group interface will load balance based on a hash of the aforementioned attributes (ip-selection source-ip destination-ip l4-destination-port l4-source-port) Configure RHEL 8 sudo dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm sudo subscription-manager repos --enable codeready-builder-for-rhel-8-x86_64-rpms dnf group install \"Development Tools\" dnf install -y libpcap-devel make make install /usr/local/bin/tcpreplay -i ens32 test.pcap Test Results The test succeeded. This was verified by checking that the sessions seen by two separate streams were mutually exclusive. At no point did we see effects as described in 4112F-ON Test Case 4 where a single session was sent down two separate lanes. Moreover, by checking the individual sessions you can see the bidirectional flow:","title":"Load Balancing with LAG on 5112F-ON"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#load-balancing-with-lag-on-5112f-on","text":"Load Balancing with LAG on 5112F-ON Version/Hardware Information The Test Environment Configure Devices Configure 5212F-ON Configure RHEL 8 Test Results","title":"Load Balancing with LAG on 5112F-ON"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#versionhardware-information","text":"Note This requires at least 10.5.3.0 and is only supported on switches with the Trident proc OS10(config)# do show version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2021 by Dell Inc. All Rights Reserved. OS Version: 10.5.3.0 Build Version: 10.5.3.0.44 Build Time: 2021-10-06T23:03:55+0000 System Type: S5212F-ON Architecture: x86_64 Up Time: 00:03:27","title":"Version/Hardware Information"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#the-test-environment","text":"I used a RHEL box to generate traffic inbound to the switch on port ethernet 1/1/5:1 which I then expected to load balance across ports ethernet 1/1/1:1 and 1/1/4:1. I used source and dest IP and source and dest port as the criteria for load balancing. Traffic was captured with a single laptop which was directly connected to the two independent receiving interfaces. A single Wireshark monitor session was established for each of the individual interfaces to ensure that they received independent, mutually-exclusive, session load balancing. The traffic was a session I generated by using a laptop that was serving as a virtual web gateway along with being used as an end user device.","title":"The Test Environment"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#configure-devices","text":"","title":"Configure Devices"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#configure-5212f-on","text":"configure terminal load-balancing ip-selection source-ip destination-ip l4-destination-port l4-source-port port-group 1/1/1 mode eth 10g-4x interface port-channel 1 no shutdown no switchport exit interface ethernet 1/1/1:1 no shut channel-group 1 speed 1000 exit interface ethernet 1/1/4:1 no shut channel-group 1 speed 1000 exit monitor session 1 destination interface port-channel 1 source interface ethernet 1/1/5:1 no shut exit Your listening source captures traffic be that a tap, span, Linux host, etc Traffic is pushed into a physical interface (ethernet 1/1/5:1) on the 5212 Traffic is mirrored from the physical interface (Ethernet 1/1/5:1) to the virtual port group interface The port group interface is tied to two physical interfaces and set to perform load balancing The virtual port group interface will load balance based on a hash of the aforementioned attributes (ip-selection source-ip destination-ip l4-destination-port l4-source-port)","title":"Configure 5212F-ON"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#configure-rhel-8","text":"sudo dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm sudo subscription-manager repos --enable codeready-builder-for-rhel-8-x86_64-rpms dnf group install \"Development Tools\" dnf install -y libpcap-devel make make install /usr/local/bin/tcpreplay -i ens32 test.pcap","title":"Configure RHEL 8"},{"location":"Load%20Balancing%20with%20LAG%20on%205112F-ON/#test-results","text":"The test succeeded. This was verified by checking that the sessions seen by two separate streams were mutually exclusive. At no point did we see effects as described in 4112F-ON Test Case 4 where a single session was sent down two separate lanes. Moreover, by checking the individual sessions you can see the bidirectional flow:","title":"Test Results"},{"location":"Make%20USB%20Read%20Only/","text":"Make USB Read Only Note : These instructions are for a UEFI bootable device with an ext4 filesystem Boot up a separate Linux machine and plug in the USB device you would like to make readonly Run sudo fdisk -l to list the available partitions 1.Confirm you have not built the device with a swap partition grant@telemetrytest:/media$ sudo fdisk -l ...SNIP.. Disk /dev/sdb: 57.29 GiB, 61505273856 bytes, 120127488 sectors Disk model: Ultra Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: C02A7A30-1742-47CE-9DFB-5B3AB96C958C Device Start End Sectors Size Type /dev/sdb1 2048 1050623 1048576 512M EFI System /dev/sdb2 1050624 118126591 117075968 55.8G Linux filesystem The first thing we need to do is get the uuid for the EFI partition. Run sudo blkid /dev/<YOUR_EFI_PARTITION> , in my case /dev/sdb1 grant@telemetrytest:/media$ sudo blkid /dev/sdb1 /dev/sdb1: UUID=\"CD68-8FEA\" TYPE=\"vfat\" PARTUUID=\"d27eda17-c6df-4115-80f3-bd86b56882ac\" Next, we need to edit the base filesystem's fstab to make sure that when this filesystem loads, it will load as readonly. Mount your ext4 filesystem with sudo mount /dev/<YOUR_PARTITION> <YOUR_MOUNT_POINT> . Ex: sudo mount /dev/sdb2 /media . Next, we need to edit fstab. sudo vim /media/etc/fstab # /etc/fstab: static file system information. # # Use 'blkid' to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # systemd generates mount units based on this file, see systemd.mount(5). # Please run 'systemctl daemon-reload' after making changes here. # # <file system> <mount point> <type> <options> <dump> <pass> # / was on /dev/sdb2 during installation UUID=6634741f-250a-47b7-96b9-379e517d4591 / ext4 errors=remount-ro 0 1 # /boot/efi was on /dev/sdb1 during installation UUID=CD68-8FEA /boot/efi vfat umask=0077 0 1 # swap was on /dev/sdb3 during installation UUID=4391d5d0-08cb-4fbe-81a8-0a67fe00758c none swap sw 0 0 /dev/sr0 /media/cdrom0 udf,iso9660 user,noauto 0 0 Look for the mount point /boot/efi and confirm that its UUID matches what you saw earlier. Change the options from UUID=CD68-8FEA /boot/efi vfat umask=0077 0 1 to UUID=CD68-8FEA /boot/efi vfat umask=0077,ro 0 1 Next we need to set the primary ext4 partition as read-only. Run sudo umount <YOUR_MOUNT> . Ex: sudo umount /media Set the ext4 filesystem as read only with sudo tune2fs -O read-only /dev/<YOUR_PARTITION> . Ex: sudo tune2fs -O read-only /dev/sdb2 Disconnect the USB drive, boot from it, and confirm read-only behavior.","title":"Make USB Read Only"},{"location":"Make%20USB%20Read%20Only/#make-usb-read-only","text":"Note : These instructions are for a UEFI bootable device with an ext4 filesystem Boot up a separate Linux machine and plug in the USB device you would like to make readonly Run sudo fdisk -l to list the available partitions 1.Confirm you have not built the device with a swap partition grant@telemetrytest:/media$ sudo fdisk -l ...SNIP.. Disk /dev/sdb: 57.29 GiB, 61505273856 bytes, 120127488 sectors Disk model: Ultra Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: C02A7A30-1742-47CE-9DFB-5B3AB96C958C Device Start End Sectors Size Type /dev/sdb1 2048 1050623 1048576 512M EFI System /dev/sdb2 1050624 118126591 117075968 55.8G Linux filesystem The first thing we need to do is get the uuid for the EFI partition. Run sudo blkid /dev/<YOUR_EFI_PARTITION> , in my case /dev/sdb1 grant@telemetrytest:/media$ sudo blkid /dev/sdb1 /dev/sdb1: UUID=\"CD68-8FEA\" TYPE=\"vfat\" PARTUUID=\"d27eda17-c6df-4115-80f3-bd86b56882ac\" Next, we need to edit the base filesystem's fstab to make sure that when this filesystem loads, it will load as readonly. Mount your ext4 filesystem with sudo mount /dev/<YOUR_PARTITION> <YOUR_MOUNT_POINT> . Ex: sudo mount /dev/sdb2 /media . Next, we need to edit fstab. sudo vim /media/etc/fstab # /etc/fstab: static file system information. # # Use 'blkid' to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # systemd generates mount units based on this file, see systemd.mount(5). # Please run 'systemctl daemon-reload' after making changes here. # # <file system> <mount point> <type> <options> <dump> <pass> # / was on /dev/sdb2 during installation UUID=6634741f-250a-47b7-96b9-379e517d4591 / ext4 errors=remount-ro 0 1 # /boot/efi was on /dev/sdb1 during installation UUID=CD68-8FEA /boot/efi vfat umask=0077 0 1 # swap was on /dev/sdb3 during installation UUID=4391d5d0-08cb-4fbe-81a8-0a67fe00758c none swap sw 0 0 /dev/sr0 /media/cdrom0 udf,iso9660 user,noauto 0 0 Look for the mount point /boot/efi and confirm that its UUID matches what you saw earlier. Change the options from UUID=CD68-8FEA /boot/efi vfat umask=0077 0 1 to UUID=CD68-8FEA /boot/efi vfat umask=0077,ro 0 1 Next we need to set the primary ext4 partition as read-only. Run sudo umount <YOUR_MOUNT> . Ex: sudo umount /media Set the ext4 filesystem as read only with sudo tune2fs -O read-only /dev/<YOUR_PARTITION> . Ex: sudo tune2fs -O read-only /dev/sdb2 Disconnect the USB drive, boot from it, and confirm read-only behavior.","title":"Make USB Read Only"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/","text":"Migrating Storage Volumes to PowerStore In my scenario I wanted to migrate storage from a Compellent attached with FC to a PowerStore attached to an MX7000 with an M9116n. Note: This is only relevant for older devices in a FC or iSCSI configuration. For NAS you would use any NAS migration technique (rsync, DobiMigrate, etc) Migrating Storage Volumes to PowerStore MX7000 FC Topology Migrating from an Old Device Other Useful Resources PowerStore Educational Videos Operating Systems Compatible with Multipath Drivers Requirements for Non-Disruptive Migration M9116n Compatibility Matrix MX7000 FC Topology Migrating from an Old Device This video describes how the migration from an old device (like a Compellent) to a PowerStore works. In general, on all effected devices, you must install a host plugin which comes with a multipath driver. Before the migration is complete, the host driver will direct all reads/writes to the old device and post migration you will use a cutover option which causes the reads/writes to be redirected to the PowerStore. There is an iSCSI connection between the PowerStore and the compellent which has a synchronization feature that will keep any updates made against the Compellent (or other older device) synced to the in progress copy to the PowerStore Other Useful Resources PowerStore Educational Videos https://www.dell.com/support/kbdoc/en-us/000130110/powerstore-info-hub-product-documentation-videos Operating Systems Compatible with Multipath Drivers https://www.dell.com/support/kbdoc/en-us/000105896/powerstore-supported-host-os-for-non-disruptive-migration-of-storage-resources?lang=en Requirements for Non-Disruptive Migration https://www.dell.com/support/manuals/en-us/powerstore-1000t/pwrstr-import/additional-resources?guid=guid-f5b0a9d3-2eae-447c-b4c3-40e0927ac5f4&lang=en-us M9116n Compatibility Matrix","title":"Migrating Storage Volumes to PowerStore"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#migrating-storage-volumes-to-powerstore","text":"In my scenario I wanted to migrate storage from a Compellent attached with FC to a PowerStore attached to an MX7000 with an M9116n. Note: This is only relevant for older devices in a FC or iSCSI configuration. For NAS you would use any NAS migration technique (rsync, DobiMigrate, etc) Migrating Storage Volumes to PowerStore MX7000 FC Topology Migrating from an Old Device Other Useful Resources PowerStore Educational Videos Operating Systems Compatible with Multipath Drivers Requirements for Non-Disruptive Migration M9116n Compatibility Matrix","title":"Migrating Storage Volumes to PowerStore"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#mx7000-fc-topology","text":"","title":"MX7000 FC Topology"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#migrating-from-an-old-device","text":"This video describes how the migration from an old device (like a Compellent) to a PowerStore works. In general, on all effected devices, you must install a host plugin which comes with a multipath driver. Before the migration is complete, the host driver will direct all reads/writes to the old device and post migration you will use a cutover option which causes the reads/writes to be redirected to the PowerStore. There is an iSCSI connection between the PowerStore and the compellent which has a synchronization feature that will keep any updates made against the Compellent (or other older device) synced to the in progress copy to the PowerStore","title":"Migrating from an Old Device"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#other-useful-resources","text":"","title":"Other Useful Resources"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#powerstore-educational-videos","text":"https://www.dell.com/support/kbdoc/en-us/000130110/powerstore-info-hub-product-documentation-videos","title":"PowerStore Educational Videos"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#operating-systems-compatible-with-multipath-drivers","text":"https://www.dell.com/support/kbdoc/en-us/000105896/powerstore-supported-host-os-for-non-disruptive-migration-of-storage-resources?lang=en","title":"Operating Systems Compatible with Multipath Drivers"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#requirements-for-non-disruptive-migration","text":"https://www.dell.com/support/manuals/en-us/powerstore-1000t/pwrstr-import/additional-resources?guid=guid-f5b0a9d3-2eae-447c-b4c3-40e0927ac5f4&lang=en-us","title":"Requirements for Non-Disruptive Migration"},{"location":"Migrating%20Storage%20Volumes%20to%20PowerStore/#m9116n-compatibility-matrix","text":"","title":"M9116n Compatibility Matrix"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/","text":"Mulitple Span on 4112F-ON with OpenSwitch In this test case I am testing to see if we can configure a Dell 4112F-ON with OpenSwitch to create a one to many port configuration using SPAN. Helpful Links ONIE Network Install Process Overview OPX Install Instructions for Dell EMC Equipment OPX Tools Source Code OPX Command Reference OPX Docs Home List of Supported Hardware My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OpenSwitch version PKGS_OPX-3.2.0-installer-x86_64 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OPX Version OS_NAME=\"OPX\" OS_VERSION=\"unstable\" PLATFORM=\"S4112F-ON\" ARCHITECTURE=\"x86_64\" INTERNAL_BUILD_ID=\"OpenSwitch blueprint for Dell 1.0.0\" BUILD_VERSION=\"unstable.0-stretch\" BUILD_DATE=\"2019-06-21T19:04:22+0000\" INSTALL_DATE=\"2019-10-23T23:16:10+00:00\" SYSTEM_UPTIME= 1 day, 5 minutes SYSTEM_STATE= running UPGRADED_PACKAGES=no ALTERED_PACKAGES=yes Wasn't sure why I got the unstable version after installation. It didn't cause any problems for testing so I just left it as is. Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Device as TAP Physical Configuration For this configuration to work, we will use the management interface as the input interface for the tap. See image below. You will need to move your network cable over from your usual network to your traffic generator. Configure Management Interface (Optional) Update: After I got it working I ended up using this as an ingress interface so this step is more or less optional. You won't be able to SSH into this interface in the end config (at least not easily). Start by running sudo -i to move to privileged mode. Warning: I noticed the OPX command line tools won't behave correctly unless you are privileged. Ex: opx-show-interface won't list any interfaces. I added vim to my box before continuing with sudo apt-get install -y vim The management interface is configured like a typicaly Debian interface with vim /etc/network/interface.d/eth0 Use the following configuration modified to your needs: auto eth0 allow-hotplug eth0 iface eth0 inet static address 192.168.1.20 netmask 255.255.255.0 gateway 192.168.1.1 When you are finished with your configuration run systemctl restart networking to apply the changes. Confirm the changes were applied with ip address show dev eth0 . If you see two IP addresses because you picked one up from DHCP you can delete the other with ip address del [IP ADDRESS] dev eth0 and then run systemctl restart networking At this juncture your management interface should be up and running and you should be able to SSH to it. I went ahead and swapped to SSH so as not to deal with the oddities that come with running in the console port. Bridge/tc Configuration After attempt 3 I started thinking about other ways to connect things. Realized I could just pump everything to a bridge and let that do the replication. That worked! Do the following to get it up and running: tc is a feature of modern Linux kernels designed for mirroring traffic. I found this article helpful. This Mellanox article was also useful. WARNING: You must use your management interface for the ingress port or this solution will not work! I noticed the other ports do not behave like normal Linux ports. More investigation required to figure out the difference. Create a bridge interface with brctl addbr br0 Attach all interfaces you want as part of the port mirroring to the bridge with brctl addif br0 < INTERFACE > 1.Make sure all interfaces in use are enabled with ip link set < INTERFACE > up Disable MAC address learning on the bridge with brctl setageing br0 0 Set the device's management interface to promiscuous mode with ip link set < MGMT_INTERFACE > promisc on The first thing I did was create an ingress queue on my input interface with tc qdisc add dev < MGMT_INTERFACE > handle ffff: ingress 1.If you need to delete a qdisc you can do it with tc qdisc del dev < MGMT_INTERFACE > [ root | ingress ] Double check your queue with handle ffff was created with tc -s qdisc ls dev < MGMT_INTERFACE > Next we want to mirror all traffic from the ingress port to an output port with tc filter add dev < MGMT_INTERFACE > parent ffff: protocol all u32 match u32 0 0 action mirred egress mirror dev br0 Check that your port mirror appeared in the config with tc -s -p filter ls dev < MGMT_INTERFACE > parent ffff: 1.If you need to delete the filters you can do so with tc filter del dev < MGMT_INTERFACE > parent ffff: Set queue to not shape traffic with tc qdisc add dev < MGMT_INTERFACE > handle 1: root prio Things I Tried I added 7 interfaces to my bridge to make sure there weren't any strange limitations I moved the SFPs around to multiple different ports to make sure the traffic was mirroing on all of them I double checked the traffic I was capturing belonged to the PCAP in question. Easy enough to see because it has IP addresses the hosts in question wouldn't ever otherwise see. Screenshots for confirmation below. Host 1 Host 2 - I checked that pure L3 traffic was passed correctly using ICMP. Noted Problem The only major issue I noticed is that pure layer 2 traffic didn't get passed. Haven't figured out how to fix that yet. Failed Ideas Attempt 1 - Mirror Ports My first go is to try using OpenSwitch's built in mirroring capability. Physical Configuration I didn't have enough target hosts to try outputting from one port to all ports so I simulated it. The purple cable in the image is the input port from the traffic generator (tcpreplay) and the white and yellow cables go out to the hosts listed as host 1 and host 2 in the test results section. The ports with the white and yellow cables were configured as the mirror's target ports. Mirror Configuration For each port you want to mirror to run opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-005-0 --direction ingress --type span . Substitute your source and destination ports appropriately. Results Mirror Port Failure After 4 I was only able to get this to work on up to 4 ports. After that I received errors. See output below: root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-005-0 --direction ingress --type span root@OPX:~# ip link set e101-009-0 up root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-009-0 --direction ingress --type span root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-002-0 --direction ingress --type span root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-003-0 --direction ingress --type span root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-004-0 --direction ingress --type span {'data': {'base-mirror/entry/dst-intf': bytearray(b'\\x0f\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b'\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': {'0': {'base-mirror/entry/intf/src': bytearray(b'\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b'\\x01\\x00\\x00\\x00')}}}, 'key': '1.27.1769488.1769473.'} opx-config-mirror: Commit failed root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-006-0 --direction ingress --type span {'data': {'base-mirror/entry/dst-intf': bytearray(b'\\x11\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b'\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': {'0': {'base-mirror/entry/intf/src': bytearray(b'\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b'\\x01\\x00\\x00\\x00')}}}, 'key': '1.27.1769488.1769473.'} opx-config-mirror: Commit failed root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-007-0 --direction ingress --type span {'data': {'base-mirror/entry/dst-intf': bytearray(b'\\x12\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b'\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': {'0': {'base-mirror/entry/intf/src': bytearray(b'\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b'\\x01\\x00\\x00\\x00')}}}, 'key': '1.27.1769488.1769473.'} opx-config-mirror: Commit failed Pretty printed version for ease of reading: { 'data': { 'base-mirror/entry/dst-intf': bytearray(b '\\x12\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b '\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': { '0': { 'base-mirror/entry/intf/src': bytearray(b '\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b '\\x01\\x00\\x00\\x00') } } }, 'key': '1.27.1769488.1769473.' } Functioning Mirror Ports Before I caught the error, I did test the first two mirror ports I made and they worked as expected. See the below. I used tcpreplay with some traffic I captured on my desktop to test the idea. I just uploaded the PCAP and replayed it with tcpreplay -i ens224 ./test_pcap.pcap --loop 500 I then confirmed that all target ports received traffic. See screenshots below: Host 1 Host 2 The host I collected the traffic on was 192.168.1.6 and as you can see from the images both hosts were able to see traffic from the tcpreplay session. Attempt 2 - tc Configuration tc is a feature of modern Linux kernels designed for mirroring traffic. I found this article helpful. This Mellanox article was also useful. The first thing I did was create an ingress queue on my input interface with tc qdisc add dev e101-001-0 handle ffff: ingress 1.If you need to delete a qdisc you can do it with tc qdisc del dev e101-001-0 [ root | ingress ] Double check your queue with handle ffff was created with tc -s qdisc ls dev e101-001-0 Next we want to mirror all traffic from the ingress port to an output port with tc filter add dev e101-001-0 parent ffff: protocol all u32 match u32 0 0 action mirred egress mirror dev e101-005-0 Check that your port mirror appeared in the config with tc -s -p filter ls dev e101-001-0 parent ffff: 1.If you need to delete the filters you can do so with tc filter del dev e101-001-0 parent ffff: Set queue to not shape traffic with tc qdisc add dev e101-001-0 handle 1: root prio Alternate Configuration I tried instead running: tc qdisc add dev e101-001-0 clsact tc filter add dev e101-001-0 ingress matchall skip_sw action mirred egress mirror dev e101-005-0 Other Things Tried Haven't been able to figure out why just yet, but only Layer 2 traffic is making it through the port mirror. Everything above gets dropped. I thought maybe it was MAC address learning, but the problem persisted when I ran opx-config-global-switch --mac-age-time 0 I also thought that it was the port not being set to promiscuous mode so I gave it ifconfig e101-001-0 promisc . That didn't work either. Conclusions I'm pretty confident that because this is a network OS for switching something funky is going on. Ex: When you run a port mirror, all the traffic passes correctly, but you won't see any of that traffic on a tcpdump session. Need to study up on the architecture. I'm pretty sure there's a way to make this particular tactic work, but for time's sake I'm going to try something else. Attempt 3 - tc on Management Interface I realized something is going on with the forwarding tables on the switch at a low level that was intercepting our traffic in attempt 2. That said, I noticed that the management interface for the switch effectively works like a standard Linux interface. I did the same thing I did in attempt 2 except I used the managament interface instead of one of the other interfaces. Results The switch accepts the config. However, the traffic only goes out to one port at a time.","title":"Mulitple Span on 4112F-ON with OpenSwitch"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#mulitple-span-on-4112f-on-with-openswitch","text":"In this test case I am testing to see if we can configure a Dell 4112F-ON with OpenSwitch to create a one to many port configuration using SPAN.","title":"Mulitple Span on 4112F-ON with OpenSwitch"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#helpful-links","text":"ONIE Network Install Process Overview OPX Install Instructions for Dell EMC Equipment OPX Tools Source Code OPX Command Reference OPX Docs Home List of Supported Hardware","title":"Helpful Links"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#my-configuration","text":"","title":"My Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OpenSwitch version PKGS_OPX-3.2.0-installer-x86_64 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#opx-version","text":"OS_NAME=\"OPX\" OS_VERSION=\"unstable\" PLATFORM=\"S4112F-ON\" ARCHITECTURE=\"x86_64\" INTERNAL_BUILD_ID=\"OpenSwitch blueprint for Dell 1.0.0\" BUILD_VERSION=\"unstable.0-stretch\" BUILD_DATE=\"2019-06-21T19:04:22+0000\" INSTALL_DATE=\"2019-10-23T23:16:10+00:00\" SYSTEM_UPTIME= 1 day, 5 minutes SYSTEM_STATE= running UPGRADED_PACKAGES=no ALTERED_PACKAGES=yes Wasn't sure why I got the unstable version after installation. It didn't cause any problems for testing so I just left it as is.","title":"OPX Version"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#configure-device-as-tap","text":"","title":"Configure Device as TAP"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#physical-configuration","text":"For this configuration to work, we will use the management interface as the input interface for the tap. See image below. You will need to move your network cable over from your usual network to your traffic generator.","title":"Physical Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#configure-management-interface-optional","text":"Update: After I got it working I ended up using this as an ingress interface so this step is more or less optional. You won't be able to SSH into this interface in the end config (at least not easily). Start by running sudo -i to move to privileged mode. Warning: I noticed the OPX command line tools won't behave correctly unless you are privileged. Ex: opx-show-interface won't list any interfaces. I added vim to my box before continuing with sudo apt-get install -y vim The management interface is configured like a typicaly Debian interface with vim /etc/network/interface.d/eth0 Use the following configuration modified to your needs: auto eth0 allow-hotplug eth0 iface eth0 inet static address 192.168.1.20 netmask 255.255.255.0 gateway 192.168.1.1 When you are finished with your configuration run systemctl restart networking to apply the changes. Confirm the changes were applied with ip address show dev eth0 . If you see two IP addresses because you picked one up from DHCP you can delete the other with ip address del [IP ADDRESS] dev eth0 and then run systemctl restart networking At this juncture your management interface should be up and running and you should be able to SSH to it. I went ahead and swapped to SSH so as not to deal with the oddities that come with running in the console port.","title":"Configure Management Interface (Optional)"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#bridgetc-configuration","text":"After attempt 3 I started thinking about other ways to connect things. Realized I could just pump everything to a bridge and let that do the replication. That worked! Do the following to get it up and running: tc is a feature of modern Linux kernels designed for mirroring traffic. I found this article helpful. This Mellanox article was also useful. WARNING: You must use your management interface for the ingress port or this solution will not work! I noticed the other ports do not behave like normal Linux ports. More investigation required to figure out the difference. Create a bridge interface with brctl addbr br0 Attach all interfaces you want as part of the port mirroring to the bridge with brctl addif br0 < INTERFACE > 1.Make sure all interfaces in use are enabled with ip link set < INTERFACE > up Disable MAC address learning on the bridge with brctl setageing br0 0 Set the device's management interface to promiscuous mode with ip link set < MGMT_INTERFACE > promisc on The first thing I did was create an ingress queue on my input interface with tc qdisc add dev < MGMT_INTERFACE > handle ffff: ingress 1.If you need to delete a qdisc you can do it with tc qdisc del dev < MGMT_INTERFACE > [ root | ingress ] Double check your queue with handle ffff was created with tc -s qdisc ls dev < MGMT_INTERFACE > Next we want to mirror all traffic from the ingress port to an output port with tc filter add dev < MGMT_INTERFACE > parent ffff: protocol all u32 match u32 0 0 action mirred egress mirror dev br0 Check that your port mirror appeared in the config with tc -s -p filter ls dev < MGMT_INTERFACE > parent ffff: 1.If you need to delete the filters you can do so with tc filter del dev < MGMT_INTERFACE > parent ffff: Set queue to not shape traffic with tc qdisc add dev < MGMT_INTERFACE > handle 1: root prio","title":"Bridge/tc Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#things-i-tried","text":"I added 7 interfaces to my bridge to make sure there weren't any strange limitations I moved the SFPs around to multiple different ports to make sure the traffic was mirroing on all of them I double checked the traffic I was capturing belonged to the PCAP in question. Easy enough to see because it has IP addresses the hosts in question wouldn't ever otherwise see. Screenshots for confirmation below.","title":"Things I Tried"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#host-1","text":"","title":"Host 1"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#host-2","text":"- I checked that pure L3 traffic was passed correctly using ICMP.","title":"Host 2"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#noted-problem","text":"The only major issue I noticed is that pure layer 2 traffic didn't get passed. Haven't figured out how to fix that yet.","title":"Noted Problem"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#failed-ideas","text":"","title":"Failed Ideas"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#attempt-1-mirror-ports","text":"My first go is to try using OpenSwitch's built in mirroring capability.","title":"Attempt 1 - Mirror Ports"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#physical-configuration_1","text":"I didn't have enough target hosts to try outputting from one port to all ports so I simulated it. The purple cable in the image is the input port from the traffic generator (tcpreplay) and the white and yellow cables go out to the hosts listed as host 1 and host 2 in the test results section. The ports with the white and yellow cables were configured as the mirror's target ports.","title":"Physical Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#mirror-configuration","text":"For each port you want to mirror to run opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-005-0 --direction ingress --type span . Substitute your source and destination ports appropriately.","title":"Mirror Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#results","text":"","title":"Results"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#mirror-port-failure-after-4","text":"I was only able to get this to work on up to 4 ports. After that I received errors. See output below: root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-005-0 --direction ingress --type span root@OPX:~# ip link set e101-009-0 up root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-009-0 --direction ingress --type span root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-002-0 --direction ingress --type span root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-003-0 --direction ingress --type span root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-004-0 --direction ingress --type span {'data': {'base-mirror/entry/dst-intf': bytearray(b'\\x0f\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b'\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': {'0': {'base-mirror/entry/intf/src': bytearray(b'\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b'\\x01\\x00\\x00\\x00')}}}, 'key': '1.27.1769488.1769473.'} opx-config-mirror: Commit failed root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-006-0 --direction ingress --type span {'data': {'base-mirror/entry/dst-intf': bytearray(b'\\x11\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b'\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': {'0': {'base-mirror/entry/intf/src': bytearray(b'\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b'\\x01\\x00\\x00\\x00')}}}, 'key': '1.27.1769488.1769473.'} opx-config-mirror: Commit failed root@OPX:~# opx-config-mirror create --src_intf e101-001-0 --dest_intf e101-007-0 --direction ingress --type span {'data': {'base-mirror/entry/dst-intf': bytearray(b'\\x12\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b'\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': {'0': {'base-mirror/entry/intf/src': bytearray(b'\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b'\\x01\\x00\\x00\\x00')}}}, 'key': '1.27.1769488.1769473.'} opx-config-mirror: Commit failed Pretty printed version for ease of reading: { 'data': { 'base-mirror/entry/dst-intf': bytearray(b '\\x12\\x00\\x00\\x00'), 'base-mirror/entry/type': bytearray(b '\\x01\\x00\\x00\\x00'), 'base-mirror/entry/intf': { '0': { 'base-mirror/entry/intf/src': bytearray(b '\\x0c\\x00\\x00\\x00'), 'base-mirror/entry/intf/direction': bytearray(b '\\x01\\x00\\x00\\x00') } } }, 'key': '1.27.1769488.1769473.' }","title":"Mirror Port Failure After 4"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#functioning-mirror-ports","text":"Before I caught the error, I did test the first two mirror ports I made and they worked as expected. See the below. I used tcpreplay with some traffic I captured on my desktop to test the idea. I just uploaded the PCAP and replayed it with tcpreplay -i ens224 ./test_pcap.pcap --loop 500 I then confirmed that all target ports received traffic. See screenshots below:","title":"Functioning Mirror Ports"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#host-1_1","text":"","title":"Host 1"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#host-2_1","text":"The host I collected the traffic on was 192.168.1.6 and as you can see from the images both hosts were able to see traffic from the tcpreplay session.","title":"Host 2"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#attempt-2-tc","text":"","title":"Attempt 2 - tc"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#configuration","text":"tc is a feature of modern Linux kernels designed for mirroring traffic. I found this article helpful. This Mellanox article was also useful. The first thing I did was create an ingress queue on my input interface with tc qdisc add dev e101-001-0 handle ffff: ingress 1.If you need to delete a qdisc you can do it with tc qdisc del dev e101-001-0 [ root | ingress ] Double check your queue with handle ffff was created with tc -s qdisc ls dev e101-001-0 Next we want to mirror all traffic from the ingress port to an output port with tc filter add dev e101-001-0 parent ffff: protocol all u32 match u32 0 0 action mirred egress mirror dev e101-005-0 Check that your port mirror appeared in the config with tc -s -p filter ls dev e101-001-0 parent ffff: 1.If you need to delete the filters you can do so with tc filter del dev e101-001-0 parent ffff: Set queue to not shape traffic with tc qdisc add dev e101-001-0 handle 1: root prio","title":"Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#alternate-configuration","text":"I tried instead running: tc qdisc add dev e101-001-0 clsact tc filter add dev e101-001-0 ingress matchall skip_sw action mirred egress mirror dev e101-005-0","title":"Alternate Configuration"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#other-things-tried","text":"Haven't been able to figure out why just yet, but only Layer 2 traffic is making it through the port mirror. Everything above gets dropped. I thought maybe it was MAC address learning, but the problem persisted when I ran opx-config-global-switch --mac-age-time 0 I also thought that it was the port not being set to promiscuous mode so I gave it ifconfig e101-001-0 promisc . That didn't work either.","title":"Other Things Tried"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#conclusions","text":"I'm pretty confident that because this is a network OS for switching something funky is going on. Ex: When you run a port mirror, all the traffic passes correctly, but you won't see any of that traffic on a tcpdump session. Need to study up on the architecture. I'm pretty sure there's a way to make this particular tactic work, but for time's sake I'm going to try something else.","title":"Conclusions"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#attempt-3-tc-on-management-interface","text":"I realized something is going on with the forwarding tables on the switch at a low level that was intercepting our traffic in attempt 2. That said, I noticed that the management interface for the switch effectively works like a standard Linux interface. I did the same thing I did in attempt 2 except I used the managament interface instead of one of the other interfaces.","title":"Attempt 3  - tc on Management Interface"},{"location":"Mulitple%20Span%20on%204112F-ON%20with%20OpenSwitch/#results_1","text":"The switch accepts the config. However, the traffic only goes out to one port at a time.","title":"Results"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/","text":"Multiple Span on 4112F-ON with OS10 In this test case I am testing to see if we can configure a Dell 4112F-ON with OS10 to create a one to many port configuration using SPAN. Helpful Links ONIE Network Install Process Overview My Configuration General Configuration ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 version 10.5.0.2 PFSense running DNS and DHCP as services RHEL Release Info NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa) OS10 Version Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:13:11 Setup ONIE Prerequisites See ONIE Install Setup for instructions. Configure Device as TAP Physical Configuration For this configuration to work, we will use the management interface as the input interface for the tap. See image below. You will need to move your network cable over from your usual network to your traffic generator. Problem The way this worked on OPX was to use the Linux kernel module called TC. The net_sched module which supports ingress packet manipulation is not available on OS10. It could be reinstalled, but I didn't explore this option. Currently I don't have a working config on OS10. Test with Mirror Ports It looks like OS10 only supports one destination port on a port mirror. See the below. OS10(conf-mon-local-1)# do show monitor session 1 S.Id Source Destination Dir Mode Source IP Dest IP DSCP TTL Gre-Protocol State Reason --------------------------------------------------------------------------------------------------------------------------------------- 1 ethernet1/1/3 both port N/A N/A N/A N/A N/A false Destination is not configured OS10(conf-mon-local-1)# destination interface ethernet 1/1/7 OS10(conf-mon-local-1)# destination interface ethernet 1/1/8 % Error: Configuration mismatch. OS10(conf-mon-local-1)# no destination interface ethernet 1/1/7 OS10(conf-mon-local-1)# destination interface ethernet 1/1/8 OS10(conf-mon-local-1)#","title":"Multiple Span on 4112F-ON with OS10"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#multiple-span-on-4112f-on-with-os10","text":"In this test case I am testing to see if we can configure a Dell 4112F-ON with OS10 to create a one to many port configuration using SPAN.","title":"Multiple Span on 4112F-ON with OS10"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#helpful-links","text":"ONIE Network Install Process Overview","title":"Helpful Links"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#my-configuration","text":"","title":"My Configuration"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#general-configuration","text":"ONIE host is running RHEL 8 I am using a Dell S4112F-ON for testing OS10 version 10.5.0.2 PFSense running DNS and DHCP as services","title":"General Configuration"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#rhel-release-info","text":"NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.0 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.0\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.0 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.0:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.0 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.0\" Red Hat Enterprise Linux release 8.0 (Ootpa) Red Hat Enterprise Linux release 8.0 (Ootpa)","title":"RHEL Release Info"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#os10-version","text":"Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2019 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.2 Build Version: 10.5.0.2.468 Build Time: 2019-10-19T00:29:00+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:13:11","title":"OS10 Version"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#setup-onie-prerequisites","text":"See ONIE Install Setup for instructions.","title":"Setup ONIE Prerequisites"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#configure-device-as-tap","text":"","title":"Configure Device as TAP"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#physical-configuration","text":"For this configuration to work, we will use the management interface as the input interface for the tap. See image below. You will need to move your network cable over from your usual network to your traffic generator.","title":"Physical Configuration"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#problem","text":"The way this worked on OPX was to use the Linux kernel module called TC. The net_sched module which supports ingress packet manipulation is not available on OS10. It could be reinstalled, but I didn't explore this option. Currently I don't have a working config on OS10.","title":"Problem"},{"location":"Multiple%20Span%20on%204112F-ON%20with%20OS10/#test-with-mirror-ports","text":"It looks like OS10 only supports one destination port on a port mirror. See the below. OS10(conf-mon-local-1)# do show monitor session 1 S.Id Source Destination Dir Mode Source IP Dest IP DSCP TTL Gre-Protocol State Reason --------------------------------------------------------------------------------------------------------------------------------------- 1 ethernet1/1/3 both port N/A N/A N/A N/A N/A false Destination is not configured OS10(conf-mon-local-1)# destination interface ethernet 1/1/7 OS10(conf-mon-local-1)# destination interface ethernet 1/1/8 % Error: Configuration mismatch. OS10(conf-mon-local-1)# no destination interface ethernet 1/1/7 OS10(conf-mon-local-1)# destination interface ethernet 1/1/8 OS10(conf-mon-local-1)#","title":"Test with Mirror Ports"},{"location":"NVMe%20Performance%20Testing/","text":"NVMe Performance Testing Helpful Resources How fast are your disks? Find out the open source way, with fio (arstechnica) Configuration Drives OS [root@r8402 ~]# cat /etc/*-release NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.2 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.2\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.2 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.2\" Red Hat Enterprise Linux release 8.2 (Ootpa) Red Hat Enterprise Linux release 8.2 (Ootpa) Tests Test 1 Config pvcreate /dev/nvme2n1 pvcreate /dev/nvme1n1 pvcreate /dev/nvme0n1 pvcreate /dev/nvme3n1 vgcreate data /dev/nvme3n1 /dev/nvme2n1 /dev/nvme1n1 /dev/nvme0n1 lvcreate -l 100%FREE -i4 -I128 -n data data mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 /dev/mapper/data-data mkdir /data mount -o rw,auto,discard /dev/mapper/data-data /data fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=64k --iodepth=32 --size=50G --readwrite=randrw --rwmixread=60 Results Test: (g=0): rw=randrw, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=libaio, iodepth=32 fio-3.7 Starting 1 process Test: Laying out IO file (1 file / 51200MiB) Jobs: 1 (f=1): [m(1)][100.0%][r=217MiB/s,w=148MiB/s][r=3476,w=2371 IOPS][eta 00m:00s] Test: (groupid=0, jobs=1): err= 0: pid=3290: Mon Sep 14 11:17:39 2020 read: IOPS=3639, BW=227MiB/s (239MB/s)(29.0GiB/134968msec) bw ( KiB/s): min=211328, max=261504, per=99.99%, avg=232911.32, stdev=8921.48, samples=269 iops : min= 3302, max= 4086, avg=3639.22, stdev=139.41, samples=269 write: IOPS=2429, BW=152MiB/s (159MB/s)(20.0GiB/134968msec) bw ( KiB/s): min=140800, max=169856, per=100.00%, avg=155506.13, stdev=5852.42, samples=269 iops : min= 2200, max= 2654, avg=2429.77, stdev=91.43, samples=269 cpu : usr=2.19%, sys=8.61%, ctx=98853, majf=0, minf=13 IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0% issued rwts: total=491242,327958,0,0 short=0,0,0,0 dropped=0,0,0,0 latency : target=0, window=0, percentile=100.00%, depth=32 Run status group 0 (all jobs): READ: bw=227MiB/s (239MB/s), 227MiB/s-227MiB/s (239MB/s-239MB/s), io=29.0GiB (32.2GB), run=134968-134968msec WRITE: bw=152MiB/s (159MB/s), 152MiB/s-152MiB/s (159MB/s-159MB/s), io=20.0GiB (21.5GB), run=134968-134968msec Disk stats (read/write): dm-0: ios=490775/327707, merge=0/0, ticks=3019139/1204501, in_queue=4223640, util=68.01%, aggrios=491243/328000, aggrmerge=1/11, aggrticks=3031345/1210547, aggrin_queue=3827355, aggrutil=67.98% sda: ios=491243/328000, merge=1/11, ticks=3031345/1210547, in_queue=3827355, util=67.98%","title":"NVMe Performance Testing"},{"location":"NVMe%20Performance%20Testing/#nvme-performance-testing","text":"","title":"NVMe Performance Testing"},{"location":"NVMe%20Performance%20Testing/#helpful-resources","text":"How fast are your disks? Find out the open source way, with fio (arstechnica)","title":"Helpful Resources"},{"location":"NVMe%20Performance%20Testing/#configuration","text":"","title":"Configuration"},{"location":"NVMe%20Performance%20Testing/#drives","text":"","title":"Drives"},{"location":"NVMe%20Performance%20Testing/#os","text":"[root@r8402 ~]# cat /etc/*-release NAME=\"Red Hat Enterprise Linux\" VERSION=\"8.2 (Ootpa)\" ID=\"rhel\" ID_LIKE=\"fedora\" VERSION_ID=\"8.2\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\" HOME_URL=\"https://www.redhat.com/\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 8\" REDHAT_BUGZILLA_PRODUCT_VERSION=8.2 REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\" REDHAT_SUPPORT_PRODUCT_VERSION=\"8.2\" Red Hat Enterprise Linux release 8.2 (Ootpa) Red Hat Enterprise Linux release 8.2 (Ootpa)","title":"OS"},{"location":"NVMe%20Performance%20Testing/#tests","text":"","title":"Tests"},{"location":"NVMe%20Performance%20Testing/#test-1","text":"","title":"Test 1"},{"location":"NVMe%20Performance%20Testing/#config","text":"pvcreate /dev/nvme2n1 pvcreate /dev/nvme1n1 pvcreate /dev/nvme0n1 pvcreate /dev/nvme3n1 vgcreate data /dev/nvme3n1 /dev/nvme2n1 /dev/nvme1n1 /dev/nvme0n1 lvcreate -l 100%FREE -i4 -I128 -n data data mkfs.ext4 -F -b 4096 -E discard,stride=16,stripe-width=256 /dev/mapper/data-data mkdir /data mount -o rw,auto,discard /dev/mapper/data-data /data fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=64k --iodepth=32 --size=50G --readwrite=randrw --rwmixread=60","title":"Config"},{"location":"NVMe%20Performance%20Testing/#results","text":"Test: (g=0): rw=randrw, bs=(R) 64.0KiB-64.0KiB, (W) 64.0KiB-64.0KiB, (T) 64.0KiB-64.0KiB, ioengine=libaio, iodepth=32 fio-3.7 Starting 1 process Test: Laying out IO file (1 file / 51200MiB) Jobs: 1 (f=1): [m(1)][100.0%][r=217MiB/s,w=148MiB/s][r=3476,w=2371 IOPS][eta 00m:00s] Test: (groupid=0, jobs=1): err= 0: pid=3290: Mon Sep 14 11:17:39 2020 read: IOPS=3639, BW=227MiB/s (239MB/s)(29.0GiB/134968msec) bw ( KiB/s): min=211328, max=261504, per=99.99%, avg=232911.32, stdev=8921.48, samples=269 iops : min= 3302, max= 4086, avg=3639.22, stdev=139.41, samples=269 write: IOPS=2429, BW=152MiB/s (159MB/s)(20.0GiB/134968msec) bw ( KiB/s): min=140800, max=169856, per=100.00%, avg=155506.13, stdev=5852.42, samples=269 iops : min= 2200, max= 2654, avg=2429.77, stdev=91.43, samples=269 cpu : usr=2.19%, sys=8.61%, ctx=98853, majf=0, minf=13 IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0% issued rwts: total=491242,327958,0,0 short=0,0,0,0 dropped=0,0,0,0 latency : target=0, window=0, percentile=100.00%, depth=32 Run status group 0 (all jobs): READ: bw=227MiB/s (239MB/s), 227MiB/s-227MiB/s (239MB/s-239MB/s), io=29.0GiB (32.2GB), run=134968-134968msec WRITE: bw=152MiB/s (159MB/s), 152MiB/s-152MiB/s (159MB/s-159MB/s), io=20.0GiB (21.5GB), run=134968-134968msec Disk stats (read/write): dm-0: ios=490775/327707, merge=0/0, ticks=3019139/1204501, in_queue=4223640, util=68.01%, aggrios=491243/328000, aggrmerge=1/11, aggrticks=3031345/1210547, aggrin_queue=3827355, aggrutil=67.98% sda: ios=491243/328000, merge=1/11, ticks=3031345/1210547, in_queue=3827355, util=67.98%","title":"Results"},{"location":"Notes%20on%20AMD%20Processor/","text":"Notes on AMD Processor Notes on AMD Processor Pictures of Physical Package Notes from Processor Programming Reference I/O Diagram One Socket I/O Two Socket I/O with 4 XGMI Links Two Socket I/O with 3 XGMI Links Core Complex (CCX) Diagram How is the iDRAC connected? Measuring Performance - Effective Frequency System Management Unit How to Change Processor Settings Run Commands on the Processor Pictures of Physical Package Link Notes from Processor Programming Reference See here for source. I/O Diagram One Socket I/O See page 32 Two Socket I/O with 4 XGMI Links See page 34 Two Socket I/O with 3 XGMI Links See page 35 Core Complex (CCX) Diagram See page 36 How is the iDRAC connected? See page 30 Each IOD (I/O die) has: Four instances of NorthBridge IO (NBIO), each of which includes: Two 8x16 PCIe\u00ae Gen4 controllers. One instance includes a 2x2 PCIe\u00ae Gen 2 controller, which can be used to attach a Baseband Management Controller (BMC) Measuring Performance - Effective Frequency When using something like iDRAC telemetry it can poll the effective frequency via the effective frequency interface. See page 47 Review on C vs P States The effective frequency interface allows software to discern the average, or effective, frequency of a given core over a configurable window of time. This provides software a measure of actual performance rather than forcing software to assume the current frequency of the core is the frequency of the last P-state requested System Management Unit There is a system management unit for each proc integrated onto the I/O die . How to Change Processor Settings There are three ways to change settings on the processor: AMD Host System Management Port (HSMP) Epyc System Management Interface (E-SMI) Library Technically, this rides on top of the HSMP but it is a separate userspace library Run Commands Directly on the Processor Run Commands on the Processor Let's say you want to disable the L2 Stream HW Prefetcher. This can be accomplished with the write MSR (Model Specific Register) Command . Model Specific Registers (MSRs) are: any of various control registers in the x86 instruction set used for debugging, program execution tracing, computer performance monitoring, and toggling certain CPU features. There is a good lecture available on the subject available here . If you want to control prefetch you would select the appropriate register and then bitmask 1 to bit 3 as described here:","title":"Notes on AMD Processor"},{"location":"Notes%20on%20AMD%20Processor/#notes-on-amd-processor","text":"Notes on AMD Processor Pictures of Physical Package Notes from Processor Programming Reference I/O Diagram One Socket I/O Two Socket I/O with 4 XGMI Links Two Socket I/O with 3 XGMI Links Core Complex (CCX) Diagram How is the iDRAC connected? Measuring Performance - Effective Frequency System Management Unit How to Change Processor Settings Run Commands on the Processor","title":"Notes on AMD Processor"},{"location":"Notes%20on%20AMD%20Processor/#pictures-of-physical-package","text":"Link","title":"Pictures of Physical Package"},{"location":"Notes%20on%20AMD%20Processor/#notes-from-processor-programming-reference","text":"See here for source.","title":"Notes from Processor Programming Reference"},{"location":"Notes%20on%20AMD%20Processor/#io-diagram","text":"","title":"I/O Diagram"},{"location":"Notes%20on%20AMD%20Processor/#one-socket-io","text":"See page 32","title":"One Socket I/O"},{"location":"Notes%20on%20AMD%20Processor/#two-socket-io-with-4-xgmi-links","text":"See page 34","title":"Two Socket I/O with 4 XGMI Links"},{"location":"Notes%20on%20AMD%20Processor/#two-socket-io-with-3-xgmi-links","text":"See page 35","title":"Two Socket I/O with 3 XGMI Links"},{"location":"Notes%20on%20AMD%20Processor/#core-complex-ccx-diagram","text":"See page 36","title":"Core Complex (CCX) Diagram"},{"location":"Notes%20on%20AMD%20Processor/#how-is-the-idrac-connected","text":"See page 30 Each IOD (I/O die) has: Four instances of NorthBridge IO (NBIO), each of which includes: Two 8x16 PCIe\u00ae Gen4 controllers. One instance includes a 2x2 PCIe\u00ae Gen 2 controller, which can be used to attach a Baseband Management Controller (BMC)","title":"How is the iDRAC connected?"},{"location":"Notes%20on%20AMD%20Processor/#measuring-performance-effective-frequency","text":"When using something like iDRAC telemetry it can poll the effective frequency via the effective frequency interface. See page 47 Review on C vs P States The effective frequency interface allows software to discern the average, or effective, frequency of a given core over a configurable window of time. This provides software a measure of actual performance rather than forcing software to assume the current frequency of the core is the frequency of the last P-state requested","title":"Measuring Performance - Effective Frequency"},{"location":"Notes%20on%20AMD%20Processor/#system-management-unit","text":"There is a system management unit for each proc integrated onto the I/O die .","title":"System Management Unit"},{"location":"Notes%20on%20AMD%20Processor/#how-to-change-processor-settings","text":"There are three ways to change settings on the processor: AMD Host System Management Port (HSMP) Epyc System Management Interface (E-SMI) Library Technically, this rides on top of the HSMP but it is a separate userspace library Run Commands Directly on the Processor","title":"How to Change Processor Settings"},{"location":"Notes%20on%20AMD%20Processor/#run-commands-on-the-processor","text":"Let's say you want to disable the L2 Stream HW Prefetcher. This can be accomplished with the write MSR (Model Specific Register) Command . Model Specific Registers (MSRs) are: any of various control registers in the x86 instruction set used for debugging, program execution tracing, computer performance monitoring, and toggling certain CPU features. There is a good lecture available on the subject available here . If you want to control prefetch you would select the appropriate register and then bitmask 1 to bit 3 as described here:","title":"Run Commands on the Processor"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/","text":"Notes on Building a Datacenter from Scratch Notes on Building a Datacenter from Scratch Power Rough Flow of Power Details on UPS Offline UPS Line Interactive Online Double conversion UPS** Online Delta conversion UPS** Rotary UPS Systems Cooling Cooling Types Room Cooling Row Cooling Rack Cooling Notes on Physics Heat Removal Techniques Humidity Cooling Strategies Aisle Arrangement Sealed Rooms Airflow Management CRAC vs CRAH Power Typically, the total power supplied to the Data Center should be two times or more than the total power required by the IT equipment (including future Loads). The other half will be consumed by the cooling and other facilities. Power is usually measured in Watts (W). Each piece of IT equipment has a specific Wattage, or Power Rating, specifying the amount of Power it consumes. The total sum of Power Ratings of all IT equipment running in the Data Center gives the total IT Load of the Data Center. IT Load, or Critical Load, is the total Power consumed by all critical IT equipment in the Data Center. Most manufacturer specified power requirements for IT equipment are usually over-stated. Actual consumption typically does not exceed 70% of stated value. A good practice is to de-rate stated values by 60 \u2013 70% before computing total IT Load Industry best practice is to allocate 4 -5 kW per rack. (TODO - still current in 2022?) Rough Flow of Power Utility Supply Generators Transfer Switches Distribution Panels Uninterruptible Power Supply (UPS) PDU Utility Supply is the power supply to the Data Center sourced from the public distribution grid. It is controlled by the government or public power distribution companies and is not considered a reliable source for powering the Data Center. They are however utilized to minimize the costs of providing power to the Data Center. Generators are machines used to generate electrical Power. They convert mechanical energy, usually from motors, to the electrical energy used to power the Data Center. They are the primary source of Power to the Data Center, since they are completely in the control of the Data Center Operators. Transfer Switches are electrical switches used to transfer electric Load from one power source to the other. The transfer could be from one utility line to another, from engine-generators to utility and vice versa, or between two generators. The transfer could be manually activated. It could also be automatic when Automatic Transfer Switches (ATS) or Static Transfer Switches (STS) are used. Distribution Panel as the name implies is an enclosure wherein a single electrical power feed is divided into separate subsidiary circuits for feeding multiple distinct Loads. The circuits may all be of equal or differing capacities. Each circuit or power feed is protected by a circuit breaker or an electrical fuse to prevent the end electrical Loads from over-drawing power beyond specified limits UPS means Uninterruptible Power Supply . The UPS is an electrical device that provides continuous power to a Load even when the mains power source is unavailable. It works by storing electrical energy in backup devices, such as batteries, from input power. The UPS then supplies the Load with the stored energy almost instantaneously when the input power is cut off. Another important function of the UPS is to clean out and stabilize the power from the mains supply. The power from the mains supply can be subject to fluctuations in form, voltage, and frequency owing to interference or generation conditions. The UPS has the ability to correct some of these anomalies. PDU means Power Distribution Unit. The PDU distributes power to the individual pieces of equipment. The PDUs come in various sizes and forms, with some being rack-mountable while others occupy Data Center whitespace. Details on UPS There are two types of UPS Systems: Static UPS and Rotary UPS Static UPS Systems are so named because they have no moving parts throughout the power flow. They typically store electricity in the form of chemical energy in batteries. This UPS system has three main components: The rectifier, which converts AC from the mains into DC The storage medium, which stores the converted DC. The most common form for storing electrical energy is through batteries[8] The inverter, which converts stored DC to AC for supply to the electrical load Offline UPS Here, the Load is powered directly from the mains when the mains input is present. The UPS switches the Load over to the battery when the mains input goes off. There is a noticeable time lag during the switching process. More so, the irregularities (if any) in the mains power are carried over to the Load. These make this configuration not conducive for sensitive critical Load. Line Interactive This configuration is similar to the Offline system. However, a voltage regulator is introduced after the mains just before the Load. The Voltage Regulator corrects some of the irregularities, but cannot correct frequency. There is still a noticeable time lag during the switching process. Critical Load is not to be powered with this system. Online Double conversion UPS** This configuration completely isolates the Load from the mains input. The Load is always fed from the DC Power. The AC power from the mains is converted to DC to keep the batteries charged. The inverter then converts the DC back to AC to supply the Load. This ensures that the supply to the Load is always clean and continuous, making it suitable to critical Data Center Loads. A bypass is included so that the Load can be switched manually switched over to the mains supply temporarily during maintenance operations. One drawback however is that this configuration is not very efficient due to losses accrued during the conversion processes. Online Delta conversion UPS** This is a variation of the Line Interactive system. It uses a Delta Converter in place of the Voltage Regulator. The Delta Conversion UPS allows a portion of the Load to be fed from the main, while the rest is fed from the Inverter. This allows the stabilization of the output voltage. It also ensures that there is no switching time lag if the main\u2019s input is cut, as the Inverter can seamlessly assume the rest of the Load Rotary UPS Systems Rotary UPS Systems are so named because they store electrical energy in the form of kinetic energy. The incoming main\u2019s supply drives a motor which in turn spins an electro-mechanical flywheel at a very high rate. The flywheel drives an electrical generator to provide power to the Load, while at the same time storing Kinetic Energy. Once power failure occurs, the Kinetic Energy in the flywheel is released to drive the generator, so that it continues to power the Load, providing a ride-through period within which the backup generator can be started. Some variations add batteries to the flywheel for energy storage. Another variation incorporates a Diesel Generator into the Rotary UPS System. Once the power outage exceeds a few seconds, the Diesel Generator is started to provide the input power. This precludes the need for an external backup generator. This system is known as a Diesel Rotary UPS (DRUPS) system. There has been an ongoing argument about which UPS system is best suited for Data Center functions. While Static UPS systems dominate the existing Data Center deployments, there is still much benefit a Rotary UPS system can offer. Manufacturers of both systems continue to advance arguments supporting their chosen lines. Rotary UPS systems are usually manufactured for higher power ranges (200kW and above). DRUPS systems are generally not found in capacities lower than 500kW. Rotary systems provide little ride-through time (about 15 seconds) compared to Static systems, which can backup power for up to 30 minutes. Also, Rotary systems require vigorous maintenance regimes, unlike Static systems, which most times just need routine cleaning. On the other hand, Rotary systems allow for massive savings in expensive Data Center space. They also have a considerable lifespan compared to Static UPS system components. In all cases, the choice of which UPS system to utilize will depend on what system suits the Business objective better. Cooling Cooling Types Room Cooling In this approach, cooling is provided for the room as a whole. This method can be suitable for small data centers, but decidedly become more cumbersome as the data center density increases. This is because the air conditioners have to constantly stir and mix the air in the room to prevent hot-spots and bring it to a common regular temperature. Row Cooling In this approach, cooling is provided on a row by row basis. This allows each row to run different load densities, so that differing cooling intensities can be applied as required. Hot-spot and cooling irregularities can be easily managed by proper layout and equipment placement. Rack Cooling In this approach, cooling is provided on a rack by rack basis. Specific air-conditioning units are dedicated to specific racks. This approach allows for maximum densities to be deployed per rack. However, this advantage can only be realized in data centers with fully loaded racks, otherwise, there would be too much cooling capacity, and air-conditioning losses alone can exceed total IT load. Notes on Physics Heat Removal Techniques From Physics, we learn that heat can only flow in one direction \u2013 from hot to cold. We also learn heat can be transferred either by Conduction, Convection, or Radiation. Conduction is the transfer of heat through a solid material, known as a conductor. Convection is the transfer of heat through the movement of a liquid or gas. Radiation is the transfer of heat by means of electromagnetic waves, emitted due to the temperature difference between two objects. Convection is the method used to transfer heat away from the data center. This transfer is done through a process known as the Refrigeration Cycle. The Refrigeration Cycle is a cycle of Evaporation, Compression, Condensation, and Expansion of a fluid or gas. This fluid or gas is known as the Refrigerant. The Refrigeration Cycle effectively transfers heat away from the data center into the external environment. Through the different stages of the refrigeration cycle, the refrigerant\u2019s physical state oscillates between liquid and gas. Evaporation will absorb heat from the data center environment and turn the refrigerant into a gas. This heat in the gaseous refrigerant is channeled to the compressor Compression will apply pressure to the gaseous refrigerant, making it absorb much more heat thereby causing its internal temperature to rise. This hot gaseous refrigerant is channeled to the condenser in the next phase of eliminating data center heat. Condensation will pass heat from the high-temperature high-pressure gas to the outside air. As heat flows from the hot region to the cold region, outside air is directed to the condensation coil. The refrigerant flowing through the coil then transfers heat to the outside air, which is then channeled out to the outdoor environment. The refrigerant then becomes a hot, high-pressure liquid. Expansion will reduce the pressure in the refrigerant thereby reducing the temperature. This ends the cycle with the refrigerant returning to a cold liquid. The cycle is then restarted. Another method of removing heat from the data center is via Chilled Water Systems. This method, while more efficient and cost-effective than direct expansion systems using the refrigeration cycle, is much more complex. It utilizes fans and cooling coils to remove heat from the data center via chilled water. Humidity Like temperature, humidity[12] is also an important environmental factor in the data center. Regulating humidity is critical. Too low humidity levels affect the incidence of static electricity, which is an electric charge at rest. This electric charge can lead to an Electrostatic Discharge (ESD), which could cause significant damage to IT equipment. Too high humidity can cause water condensation on IT equipment, which could lead to water dropping on the chips in equipment, resulting in a current short-circuit. In measuring humidity, the terms Relative Humidity, Dew Point, and Saturation are used. Relative humidity is the amount of water vapor in the air as a percentage of the maximum amount of water vapor the air can hold at a given temperature. It follows that relative humidity can vary as the air temperature changes. e.g. at a higher temperature, air will expand causing it to be able to hold more water, thus relative humidity becomes lower. The reverse is the case at lower temperatures. ASHRAE recommends maximum relative humidity levels of 60%. Dew point is the exact temperature where relative humidity becomes 100%. At this point, the water vapor leaves the air and appears as liquid water droplets on any object in the data center. ASHRAE recommends a maximum of 15.50C dew point. The air is said to be \u201csaturated\u201d at this temperature. Humidity in the data center is regulated using Precision Cooling units, which regulate temperature and water vapor levels in the environment. Humidification/Dehumidification systems are used. These produce/reduce water vapor in the atmosphere to the desired quantities. In addition to humidity regulation equipment, the following practices should be followed to restrict fluctuation in humidity levels: - Reduce the frequency of entry/exit into/from the data center. Constant opening of data center entrances can lead to infiltration of warmer air from outside, which could destabilize the environment - Seal perimeter infiltrations and entrance points that lead to uncontrolled environments - Seal doorways to guard against air and vapor leaks - Paint perimeter walls to prevent the penetration of moisture - Avoid unnecessary openings Cooling Strategies Aisle Arrangement As discussed in an earlier section, it is advantageous to provide cooling on a row-by-row basis. Taking this further, many standard bodies, including TIA and ASHRAE, recommend arranging racks and cabinets in a hot-aisle/cold-aisle alignment. In this arrangement, the racks in each row are arranged such that the front and backs of adjacent rows face each other. This leads to a repeatable sequence after every 7 tiles, known as the 7 pitch tile rule. When cold air is channeled to the front of the racks in this arrangement, the aisle between racks\u2019 fronts facing each other is distinctly cold (cold aisle), while that at racks\u2019 backs is distinctly hot (hot aisle). The cooling unit is placed at the hot aisle. Proper distance should be maintained between the air cooling unit and the equipment, typically between 2.5m (8ft) and 10m (32ft). Sealed Rooms The data center should be completely sealed to prevent the escape of cold air to the external environment. This could progressively worsen the energy situation as more and more energy is consumed to adequately cool the server room space only for the cold air to escape to other areas Airflow Management Open spaces in the cabinets should be minimized as much as possible. This can be done by placing blanking plates in unused rack unit spaces, blocking of cabinet sides, and making use of perforated front and back doors. In-Row Units - Can be used to cool by sucking in the hot air in the hot aisle. CRAC vs CRAH CRAH is an acronym for Computer Room Air Handler, while CRAC is an acronym for Computer Room Air Conditioner. CRAHs are indoor cooling units that do not have their own compressors. They are typically components of a Chilled Water-based cooling system. CRACs on the other hand have their own self-contained compressor. They are a staple of Direct Expansion based cooling systems.","title":"Notes on Building a Datacenter from Scratch"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#notes-on-building-a-datacenter-from-scratch","text":"Notes on Building a Datacenter from Scratch Power Rough Flow of Power Details on UPS Offline UPS Line Interactive Online Double conversion UPS** Online Delta conversion UPS** Rotary UPS Systems Cooling Cooling Types Room Cooling Row Cooling Rack Cooling Notes on Physics Heat Removal Techniques Humidity Cooling Strategies Aisle Arrangement Sealed Rooms Airflow Management CRAC vs CRAH","title":"Notes on Building a Datacenter from Scratch"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#power","text":"Typically, the total power supplied to the Data Center should be two times or more than the total power required by the IT equipment (including future Loads). The other half will be consumed by the cooling and other facilities. Power is usually measured in Watts (W). Each piece of IT equipment has a specific Wattage, or Power Rating, specifying the amount of Power it consumes. The total sum of Power Ratings of all IT equipment running in the Data Center gives the total IT Load of the Data Center. IT Load, or Critical Load, is the total Power consumed by all critical IT equipment in the Data Center. Most manufacturer specified power requirements for IT equipment are usually over-stated. Actual consumption typically does not exceed 70% of stated value. A good practice is to de-rate stated values by 60 \u2013 70% before computing total IT Load Industry best practice is to allocate 4 -5 kW per rack. (TODO - still current in 2022?)","title":"Power"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#rough-flow-of-power","text":"Utility Supply Generators Transfer Switches Distribution Panels Uninterruptible Power Supply (UPS) PDU Utility Supply is the power supply to the Data Center sourced from the public distribution grid. It is controlled by the government or public power distribution companies and is not considered a reliable source for powering the Data Center. They are however utilized to minimize the costs of providing power to the Data Center. Generators are machines used to generate electrical Power. They convert mechanical energy, usually from motors, to the electrical energy used to power the Data Center. They are the primary source of Power to the Data Center, since they are completely in the control of the Data Center Operators. Transfer Switches are electrical switches used to transfer electric Load from one power source to the other. The transfer could be from one utility line to another, from engine-generators to utility and vice versa, or between two generators. The transfer could be manually activated. It could also be automatic when Automatic Transfer Switches (ATS) or Static Transfer Switches (STS) are used. Distribution Panel as the name implies is an enclosure wherein a single electrical power feed is divided into separate subsidiary circuits for feeding multiple distinct Loads. The circuits may all be of equal or differing capacities. Each circuit or power feed is protected by a circuit breaker or an electrical fuse to prevent the end electrical Loads from over-drawing power beyond specified limits UPS means Uninterruptible Power Supply . The UPS is an electrical device that provides continuous power to a Load even when the mains power source is unavailable. It works by storing electrical energy in backup devices, such as batteries, from input power. The UPS then supplies the Load with the stored energy almost instantaneously when the input power is cut off. Another important function of the UPS is to clean out and stabilize the power from the mains supply. The power from the mains supply can be subject to fluctuations in form, voltage, and frequency owing to interference or generation conditions. The UPS has the ability to correct some of these anomalies. PDU means Power Distribution Unit. The PDU distributes power to the individual pieces of equipment. The PDUs come in various sizes and forms, with some being rack-mountable while others occupy Data Center whitespace.","title":"Rough Flow of Power"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#details-on-ups","text":"There are two types of UPS Systems: Static UPS and Rotary UPS Static UPS Systems are so named because they have no moving parts throughout the power flow. They typically store electricity in the form of chemical energy in batteries. This UPS system has three main components: The rectifier, which converts AC from the mains into DC The storage medium, which stores the converted DC. The most common form for storing electrical energy is through batteries[8] The inverter, which converts stored DC to AC for supply to the electrical load","title":"Details on UPS"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#offline-ups","text":"Here, the Load is powered directly from the mains when the mains input is present. The UPS switches the Load over to the battery when the mains input goes off. There is a noticeable time lag during the switching process. More so, the irregularities (if any) in the mains power are carried over to the Load. These make this configuration not conducive for sensitive critical Load.","title":"Offline UPS"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#line-interactive","text":"This configuration is similar to the Offline system. However, a voltage regulator is introduced after the mains just before the Load. The Voltage Regulator corrects some of the irregularities, but cannot correct frequency. There is still a noticeable time lag during the switching process. Critical Load is not to be powered with this system.","title":"Line Interactive"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#online-double-conversion-ups","text":"This configuration completely isolates the Load from the mains input. The Load is always fed from the DC Power. The AC power from the mains is converted to DC to keep the batteries charged. The inverter then converts the DC back to AC to supply the Load. This ensures that the supply to the Load is always clean and continuous, making it suitable to critical Data Center Loads. A bypass is included so that the Load can be switched manually switched over to the mains supply temporarily during maintenance operations. One drawback however is that this configuration is not very efficient due to losses accrued during the conversion processes.","title":"Online Double conversion UPS**"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#online-delta-conversion-ups","text":"This is a variation of the Line Interactive system. It uses a Delta Converter in place of the Voltage Regulator. The Delta Conversion UPS allows a portion of the Load to be fed from the main, while the rest is fed from the Inverter. This allows the stabilization of the output voltage. It also ensures that there is no switching time lag if the main\u2019s input is cut, as the Inverter can seamlessly assume the rest of the Load","title":"Online Delta conversion UPS**"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#rotary-ups-systems","text":"Rotary UPS Systems are so named because they store electrical energy in the form of kinetic energy. The incoming main\u2019s supply drives a motor which in turn spins an electro-mechanical flywheel at a very high rate. The flywheel drives an electrical generator to provide power to the Load, while at the same time storing Kinetic Energy. Once power failure occurs, the Kinetic Energy in the flywheel is released to drive the generator, so that it continues to power the Load, providing a ride-through period within which the backup generator can be started. Some variations add batteries to the flywheel for energy storage. Another variation incorporates a Diesel Generator into the Rotary UPS System. Once the power outage exceeds a few seconds, the Diesel Generator is started to provide the input power. This precludes the need for an external backup generator. This system is known as a Diesel Rotary UPS (DRUPS) system. There has been an ongoing argument about which UPS system is best suited for Data Center functions. While Static UPS systems dominate the existing Data Center deployments, there is still much benefit a Rotary UPS system can offer. Manufacturers of both systems continue to advance arguments supporting their chosen lines. Rotary UPS systems are usually manufactured for higher power ranges (200kW and above). DRUPS systems are generally not found in capacities lower than 500kW. Rotary systems provide little ride-through time (about 15 seconds) compared to Static systems, which can backup power for up to 30 minutes. Also, Rotary systems require vigorous maintenance regimes, unlike Static systems, which most times just need routine cleaning. On the other hand, Rotary systems allow for massive savings in expensive Data Center space. They also have a considerable lifespan compared to Static UPS system components. In all cases, the choice of which UPS system to utilize will depend on what system suits the Business objective better.","title":"Rotary UPS Systems"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#cooling","text":"","title":"Cooling"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#cooling-types","text":"","title":"Cooling Types"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#room-cooling","text":"In this approach, cooling is provided for the room as a whole. This method can be suitable for small data centers, but decidedly become more cumbersome as the data center density increases. This is because the air conditioners have to constantly stir and mix the air in the room to prevent hot-spots and bring it to a common regular temperature.","title":"Room Cooling"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#row-cooling","text":"In this approach, cooling is provided on a row by row basis. This allows each row to run different load densities, so that differing cooling intensities can be applied as required. Hot-spot and cooling irregularities can be easily managed by proper layout and equipment placement.","title":"Row Cooling"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#rack-cooling","text":"In this approach, cooling is provided on a rack by rack basis. Specific air-conditioning units are dedicated to specific racks. This approach allows for maximum densities to be deployed per rack. However, this advantage can only be realized in data centers with fully loaded racks, otherwise, there would be too much cooling capacity, and air-conditioning losses alone can exceed total IT load.","title":"Rack Cooling"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#notes-on-physics","text":"","title":"Notes on Physics"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#heat-removal-techniques","text":"From Physics, we learn that heat can only flow in one direction \u2013 from hot to cold. We also learn heat can be transferred either by Conduction, Convection, or Radiation. Conduction is the transfer of heat through a solid material, known as a conductor. Convection is the transfer of heat through the movement of a liquid or gas. Radiation is the transfer of heat by means of electromagnetic waves, emitted due to the temperature difference between two objects. Convection is the method used to transfer heat away from the data center. This transfer is done through a process known as the Refrigeration Cycle. The Refrigeration Cycle is a cycle of Evaporation, Compression, Condensation, and Expansion of a fluid or gas. This fluid or gas is known as the Refrigerant. The Refrigeration Cycle effectively transfers heat away from the data center into the external environment. Through the different stages of the refrigeration cycle, the refrigerant\u2019s physical state oscillates between liquid and gas. Evaporation will absorb heat from the data center environment and turn the refrigerant into a gas. This heat in the gaseous refrigerant is channeled to the compressor Compression will apply pressure to the gaseous refrigerant, making it absorb much more heat thereby causing its internal temperature to rise. This hot gaseous refrigerant is channeled to the condenser in the next phase of eliminating data center heat. Condensation will pass heat from the high-temperature high-pressure gas to the outside air. As heat flows from the hot region to the cold region, outside air is directed to the condensation coil. The refrigerant flowing through the coil then transfers heat to the outside air, which is then channeled out to the outdoor environment. The refrigerant then becomes a hot, high-pressure liquid. Expansion will reduce the pressure in the refrigerant thereby reducing the temperature. This ends the cycle with the refrigerant returning to a cold liquid. The cycle is then restarted. Another method of removing heat from the data center is via Chilled Water Systems. This method, while more efficient and cost-effective than direct expansion systems using the refrigeration cycle, is much more complex. It utilizes fans and cooling coils to remove heat from the data center via chilled water.","title":"Heat Removal Techniques"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#humidity","text":"Like temperature, humidity[12] is also an important environmental factor in the data center. Regulating humidity is critical. Too low humidity levels affect the incidence of static electricity, which is an electric charge at rest. This electric charge can lead to an Electrostatic Discharge (ESD), which could cause significant damage to IT equipment. Too high humidity can cause water condensation on IT equipment, which could lead to water dropping on the chips in equipment, resulting in a current short-circuit. In measuring humidity, the terms Relative Humidity, Dew Point, and Saturation are used. Relative humidity is the amount of water vapor in the air as a percentage of the maximum amount of water vapor the air can hold at a given temperature. It follows that relative humidity can vary as the air temperature changes. e.g. at a higher temperature, air will expand causing it to be able to hold more water, thus relative humidity becomes lower. The reverse is the case at lower temperatures. ASHRAE recommends maximum relative humidity levels of 60%. Dew point is the exact temperature where relative humidity becomes 100%. At this point, the water vapor leaves the air and appears as liquid water droplets on any object in the data center. ASHRAE recommends a maximum of 15.50C dew point. The air is said to be \u201csaturated\u201d at this temperature. Humidity in the data center is regulated using Precision Cooling units, which regulate temperature and water vapor levels in the environment. Humidification/Dehumidification systems are used. These produce/reduce water vapor in the atmosphere to the desired quantities. In addition to humidity regulation equipment, the following practices should be followed to restrict fluctuation in humidity levels: - Reduce the frequency of entry/exit into/from the data center. Constant opening of data center entrances can lead to infiltration of warmer air from outside, which could destabilize the environment - Seal perimeter infiltrations and entrance points that lead to uncontrolled environments - Seal doorways to guard against air and vapor leaks - Paint perimeter walls to prevent the penetration of moisture - Avoid unnecessary openings","title":"Humidity"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#cooling-strategies","text":"","title":"Cooling Strategies"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#aisle-arrangement","text":"As discussed in an earlier section, it is advantageous to provide cooling on a row-by-row basis. Taking this further, many standard bodies, including TIA and ASHRAE, recommend arranging racks and cabinets in a hot-aisle/cold-aisle alignment. In this arrangement, the racks in each row are arranged such that the front and backs of adjacent rows face each other. This leads to a repeatable sequence after every 7 tiles, known as the 7 pitch tile rule. When cold air is channeled to the front of the racks in this arrangement, the aisle between racks\u2019 fronts facing each other is distinctly cold (cold aisle), while that at racks\u2019 backs is distinctly hot (hot aisle). The cooling unit is placed at the hot aisle. Proper distance should be maintained between the air cooling unit and the equipment, typically between 2.5m (8ft) and 10m (32ft).","title":"Aisle Arrangement"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#sealed-rooms","text":"The data center should be completely sealed to prevent the escape of cold air to the external environment. This could progressively worsen the energy situation as more and more energy is consumed to adequately cool the server room space only for the cold air to escape to other areas","title":"Sealed Rooms"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#airflow-management","text":"Open spaces in the cabinets should be minimized as much as possible. This can be done by placing blanking plates in unused rack unit spaces, blocking of cabinet sides, and making use of perforated front and back doors. In-Row Units - Can be used to cool by sucking in the hot air in the hot aisle.","title":"Airflow Management"},{"location":"Notes%20on%20Building%20a%20Datacenter%20from%20Scratch/#crac-vs-crah","text":"CRAH is an acronym for Computer Room Air Handler, while CRAC is an acronym for Computer Room Air Conditioner. CRAHs are indoor cooling units that do not have their own compressors. They are typically components of a Chilled Water-based cooling system. CRACs on the other hand have their own self-contained compressor. They are a staple of Direct Expansion based cooling systems.","title":"CRAC vs CRAH"},{"location":"Notes%20on%20HPC/","text":"Notes on HPC KEY TAKEAWAY Economics will drive the pooling of main memory, and whether or not customers choose the CXL way or the Gen-Z way. Considering that memory can account for half of the cost of a server at a hyperscaler, anything that allows a machine to have a minimal amount of capacity on the node and then share the rest in the rack with all of it being transparent to the operating system and all of it looking local will be adopted. There is just no question about that. Memory area networks, in one fashion or another, are going to be common in datacenters before too long, and this will be driven by economics. Load Store Architecture A load\u2013store architecture is an instruction set architecture that divides instructions into two categories: memory access (load and store between memory and registers) and ALU operations (which only occur between registers). For instance, in a load\u2013store approach both operands and destination for an ADD operation must be in registers. This differs from a register-memory architecture (for example, a CISC instruction set architecture such as x86) in which one of the operands for the ADD operation may be in memory, while the other is in a register. https://www.sciencedirect.com/topics/computer-science/load-store-architecture https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture Fabric Attached Memory See Fabric Attached Memory CXL See Compute Express Link Radix https://github.com/HewlettPackard/meadowlark https://ieeexplore.ieee.org/document/6307777 Things to investigate https://www.techpowerup.com/292256/amd-details-its-3d-v-cache-design-at-isscc","title":"Notes on HPC"},{"location":"Notes%20on%20HPC/#notes-on-hpc","text":"KEY TAKEAWAY Economics will drive the pooling of main memory, and whether or not customers choose the CXL way or the Gen-Z way. Considering that memory can account for half of the cost of a server at a hyperscaler, anything that allows a machine to have a minimal amount of capacity on the node and then share the rest in the rack with all of it being transparent to the operating system and all of it looking local will be adopted. There is just no question about that. Memory area networks, in one fashion or another, are going to be common in datacenters before too long, and this will be driven by economics.","title":"Notes on HPC"},{"location":"Notes%20on%20HPC/#load-store-architecture","text":"A load\u2013store architecture is an instruction set architecture that divides instructions into two categories: memory access (load and store between memory and registers) and ALU operations (which only occur between registers). For instance, in a load\u2013store approach both operands and destination for an ADD operation must be in registers. This differs from a register-memory architecture (for example, a CISC instruction set architecture such as x86) in which one of the operands for the ADD operation may be in memory, while the other is in a register. https://www.sciencedirect.com/topics/computer-science/load-store-architecture https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture","title":"Load Store Architecture"},{"location":"Notes%20on%20HPC/#fabric-attached-memory","text":"See Fabric Attached Memory","title":"Fabric Attached Memory"},{"location":"Notes%20on%20HPC/#cxl","text":"See Compute Express Link","title":"CXL"},{"location":"Notes%20on%20HPC/#radix","text":"https://github.com/HewlettPackard/meadowlark https://ieeexplore.ieee.org/document/6307777","title":"Radix"},{"location":"Notes%20on%20HPC/#things-to-investigate","text":"https://www.techpowerup.com/292256/amd-details-its-3d-v-cache-design-at-isscc","title":"Things to investigate"},{"location":"Notes%20on%20HPC/chiplet_based_systems/","text":"Chiplet-Based Systems Return to HPC Notes README.md What is the problem Moore's Low is slowing Manufacturing costs are rising You could make larger chips to increase performance but: They are more expensive to make Verification costs are higher Manufacturing defects in densely packed logic reduce wafer yield You could create specialized chips but it is difficult to make a financial case for that What are chiplet-based systems Chiplet-based systems propose the integration of multiple discrete chips within the same package via an integration technology such as a multi-chip module or silicon interposer. Ex: From: https://www.sigarch.org/chiplet-based-systems/ Why chiplets Cost Previously, chiplets weren't considered practical because you introduce multiple parts plus having to contend with on-dye communication between them. However, now the smaller chips have sufficiently cheap manufacturing costs (compared to larger) that this is a viable alternative. Flexibility If you want to move from mobile, to desktop, to server this may be a matter of just increasing the number of chiplets. It is also possible that if we develop the proper standards that we could have a future system where we have general interconnects which would allow multiple different vendor chiplets to work together. Ex: Common Heterogeneous Integration and IP Reuse Strategies (CHIPS) Questions What is process technology? A process technology is the process of creating a single chip. In this case, you could use older process technologies to create the chiplets and then put them together.","title":"Chiplet-Based Systems"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#chiplet-based-systems","text":"Return to HPC Notes README.md","title":"Chiplet-Based Systems"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#what-is-the-problem","text":"Moore's Low is slowing Manufacturing costs are rising You could make larger chips to increase performance but: They are more expensive to make Verification costs are higher Manufacturing defects in densely packed logic reduce wafer yield You could create specialized chips but it is difficult to make a financial case for that","title":"What is the problem"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#what-are-chiplet-based-systems","text":"Chiplet-based systems propose the integration of multiple discrete chips within the same package via an integration technology such as a multi-chip module or silicon interposer. Ex: From: https://www.sigarch.org/chiplet-based-systems/","title":"What are chiplet-based systems"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#why-chiplets","text":"","title":"Why chiplets"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#cost","text":"Previously, chiplets weren't considered practical because you introduce multiple parts plus having to contend with on-dye communication between them. However, now the smaller chips have sufficiently cheap manufacturing costs (compared to larger) that this is a viable alternative.","title":"Cost"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#flexibility","text":"If you want to move from mobile, to desktop, to server this may be a matter of just increasing the number of chiplets. It is also possible that if we develop the proper standards that we could have a future system where we have general interconnects which would allow multiple different vendor chiplets to work together. Ex: Common Heterogeneous Integration and IP Reuse Strategies (CHIPS)","title":"Flexibility"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#questions","text":"","title":"Questions"},{"location":"Notes%20on%20HPC/chiplet_based_systems/#what-is-process-technology","text":"A process technology is the process of creating a single chip. In this case, you could use older process technologies to create the chiplets and then put them together.","title":"What is process technology?"},{"location":"Notes%20on%20HPC/cxl/","text":"Compute Express Link (CXL) Return to HPC Notes README.md Compute Express Link (CXL) Useful Resources Examples of Vendor Interconnects More Specific Interconnects What is the Purpose of CXL? Protocols Devices Type 1 Device Type 2 Device Type 3 Device Memory Pooling Switching Useful Resources Interesting article on roadmap: https://www.nextplatform.com/2021/09/07/the-cxl-roadmap-opens-up-the-memory-hierarchy/ Deep Dive: https://www.nextplatform.com/2019/09/18/eating-the-interconnect-alphabet-soup-with-intels-cxl/ Examples of Vendor Interconnects Intel's Compute Express Link (CXL) IBM's Coherent Accelerator Interface (CAPI) Xilinx's Cache Coherence Interconnect for Accelerators (CCIX) AMD's Infinity Fabric More Specific Interconnects Nvidia's NVLink IBM's OpenCAPI HPE's Gen-Z: It can be used to hook anything from DRAM to flash to accelerators in meshes with any manner of CPU. What is the Purpose of CXL? The primary purpose is to disaggregate I/O and memory and to effectively virtualize the motherboard to make the following malleable across clusters of components: - Compute, memory, and I/O - Computational offload to devices such as GPU and FPGA accelerators - Memory buffers and other kinds of devices such as SmartNICs CXL is a set of sub-protocols that ride on the PCI-Express bus on a single link Protocols CXL.io: This sub-protocol is functionally equivalent to the PCIe 5.0 protocol and utilizes the broad industry adoption and familiarity of PCIe. It is effectively the PCIe transaction layer reformatted to allow two sub-protocols to co-exist side by side. CXL.io is used to discover devices in systems, manage interrupts, give access to registers, handle initialization, and deal with signaling errors. CXL.cache: This sub-protocol, which is designed for more specific applications, enables accelerators to efficiently access and cache host memory for optimized performance. It allows an accelerator to access the CPU's DRAM. CXL.memory: This sub-protocol enables a host, such as a processor, to access device-attached memory using load/store commands. It is not expected that all three protocols are used in all configurations. There are three basic usage templates which represent the three usages expected: From https://www.servethehome.com/compute-express-link-cxl-2-0-specification-released-the-big-one/cxl-1-0-and-1-1-usages/ Devices Type 1 Device Accelerators such as smart NICs typically lack local memory. However, they can leverage the CXL.io protocol and CXL.cache to communicate with the host processors DDR memory. Type 2 Device The idea here is there is memory (like HBM or DDR) on the accelerator (GPUs, ASICs, FPGAs, etc) and you want the accelerator's memory to be locally available to the CPU and the CPU's memory to be locally available to the accelerator. The CXL.io protocol is used to allow the CPU to discover the device and configure it and then you use the CXL.cache to allow the processor to touch the device\u2019s memory and CXL.memory to allow the accelerator to touch the CPU's memory. This memory should be co-located in the same cache coherent domain. Type 3 Device The CXL.io and CXL.memory protocols can be leveraged for memory expansion and pooling. For example, a buffer attached to the CXL bus could be used to enable DRAM capacity expansion, augmenting memory bandwidth, or adding persistent memory without the loss of DRAM slots. In real world terms, this means the high-speed, low-latency storage devices that would have previously displaced DRAM can instead complement it with CXL-enabled devices. These could include non-volatile technologies in various form factors such as add-in cards, U.2, and EDSFF. For type 3 devices you need the CXL.io sub-protocol to discover and configure the device and the CXL.memory sub-protocol to allow the CPU to reach into the memory attached to your memory buffer. WHERE I LEFT OFF : Left off studying symmetric cache coherency protocols vs asymmetric on this article: https://www.nextplatform.com/2019/09/18/eating-the-interconnect-alphabet-soup-with-intels-cxl/ Memory Pooling CXL 2.0 supports switching to enable memory pooling. With a CXL 2.0 switch, a host can access one or more devices from the pool. Although the hosts must be CXL 2.0-enabled to leverage this capability, the memory devices can be a mix of CXL 1.0, 1.1, and 2.0-enabled hardware. At 1.0/1.1, a device is limited to behaving as a single logical device accessible by only one host at a time. However, a 2.0 level device can be partitioned as multiple logical devices, allowing up to 16 hosts to simultaneously access different portions of the memory. As an example, a host 1 (H1) can use half the memory in device 1 (D1) and a quarter of the memory in device 2 (D2) to finely match the memory requirements of its workload to the available capacity in the memory pool. The remaining capacity in devices D1 and D2 can be used by one or more of the other hosts up to a maximum of 16. Devices D3 and D4, CXL 1.0 and 1.1-enabled respectively, can be used by only one host at a time. Switching By moving to a CXL 2.0 direct-connect architecture, data centers can achieve the performance benefits of main memory expansion\ufffdand the efficiency and total cost of ownership (TCO) benefits of pooled memory. Assuming all hosts and devices are CXL 2.0-enabled, \ufffdswitching is incorporated into the memory devices via a crossbar in the CXL memory pooling chip. This keeps latency low but requires a more powerful chip since it is now responsible for the control plane functionality performed by the switch. With low-latency direct connections, attached memory devices can employ DDR DRAM to provide expansion of host main memory. This can be done on a very flexible basis, as a host is able to access all\ufffdor portions of\ufffdthe capacity of as many devices as needed to tackle a specific workload.","title":"Compute Express Link (CXL)"},{"location":"Notes%20on%20HPC/cxl/#compute-express-link-cxl","text":"Return to HPC Notes README.md Compute Express Link (CXL) Useful Resources Examples of Vendor Interconnects More Specific Interconnects What is the Purpose of CXL? Protocols Devices Type 1 Device Type 2 Device Type 3 Device Memory Pooling Switching","title":"Compute Express Link (CXL)"},{"location":"Notes%20on%20HPC/cxl/#useful-resources","text":"Interesting article on roadmap: https://www.nextplatform.com/2021/09/07/the-cxl-roadmap-opens-up-the-memory-hierarchy/ Deep Dive: https://www.nextplatform.com/2019/09/18/eating-the-interconnect-alphabet-soup-with-intels-cxl/","title":"Useful Resources"},{"location":"Notes%20on%20HPC/cxl/#examples-of-vendor-interconnects","text":"Intel's Compute Express Link (CXL) IBM's Coherent Accelerator Interface (CAPI) Xilinx's Cache Coherence Interconnect for Accelerators (CCIX) AMD's Infinity Fabric","title":"Examples of Vendor Interconnects"},{"location":"Notes%20on%20HPC/cxl/#more-specific-interconnects","text":"Nvidia's NVLink IBM's OpenCAPI HPE's Gen-Z: It can be used to hook anything from DRAM to flash to accelerators in meshes with any manner of CPU.","title":"More Specific Interconnects"},{"location":"Notes%20on%20HPC/cxl/#what-is-the-purpose-of-cxl","text":"The primary purpose is to disaggregate I/O and memory and to effectively virtualize the motherboard to make the following malleable across clusters of components: - Compute, memory, and I/O - Computational offload to devices such as GPU and FPGA accelerators - Memory buffers and other kinds of devices such as SmartNICs CXL is a set of sub-protocols that ride on the PCI-Express bus on a single link","title":"What is the Purpose of CXL?"},{"location":"Notes%20on%20HPC/cxl/#protocols","text":"CXL.io: This sub-protocol is functionally equivalent to the PCIe 5.0 protocol and utilizes the broad industry adoption and familiarity of PCIe. It is effectively the PCIe transaction layer reformatted to allow two sub-protocols to co-exist side by side. CXL.io is used to discover devices in systems, manage interrupts, give access to registers, handle initialization, and deal with signaling errors. CXL.cache: This sub-protocol, which is designed for more specific applications, enables accelerators to efficiently access and cache host memory for optimized performance. It allows an accelerator to access the CPU's DRAM. CXL.memory: This sub-protocol enables a host, such as a processor, to access device-attached memory using load/store commands. It is not expected that all three protocols are used in all configurations. There are three basic usage templates which represent the three usages expected: From https://www.servethehome.com/compute-express-link-cxl-2-0-specification-released-the-big-one/cxl-1-0-and-1-1-usages/","title":"Protocols"},{"location":"Notes%20on%20HPC/cxl/#devices","text":"","title":"Devices"},{"location":"Notes%20on%20HPC/cxl/#type-1-device","text":"Accelerators such as smart NICs typically lack local memory. However, they can leverage the CXL.io protocol and CXL.cache to communicate with the host processors DDR memory.","title":"Type 1 Device"},{"location":"Notes%20on%20HPC/cxl/#type-2-device","text":"The idea here is there is memory (like HBM or DDR) on the accelerator (GPUs, ASICs, FPGAs, etc) and you want the accelerator's memory to be locally available to the CPU and the CPU's memory to be locally available to the accelerator. The CXL.io protocol is used to allow the CPU to discover the device and configure it and then you use the CXL.cache to allow the processor to touch the device\u2019s memory and CXL.memory to allow the accelerator to touch the CPU's memory. This memory should be co-located in the same cache coherent domain.","title":"Type 2 Device"},{"location":"Notes%20on%20HPC/cxl/#type-3-device","text":"The CXL.io and CXL.memory protocols can be leveraged for memory expansion and pooling. For example, a buffer attached to the CXL bus could be used to enable DRAM capacity expansion, augmenting memory bandwidth, or adding persistent memory without the loss of DRAM slots. In real world terms, this means the high-speed, low-latency storage devices that would have previously displaced DRAM can instead complement it with CXL-enabled devices. These could include non-volatile technologies in various form factors such as add-in cards, U.2, and EDSFF. For type 3 devices you need the CXL.io sub-protocol to discover and configure the device and the CXL.memory sub-protocol to allow the CPU to reach into the memory attached to your memory buffer. WHERE I LEFT OFF : Left off studying symmetric cache coherency protocols vs asymmetric on this article: https://www.nextplatform.com/2019/09/18/eating-the-interconnect-alphabet-soup-with-intels-cxl/","title":"Type 3 Device"},{"location":"Notes%20on%20HPC/cxl/#memory-pooling","text":"CXL 2.0 supports switching to enable memory pooling. With a CXL 2.0 switch, a host can access one or more devices from the pool. Although the hosts must be CXL 2.0-enabled to leverage this capability, the memory devices can be a mix of CXL 1.0, 1.1, and 2.0-enabled hardware. At 1.0/1.1, a device is limited to behaving as a single logical device accessible by only one host at a time. However, a 2.0 level device can be partitioned as multiple logical devices, allowing up to 16 hosts to simultaneously access different portions of the memory. As an example, a host 1 (H1) can use half the memory in device 1 (D1) and a quarter of the memory in device 2 (D2) to finely match the memory requirements of its workload to the available capacity in the memory pool. The remaining capacity in devices D1 and D2 can be used by one or more of the other hosts up to a maximum of 16. Devices D3 and D4, CXL 1.0 and 1.1-enabled respectively, can be used by only one host at a time.","title":"Memory Pooling"},{"location":"Notes%20on%20HPC/cxl/#switching","text":"By moving to a CXL 2.0 direct-connect architecture, data centers can achieve the performance benefits of main memory expansion\ufffdand the efficiency and total cost of ownership (TCO) benefits of pooled memory. Assuming all hosts and devices are CXL 2.0-enabled, \ufffdswitching is incorporated into the memory devices via a crossbar in the CXL memory pooling chip. This keeps latency low but requires a more powerful chip since it is now responsible for the control plane functionality performed by the switch. With low-latency direct connections, attached memory devices can employ DDR DRAM to provide expansion of host main memory. This can be done on a very flexible basis, as a host is able to access all\ufffdor portions of\ufffdthe capacity of as many devices as needed to tackle a specific workload.","title":"Switching"},{"location":"Notes%20on%20HPC/fabric_attached_memory/","text":"Fabric Attached Memory Return to README.md Fabric Attached Memory Resources What is it What Problem is it Solving The Future of FAM Questions: Resources Broad overview: https://itigic.com/fabric-attached-memory-is-not-ram-or-cache-in-cpu/ The Machine background information: https://github.com/FabricAttachedMemory/Emulation/wiki How the emulation for the Machine works: https://github.com/FabricAttachedMemory/Emulation/wiki/Emulation-via-Virtual-Machines What is it FAM is a type of scratchpad memory. Scratchpad memory is memory that resides inside the processor (usually). This brings with it two obvious benefits: Programs that run inside scratchpad memory run faster due to the low distance to the processor and with lower power consumption Due to its proximity to the processor, a cache system is not needed to access said memory The difference between regular scratchpad memory and FAM is that FAM uses some network interface to communicate. What Problem is it Solving The main problem with main memory is that the increased wire distance leads to a large increase in power. FAM seeks to solve this by moving it closer to the processor. It also allows processors to directly share information (or at least not have to write it to main memory and then recover it) by instead writing to FAM which is located between the last level cache and the interface to RAM for each of them. The Future of FAM To understand this part you will need to understand chiplets The best solution is a chiplet-based system where the Northbridge is disconnected from the rest of the system, as is the case in AMD\u2018s Ryzen 3000 and Ryzen 5000 CPUs. FAM, by its nature should have more capacity than the fastest cache but less than RAM. With the northbridge on a separate chip you can integrate FAM into it. However this is difficult to do on 2D chip so instead it would be preferable to use a 3D chip with the northbridge on one level and FAM on the others. Questions: Why is it difficult to integrate FAM onto a 2D chip?","title":"Fabric Attached Memory"},{"location":"Notes%20on%20HPC/fabric_attached_memory/#fabric-attached-memory","text":"Return to README.md Fabric Attached Memory Resources What is it What Problem is it Solving The Future of FAM Questions:","title":"Fabric Attached Memory"},{"location":"Notes%20on%20HPC/fabric_attached_memory/#resources","text":"Broad overview: https://itigic.com/fabric-attached-memory-is-not-ram-or-cache-in-cpu/ The Machine background information: https://github.com/FabricAttachedMemory/Emulation/wiki How the emulation for the Machine works: https://github.com/FabricAttachedMemory/Emulation/wiki/Emulation-via-Virtual-Machines","title":"Resources"},{"location":"Notes%20on%20HPC/fabric_attached_memory/#what-is-it","text":"FAM is a type of scratchpad memory. Scratchpad memory is memory that resides inside the processor (usually). This brings with it two obvious benefits: Programs that run inside scratchpad memory run faster due to the low distance to the processor and with lower power consumption Due to its proximity to the processor, a cache system is not needed to access said memory The difference between regular scratchpad memory and FAM is that FAM uses some network interface to communicate.","title":"What is it"},{"location":"Notes%20on%20HPC/fabric_attached_memory/#what-problem-is-it-solving","text":"The main problem with main memory is that the increased wire distance leads to a large increase in power. FAM seeks to solve this by moving it closer to the processor. It also allows processors to directly share information (or at least not have to write it to main memory and then recover it) by instead writing to FAM which is located between the last level cache and the interface to RAM for each of them.","title":"What Problem is it Solving"},{"location":"Notes%20on%20HPC/fabric_attached_memory/#the-future-of-fam","text":"To understand this part you will need to understand chiplets The best solution is a chiplet-based system where the Northbridge is disconnected from the rest of the system, as is the case in AMD\u2018s Ryzen 3000 and Ryzen 5000 CPUs. FAM, by its nature should have more capacity than the fastest cache but less than RAM. With the northbridge on a separate chip you can integrate FAM into it. However this is difficult to do on 2D chip so instead it would be preferable to use a 3D chip with the northbridge on one level and FAM on the others.","title":"The Future of FAM"},{"location":"Notes%20on%20HPC/fabric_attached_memory/#questions","text":"Why is it difficult to integrate FAM onto a 2D chip?","title":"Questions:"},{"location":"Notes%20on%20HSM/","text":"Notes on HSM How Does HSM for Manufacturing Work? The process of creating a trusted baseline of the server's firmware and hardware components involves measuring the components and creating a hash of the measurements. The measurements can be taken at various stages of the server's lifecycle, such as during manufacturing, configuration, or deployment. The measurements can include data such as the firmware version, BIOS settings, boot configuration, hardware components, and other system settings. These measurements are then stored securely in a trusted repository, such as an HSM. When the server is booted up, the measurements of the current firmware and hardware components are taken and hashed. These current measurements are then compared to the measurements stored in the trusted repository. If the current measurements match the trusted baseline, it indicates that the server is running in a trusted state and has not been tampered with. If the measurements do not match, it suggests that the firmware or hardware components have been modified, and the server may not be running in a trusted state. Overall, the process of creating a trusted baseline, measuring the firmware and hardware components, and comparing them to the trusted baseline is used to ensure the integrity and authenticity of the server's components, and to provide assurance that the server is running in a trusted state. This is an important part of a security strategy, particularly in environments where data security and privacy are critical.","title":"Notes on HSM"},{"location":"Notes%20on%20HSM/#notes-on-hsm","text":"","title":"Notes on HSM"},{"location":"Notes%20on%20HSM/#how-does-hsm-for-manufacturing-work","text":"The process of creating a trusted baseline of the server's firmware and hardware components involves measuring the components and creating a hash of the measurements. The measurements can be taken at various stages of the server's lifecycle, such as during manufacturing, configuration, or deployment. The measurements can include data such as the firmware version, BIOS settings, boot configuration, hardware components, and other system settings. These measurements are then stored securely in a trusted repository, such as an HSM. When the server is booted up, the measurements of the current firmware and hardware components are taken and hashed. These current measurements are then compared to the measurements stored in the trusted repository. If the current measurements match the trusted baseline, it indicates that the server is running in a trusted state and has not been tampered with. If the measurements do not match, it suggests that the firmware or hardware components have been modified, and the server may not be running in a trusted state. Overall, the process of creating a trusted baseline, measuring the firmware and hardware components, and comparing them to the trusted baseline is used to ensure the integrity and authenticity of the server's components, and to provide assurance that the server is running in a trusted state. This is an important part of a security strategy, particularly in environments where data security and privacy are critical.","title":"How Does HSM for Manufacturing Work?"},{"location":"Notes%20on%20Improving%20Drive%20Performance/","text":"Notes on Improving Drive Performance Located NUMA Nodes https://community.mellanox.com/s/article/understanding-numa-node-for-performance-benchmarks Definition of Drive Stats","title":"Notes on Improving Drive Performance"},{"location":"Notes%20on%20Improving%20Drive%20Performance/#notes-on-improving-drive-performance","text":"","title":"Notes on Improving Drive Performance"},{"location":"Notes%20on%20Improving%20Drive%20Performance/#located-numa-nodes","text":"https://community.mellanox.com/s/article/understanding-numa-node-for-performance-benchmarks","title":"Located NUMA Nodes"},{"location":"Notes%20on%20Improving%20Drive%20Performance/#definition-of-drive-stats","text":"","title":"Definition of Drive Stats"},{"location":"Notes%20on%20NVMe%20Log%20Pages/","text":"Notes on NVMe Log Pages Notes on NVMe Log Pages Quick Overview My Test Drive Get Log Page Identifiers Error Information (01h) Sample Output SMART / Health Information (02h) Sample Output Firmware Slot Information (03h) Sample Output Changed Namespace List (04h) Commands Supported and Effects (05h) Sample Output Device Self-test (06h) Telemetry Host-Initiated (07h) Notes on Telemetry Sample Output Telemetry Controller-Initiated (08h) Notes on Telemetry Sample Output Endurance Group Information (09h) Predictable Latency Per NVM Set (0Ah) Predictable Latency Event Aggregate Log Page (0Bh) Asymmetric Namespace Access (0Ch) Persistent Event Log (0Dh) Endurance Group Event Aggregate (0Fh) Media Unit Status (10h) Supported Capacity Configuration List (11h) Feature Identifiers Supported and Effects (12h) NVMe-MI Commands Supported and Effects (13h) Command and Feature Lockdown (14h) Boot Partition (15h) Rotational Media Information Log (16h) Discovery Log Page (70h) Command Syntax Reservation Notification (80h) Sanitize Status (81h) Command Syntax Other NVMe CLI Commands List All NVMe Drives Quick Overview See this excel document My Test Drive [root@r8402 ~]# nvme id-ctrl /dev/nvme0n1 NVME Identify Controller: vid : 0x8086 ssvid : 0x1028 sn : PHLN939602VB3P2BGN mn : Dell Express Flash NVMe P4610 3.2TB SFF fr : VDV1DP25 rab : 0 ieee : 5cd2e4 cmic : 0 mdts : 5 cntlid : 0 ver : 0x10200 rtd3r : 0x989680 rtd3e : 0xe4e1c0 oaes : 0x200 ctratt : 0 rrls : 0 cntrltype : 0 fguid : crdt1 : 0 crdt2 : 0 crdt3 : 0 oacs : 0x6 acl : 3 aerl : 3 frmw : 0x18 lpa : 0xe elpe : 63 npss : 0 avscc : 0 apsta : 0 wctemp : 343 cctemp : 349 mtfa : 0 hmpre : 0 hmmin : 0 tnvmcap : 3200631791616 unvmcap : 0 rpmbs : 0 edstt : 0 dsto : 0 fwug : 0 kas : 0 hctma : 0 mntmt : 0 mxtmt : 0 sanicap : 0 hmminds : 0 hmmaxd : 0 nsetidmax : 0 endgidmax : 0 anatt : 0 anacap : 0 anagrpmax : 0 nanagrpid : 0 pels : 0 sqes : 0x66 cqes : 0x44 maxcmd : 0 nn : 1 oncs : 0x6 fuses : 0 fna : 0x4 vwc : 0 awun : 0 awupf : 0 icsvscc : 0 nwpc : 0 acwu : 0 sgls : 0 mnan : 0 subnqn : ioccsz : 0 iorcsz : 0 icdoff : 0 fcatt : 0 msdbd : 0 ofcs : 0 ps 0 : mp:25.00W operational enlat:0 exlat:0 rrt:0 rrl:0 rwt:0 rwl:0 idle_power:- active_power:- Get Log Page Identifiers NVMe Express Base Specification Error Information (01h) This log page is used to describe extended error information for a command that completed with error or report an error that is not specific to a particular command. Extended error information is provided when the More (M) bit is set to \u20181\u2019 in the Status Field for the completion queue entry associated with the command that completed with error or as part of an asynchronous event with an Error status type. This log page is global to the controller. This error log may return the last n errors. If host software specifies a data transfer of the size of n error logs, then the error logs for the most recent n errors are returned. The ordering of the entries is based on the time when the error occurred, with the most recent error being returned as the first log entry. Each entry in the log page returned is defined in Figure 206. The log page is a set of 64-byte entries; the maximum number of entries supported is indicated in the ELPE field in the Identify Controller data structure (refer to Figure 275). If the log page is full when a new entry is generated, the controller should insert the new entry into the log and discard the oldest entry. The controller should clear this log page by removing all entries on power cycle and Controller Level Reset. See page 178 for a description. Sample Output [root@r8402 ~]# nvme error-log /dev/nvme0n1 Error Log Entries for device:nvme0n1 entries:64 ................. Entry[ 0] ................. error_count : 0 sqid : 0 cmdid : 0 status_field : 0(SUCCESS: The command completed successfully) phase_tag : 0 parm_err_loc : 0 lba : 0 nsid : 0 vs : 0 trtype : The transport type is not indicated or the error is not transport related. cs : 0 trtype_spec_info: 0 ................. ...SNIP... Entry[63] ................. error_count : 0 sqid : 0 cmdid : 0 status_field : 0(SUCCESS: The command completed successfully) phase_tag : 0 parm_err_loc : 0 lba : 0 nsid : 0 vs : 0 trtype : The transport type is not indicated or the error is not transport related. cs : 0 trtype_spec_info: 0 ................. SMART / Health Information (02h) This log page is used to provide SMART and general health information. The information provided is over the life of the controller and is retained across power cycles. To request the controller log page, the namespace identifier specified is FFFFFFFFh or 0h. For compatibility with implementations compliant with NVM Express Base Specification revision 1.4 and earlier, hosts should use a namespace identifier of FFFFFFFFh to request the controller log page. The controller may also support requesting the log page on a per namespace basis, as indicated by bit 0 of the LPA field in the Identify Controller data structure in Figure 275. See page 180 for a description. Sample Output [root@r8402 ~]# nvme smart-log /dev/nvme0n1 Smart Log for NVME device:nvme0n1 namespace-id:ffffffff critical_warning : 0 temperature : 26 C available_spare : 100% available_spare_threshold : 10% percentage_used : 0% endurance group critical warning summary: 0 data_units_read : 4,002,753 data_units_written : 255,875,492 host_read_commands : 45,714,473 host_write_commands : 1,620,770,593 controller_busy_time : 372 power_cycles : 150 power_on_hours : 5,219 unsafe_shutdowns : 99 media_errors : 0 num_err_log_entries : 0 Warning Temperature Time : 0 Critical Composite Temperature Time : 0 Thermal Management T1 Trans Count : 0 Thermal Management T2 Trans Count : 0 Thermal Management T1 Total Time : 0 Thermal Management T2 Total Time : 0 Firmware Slot Information (03h) This log page is used to describe the firmware revision stored in each firmware slot supported. The firmware revision is indicated as an ASCII string. The log page also indicates the active slot number. The log page returned is defined in Figure 209 Sample Output [root@r8402 ~]# nvme fw-log /dev/nvme0n1 Firmware Log for device:nvme0n1 afi : 0x1 frs1 : 0x3532504431564456 (VDV1DP25) frs2 : 0x3532504431564456 (VDV1DP25) NOTE AFI stands for active firmware version. Changed Namespace List (04h) NOTE This command is not currently supported because the drive currently only has one namespace. This log page is used to describe namespaces attached to the controller that have: changed information in their Identify Namespace data structures (refer to in Figure 146) since the last time the log page was read; been added; and been deleted. The log page contains a Namespace List with up to 1,024 entries. If more than 1,024 namespaces have changed attributes since the last time the log page was read, the first entry in the log page shall be set to FFFFFFFFh and the remainder of the list shall be zero filled. See page 184 for a description. Commands Supported and Effects (05h) This log page is used to describe the commands that the controller supports and the effects of those commands on the state of the NVM subsystem. The log page is 4,096 bytes in size. There is one Commands Supported and Effects data structure per Admin command and one Commands Supported and Effects data structure per I/O command based on: the I/O Command Set selected in CC.CSS, if CC.CSS is not set to 110b; and the Command Set Identifier field in CDW 14, if CC.CSS is set to 110b. See page 185 for a description. Sample Output [root@r8402 ~]# nvme effects-log /dev/nvme0n1 Admin Command Set ACS0 [Delete I/O Submission Queue ] 00000001 ACS1 [Create I/O Submission Queue ] 00020001 ACS2 [Get Log Page ] 00000001 ACS4 [Delete I/O Completion Queue ] 00000001 ACS5 [Create I/O Completion Queue ] 00020001 ACS6 [Identify ] 00000001 ACS8 [Abort ] 00000001 ACS9 [Set Features ] 0000001d ACS10 [Get Features ] 00000001 ACS12 [Asynchronous Event Request ] 00000001 ACS16 [Firmware Commit ] 00000011 ACS17 [Firmware Image Download ] 00000001 ACS128 [Format NVM ] 0002001f ACS200 [Unknown ] 00000001 ACS210 [Unknown ] 00000001 ACS225 [Unknown ] 0002000f ACS226 [Unknown ] 0002000f NVM Command Set IOCS0 [Flush ] 00000003 IOCS1 [Write ] 00000003 IOCS2 [Read ] 00000001 IOCS4 [Write Uncorrectable ] 00000003 IOCS9 [Dataset Management ] 00000003 Device Self-test (06h) NOTE : This command is not currently supported. TODO This log page is used to indicate: the status of any device self-test operation in progress and the percentage complete of that operation; and the results of the last 20 device self-test operations. The Self-test Result Data Structure contained in the Newest Self-test Result Data Structure field is always the result of the last completed or aborted self-test operation. The next Self-test Result Data Structure field in the Device Self-test log page contains the results of the second newest self-test operation and so on. If fewer than 20 self-test operations have completed or been aborted, then the Device Self-test Status field shall be set to Fh in the unused Self-test Result Data Structure fields and all other fields in that Self-test Result Data Structure are ignored. See page 187 for additional information. Telemetry Host-Initiated (07h) This log consists of a header describing the log and zero or more Telemetry Data Blocks (refer to section 8.24). All Telemetry Data Blocks are 512 bytes in size. The controller shall initiate a capture of the controller\u2019s internal controller state to this log if the controller processes a Get Log Page command for this log with the Create Telemetry Host-Initiated Data bit set to \u20181\u2019 in the Log Specific field. If the host specifies a Log Page Offset Lower value that is not a multiple of 512 bytes in the Get Log Page command for this log, then the controller shall return an error with a status code set to Invalid Field in Command. This log page is global to the controller or global to the NVM subsystem. See page 189 for additional information. Notes on Telemetry See page 422 for additional details. Telemetry enables manufacturers to collect internal data logs to improve the functionality and reliability of products. The telemetry data collection may be initiated by the host or by the controller. The data is returned in the Telemetry Host-Initiated log page or the Telemetry Controller-Initiated log page (refer to section 5.16.1.8 and 5.16.1.9). The data captured is vendor specific. The telemetry feature defines the mechanism to collect the vendor specific data. The controller indicates support for the telemetry log pages and for the Data Area 4 size in the Log Page Attributes (LPA) field in the Identify Controller data structure (refer to Figure 275). Sample Output nvme telemetry-log --output-file /root/test.log --host-generate=1 /dev/nvme0n1 Telemetry Controller-Initiated (08h) Telemetry enables manufacturers to collect internal data logs to improve the functionality and reliability of products. The telemetry data collection may be initiated by the host or by the controller. The data is returned in the Telemetry Host-Initiated log page or the Telemetry Controller-Initiated log page (refer to section 5.16.1.8 and 5.16.1.9). The data captured is vendor specific. The telemetry feature defines the mechanism to collect the vendor specific data. The controller indicates support for the telemetry log pages and for the Data Area 4 size in the Log Page Attributes (LPA) field in the Identify Controller data structure (refer to Figure 275). See page 191 for additional information. Notes on Telemetry See Notes on Telemetry Sample Output nvme telemetry-log --output-file /root/test.log --host-generate=0 /dev/nvme0n1 Endurance Group Information (09h) NOTE This command is not currently supported because there is only one endurance group (endgidmax=0) This log page is used to provide endurance information based on the Endurance Group (refer to section 3.2.3). An Endurance Group contains capacity that may be allocated to zero or more NVM Sets. Capacity that has not been allocated to an NVM Set is unallocated Endurance Group capacity. The information provided is over the life of the Endurance Group. The Endurance Group Identifier is specified in the Log Specific Identifier field in Command Dword 11 of the Get Log Page command. The log page is 512 bytes in size. See page 193 for additional information. Predictable Latency Per NVM Set (0Ah) NOTE This log is not supported because the drives only support one NVM Set. This log page may be used to determine the current window for the specified NVM Set when Predictable Latency Mode is enabled and any events that have occurred for the specified NVM Set. There is one log page for each NVM Set when Predictable Latency Mode is supported. Command Dword 11 (refer to Figure 198) specifies the NVM Set for which the log page is to be returned. The log page is 512 bytes in size. The log page indicates typical values and reliable estimates for attributes associated with the Deterministic Window and the Non-Deterministic Window of the specified NVM Set. The Typical, Maximum, and Minimum values are static and worst-case values over the lifetime of the NVM subsystem. After the controller successfully completes a read of this log page with Retain Asynchronous Event bit cleared to \u20180\u2019, then reported events are cleared to \u20180\u2019 for the specified NVM Set and the field corresponding to the specified NVM Set is cleared to \u20180\u2019 in the Predictable Latency Event Aggregate log page. Coordination between two or more hosts is beyond the scope of this specification. See page 195 for additional information. Predictable Latency Event Aggregate Log Page (0Bh) NOTE This log page indicates if a Predictable Latency Event (refer to section 8.16) has occurred for a particular NVM Set. If a Predictable Latency Event has occurred, the details of the particular event are included in the Predictable Latency Per NVM Set log page for that NVM Set. An asynchronous event is generated when an entry for an NVM Set is newly added to this log page. This log page shall not contain an entry (i.e., an NVM Set Identifier) that is cleared to 0h. If there is an enabled Predictable Latency Event pending for an NVM Set, then the Predictable Latency Event Aggregate log page includes an entry for that NVM Set. The log page is an ordered list by NVM Set Identifier. For example, if Predictable Latency Events are pending for NVM Set 27, 13, and 17, then the log page shall have entries in numerical order of 13, 17, and 27. A particular NVM Set is removed from this log page after the Get Log Page is completed successfully with the Retain Asynchronous Event bit cleared to \u20180\u2019 for the Predictable Latency Per NVM Set log page for that NVM Set. See page 196 for details. Asymmetric Namespace Access (0Ch) NOTE This log is not supported because there is only one namespace on the drive. This log consists of a header describing the log and descriptors containing the asymmetric namespace access information for ANA Groups (refer to section 8.1.2) that contain namespaces that are attached to the controller processing the command. If ANA Reporting (refer to section 8.1) is supported, this log page is supported. ANA Group Descriptors shall be returned in ascending ANA Group Identifier order. If the Index Offset Supported bit is cleared to \u20180\u2019 in the LID Support and Effects data structure for this log page (refer to Figure 204), then: if the RGO bit is cleared to \u20180\u2019 in Command Dword 10, then the LPOL field in Command Dword 12 and the LPOU field in Command Dword 13 of the Get Log Page command should be cleared to 0h. If the Index Offset Supported bit is set to \u20181\u2019 in the LID Supported and Effects data structure for this log page (refer to Figure 204), then: the entry data structure that is indexed is an ANA Group Descriptor (e.g., specifying an index offset of 2 returns this log page starting at the offset of ANA Group Descriptor 1). If the host performs multiple Get Log Page commands to read the ANA log page (e.g., using the LPOL field or the LPOU field), the host should re-read the header of the log page and ensure that the Change Count field in the Asymmetric Namespace Access log matches the original value read. If it does not match, then the data captured is not consistent and the ANA log page should be re-read. See page 197 for details. Persistent Event Log (0Dh) NOTE TODO The Persistent Event Log page contains information about significant events not specific to a particular command. The information in this log page shall be retained across power cycles and resets. NVM subsystems should be designed for minimal loss of event information upon power failure. This log consists of a header describing the log and zero or more Persistent Events (refer to section 5.16.1.14.1). This log page is global to the NVM subsystem. A sanitize operation may alter this log page (e.g., remove or modify events to prevent derivation of user data from log page information, refer to section 8.20). The events removed from this log page by a sanitize operation are unspecified. Persistent Event Log events specified in this section should be reported in an order such that more recent events are generally reported earlier in the log data than older events. The method by which the NVM subsystem determines the order in which events occurred is vendor specific. The number of events supported is vendor specific. The supported maximum size for the Persistent Event Log is indicated in the PELS field of the Identify Controller data structure (refer to Figure 275). The number of events supported and the supported maximum size should be large enough that the number of events or the size of the Persistent Event Log data does not reach the maximum supported size over the usable life of the NVM subsystem. The controller shall log all supported events at each event occurrence unless the controller determines that the same event is occurring at a frequency that exceeds a vendor specific threshold for the frequency of event creation. If the same event is occurring at a frequency that exceeds a vendor specific threshold then the vendor may suppress further entries for the same event. A controller may indicate if events have been suppressed in vendor specific event data. See page 199 for details. Endurance Group Event Aggregate (0Fh) NOTE This is not supported because endurance groups are not in use. This log page indicates if an Endurance Group Event (refer to section 3.2.3) has occurred for a particular Endurance Group. If an Endurance Group Event has occurred, the details of the particular event are included in the Endurance Group Information log page for that Endurance Group. An asynchronous event is generated when an entry for an Endurance Group is newly added to this log page. If there is an enabled Endurance Group Event pending for an Endurance Group, then the Endurance Group Event Aggregate log page includes an entry for that Endurance Group. The log page is an ordered list by Endurance Group Identifier. For example, if Endurance Group Events are pending for Endurance Group 2, 1, and 7, then the log page shall have entries in numerical order of 1, 2, and 7. A particular Endurance Group entry is removed from this log page after the Get Log Page is completed successfully with the Retain Asynchronous Event bit cleared to \u20180\u2019 for the Endurance Group Information log page for that Endurance Group. The log page size is limited by the Endurance Group Identifier Maximum value reported in the Identify Controller data structure (refer to Figure 275). If the host reads beyond the end of the log page, zeroes are returned. The log page is defined in Figure 247. See page 220 for details. Media Unit Status (10h) NOTE This page is not supported because it is used for NVM sets which are not in use. This log page is used to describe the configuration and wear of Media Units (refer to section 8.3). The log page contains one Media Unit Status Descriptor for each Media Unit accessible by the specified domain. Each Media Unit Status Descriptor (refer to Figure 249) indicates the configuration of the Media Unit (e.g., to which Endurance Group the Media Unit is assigned, to which NVM Set the Media Unit is assigned, to which Channels the Media Unit is attached) and indications of wear (e.g., the Available Spare field and the Percentage Used field). The indications of wear change as the Media Unit is written and read. If the NVM subsystem supports multiple domains, then the controller reports the Media Unit Status log page for the domain specified in the Log Specific Identifier field (refer to Figure 198), if accessible. If the information is not accessible, then the log page is not available (refer to section 8.1.4). If the Log Specific Identifier field is cleared to 0h, then the specified domain is the domain containing the controller that is processing the command. Media Unit Identifier values (refer to Figure 249) begin with 0h and increase sequentially. If the NVM subsystem supports multiple domains, then the Media Unit Identifier values are unique within the specified domain. If the NVM subsystem does not support multiple domains, then the Media Unit Identifier values are unique within the NVM subsystem. Media Unit Status Descriptors are listed in ascending order by Media Unit Identifier. See page 220 for details. Supported Capacity Configuration List (11h) NOTE This log page is not available because the drives do not currently support multiple endurance groups. This log page is used to provide a list of Supported Capacity Configuration Descriptors (refer to Figure 250). Each entry in the list defines a different configuration of Endurance Groups supported by the specified domain. If the NVM subsystem supports multiple domains, then the controller reports the Supported Capacity Configuration List log page for the domain specified in the Log Specific Identifier field (refer to Figure 198), if accessible. If the information is not accessible, then the log page is not available (refer to section 8.1.3). If the Log Specific Identifier field is cleared to 0h, then the specified domain is the domain containing the controller that is processing the command. If the NVM subsystem supports multiple domains, then Capacity Configuration Identifier values are unique within the specified domain. If the NVM subsystem does not support multiple domains, then Capacity Configuration Identifier values are unique within the NVM subsystem. Capacity Configuration Descriptors are listed in ascending order by Capacity Configuration Identifier, and each Capacity Configuration Identifier shall appear only once. For details see page 222 Feature Identifiers Supported and Effects (12h) NOTE TODO An NVM subsystem may support several interfaces for submitting a Get Log Page command such as an Admin Submission Queue, PCIe VDM Management Endpoint, or SMBus/I2C Management Endpoint (refer the NVM Express Management Interface Specification for details on Management Endpoints) and may have zero or more instances of each of those interfaces. The feature identifiers (FIDs) supported on each instance of each interface may be different. This log page describes the FIDs that are supported on the interface to which the Get Log Page command was submitted and the effects of those features on the state of the NVM subsystem. The log page is defined in Figure 255. Each Feature Identifier\u2019s effects are described in a FID Supported and Effects data structure defined in Figure 256. The features that the controller supports are dependent on the I/O Command Set that is based on: - the I/O Command Set selected in CC.CSS, if CC.CSS is not set to 110b; and - the Command Set Identifier (CSI) field in CDW 14, if CC.CSS is set to 110b. For details see page 225 NVMe-MI Commands Supported and Effects (13h) This log page describes the Management Interface Command Set commands (refer to the NVMe Management Interface Specification ) that the controller supports using the NVMe-MI Send and NVMe-MI Receive commands and the effects of those Management Interface Command Set commands on the state of the NVM subsystem. The log page is defined in Figure 257. See page 227 for details. Command and Feature Lockdown (14h) NOTE This command is not supported. It is used for preventing certain commands for security purposes. It is not relevant to performance testing. This log page is used to indicate which commands and Set Features Feature Identifiers are supported to be prohibited from execution using the Command and Feature Lockdown capability (refer to section 8.4) and which commands are currently prohibited if received on an NVM Express controller Admin Submission Queue or received out-of-band on a Management Endpoint (refer to the NVM Express Management Interface Specification). This log page uses the Log Specific Field field (refer to Figure 259) and may use the UUID Index field in the Get Log Page command to specify the scope and content of the list returned in the Command and Feature Identifier List field of this log page. The UUID Index field may be used if the Scope field is set to 2h, allowing returning of vendor specific Set Features Feature Identifier lockdown information. See page 228 for details. Boot Partition (15h) NOTE This command is not supported and does not have any relevance to drive performance. It allows you to see the boot partition of the drive. The Boot Partition Log page provides read only access to the Boot Partition (refer to section 8.2) accessible by this controller through the BPRSEL register (refer to section 3.1.3.14). This log consists of a header describing the Boot Partition and Boot Partition data as defined by Figure 262. The Boot Partition Identifier bit in the Log Specific Field field determines the Boot Partition. A host reading this log page has no effects on the BPINFO (refer to section 3.1.3.13), BPRSEL, and BPMBL (refer to section 3.1.3.15) registers. See page 230 for details. Rotational Media Information Log (16h) NOTE This is specific to multiple endurance groups so it is not supported (since there is only one) This log page provides rotational media information (refer to section 8.20) for Endurance Groups that store data on rotational media. The information provided is retained across power cycles and resets. The Endurance Group Identifier is specified in the Log Specific Identifier field in Command Dword 11 of the Get Log Page command. If the NVM subsystem does not contain any Endurance Groups that store data on rotational media, then the Rotational Media Information Log should not be supported. See page 231 for details. Discovery Log Page (70h) NOTE This log page is not supported. It is specific to NVMe-over-Fabrics (ex: RDMA) The Discovery Log Page shall only be supported by Discovery controllers. The Discovery Log Page shall not be supported by controllers that expose namespaces for NVMe over PCIe or NVMe over Fabrics. The Discovery Log Page provides an inventory of NVM subsystems with which a host may attempt to form an association. The Discovery Log Page may be specific to the host requesting the log. The Discovery Log Page is persistent across power cycles. The Log Page Offset may be used to retrieve specific records. The number of records is returned in the header of the log page. The format for a Discovery Log Page Entry is defined in Figure 264. The format for the Discovery Log Page is defined in Figure 265. A single Get Log Page command used to read the Discovery Log Page shall be atomic. If the host reads the Discovery Log Page using multiple Get Log Page commands the host should ensure that there has not been a change in the contents of the data. The host should read the Discovery Log Page contents in order (i.e., with increasing Log Page Offset values) and then re-read the Generation Counter after the entire log page is transferred. If the Generation Counter does not match the original value read, the host should discard the log page read as the entries may be inconsistent. If the log page contents change during this command sequence, the controller may return a status code of Discover Restart. Every record indicates via the SUBTYPE field if that record is referring to another Discovery Service or if the record indicates an NVM subsystem composed of controllers that may expose namespaces. A referral to another Discovery Service (i.e., SUBTYPE 01h) is a mechanism to find additional Discovery subsystems. An NVM subsystem entry (i.e., SUBTYPE 02h) is a mechanism to find NVM subsystems that contain controllers that may expose namespaces. Referrals shall not be deeper than eight levels. If an NVM subsystem supports the dynamic controller model, then all entries for that NVM subsystem shall have the Controller ID field set to FFFFh. For a particular NVM subsystem port and NVMe Transport address in an NVM subsystem, there shall be no more than one entry with the Controller ID field set to: - FFFFh if that NVM subsystem supports the dynamic controller model; or - FFFEh if that NVM subsystem supports the static controller model. See page 232 for details. Command Syntax This log uses the nvme-discover command. Reservation Notification (80h) NOTE TODO The Reservation Notification log page reports one log page from a time ordered queue of Reservation Notification log pages, if available. A new Reservation Notification log page is created and added to the end of the queue of reservation notifications whenever an unmasked reservation notification occurs on any namespace that is attached to the controller. The Get Log Page command: returns a data buffer containing a log page corresponding to the oldest log page in the reservation notification queue (i.e., the log page containing the lowest Log Page Count field; accounting for wrapping); and removes that Reservation Notification log page from the queue. If there are no available Reservation Notification log page entries when a Get Log Page command is issued, then an empty log page (i.e., all fields in the log page cleared to 0h) shall be returned. If the controller is unable to store a reservation notification in the Reservation Notification log page due to the size of the queue, that reservation notification is lost. If a reservation notification is lost, then the controller shall increment the Log Page Count field of the last reservation notification in the queue (i.e., the Log Page Count field in the last reservation notification in the queue shall contain the value associated with the most recent reservation notification that has been lost). See page 234 for details. Sanitize Status (81h) NOTE This log is not supported but has no bearing on drive performance. The Sanitize Status log page is used to report sanitize operation time estimates and information about the most recent sanitize operation (refer to section 8.20). The Get Log Page command returns a data buffer containing a log page formatted as defined in Figure 267. This log page shall be retained across power cycles and resets. This log page shall contain valid data whenever CSTS.RDY is set to \u20181\u2019. If the Sanitize Capabilities (SANICAP) field in the Identify Controller data structure is not cleared to 0h (i.e., the Sanitize command is supported), then this log page shall be supported. If the Sanitize Capabilities field in the Identify Controller data structure is cleared to 0h, then this log page is reserved. See page 235 for details. Command Syntax This log uses the nvme-resv-notif-log command. Other NVMe CLI Commands List All NVMe Drives nvme list Lists all the NVMe SSDs attached: name, serial number, size, LBA format, and serial","title":"Notes on NVMe Log Pages"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#notes-on-nvme-log-pages","text":"Notes on NVMe Log Pages Quick Overview My Test Drive Get Log Page Identifiers Error Information (01h) Sample Output SMART / Health Information (02h) Sample Output Firmware Slot Information (03h) Sample Output Changed Namespace List (04h) Commands Supported and Effects (05h) Sample Output Device Self-test (06h) Telemetry Host-Initiated (07h) Notes on Telemetry Sample Output Telemetry Controller-Initiated (08h) Notes on Telemetry Sample Output Endurance Group Information (09h) Predictable Latency Per NVM Set (0Ah) Predictable Latency Event Aggregate Log Page (0Bh) Asymmetric Namespace Access (0Ch) Persistent Event Log (0Dh) Endurance Group Event Aggregate (0Fh) Media Unit Status (10h) Supported Capacity Configuration List (11h) Feature Identifiers Supported and Effects (12h) NVMe-MI Commands Supported and Effects (13h) Command and Feature Lockdown (14h) Boot Partition (15h) Rotational Media Information Log (16h) Discovery Log Page (70h) Command Syntax Reservation Notification (80h) Sanitize Status (81h) Command Syntax Other NVMe CLI Commands List All NVMe Drives","title":"Notes on NVMe Log Pages"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#quick-overview","text":"See this excel document","title":"Quick Overview"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#my-test-drive","text":"[root@r8402 ~]# nvme id-ctrl /dev/nvme0n1 NVME Identify Controller: vid : 0x8086 ssvid : 0x1028 sn : PHLN939602VB3P2BGN mn : Dell Express Flash NVMe P4610 3.2TB SFF fr : VDV1DP25 rab : 0 ieee : 5cd2e4 cmic : 0 mdts : 5 cntlid : 0 ver : 0x10200 rtd3r : 0x989680 rtd3e : 0xe4e1c0 oaes : 0x200 ctratt : 0 rrls : 0 cntrltype : 0 fguid : crdt1 : 0 crdt2 : 0 crdt3 : 0 oacs : 0x6 acl : 3 aerl : 3 frmw : 0x18 lpa : 0xe elpe : 63 npss : 0 avscc : 0 apsta : 0 wctemp : 343 cctemp : 349 mtfa : 0 hmpre : 0 hmmin : 0 tnvmcap : 3200631791616 unvmcap : 0 rpmbs : 0 edstt : 0 dsto : 0 fwug : 0 kas : 0 hctma : 0 mntmt : 0 mxtmt : 0 sanicap : 0 hmminds : 0 hmmaxd : 0 nsetidmax : 0 endgidmax : 0 anatt : 0 anacap : 0 anagrpmax : 0 nanagrpid : 0 pels : 0 sqes : 0x66 cqes : 0x44 maxcmd : 0 nn : 1 oncs : 0x6 fuses : 0 fna : 0x4 vwc : 0 awun : 0 awupf : 0 icsvscc : 0 nwpc : 0 acwu : 0 sgls : 0 mnan : 0 subnqn : ioccsz : 0 iorcsz : 0 icdoff : 0 fcatt : 0 msdbd : 0 ofcs : 0 ps 0 : mp:25.00W operational enlat:0 exlat:0 rrt:0 rrl:0 rwt:0 rwl:0 idle_power:- active_power:-","title":"My Test Drive"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#get-log-page-identifiers","text":"NVMe Express Base Specification","title":"Get Log Page Identifiers"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#error-information-01h","text":"This log page is used to describe extended error information for a command that completed with error or report an error that is not specific to a particular command. Extended error information is provided when the More (M) bit is set to \u20181\u2019 in the Status Field for the completion queue entry associated with the command that completed with error or as part of an asynchronous event with an Error status type. This log page is global to the controller. This error log may return the last n errors. If host software specifies a data transfer of the size of n error logs, then the error logs for the most recent n errors are returned. The ordering of the entries is based on the time when the error occurred, with the most recent error being returned as the first log entry. Each entry in the log page returned is defined in Figure 206. The log page is a set of 64-byte entries; the maximum number of entries supported is indicated in the ELPE field in the Identify Controller data structure (refer to Figure 275). If the log page is full when a new entry is generated, the controller should insert the new entry into the log and discard the oldest entry. The controller should clear this log page by removing all entries on power cycle and Controller Level Reset. See page 178 for a description.","title":"Error Information (01h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sample-output","text":"[root@r8402 ~]# nvme error-log /dev/nvme0n1 Error Log Entries for device:nvme0n1 entries:64 ................. Entry[ 0] ................. error_count : 0 sqid : 0 cmdid : 0 status_field : 0(SUCCESS: The command completed successfully) phase_tag : 0 parm_err_loc : 0 lba : 0 nsid : 0 vs : 0 trtype : The transport type is not indicated or the error is not transport related. cs : 0 trtype_spec_info: 0 ................. ...SNIP... Entry[63] ................. error_count : 0 sqid : 0 cmdid : 0 status_field : 0(SUCCESS: The command completed successfully) phase_tag : 0 parm_err_loc : 0 lba : 0 nsid : 0 vs : 0 trtype : The transport type is not indicated or the error is not transport related. cs : 0 trtype_spec_info: 0 .................","title":"Sample Output"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#smart-health-information-02h","text":"This log page is used to provide SMART and general health information. The information provided is over the life of the controller and is retained across power cycles. To request the controller log page, the namespace identifier specified is FFFFFFFFh or 0h. For compatibility with implementations compliant with NVM Express Base Specification revision 1.4 and earlier, hosts should use a namespace identifier of FFFFFFFFh to request the controller log page. The controller may also support requesting the log page on a per namespace basis, as indicated by bit 0 of the LPA field in the Identify Controller data structure in Figure 275. See page 180 for a description.","title":"SMART / Health Information (02h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sample-output_1","text":"[root@r8402 ~]# nvme smart-log /dev/nvme0n1 Smart Log for NVME device:nvme0n1 namespace-id:ffffffff critical_warning : 0 temperature : 26 C available_spare : 100% available_spare_threshold : 10% percentage_used : 0% endurance group critical warning summary: 0 data_units_read : 4,002,753 data_units_written : 255,875,492 host_read_commands : 45,714,473 host_write_commands : 1,620,770,593 controller_busy_time : 372 power_cycles : 150 power_on_hours : 5,219 unsafe_shutdowns : 99 media_errors : 0 num_err_log_entries : 0 Warning Temperature Time : 0 Critical Composite Temperature Time : 0 Thermal Management T1 Trans Count : 0 Thermal Management T2 Trans Count : 0 Thermal Management T1 Total Time : 0 Thermal Management T2 Total Time : 0","title":"Sample Output"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#firmware-slot-information-03h","text":"This log page is used to describe the firmware revision stored in each firmware slot supported. The firmware revision is indicated as an ASCII string. The log page also indicates the active slot number. The log page returned is defined in Figure 209","title":"Firmware Slot Information (03h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sample-output_2","text":"[root@r8402 ~]# nvme fw-log /dev/nvme0n1 Firmware Log for device:nvme0n1 afi : 0x1 frs1 : 0x3532504431564456 (VDV1DP25) frs2 : 0x3532504431564456 (VDV1DP25) NOTE AFI stands for active firmware version.","title":"Sample Output"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#changed-namespace-list-04h","text":"NOTE This command is not currently supported because the drive currently only has one namespace. This log page is used to describe namespaces attached to the controller that have: changed information in their Identify Namespace data structures (refer to in Figure 146) since the last time the log page was read; been added; and been deleted. The log page contains a Namespace List with up to 1,024 entries. If more than 1,024 namespaces have changed attributes since the last time the log page was read, the first entry in the log page shall be set to FFFFFFFFh and the remainder of the list shall be zero filled. See page 184 for a description.","title":"Changed Namespace List (04h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#commands-supported-and-effects-05h","text":"This log page is used to describe the commands that the controller supports and the effects of those commands on the state of the NVM subsystem. The log page is 4,096 bytes in size. There is one Commands Supported and Effects data structure per Admin command and one Commands Supported and Effects data structure per I/O command based on: the I/O Command Set selected in CC.CSS, if CC.CSS is not set to 110b; and the Command Set Identifier field in CDW 14, if CC.CSS is set to 110b. See page 185 for a description.","title":"Commands Supported and Effects (05h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sample-output_3","text":"[root@r8402 ~]# nvme effects-log /dev/nvme0n1 Admin Command Set ACS0 [Delete I/O Submission Queue ] 00000001 ACS1 [Create I/O Submission Queue ] 00020001 ACS2 [Get Log Page ] 00000001 ACS4 [Delete I/O Completion Queue ] 00000001 ACS5 [Create I/O Completion Queue ] 00020001 ACS6 [Identify ] 00000001 ACS8 [Abort ] 00000001 ACS9 [Set Features ] 0000001d ACS10 [Get Features ] 00000001 ACS12 [Asynchronous Event Request ] 00000001 ACS16 [Firmware Commit ] 00000011 ACS17 [Firmware Image Download ] 00000001 ACS128 [Format NVM ] 0002001f ACS200 [Unknown ] 00000001 ACS210 [Unknown ] 00000001 ACS225 [Unknown ] 0002000f ACS226 [Unknown ] 0002000f NVM Command Set IOCS0 [Flush ] 00000003 IOCS1 [Write ] 00000003 IOCS2 [Read ] 00000001 IOCS4 [Write Uncorrectable ] 00000003 IOCS9 [Dataset Management ] 00000003","title":"Sample Output"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#device-self-test-06h","text":"NOTE : This command is not currently supported. TODO This log page is used to indicate: the status of any device self-test operation in progress and the percentage complete of that operation; and the results of the last 20 device self-test operations. The Self-test Result Data Structure contained in the Newest Self-test Result Data Structure field is always the result of the last completed or aborted self-test operation. The next Self-test Result Data Structure field in the Device Self-test log page contains the results of the second newest self-test operation and so on. If fewer than 20 self-test operations have completed or been aborted, then the Device Self-test Status field shall be set to Fh in the unused Self-test Result Data Structure fields and all other fields in that Self-test Result Data Structure are ignored. See page 187 for additional information.","title":"Device Self-test (06h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#telemetry-host-initiated-07h","text":"This log consists of a header describing the log and zero or more Telemetry Data Blocks (refer to section 8.24). All Telemetry Data Blocks are 512 bytes in size. The controller shall initiate a capture of the controller\u2019s internal controller state to this log if the controller processes a Get Log Page command for this log with the Create Telemetry Host-Initiated Data bit set to \u20181\u2019 in the Log Specific field. If the host specifies a Log Page Offset Lower value that is not a multiple of 512 bytes in the Get Log Page command for this log, then the controller shall return an error with a status code set to Invalid Field in Command. This log page is global to the controller or global to the NVM subsystem. See page 189 for additional information.","title":"Telemetry Host-Initiated (07h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#notes-on-telemetry","text":"See page 422 for additional details. Telemetry enables manufacturers to collect internal data logs to improve the functionality and reliability of products. The telemetry data collection may be initiated by the host or by the controller. The data is returned in the Telemetry Host-Initiated log page or the Telemetry Controller-Initiated log page (refer to section 5.16.1.8 and 5.16.1.9). The data captured is vendor specific. The telemetry feature defines the mechanism to collect the vendor specific data. The controller indicates support for the telemetry log pages and for the Data Area 4 size in the Log Page Attributes (LPA) field in the Identify Controller data structure (refer to Figure 275).","title":"Notes on Telemetry"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sample-output_4","text":"nvme telemetry-log --output-file /root/test.log --host-generate=1 /dev/nvme0n1","title":"Sample Output"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#telemetry-controller-initiated-08h","text":"Telemetry enables manufacturers to collect internal data logs to improve the functionality and reliability of products. The telemetry data collection may be initiated by the host or by the controller. The data is returned in the Telemetry Host-Initiated log page or the Telemetry Controller-Initiated log page (refer to section 5.16.1.8 and 5.16.1.9). The data captured is vendor specific. The telemetry feature defines the mechanism to collect the vendor specific data. The controller indicates support for the telemetry log pages and for the Data Area 4 size in the Log Page Attributes (LPA) field in the Identify Controller data structure (refer to Figure 275). See page 191 for additional information.","title":"Telemetry Controller-Initiated (08h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#notes-on-telemetry_1","text":"See Notes on Telemetry","title":"Notes on Telemetry"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sample-output_5","text":"nvme telemetry-log --output-file /root/test.log --host-generate=0 /dev/nvme0n1","title":"Sample Output"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#endurance-group-information-09h","text":"NOTE This command is not currently supported because there is only one endurance group (endgidmax=0) This log page is used to provide endurance information based on the Endurance Group (refer to section 3.2.3). An Endurance Group contains capacity that may be allocated to zero or more NVM Sets. Capacity that has not been allocated to an NVM Set is unallocated Endurance Group capacity. The information provided is over the life of the Endurance Group. The Endurance Group Identifier is specified in the Log Specific Identifier field in Command Dword 11 of the Get Log Page command. The log page is 512 bytes in size. See page 193 for additional information.","title":"Endurance Group Information (09h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#predictable-latency-per-nvm-set-0ah","text":"NOTE This log is not supported because the drives only support one NVM Set. This log page may be used to determine the current window for the specified NVM Set when Predictable Latency Mode is enabled and any events that have occurred for the specified NVM Set. There is one log page for each NVM Set when Predictable Latency Mode is supported. Command Dword 11 (refer to Figure 198) specifies the NVM Set for which the log page is to be returned. The log page is 512 bytes in size. The log page indicates typical values and reliable estimates for attributes associated with the Deterministic Window and the Non-Deterministic Window of the specified NVM Set. The Typical, Maximum, and Minimum values are static and worst-case values over the lifetime of the NVM subsystem. After the controller successfully completes a read of this log page with Retain Asynchronous Event bit cleared to \u20180\u2019, then reported events are cleared to \u20180\u2019 for the specified NVM Set and the field corresponding to the specified NVM Set is cleared to \u20180\u2019 in the Predictable Latency Event Aggregate log page. Coordination between two or more hosts is beyond the scope of this specification. See page 195 for additional information.","title":"Predictable Latency Per NVM Set (0Ah)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#predictable-latency-event-aggregate-log-page-0bh","text":"NOTE This log page indicates if a Predictable Latency Event (refer to section 8.16) has occurred for a particular NVM Set. If a Predictable Latency Event has occurred, the details of the particular event are included in the Predictable Latency Per NVM Set log page for that NVM Set. An asynchronous event is generated when an entry for an NVM Set is newly added to this log page. This log page shall not contain an entry (i.e., an NVM Set Identifier) that is cleared to 0h. If there is an enabled Predictable Latency Event pending for an NVM Set, then the Predictable Latency Event Aggregate log page includes an entry for that NVM Set. The log page is an ordered list by NVM Set Identifier. For example, if Predictable Latency Events are pending for NVM Set 27, 13, and 17, then the log page shall have entries in numerical order of 13, 17, and 27. A particular NVM Set is removed from this log page after the Get Log Page is completed successfully with the Retain Asynchronous Event bit cleared to \u20180\u2019 for the Predictable Latency Per NVM Set log page for that NVM Set. See page 196 for details.","title":"Predictable Latency Event Aggregate Log Page (0Bh)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#asymmetric-namespace-access-0ch","text":"NOTE This log is not supported because there is only one namespace on the drive. This log consists of a header describing the log and descriptors containing the asymmetric namespace access information for ANA Groups (refer to section 8.1.2) that contain namespaces that are attached to the controller processing the command. If ANA Reporting (refer to section 8.1) is supported, this log page is supported. ANA Group Descriptors shall be returned in ascending ANA Group Identifier order. If the Index Offset Supported bit is cleared to \u20180\u2019 in the LID Support and Effects data structure for this log page (refer to Figure 204), then: if the RGO bit is cleared to \u20180\u2019 in Command Dword 10, then the LPOL field in Command Dword 12 and the LPOU field in Command Dword 13 of the Get Log Page command should be cleared to 0h. If the Index Offset Supported bit is set to \u20181\u2019 in the LID Supported and Effects data structure for this log page (refer to Figure 204), then: the entry data structure that is indexed is an ANA Group Descriptor (e.g., specifying an index offset of 2 returns this log page starting at the offset of ANA Group Descriptor 1). If the host performs multiple Get Log Page commands to read the ANA log page (e.g., using the LPOL field or the LPOU field), the host should re-read the header of the log page and ensure that the Change Count field in the Asymmetric Namespace Access log matches the original value read. If it does not match, then the data captured is not consistent and the ANA log page should be re-read. See page 197 for details.","title":"Asymmetric Namespace Access (0Ch)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#persistent-event-log-0dh","text":"NOTE TODO The Persistent Event Log page contains information about significant events not specific to a particular command. The information in this log page shall be retained across power cycles and resets. NVM subsystems should be designed for minimal loss of event information upon power failure. This log consists of a header describing the log and zero or more Persistent Events (refer to section 5.16.1.14.1). This log page is global to the NVM subsystem. A sanitize operation may alter this log page (e.g., remove or modify events to prevent derivation of user data from log page information, refer to section 8.20). The events removed from this log page by a sanitize operation are unspecified. Persistent Event Log events specified in this section should be reported in an order such that more recent events are generally reported earlier in the log data than older events. The method by which the NVM subsystem determines the order in which events occurred is vendor specific. The number of events supported is vendor specific. The supported maximum size for the Persistent Event Log is indicated in the PELS field of the Identify Controller data structure (refer to Figure 275). The number of events supported and the supported maximum size should be large enough that the number of events or the size of the Persistent Event Log data does not reach the maximum supported size over the usable life of the NVM subsystem. The controller shall log all supported events at each event occurrence unless the controller determines that the same event is occurring at a frequency that exceeds a vendor specific threshold for the frequency of event creation. If the same event is occurring at a frequency that exceeds a vendor specific threshold then the vendor may suppress further entries for the same event. A controller may indicate if events have been suppressed in vendor specific event data. See page 199 for details.","title":"Persistent Event Log (0Dh)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#endurance-group-event-aggregate-0fh","text":"NOTE This is not supported because endurance groups are not in use. This log page indicates if an Endurance Group Event (refer to section 3.2.3) has occurred for a particular Endurance Group. If an Endurance Group Event has occurred, the details of the particular event are included in the Endurance Group Information log page for that Endurance Group. An asynchronous event is generated when an entry for an Endurance Group is newly added to this log page. If there is an enabled Endurance Group Event pending for an Endurance Group, then the Endurance Group Event Aggregate log page includes an entry for that Endurance Group. The log page is an ordered list by Endurance Group Identifier. For example, if Endurance Group Events are pending for Endurance Group 2, 1, and 7, then the log page shall have entries in numerical order of 1, 2, and 7. A particular Endurance Group entry is removed from this log page after the Get Log Page is completed successfully with the Retain Asynchronous Event bit cleared to \u20180\u2019 for the Endurance Group Information log page for that Endurance Group. The log page size is limited by the Endurance Group Identifier Maximum value reported in the Identify Controller data structure (refer to Figure 275). If the host reads beyond the end of the log page, zeroes are returned. The log page is defined in Figure 247. See page 220 for details.","title":"Endurance Group Event Aggregate (0Fh)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#media-unit-status-10h","text":"NOTE This page is not supported because it is used for NVM sets which are not in use. This log page is used to describe the configuration and wear of Media Units (refer to section 8.3). The log page contains one Media Unit Status Descriptor for each Media Unit accessible by the specified domain. Each Media Unit Status Descriptor (refer to Figure 249) indicates the configuration of the Media Unit (e.g., to which Endurance Group the Media Unit is assigned, to which NVM Set the Media Unit is assigned, to which Channels the Media Unit is attached) and indications of wear (e.g., the Available Spare field and the Percentage Used field). The indications of wear change as the Media Unit is written and read. If the NVM subsystem supports multiple domains, then the controller reports the Media Unit Status log page for the domain specified in the Log Specific Identifier field (refer to Figure 198), if accessible. If the information is not accessible, then the log page is not available (refer to section 8.1.4). If the Log Specific Identifier field is cleared to 0h, then the specified domain is the domain containing the controller that is processing the command. Media Unit Identifier values (refer to Figure 249) begin with 0h and increase sequentially. If the NVM subsystem supports multiple domains, then the Media Unit Identifier values are unique within the specified domain. If the NVM subsystem does not support multiple domains, then the Media Unit Identifier values are unique within the NVM subsystem. Media Unit Status Descriptors are listed in ascending order by Media Unit Identifier. See page 220 for details.","title":"Media Unit Status (10h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#supported-capacity-configuration-list-11h","text":"NOTE This log page is not available because the drives do not currently support multiple endurance groups. This log page is used to provide a list of Supported Capacity Configuration Descriptors (refer to Figure 250). Each entry in the list defines a different configuration of Endurance Groups supported by the specified domain. If the NVM subsystem supports multiple domains, then the controller reports the Supported Capacity Configuration List log page for the domain specified in the Log Specific Identifier field (refer to Figure 198), if accessible. If the information is not accessible, then the log page is not available (refer to section 8.1.3). If the Log Specific Identifier field is cleared to 0h, then the specified domain is the domain containing the controller that is processing the command. If the NVM subsystem supports multiple domains, then Capacity Configuration Identifier values are unique within the specified domain. If the NVM subsystem does not support multiple domains, then Capacity Configuration Identifier values are unique within the NVM subsystem. Capacity Configuration Descriptors are listed in ascending order by Capacity Configuration Identifier, and each Capacity Configuration Identifier shall appear only once. For details see page 222","title":"Supported Capacity Configuration List (11h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#feature-identifiers-supported-and-effects-12h","text":"NOTE TODO An NVM subsystem may support several interfaces for submitting a Get Log Page command such as an Admin Submission Queue, PCIe VDM Management Endpoint, or SMBus/I2C Management Endpoint (refer the NVM Express Management Interface Specification for details on Management Endpoints) and may have zero or more instances of each of those interfaces. The feature identifiers (FIDs) supported on each instance of each interface may be different. This log page describes the FIDs that are supported on the interface to which the Get Log Page command was submitted and the effects of those features on the state of the NVM subsystem. The log page is defined in Figure 255. Each Feature Identifier\u2019s effects are described in a FID Supported and Effects data structure defined in Figure 256. The features that the controller supports are dependent on the I/O Command Set that is based on: - the I/O Command Set selected in CC.CSS, if CC.CSS is not set to 110b; and - the Command Set Identifier (CSI) field in CDW 14, if CC.CSS is set to 110b. For details see page 225","title":"Feature Identifiers Supported and Effects (12h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#nvme-mi-commands-supported-and-effects-13h","text":"This log page describes the Management Interface Command Set commands (refer to the NVMe Management Interface Specification ) that the controller supports using the NVMe-MI Send and NVMe-MI Receive commands and the effects of those Management Interface Command Set commands on the state of the NVM subsystem. The log page is defined in Figure 257. See page 227 for details.","title":"NVMe-MI Commands Supported and Effects (13h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#command-and-feature-lockdown-14h","text":"NOTE This command is not supported. It is used for preventing certain commands for security purposes. It is not relevant to performance testing. This log page is used to indicate which commands and Set Features Feature Identifiers are supported to be prohibited from execution using the Command and Feature Lockdown capability (refer to section 8.4) and which commands are currently prohibited if received on an NVM Express controller Admin Submission Queue or received out-of-band on a Management Endpoint (refer to the NVM Express Management Interface Specification). This log page uses the Log Specific Field field (refer to Figure 259) and may use the UUID Index field in the Get Log Page command to specify the scope and content of the list returned in the Command and Feature Identifier List field of this log page. The UUID Index field may be used if the Scope field is set to 2h, allowing returning of vendor specific Set Features Feature Identifier lockdown information. See page 228 for details.","title":"Command and Feature Lockdown (14h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#boot-partition-15h","text":"NOTE This command is not supported and does not have any relevance to drive performance. It allows you to see the boot partition of the drive. The Boot Partition Log page provides read only access to the Boot Partition (refer to section 8.2) accessible by this controller through the BPRSEL register (refer to section 3.1.3.14). This log consists of a header describing the Boot Partition and Boot Partition data as defined by Figure 262. The Boot Partition Identifier bit in the Log Specific Field field determines the Boot Partition. A host reading this log page has no effects on the BPINFO (refer to section 3.1.3.13), BPRSEL, and BPMBL (refer to section 3.1.3.15) registers. See page 230 for details.","title":"Boot Partition (15h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#rotational-media-information-log-16h","text":"NOTE This is specific to multiple endurance groups so it is not supported (since there is only one) This log page provides rotational media information (refer to section 8.20) for Endurance Groups that store data on rotational media. The information provided is retained across power cycles and resets. The Endurance Group Identifier is specified in the Log Specific Identifier field in Command Dword 11 of the Get Log Page command. If the NVM subsystem does not contain any Endurance Groups that store data on rotational media, then the Rotational Media Information Log should not be supported. See page 231 for details.","title":"Rotational Media Information Log (16h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#discovery-log-page-70h","text":"NOTE This log page is not supported. It is specific to NVMe-over-Fabrics (ex: RDMA) The Discovery Log Page shall only be supported by Discovery controllers. The Discovery Log Page shall not be supported by controllers that expose namespaces for NVMe over PCIe or NVMe over Fabrics. The Discovery Log Page provides an inventory of NVM subsystems with which a host may attempt to form an association. The Discovery Log Page may be specific to the host requesting the log. The Discovery Log Page is persistent across power cycles. The Log Page Offset may be used to retrieve specific records. The number of records is returned in the header of the log page. The format for a Discovery Log Page Entry is defined in Figure 264. The format for the Discovery Log Page is defined in Figure 265. A single Get Log Page command used to read the Discovery Log Page shall be atomic. If the host reads the Discovery Log Page using multiple Get Log Page commands the host should ensure that there has not been a change in the contents of the data. The host should read the Discovery Log Page contents in order (i.e., with increasing Log Page Offset values) and then re-read the Generation Counter after the entire log page is transferred. If the Generation Counter does not match the original value read, the host should discard the log page read as the entries may be inconsistent. If the log page contents change during this command sequence, the controller may return a status code of Discover Restart. Every record indicates via the SUBTYPE field if that record is referring to another Discovery Service or if the record indicates an NVM subsystem composed of controllers that may expose namespaces. A referral to another Discovery Service (i.e., SUBTYPE 01h) is a mechanism to find additional Discovery subsystems. An NVM subsystem entry (i.e., SUBTYPE 02h) is a mechanism to find NVM subsystems that contain controllers that may expose namespaces. Referrals shall not be deeper than eight levels. If an NVM subsystem supports the dynamic controller model, then all entries for that NVM subsystem shall have the Controller ID field set to FFFFh. For a particular NVM subsystem port and NVMe Transport address in an NVM subsystem, there shall be no more than one entry with the Controller ID field set to: - FFFFh if that NVM subsystem supports the dynamic controller model; or - FFFEh if that NVM subsystem supports the static controller model. See page 232 for details.","title":"Discovery Log Page (70h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#command-syntax","text":"This log uses the nvme-discover command.","title":"Command Syntax"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#reservation-notification-80h","text":"NOTE TODO The Reservation Notification log page reports one log page from a time ordered queue of Reservation Notification log pages, if available. A new Reservation Notification log page is created and added to the end of the queue of reservation notifications whenever an unmasked reservation notification occurs on any namespace that is attached to the controller. The Get Log Page command: returns a data buffer containing a log page corresponding to the oldest log page in the reservation notification queue (i.e., the log page containing the lowest Log Page Count field; accounting for wrapping); and removes that Reservation Notification log page from the queue. If there are no available Reservation Notification log page entries when a Get Log Page command is issued, then an empty log page (i.e., all fields in the log page cleared to 0h) shall be returned. If the controller is unable to store a reservation notification in the Reservation Notification log page due to the size of the queue, that reservation notification is lost. If a reservation notification is lost, then the controller shall increment the Log Page Count field of the last reservation notification in the queue (i.e., the Log Page Count field in the last reservation notification in the queue shall contain the value associated with the most recent reservation notification that has been lost). See page 234 for details.","title":"Reservation Notification (80h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#sanitize-status-81h","text":"NOTE This log is not supported but has no bearing on drive performance. The Sanitize Status log page is used to report sanitize operation time estimates and information about the most recent sanitize operation (refer to section 8.20). The Get Log Page command returns a data buffer containing a log page formatted as defined in Figure 267. This log page shall be retained across power cycles and resets. This log page shall contain valid data whenever CSTS.RDY is set to \u20181\u2019. If the Sanitize Capabilities (SANICAP) field in the Identify Controller data structure is not cleared to 0h (i.e., the Sanitize command is supported), then this log page shall be supported. If the Sanitize Capabilities field in the Identify Controller data structure is cleared to 0h, then this log page is reserved. See page 235 for details.","title":"Sanitize Status (81h)"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#command-syntax_1","text":"This log uses the nvme-resv-notif-log command.","title":"Command Syntax"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#other-nvme-cli-commands","text":"","title":"Other NVMe CLI Commands"},{"location":"Notes%20on%20NVMe%20Log%20Pages/#list-all-nvme-drives","text":"nvme list Lists all the NVMe SSDs attached: name, serial number, size, LBA format, and serial","title":"List All NVMe Drives"},{"location":"Notes%20on%20PCIe/","text":"Notes on PCIe Notes on PCIe PCIe Basics and Background How multiple root complexes are handled Interpreting PCIe Device to CPU Locality Information What is the PCIe PHY Human readable overview of how PCIe works How does ID-based Ordering (IDO) Work? How does transaction ordering work? What is a PCIe Root Complex? How does PCIe Enumeration Work? NVMe over PCIe vs Other Protocols What is a PCIe Function? PCIe-Bus and NUMA Node Correlation How does the root complex work? What is PCIe P2P? What is Relaxed Ordering What is a traffic class (TC)? PCIe BAR Register How NVMe Drive Opcodes Work How does SR-IOV work? PCIe Bridge vs Switch PCIe Configuration Space PCIe Switches How to Check CPU Affinity PCIe Basics and Background https://pcisig.com/sites/default/files/files/PCI_Express_Basics_Background.pdf#page=26 How multiple root complexes are handled https://codywu2010.wordpress.com/2015/11/29/how-modern-multi-processor-multi-root-complex-system-assigns-pci-bus-number/ Interpreting PCIe Device to CPU Locality Information https://dshcherb.github.io/2019/02/02/interpreting-pcie-device-to-cpu-locality-information.html What is the PCIe PHY https://www.linkedin.com/pulse/pci-express-depth-physical-layer-luigi-c-filho-/ Human readable overview of how PCIe works http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1/ http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-2 How does ID-based Ordering (IDO) Work? https://blog.csdn.net/weixin_48180416/article/details/115790068 How does transaction ordering work? https://blog.csdn.net/weixin_40357487/article/details/120162461?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&utm_relevant_index=1 What is a PCIe Root Complex? https://www.quora.com/What-is-a-PCIe-root-complex?share=1 How does PCIe Enumeration Work? https://www.quora.com/What-is-PCIE-enumeration/answer/Satish-Kumar-525?ch=15&oid=31389493&share=44585235&target_type=answer NVMe over PCIe vs Other Protocols https://www.quora.com/Is-NVMe-faster-than-PCIe/answer/Mike-Jones-169?ch=15&oid=193548046&share=a587ff45&target_type=answer What is a PCIe Function? https://www.quora.com/What-is-a-PCIe-function/answer/Udit-Khanna-2?ch=15&oid=58319695&share=c7f066e5&target_type=answer PCIe-Bus and NUMA Node Correlation https://social.msdn.microsoft.com/Forums/en-US/fabb05b7-eb3f-4a7c-91c5-1ced90af3d0c/pciebus-and-numanode-correlation How does the root complex work? https://codywu2010.wordpress.com/2015/11/29/how-modern-multi-processor-multi-root-complex-system-assigns-pci-bus-number/ What is PCIe P2P? https://xilinx.github.io/XRT/master/html/p2p.html What is Relaxed Ordering https://qr.ae/pG6SWe What is a traffic class (TC)? https://www.oreilly.com/library/view/pci-express-system/0321156307/0321156307_ch06lev1sec6.html PCIe BAR Register https://github.com/cirosantilli/linux-kernel-module-cheat/blob/366b1c1af269f56d6a7e6464f2862ba2bc368062/kernel_module/pci.c How NVMe Drive Opcodes Work https://stackoverflow.com/questions/30190050/what-is-the-base-address-register-bar-in-pcie https://stackoverflow.com/questions/19006632/how-is-a-pci-pcie-bar-size-determined BIOS/OS discovers whether PCIe device exists Places the addresses for mmio or I/O port addresses in NVMe drive\u200b's BAR registers (which it figures out from the configuration registers) It seems from the documentation I found NVMe does this through 64bit mmio Driver establishes the admin queue via BAR0. The admin queue's base addresses are in ASQ and ACQ respectively I submit commands to the admin submission queue to establish I/O queues. Send/receive data via I/O queues. How does SR-IOV work? https://docs.microsoft.com/en-us/windows-hardware/drivers/network/overview-of-single-root-i-o-virtualization--sr-iov- Architecture: https://docs.microsoft.com/en-us/windows-hardware/drivers/network/sr-iov-architecture PCIe Bridge vs Switch wke...@gmail.com wrote: I would appreciate of someone can explain the difference between a PCI bridge and a PCI switch. With good ol' PCI, a single bus can have many devices. A PCI bridge is a device that connects multiple buses together, which is something that was very seldom needed. PCI Express looks, for software, very similar to PCI, but is electrically a point-to-point connection, i.e., a PCIe bus has exactly two devices. To connect PCIe with PCI, you need a PCI/PCIe or PCIe/PCI bridge. If you have a single PCIe connector and multiple PCIe devices, you need a PCIe switch. A single PCIe connection still is between exactly two devices, so a PCIe switch consists of a (virtual) PCI bridge for the upstream PCIe connection, and one (virtual) PCI bridge for each downstream PCIe connection. Regards, Clemens PCIe Configuration Space https://docs.oracle.com/cd/E19683-01/806-5222/hwovr-22/#:~:text=The%20PCI%20host%20bridge%20provides,of%20other%20PCI%20bus%20masters. https://bitwiseanne.wordpress.com/2020/05/15/pcie-101-the-root-complex-and-the-endpoint/ PCIe Switches https://linuxhint.com/pcie-switch/#:~:text=PCIe%20switches%20are%20devices%20that,the%20CPU%20alone%20can%20handle. How to Check CPU Affinity [root@r7525 ~]# cat /sys/class/pci_bus/0000\\:00/cpulistaffinity 24-31,88-95 [root@r7525 ~]# lscpu | grep -i numa NUMA node(s): 8 NUMA node0 CPU(s): 0-7,64-71 NUMA node1 CPU(s): 8-15,72-79 NUMA node2 CPU(s): 16-23,80-87 NUMA node3 CPU(s): 24-31,88-95 NUMA node4 CPU(s): 32-39,96-103 NUMA node5 CPU(s): 40-47,104-111 NUMA node6 CPU(s): 48-55,112-119 NUMA node7 CPU(s): 56-63,120-127 You can check the CPU affinity of a PCIe bus and then see what processor it is aligned to by referencing the processor ranges.","title":"Notes on PCIe"},{"location":"Notes%20on%20PCIe/#notes-on-pcie","text":"Notes on PCIe PCIe Basics and Background How multiple root complexes are handled Interpreting PCIe Device to CPU Locality Information What is the PCIe PHY Human readable overview of how PCIe works How does ID-based Ordering (IDO) Work? How does transaction ordering work? What is a PCIe Root Complex? How does PCIe Enumeration Work? NVMe over PCIe vs Other Protocols What is a PCIe Function? PCIe-Bus and NUMA Node Correlation How does the root complex work? What is PCIe P2P? What is Relaxed Ordering What is a traffic class (TC)? PCIe BAR Register How NVMe Drive Opcodes Work How does SR-IOV work? PCIe Bridge vs Switch PCIe Configuration Space PCIe Switches How to Check CPU Affinity","title":"Notes on PCIe"},{"location":"Notes%20on%20PCIe/#pcie-basics-and-background","text":"https://pcisig.com/sites/default/files/files/PCI_Express_Basics_Background.pdf#page=26","title":"PCIe Basics and Background"},{"location":"Notes%20on%20PCIe/#how-multiple-root-complexes-are-handled","text":"https://codywu2010.wordpress.com/2015/11/29/how-modern-multi-processor-multi-root-complex-system-assigns-pci-bus-number/","title":"How multiple root complexes are handled"},{"location":"Notes%20on%20PCIe/#interpreting-pcie-device-to-cpu-locality-information","text":"https://dshcherb.github.io/2019/02/02/interpreting-pcie-device-to-cpu-locality-information.html","title":"Interpreting PCIe Device to CPU Locality Information"},{"location":"Notes%20on%20PCIe/#what-is-the-pcie-phy","text":"https://www.linkedin.com/pulse/pci-express-depth-physical-layer-luigi-c-filho-/","title":"What is the PCIe PHY"},{"location":"Notes%20on%20PCIe/#human-readable-overview-of-how-pcie-works","text":"http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1/ http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-2","title":"Human readable overview of how PCIe works"},{"location":"Notes%20on%20PCIe/#how-does-id-based-ordering-ido-work","text":"https://blog.csdn.net/weixin_48180416/article/details/115790068","title":"How does ID-based Ordering (IDO) Work?"},{"location":"Notes%20on%20PCIe/#how-does-transaction-ordering-work","text":"https://blog.csdn.net/weixin_40357487/article/details/120162461?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&utm_relevant_index=1","title":"How does transaction ordering work?"},{"location":"Notes%20on%20PCIe/#what-is-a-pcie-root-complex","text":"https://www.quora.com/What-is-a-PCIe-root-complex?share=1","title":"What is a PCIe Root Complex?"},{"location":"Notes%20on%20PCIe/#how-does-pcie-enumeration-work","text":"https://www.quora.com/What-is-PCIE-enumeration/answer/Satish-Kumar-525?ch=15&oid=31389493&share=44585235&target_type=answer","title":"How does PCIe Enumeration Work?"},{"location":"Notes%20on%20PCIe/#nvme-over-pcie-vs-other-protocols","text":"https://www.quora.com/Is-NVMe-faster-than-PCIe/answer/Mike-Jones-169?ch=15&oid=193548046&share=a587ff45&target_type=answer","title":"NVMe over PCIe vs Other Protocols"},{"location":"Notes%20on%20PCIe/#what-is-a-pcie-function","text":"https://www.quora.com/What-is-a-PCIe-function/answer/Udit-Khanna-2?ch=15&oid=58319695&share=c7f066e5&target_type=answer","title":"What is a PCIe Function?"},{"location":"Notes%20on%20PCIe/#pcie-bus-and-numa-node-correlation","text":"https://social.msdn.microsoft.com/Forums/en-US/fabb05b7-eb3f-4a7c-91c5-1ced90af3d0c/pciebus-and-numanode-correlation","title":"PCIe-Bus and NUMA Node Correlation"},{"location":"Notes%20on%20PCIe/#how-does-the-root-complex-work","text":"https://codywu2010.wordpress.com/2015/11/29/how-modern-multi-processor-multi-root-complex-system-assigns-pci-bus-number/","title":"How does the root complex work?"},{"location":"Notes%20on%20PCIe/#what-is-pcie-p2p","text":"https://xilinx.github.io/XRT/master/html/p2p.html","title":"What is PCIe P2P?"},{"location":"Notes%20on%20PCIe/#what-is-relaxed-ordering","text":"https://qr.ae/pG6SWe","title":"What is Relaxed Ordering"},{"location":"Notes%20on%20PCIe/#what-is-a-traffic-class-tc","text":"https://www.oreilly.com/library/view/pci-express-system/0321156307/0321156307_ch06lev1sec6.html","title":"What is a traffic class (TC)?"},{"location":"Notes%20on%20PCIe/#pcie-bar-register","text":"https://github.com/cirosantilli/linux-kernel-module-cheat/blob/366b1c1af269f56d6a7e6464f2862ba2bc368062/kernel_module/pci.c","title":"PCIe BAR Register"},{"location":"Notes%20on%20PCIe/#how-nvme-drive-opcodes-work","text":"https://stackoverflow.com/questions/30190050/what-is-the-base-address-register-bar-in-pcie https://stackoverflow.com/questions/19006632/how-is-a-pci-pcie-bar-size-determined BIOS/OS discovers whether PCIe device exists Places the addresses for mmio or I/O port addresses in NVMe drive\u200b's BAR registers (which it figures out from the configuration registers) It seems from the documentation I found NVMe does this through 64bit mmio Driver establishes the admin queue via BAR0. The admin queue's base addresses are in ASQ and ACQ respectively I submit commands to the admin submission queue to establish I/O queues. Send/receive data via I/O queues.","title":"How NVMe Drive Opcodes Work"},{"location":"Notes%20on%20PCIe/#how-does-sr-iov-work","text":"https://docs.microsoft.com/en-us/windows-hardware/drivers/network/overview-of-single-root-i-o-virtualization--sr-iov- Architecture: https://docs.microsoft.com/en-us/windows-hardware/drivers/network/sr-iov-architecture","title":"How does SR-IOV work?"},{"location":"Notes%20on%20PCIe/#pcie-bridge-vs-switch","text":"wke...@gmail.com wrote: I would appreciate of someone can explain the difference between a PCI bridge and a PCI switch. With good ol' PCI, a single bus can have many devices. A PCI bridge is a device that connects multiple buses together, which is something that was very seldom needed. PCI Express looks, for software, very similar to PCI, but is electrically a point-to-point connection, i.e., a PCIe bus has exactly two devices. To connect PCIe with PCI, you need a PCI/PCIe or PCIe/PCI bridge. If you have a single PCIe connector and multiple PCIe devices, you need a PCIe switch. A single PCIe connection still is between exactly two devices, so a PCIe switch consists of a (virtual) PCI bridge for the upstream PCIe connection, and one (virtual) PCI bridge for each downstream PCIe connection. Regards, Clemens","title":"PCIe Bridge vs Switch"},{"location":"Notes%20on%20PCIe/#pcie-configuration-space","text":"https://docs.oracle.com/cd/E19683-01/806-5222/hwovr-22/#:~:text=The%20PCI%20host%20bridge%20provides,of%20other%20PCI%20bus%20masters. https://bitwiseanne.wordpress.com/2020/05/15/pcie-101-the-root-complex-and-the-endpoint/","title":"PCIe Configuration Space"},{"location":"Notes%20on%20PCIe/#pcie-switches","text":"https://linuxhint.com/pcie-switch/#:~:text=PCIe%20switches%20are%20devices%20that,the%20CPU%20alone%20can%20handle.","title":"PCIe Switches"},{"location":"Notes%20on%20PCIe/#how-to-check-cpu-affinity","text":"[root@r7525 ~]# cat /sys/class/pci_bus/0000\\:00/cpulistaffinity 24-31,88-95 [root@r7525 ~]# lscpu | grep -i numa NUMA node(s): 8 NUMA node0 CPU(s): 0-7,64-71 NUMA node1 CPU(s): 8-15,72-79 NUMA node2 CPU(s): 16-23,80-87 NUMA node3 CPU(s): 24-31,88-95 NUMA node4 CPU(s): 32-39,96-103 NUMA node5 CPU(s): 40-47,104-111 NUMA node6 CPU(s): 48-55,112-119 NUMA node7 CPU(s): 56-63,120-127 You can check the CPU affinity of a PCIe bus and then see what processor it is aligned to by referencing the processor ranges.","title":"How to Check CPU Affinity"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/","text":"Notes on mdraid Performance Testing Notes on mdraid Performance Testing Helpful Resources Helpful Commands Check I/O Scheduler Check Available CPU Governors RAW IO vs Direct IO My Notes What are NUMAs per socket? What is rq_affinity Configuration My Hardware My Configuration FIO Command libaio I/O Depth Direct Ramp Time Time Based readwrite (rw) Name numjobs Blocksize NUMA Memory Policy NUMA CPU Nodes Raw I/O Testing Research P-states and C-States Power performance states (ACPI P states) Processor idle sleep states (ACPI C states) I/O Models Blocking I/O Nonblocking I/O I/O Multiplexing Model Signal Driven I/O Model Asynchronous I/O Model What is aqu-sz From Understanding the Linux Kernel How does VFS Work? The superblock object The inode object The file object The dentry object Block Devices Handling Block Device Sizes Sectors Blocks Segments Generic Block layer My Questions Helpful Resources https://www.amd.com/system/files/TechDocs/56163-PUB.pdf https://www.computerworld.com/article/2785965/raw-disk-i-o.html https://www.cloudbees.com/blog/linux-io-scheduler-tuning https://wiki.ubuntu.com/Kernel/Reference/IOSchedulers http://developer.amd.com/wp-content/resources/56420.pdf https://infohub.delltechnologies.com/l/cpu-best-practices-3/poweredge-numa-nodes-per-socket-1#:~:text=AMD%20servers%20provide%20the%20ability,bank%20into%20two%20equal%20parts. Helpful Commands Check I/O Scheduler # cat /sys/block/sda/queue/scheduler noop [deadline] cfq Check Available CPU Governors cpupower frequency-info --governors analyzing CPU 0: available cpufreq governors: performance powersave RAW IO vs Direct IO Raw I/O is issued directly to disk offsets, bypassing the file system altogether. It has been used by some applications, especially databases, that can manage and cache their own data better than the file system cache. A drawback is more complexity in the software. From Oracle\u2019s official website, input/output (I/O) to a raw partition offers approximately a 5% to 10% performance improvement over I/O to a partition with a file system on it. Direct I/O allows applications to use a file system but bypass the file system cache, for example, by using the O_DIRECT open(2) flag on Linux. This is similar to synchronous writes (but without the guarantees that O_SYNC offers), and it works for reads as well. It isn\u2019t as direct as raw device I/O, since mapping of file offsets to disk offsets must still be performed by file system code, and I/O may also be resized to match the size used by the file system for on-disk layout (its record size) or it may error (EINVAL). My Notes What are NUMAs per socket? What are NUMAs per socket What is rq_affinity https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-storage_and_file_systems-configuration_tools By default, I/O completions can be processed on a different processor than the processor that issued the I/O request. Set rq_affinity to 1 to disable this ability and perform completions only on the processor that issued the I/O request. This can improve the effectiveness of processor data caching. Configuration Initial driver: /lib/modules/4.18.0-305.el8.x86_64/kernel/drivers/md/raid456.ko.xz I think this has been changed? mdraid looks like it has two stripes 12 NVMe drives in one and 12 in the other all in RAID5. They are all numa aligned by some program called map_numa.sh. Must check drive My Hardware Dell R840 12 Intel P4610 NVMe drives are only attached to processors three and four in the split backplane configuartion. My Configuration I checked firmware rev with nvme list to make sure that all drives were the same. If not need to update 1.TODO still need to do Set the CPU governor to performance. You can check the governors with cpupower frequency-info --governors and then set it with cpupower frequency-set --governor performance . You can check the current governor with cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor (substitute the CPU number accordingly) FIO Command libaio Linux native asynchronous I/O. Note that Linux may only support queued behavior with non-buffered I/O (set direct=1 or buffered=0). This engine defines engine specific options. I/O Depth Number of I/O units to keep in flight against the file. Note that increasing iodepth beyond 1 will not affect synchronous ioengines (except for small degrees when verify_async is in use). Even async engines may impose OS restrictions causing the desired depth not to be achieved. This may happen on Linux when using libaio and not setting direct=1, since buffered I/O is not async on that OS. Keep an eye on the I/O depth distribution in the fio output to verify that the achieved depth is as expected. Default: 1. Direct If value is true, use non-buffered I/O. This is usually O_DIRECT. Note that OpenBSD and ZFS on Solaris don\u2019t support direct I/O. On Windows the synchronous ioengines don\u2019t support direct I/O. Default: false. See https://stackoverflow.com/a/49462406/4427375 Ramp Time If set, fio will run the specified workload for this amount of time before logging any performance numbers. Useful for letting performance settle before logging results, thus minimizing the runtime required for stable results. Note that the ramp_time is considered lead in time for a job, thus it will increase the total runtime if a special timeout or runtime is specified. When the unit is omitted, the value is given in seconds. Time Based If set, fio will run for the duration of the runtime specified even if the file(s) are completely read or written. It will simply loop over the same workload as many times as the runtime allows. readwrite (rw) Type of I/O pattern. Fio defaults to read if the option is not specified. For the mixed I/O types, the default is to split them 50/50. For certain types of I/O the result may still be skewed a bit, since the speed may be different. It is possible to specify the number of I/Os to do before getting a new offset by appending : to the end of the string given. For a random read, it would look like rw=randread:8 for passing in an offset modifier with a value of 8. If the suffix is used with a sequential I/O pattern, then the value specified will be added to the generated offset for each I/O turning sequential I/O into sequential I/O with holes. For instance, using rw=write:4k will skip 4k for every write. Also see the rw_sequencer option. Name ASCII name of the job. This may be used to override the name printed by fio for this job. Otherwise the job name is used. On the command line this parameter has the special purpose of also signaling the start of a new job. numjobs Create the specified number of clones of this job. Each clone of job is spawned as an independent thread or process. May be used to setup a larger number of threads/processes doing the same thing. Each thread is reported separately; to see statistics for all clones as a whole, use group_reporting in conjunction with new_group. See --max-jobs. Default: 1. Blocksize The block size in bytes used for I/O units. Default: 4096. A single value applies to reads, writes, and trims. Comma-separated values may be specified for reads, writes, and trims. A value not terminated in a comma applies to subsequent types. NUMA Memory Policy Set this job\u2019s memory policy and corresponding NUMA nodes. Format of the arguments: <mode>[:<nodelist>] mode is one of the following memory policies: default, prefer, bind, interleave or local. For default and local memory policies, no node needs to be specified. For prefer, only one node is allowed. For bind and interleave the nodelist may be as follows: a comma delimited list of numbers, A-B ranges, or all. NUMA CPU Nodes Set this job running on specified NUMA nodes\u2019 CPUs. The arguments allow comma delimited list of cpu numbers, A-B ranges, or all. Note, to enable NUMA options support, fio must be built on a system with libnuma-dev(el) installed. Raw I/O Testing Research P-states and C-States These are defined in the ACPI specification. Power performance states (ACPI P states) P-states provide a way to scale the frequency and voltage at which the processor runs so as to reduce the power consumption of the CPU. The number of available P-states can be different for each model of CPU, even those from the same family. Processor idle sleep states (ACPI C states) C-states are states when the CPU has reduced or turned off selected functions. Different processors support different numbers of C-states in which various parts of the CPU are turned off. To better understand the C-states that are supported and exposed, contact the CPU vendor. Generally, higher C-states turn off more parts of the CPU, which significantly reduce power consumption. Processors may have deeper C-states that are not exposed to the operating system. I/O Models Blocking I/O In networking, there is a call to recvfrom which will then lead to a system call into the kernel which will block until data is available. Nonblocking I/O Assuming UDP a call is made to recvfrom and if ther is no data available the kernel sends back EWOULDBLOCK saying no data is available and this is repeated until a datagram is available. This is polling. I/O Multiplexing Model With I/O multiplexing you call select which will block until data is available and then when data is available it ill return that there is return readable. After this you can call recvfrom. The difference is select can read from multiple potential sockets. Signal Driven I/O Model In this model we register a signal handler using the sigaction system call. This will listen for the SIGIO signal. When data is ready our SIGIO handler will be called at which point we have two options. We can call recvfrom from the handler and then pass that data to the main thread OR we can alert the main thread that data is waiting and let it handle it. Asynchronous I/O Model This is the same as signal driven I/O except the thread notifies us when the data has been copied from kernel space to user space. We call aio_read and pass the kernel the fdescriptor, buffer pointer, buffer size (the same three arguments for read), file offset (similar to lseek), and how to notify us when the entire operation is complete. When the copy is complete our signal handler is notified. What is aqu-sz The average queue length of the requests that were issued to the device. From Understanding the Linux Kernel How does VFS Work? The idea behind the Virtual Filesystem is to put a wide range of information in the kernel to represent many different types of filesystems ; there is a field or function to support each operation provided by all real filesystems supported by Linux. For each read, write, or other function called, the kernel substitutes the actual function that supports a native Linux filesystem, the NTFS filesystem, or whatever other filesystem the file is on. Bovet, Daniel P.. Understanding the Linux Kernel (Kindle Locations 14260-14263). O'Reilly Media. Kindle Edition. $ cp /floppy/ TEST /tmp/ test where /floppy is the mount point of an MS-DOS diskette and /tmp is a normal Second Extended Filesystem (Ext2) directory. The VFS is an abstraction layer between the application program and the filesystem implementations (see Figure 12-1( a)). Therefore, the cp program is not required to know the filesystem types of /floppy/ TEST and /tmp/ test. Instead, cp interacts with the VFS by means of generic system calls known to anyone who has done Unix programming (see the section \"File-Handling System Calls\" in Chapter 1); the code executed by cp is shown in Figure 12-1( b). More essentially, the Linux kernel cannot hardcode a particular function to handle an operation such as read( ) or ioctl( ) . Instead, it must use a pointer for each operation; the pointer is made to point to the proper function for the particular filesystem being accessed. Let\u2019s illustrate this concept by showing how the read( ) shown in Figure 12-1 would be translated by the kernel into a call specific to the MS-DOS filesystem. The application\u2019s call to read( ) makes the kernel invoke the corresponding sys_read( ) service routine, like every other system call. The file is represented by a file data structure in kernel memory, as we\u2019ll see later in this chapter. This data structure contains a field called f_op that contains pointers to functions specific to MS-DOS files, including a function that reads a file. sys_read( ) finds the pointer to this function and invokes it. Thus, the application\u2019s read( ) is turned into the rather indirect call: file-> f_op-> read(...); One can think of the common file model as object-oriented, where an object is a software construct that defines both a data structure and the methods that operate on it. For reasons of efficiency, Linux is not coded in an object-oriented language such as C ++. Objects are therefore implemented as plain C data structures with some fields pointing to functions that correspond to the object\u2019s methods. The common file model consists of the following object types: The superblock object Stores information concerning a mounted filesystem. For disk-based filesystems, this object usually corresponds to a filesystem control block stored on disk. The inode object Stores general information about a specific file. For disk-based filesystems, this object usually corresponds to a file control block stored on disk. Each inode object is associated with an inode number, which uniquely identifies the file within the filesystem. The file object Stores information about the interaction between an open file and a process. This information exists only in kernel memory during the period when a process has the file open. The dentry object Stores information about the linking of a directory entry (that is, a particular name of the file) with the corresponding file. Each disk-based filesystem stores this information in its own particular way on disk. The picture below illustrates with a simple example how processes interact with files. Three different processes have opened the same file, two of them using the same hard link. In this case, each of the three processes uses its own file object, while only two dentry objects are required \u2014 one for each hard link. Both dentry objects refer to the same inode object, which identifies the superblock object and, together with the latter, the common disk file. Block Devices Handling We will follow the path of a call to read() through the kernel. The service routine of the read( ) system call activates a suitable VFS function, passing to it a file descriptor and an offset inside the file. The Virtual Filesystem is the upper layer of the block device handling architecture, and it provides a common file model adopted by all filesystems supported by Linux. The VFS function determines if the requested data is already available and, if necessary, how to perform the read operation. Sometimes there is no need to access the data on disk, because the kernel keeps in RAM the data most recently read from \u2014 or written to \u2014 a block device. TODO - investigate pacge cache in chapter 15 and how VFS talks to the cache in chapter 16. Let\u2019s assume that the kernel must read the data from the block device, thus it must determine the physical location of that data. To do this, the kernel relies on the mapping layer , which typically executes two steps: 1.It determines the block size of the filesystem including the file and computes the extent of the requested data in terms of file block numbers . Essentially, the file is seen as split in many blocks, and the kernel determines the numbers (indices relative to the beginning of file) of the blocks containing the requested data. 2.Next, the mapping layer invokes a filesystem-specific function that accesses the file\u2019s disk inode and determines the position of the requested data on disk in terms of logical block numbers. Essentially, the disk is seen as split in blocks, and the kernel determines the numbers (indices relative to the beginning of the disk or partition) corresponding to the blocks storing the requested data. Because a file may be stored in nonadjacent blocks on disk, a data structure stored in the disk inode maps each file block number to a logical block number.[*] However, if the read access was done on a raw block device file, the mapping layer does not invoke a filesystem-specific method; rather, it translates the offset in the block device file to a position inside the disk \u2014 or disk partition \u2014 corresponding to the device file. The kernel can now issue the read operation on the block device. It makes use of the generic block layer , which starts the I/ O operations that transfer the requested data. In general, each I/ O operation involves a group of blocks that are adjacent on disk. Because the requested data is not necessarily adjacent on disk, the generic block layer might start several I/ O operations. Each I/ O operation is represented by a \"block I/ O\ufffd (in short, \"bio\") structure, which collects all information needed by the lower components to satisfy the request. The generic block layer hides the peculiarities of each hardware block device, thus offering an abstract view of the block devices. Because almost all block devices are disks, the generic block layer also provides some general data structures that describe \"disks\" and \"disk partitions.\" Below the generic block layer, the \"I/ O scheduler \" sorts the pending I/ O data transfer requests according to predefined kernel policies. The purpose of the scheduler is to group requests of data that lie near each other on the physical medium. Finally, the block device drivers take care of the actual data transfer by sending suitable commands to the hardware interfaces of the disk controllers. Block Device Sizes There are many kernel components that are concerned with data stored in block devices; each of them manages the disk data using chunks of different length: The controllers of the hardware block devices transfer data in chunks of fixed length called \"sectors.\" Therefore, the I/ O scheduler and the block device drivers must manage sectors of data. The Virtual Filesystem, the mapping layer, and the filesystems group the disk data in logical units called \"blocks.\" A block corresponds to the minimal disk storage unit inside a filesystem. Block device drivers should be able to cope with \"segments\" of data: each segment is a memory page \u2014 or a portion of a memory page \u2014 including chunks of data that are physically adjacent on disk. The disk caches work on \"pages\" of disk data, each of which fits in a page frame. The generic block layer glues together all the upper and lower components, thus it knows about sectors , blocks, segments, and pages of data. Even if there are many different chunks of data, they usually share the same physical RAM cells. For instance, Figure 14-2 shows the layout of a 4,096-byte page. The upper kernel components see the page as composed of four block buffers of 1,024 bytes each. The last three blocks of the page are being transferred by the block device driver, thus they are inserted in a segment covering the last 3,072 bytes of the page. The hard disk controller considers the segment as composed of six 512-byte sectors. Sectors To achieve acceptable performance, hard disks and similar devices transfer several adjacent bytes at once. Each data transfer operation for a block device acts on a group of adjacent bytes called a sector. In the following discussion, we say that groups of bytes are adjacent when they are recorded on the disk surface in such a manner that a single seek operation can access them. Although the physical geometry of a disk is usually very complicated, the hard disk controller accepts commands that refer to the disk as a large array of sectors. In most disk devices, the size of a sector is 512 bytes, although there are devices that use larger sectors (1,024 and 2,048 bytes). Notice that the sector should be considered as the basic unit of data transfer; it is never possible to transfer less than one sector, although most disk devices are capable of transferring several adjacent sectors at once. In Linux, the size of a sector is conventionally set to 512 bytes; if a block device uses larger sectors, the corresponding low-level block device driver will do the necessary conversions. Thus, a group of data stored in a block device is identified on disk by its position \u2014 the index of the first 512-byte sector \u2014 and its length as number of 512-byte sectors. Sector indices are stored in 32- or 64-bit variables of type sector_t. Blocks While the sector is the basic unit of data transfer for the hardware devices, the block is the basic unit of data transfer for the VFS and, consequently, for the filesystems. For example, when the kernel accesses the contents of a file, it must first read from disk a block containing the disk inode of the file (see the section \"Inode Objects\" in Chapter 12). This block on disk corresponds to one or more adjacent sectors, which are looked at by the VFS as a single data unit. In Linux, the block size must be a power of 2 and cannot be larger than a page frame. Moreover, it must be a multiple of the sector size, because each block must include an integral number of sectors. Therefore, on 80 \u00d7 86 architecture, the permitted block sizes are 512, 1,024, 2,048, and 4,096 bytes. The block size is not specific to a block device. When creating a disk-based filesystem, the administrator may select the proper block size. Thus, several partitions on the same disk might make use of different block sizes. Furthermore, each read or write operation issued on a block device file is a \"raw\" access that bypasses the disk-based filesystem; the kernel executes it by using blocks of largest size (4,096 bytes). Each block requires its own block buffer, which is a RAM memory area used by the kernel to store the block\u2019s content. When the kernel reads a block from disk, it fills the corresponding block buffer with the values obtained from the hardware device; similarly, when the kernel writes a block on disk, it updates the corresponding group of adjacent bytes on the hardware device with the actual values of the associated block buffer. The size of a block buffer always matches the size of the corresponding block. Each buffer has a \"buffer head\" descriptor of type buffer_head. This descriptor contains all the information needed by the kernel to know how to handle the buffer; thus, before operating on each buffer, the kernel checks its buffer head. We will give a detailed explanation of all fields of the buffer head in Chapter 15; in the present chapter, however, we will only consider a few fields: b_page, b_data, b_blocknr, and b_bdev. The b_page field stores the page descriptor address of the page frame that includes the block buffer. If the page frame is in high memory, the b_data field stores the offset of the block buffer inside the page; otherwise, it stores the starting linear address of the block buffer itself. The b_blocknr field stores the logical block number (i.e., the index of the block inside the disk partition). Finally, the b_bdev field identifies the block device that is using the buffer head Segments We know that each disk I/ O operation consists of transferring the contents of some adjacent sectors from \u2014 or to \u2014 some RAM locations. In almost all cases, the data transfer is directly performed by the disk controller with a DMA operation (see the section \"Direct Memory Access (DMA)\" in Chapter 13). The block device driver simply triggers the data transfer by sending suitable commands to the disk controller; once the data transfer is finished, the controller raises an interrupt to notify the block device driver. The data transferred by a single DMA operation must belong to sectors that are adjacent on disk. This is a physical constraint: a disk controller that allows DMA transfers to non-adjacent sectors would have a poor transfer rate, because moving a read/ write head on the disk surface is quite a slow operation. Older disk controllers support \"simple\" DMA operations only: in each such operation, data is transferred from or to memory cells that are physically contiguous in RAM. Recent disk controllers, however, may also support the so-called scatter-gather DMA transfers : in each such operation, the data can be transferred from or to several noncontiguous memory areas. For each scatter-gather DMA transfer, the block device driver must send to the disk controller: The initial disk sector number and the total number of sectors to be transferred A list of descriptors of memory areas, each of which consists of an address and a length. The disk controller takes care of the whole data transfer; for instance, in a read operation the controller fetches the data from the adjacent disk sectors and scatters it into the various memory areas. To make use of scatter-gather DMA operations, block device drivers must handle the data in units called segments . A segment is simply a memory page \u2014 or a portion of a memory page \u2014 that includes the data of some adjacent disk sectors. Thus, a scatter-gather DMA operation may involve several segments at once. Notice that a block device driver does not need to know about blocks, block sizes, and block buffers. Thus, even if a segment is seen by the higher levels as a page composed of several block buffers, the block device driver does not care about it. As we\u2019ll see, the generic block layer can merge different segments if the corresponding page frames happen to be contiguous in RAM and the corresponding chunks of disk data are adjacent on disk. The larger memory area resulting from this merge operation is called physical segment. Yet another merge operation is allowed on architectures that handle the mapping between bus addresses and physical addresses through a dedicated bus circuitry (the IO-MMU; see the section \"Direct Memory Access (DMA)\" in Chapter 13). The memory area resulting from this kind of merge operation is called hardware segment . Because we will focus on the 80 \u00d7 86 architecture, which has no such dynamic mapping between bus addresses and physical addresses, we will assume in the rest of this chapter that hardware segments always coincide with physical segments . TODO - need to go read about how DMA works Generic Block layer My Questions - When running FIO, to what extent is disk caching engaged?","title":"Notes on mdraid Performance Testing"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#notes-on-mdraid-performance-testing","text":"Notes on mdraid Performance Testing Helpful Resources Helpful Commands Check I/O Scheduler Check Available CPU Governors RAW IO vs Direct IO My Notes What are NUMAs per socket? What is rq_affinity Configuration My Hardware My Configuration FIO Command libaio I/O Depth Direct Ramp Time Time Based readwrite (rw) Name numjobs Blocksize NUMA Memory Policy NUMA CPU Nodes Raw I/O Testing Research P-states and C-States Power performance states (ACPI P states) Processor idle sleep states (ACPI C states) I/O Models Blocking I/O Nonblocking I/O I/O Multiplexing Model Signal Driven I/O Model Asynchronous I/O Model What is aqu-sz From Understanding the Linux Kernel How does VFS Work? The superblock object The inode object The file object The dentry object Block Devices Handling Block Device Sizes Sectors Blocks Segments Generic Block layer My Questions","title":"Notes on mdraid Performance Testing"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#helpful-resources","text":"https://www.amd.com/system/files/TechDocs/56163-PUB.pdf https://www.computerworld.com/article/2785965/raw-disk-i-o.html https://www.cloudbees.com/blog/linux-io-scheduler-tuning https://wiki.ubuntu.com/Kernel/Reference/IOSchedulers http://developer.amd.com/wp-content/resources/56420.pdf https://infohub.delltechnologies.com/l/cpu-best-practices-3/poweredge-numa-nodes-per-socket-1#:~:text=AMD%20servers%20provide%20the%20ability,bank%20into%20two%20equal%20parts.","title":"Helpful Resources"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#helpful-commands","text":"","title":"Helpful Commands"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#check-io-scheduler","text":"# cat /sys/block/sda/queue/scheduler noop [deadline] cfq","title":"Check I/O Scheduler"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#check-available-cpu-governors","text":"cpupower frequency-info --governors analyzing CPU 0: available cpufreq governors: performance powersave","title":"Check Available CPU Governors"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#raw-io-vs-direct-io","text":"Raw I/O is issued directly to disk offsets, bypassing the file system altogether. It has been used by some applications, especially databases, that can manage and cache their own data better than the file system cache. A drawback is more complexity in the software. From Oracle\u2019s official website, input/output (I/O) to a raw partition offers approximately a 5% to 10% performance improvement over I/O to a partition with a file system on it. Direct I/O allows applications to use a file system but bypass the file system cache, for example, by using the O_DIRECT open(2) flag on Linux. This is similar to synchronous writes (but without the guarantees that O_SYNC offers), and it works for reads as well. It isn\u2019t as direct as raw device I/O, since mapping of file offsets to disk offsets must still be performed by file system code, and I/O may also be resized to match the size used by the file system for on-disk layout (its record size) or it may error (EINVAL).","title":"RAW IO vs Direct IO"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#my-notes","text":"","title":"My Notes"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#what-are-numas-per-socket","text":"What are NUMAs per socket","title":"What are NUMAs per socket?"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#what-is-rq_affinity","text":"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-storage_and_file_systems-configuration_tools By default, I/O completions can be processed on a different processor than the processor that issued the I/O request. Set rq_affinity to 1 to disable this ability and perform completions only on the processor that issued the I/O request. This can improve the effectiveness of processor data caching.","title":"What is rq_affinity"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#configuration","text":"Initial driver: /lib/modules/4.18.0-305.el8.x86_64/kernel/drivers/md/raid456.ko.xz I think this has been changed? mdraid looks like it has two stripes 12 NVMe drives in one and 12 in the other all in RAID5. They are all numa aligned by some program called map_numa.sh. Must check drive","title":"Configuration"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#my-hardware","text":"Dell R840 12 Intel P4610 NVMe drives are only attached to processors three and four in the split backplane configuartion.","title":"My Hardware"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#my-configuration","text":"I checked firmware rev with nvme list to make sure that all drives were the same. If not need to update 1.TODO still need to do Set the CPU governor to performance. You can check the governors with cpupower frequency-info --governors and then set it with cpupower frequency-set --governor performance . You can check the current governor with cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor (substitute the CPU number accordingly)","title":"My Configuration"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#fio-command","text":"","title":"FIO Command"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#libaio","text":"Linux native asynchronous I/O. Note that Linux may only support queued behavior with non-buffered I/O (set direct=1 or buffered=0). This engine defines engine specific options.","title":"libaio"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#io-depth","text":"Number of I/O units to keep in flight against the file. Note that increasing iodepth beyond 1 will not affect synchronous ioengines (except for small degrees when verify_async is in use). Even async engines may impose OS restrictions causing the desired depth not to be achieved. This may happen on Linux when using libaio and not setting direct=1, since buffered I/O is not async on that OS. Keep an eye on the I/O depth distribution in the fio output to verify that the achieved depth is as expected. Default: 1.","title":"I/O Depth"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#direct","text":"If value is true, use non-buffered I/O. This is usually O_DIRECT. Note that OpenBSD and ZFS on Solaris don\u2019t support direct I/O. On Windows the synchronous ioengines don\u2019t support direct I/O. Default: false. See https://stackoverflow.com/a/49462406/4427375","title":"Direct"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#ramp-time","text":"If set, fio will run the specified workload for this amount of time before logging any performance numbers. Useful for letting performance settle before logging results, thus minimizing the runtime required for stable results. Note that the ramp_time is considered lead in time for a job, thus it will increase the total runtime if a special timeout or runtime is specified. When the unit is omitted, the value is given in seconds.","title":"Ramp Time"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#time-based","text":"If set, fio will run for the duration of the runtime specified even if the file(s) are completely read or written. It will simply loop over the same workload as many times as the runtime allows.","title":"Time Based"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#readwrite-rw","text":"Type of I/O pattern. Fio defaults to read if the option is not specified. For the mixed I/O types, the default is to split them 50/50. For certain types of I/O the result may still be skewed a bit, since the speed may be different. It is possible to specify the number of I/Os to do before getting a new offset by appending : to the end of the string given. For a random read, it would look like rw=randread:8 for passing in an offset modifier with a value of 8. If the suffix is used with a sequential I/O pattern, then the value specified will be added to the generated offset for each I/O turning sequential I/O into sequential I/O with holes. For instance, using rw=write:4k will skip 4k for every write. Also see the rw_sequencer option.","title":"readwrite (rw)"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#name","text":"ASCII name of the job. This may be used to override the name printed by fio for this job. Otherwise the job name is used. On the command line this parameter has the special purpose of also signaling the start of a new job.","title":"Name"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#numjobs","text":"Create the specified number of clones of this job. Each clone of job is spawned as an independent thread or process. May be used to setup a larger number of threads/processes doing the same thing. Each thread is reported separately; to see statistics for all clones as a whole, use group_reporting in conjunction with new_group. See --max-jobs. Default: 1.","title":"numjobs"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#blocksize","text":"The block size in bytes used for I/O units. Default: 4096. A single value applies to reads, writes, and trims. Comma-separated values may be specified for reads, writes, and trims. A value not terminated in a comma applies to subsequent types.","title":"Blocksize"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#numa-memory-policy","text":"Set this job\u2019s memory policy and corresponding NUMA nodes. Format of the arguments: <mode>[:<nodelist>] mode is one of the following memory policies: default, prefer, bind, interleave or local. For default and local memory policies, no node needs to be specified. For prefer, only one node is allowed. For bind and interleave the nodelist may be as follows: a comma delimited list of numbers, A-B ranges, or all.","title":"NUMA Memory Policy"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#numa-cpu-nodes","text":"Set this job running on specified NUMA nodes\u2019 CPUs. The arguments allow comma delimited list of cpu numbers, A-B ranges, or all. Note, to enable NUMA options support, fio must be built on a system with libnuma-dev(el) installed.","title":"NUMA CPU Nodes"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#raw-io-testing","text":"","title":"Raw I/O Testing"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#research","text":"","title":"Research"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#p-states-and-c-states","text":"These are defined in the ACPI specification.","title":"P-states and C-States"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#power-performance-states-acpi-p-states","text":"P-states provide a way to scale the frequency and voltage at which the processor runs so as to reduce the power consumption of the CPU. The number of available P-states can be different for each model of CPU, even those from the same family.","title":"Power performance states (ACPI P states)"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#processor-idle-sleep-states-acpi-c-states","text":"C-states are states when the CPU has reduced or turned off selected functions. Different processors support different numbers of C-states in which various parts of the CPU are turned off. To better understand the C-states that are supported and exposed, contact the CPU vendor. Generally, higher C-states turn off more parts of the CPU, which significantly reduce power consumption. Processors may have deeper C-states that are not exposed to the operating system.","title":"Processor idle sleep states (ACPI C states)"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#io-models","text":"","title":"I/O Models"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#blocking-io","text":"In networking, there is a call to recvfrom which will then lead to a system call into the kernel which will block until data is available.","title":"Blocking I/O"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#nonblocking-io","text":"Assuming UDP a call is made to recvfrom and if ther is no data available the kernel sends back EWOULDBLOCK saying no data is available and this is repeated until a datagram is available. This is polling.","title":"Nonblocking I/O"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#io-multiplexing-model","text":"With I/O multiplexing you call select which will block until data is available and then when data is available it ill return that there is return readable. After this you can call recvfrom. The difference is select can read from multiple potential sockets.","title":"I/O Multiplexing Model"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#signal-driven-io-model","text":"In this model we register a signal handler using the sigaction system call. This will listen for the SIGIO signal. When data is ready our SIGIO handler will be called at which point we have two options. We can call recvfrom from the handler and then pass that data to the main thread OR we can alert the main thread that data is waiting and let it handle it.","title":"Signal Driven I/O Model"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#asynchronous-io-model","text":"This is the same as signal driven I/O except the thread notifies us when the data has been copied from kernel space to user space. We call aio_read and pass the kernel the fdescriptor, buffer pointer, buffer size (the same three arguments for read), file offset (similar to lseek), and how to notify us when the entire operation is complete. When the copy is complete our signal handler is notified.","title":"Asynchronous I/O Model"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#what-is-aqu-sz","text":"The average queue length of the requests that were issued to the device.","title":"What is aqu-sz"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#from-understanding-the-linux-kernel","text":"","title":"From Understanding the Linux Kernel"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#how-does-vfs-work","text":"The idea behind the Virtual Filesystem is to put a wide range of information in the kernel to represent many different types of filesystems ; there is a field or function to support each operation provided by all real filesystems supported by Linux. For each read, write, or other function called, the kernel substitutes the actual function that supports a native Linux filesystem, the NTFS filesystem, or whatever other filesystem the file is on. Bovet, Daniel P.. Understanding the Linux Kernel (Kindle Locations 14260-14263). O'Reilly Media. Kindle Edition. $ cp /floppy/ TEST /tmp/ test where /floppy is the mount point of an MS-DOS diskette and /tmp is a normal Second Extended Filesystem (Ext2) directory. The VFS is an abstraction layer between the application program and the filesystem implementations (see Figure 12-1( a)). Therefore, the cp program is not required to know the filesystem types of /floppy/ TEST and /tmp/ test. Instead, cp interacts with the VFS by means of generic system calls known to anyone who has done Unix programming (see the section \"File-Handling System Calls\" in Chapter 1); the code executed by cp is shown in Figure 12-1( b). More essentially, the Linux kernel cannot hardcode a particular function to handle an operation such as read( ) or ioctl( ) . Instead, it must use a pointer for each operation; the pointer is made to point to the proper function for the particular filesystem being accessed. Let\u2019s illustrate this concept by showing how the read( ) shown in Figure 12-1 would be translated by the kernel into a call specific to the MS-DOS filesystem. The application\u2019s call to read( ) makes the kernel invoke the corresponding sys_read( ) service routine, like every other system call. The file is represented by a file data structure in kernel memory, as we\u2019ll see later in this chapter. This data structure contains a field called f_op that contains pointers to functions specific to MS-DOS files, including a function that reads a file. sys_read( ) finds the pointer to this function and invokes it. Thus, the application\u2019s read( ) is turned into the rather indirect call: file-> f_op-> read(...); One can think of the common file model as object-oriented, where an object is a software construct that defines both a data structure and the methods that operate on it. For reasons of efficiency, Linux is not coded in an object-oriented language such as C ++. Objects are therefore implemented as plain C data structures with some fields pointing to functions that correspond to the object\u2019s methods. The common file model consists of the following object types:","title":"How does VFS Work?"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#the-superblock-object","text":"Stores information concerning a mounted filesystem. For disk-based filesystems, this object usually corresponds to a filesystem control block stored on disk.","title":"The superblock object"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#the-inode-object","text":"Stores general information about a specific file. For disk-based filesystems, this object usually corresponds to a file control block stored on disk. Each inode object is associated with an inode number, which uniquely identifies the file within the filesystem.","title":"The inode object"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#the-file-object","text":"Stores information about the interaction between an open file and a process. This information exists only in kernel memory during the period when a process has the file open.","title":"The file object"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#the-dentry-object","text":"Stores information about the linking of a directory entry (that is, a particular name of the file) with the corresponding file. Each disk-based filesystem stores this information in its own particular way on disk. The picture below illustrates with a simple example how processes interact with files. Three different processes have opened the same file, two of them using the same hard link. In this case, each of the three processes uses its own file object, while only two dentry objects are required \u2014 one for each hard link. Both dentry objects refer to the same inode object, which identifies the superblock object and, together with the latter, the common disk file.","title":"The dentry object"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#block-devices-handling","text":"We will follow the path of a call to read() through the kernel. The service routine of the read( ) system call activates a suitable VFS function, passing to it a file descriptor and an offset inside the file. The Virtual Filesystem is the upper layer of the block device handling architecture, and it provides a common file model adopted by all filesystems supported by Linux. The VFS function determines if the requested data is already available and, if necessary, how to perform the read operation. Sometimes there is no need to access the data on disk, because the kernel keeps in RAM the data most recently read from \u2014 or written to \u2014 a block device. TODO - investigate pacge cache in chapter 15 and how VFS talks to the cache in chapter 16. Let\u2019s assume that the kernel must read the data from the block device, thus it must determine the physical location of that data. To do this, the kernel relies on the mapping layer , which typically executes two steps: 1.It determines the block size of the filesystem including the file and computes the extent of the requested data in terms of file block numbers . Essentially, the file is seen as split in many blocks, and the kernel determines the numbers (indices relative to the beginning of file) of the blocks containing the requested data. 2.Next, the mapping layer invokes a filesystem-specific function that accesses the file\u2019s disk inode and determines the position of the requested data on disk in terms of logical block numbers. Essentially, the disk is seen as split in blocks, and the kernel determines the numbers (indices relative to the beginning of the disk or partition) corresponding to the blocks storing the requested data. Because a file may be stored in nonadjacent blocks on disk, a data structure stored in the disk inode maps each file block number to a logical block number.[*] However, if the read access was done on a raw block device file, the mapping layer does not invoke a filesystem-specific method; rather, it translates the offset in the block device file to a position inside the disk \u2014 or disk partition \u2014 corresponding to the device file. The kernel can now issue the read operation on the block device. It makes use of the generic block layer , which starts the I/ O operations that transfer the requested data. In general, each I/ O operation involves a group of blocks that are adjacent on disk. Because the requested data is not necessarily adjacent on disk, the generic block layer might start several I/ O operations. Each I/ O operation is represented by a \"block I/ O\ufffd (in short, \"bio\") structure, which collects all information needed by the lower components to satisfy the request. The generic block layer hides the peculiarities of each hardware block device, thus offering an abstract view of the block devices. Because almost all block devices are disks, the generic block layer also provides some general data structures that describe \"disks\" and \"disk partitions.\" Below the generic block layer, the \"I/ O scheduler \" sorts the pending I/ O data transfer requests according to predefined kernel policies. The purpose of the scheduler is to group requests of data that lie near each other on the physical medium. Finally, the block device drivers take care of the actual data transfer by sending suitable commands to the hardware interfaces of the disk controllers.","title":"Block Devices Handling"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#block-device-sizes","text":"There are many kernel components that are concerned with data stored in block devices; each of them manages the disk data using chunks of different length: The controllers of the hardware block devices transfer data in chunks of fixed length called \"sectors.\" Therefore, the I/ O scheduler and the block device drivers must manage sectors of data. The Virtual Filesystem, the mapping layer, and the filesystems group the disk data in logical units called \"blocks.\" A block corresponds to the minimal disk storage unit inside a filesystem. Block device drivers should be able to cope with \"segments\" of data: each segment is a memory page \u2014 or a portion of a memory page \u2014 including chunks of data that are physically adjacent on disk. The disk caches work on \"pages\" of disk data, each of which fits in a page frame. The generic block layer glues together all the upper and lower components, thus it knows about sectors , blocks, segments, and pages of data. Even if there are many different chunks of data, they usually share the same physical RAM cells. For instance, Figure 14-2 shows the layout of a 4,096-byte page. The upper kernel components see the page as composed of four block buffers of 1,024 bytes each. The last three blocks of the page are being transferred by the block device driver, thus they are inserted in a segment covering the last 3,072 bytes of the page. The hard disk controller considers the segment as composed of six 512-byte sectors.","title":"Block Device Sizes"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#sectors","text":"To achieve acceptable performance, hard disks and similar devices transfer several adjacent bytes at once. Each data transfer operation for a block device acts on a group of adjacent bytes called a sector. In the following discussion, we say that groups of bytes are adjacent when they are recorded on the disk surface in such a manner that a single seek operation can access them. Although the physical geometry of a disk is usually very complicated, the hard disk controller accepts commands that refer to the disk as a large array of sectors. In most disk devices, the size of a sector is 512 bytes, although there are devices that use larger sectors (1,024 and 2,048 bytes). Notice that the sector should be considered as the basic unit of data transfer; it is never possible to transfer less than one sector, although most disk devices are capable of transferring several adjacent sectors at once. In Linux, the size of a sector is conventionally set to 512 bytes; if a block device uses larger sectors, the corresponding low-level block device driver will do the necessary conversions. Thus, a group of data stored in a block device is identified on disk by its position \u2014 the index of the first 512-byte sector \u2014 and its length as number of 512-byte sectors. Sector indices are stored in 32- or 64-bit variables of type sector_t.","title":"Sectors"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#blocks","text":"While the sector is the basic unit of data transfer for the hardware devices, the block is the basic unit of data transfer for the VFS and, consequently, for the filesystems. For example, when the kernel accesses the contents of a file, it must first read from disk a block containing the disk inode of the file (see the section \"Inode Objects\" in Chapter 12). This block on disk corresponds to one or more adjacent sectors, which are looked at by the VFS as a single data unit. In Linux, the block size must be a power of 2 and cannot be larger than a page frame. Moreover, it must be a multiple of the sector size, because each block must include an integral number of sectors. Therefore, on 80 \u00d7 86 architecture, the permitted block sizes are 512, 1,024, 2,048, and 4,096 bytes. The block size is not specific to a block device. When creating a disk-based filesystem, the administrator may select the proper block size. Thus, several partitions on the same disk might make use of different block sizes. Furthermore, each read or write operation issued on a block device file is a \"raw\" access that bypasses the disk-based filesystem; the kernel executes it by using blocks of largest size (4,096 bytes). Each block requires its own block buffer, which is a RAM memory area used by the kernel to store the block\u2019s content. When the kernel reads a block from disk, it fills the corresponding block buffer with the values obtained from the hardware device; similarly, when the kernel writes a block on disk, it updates the corresponding group of adjacent bytes on the hardware device with the actual values of the associated block buffer. The size of a block buffer always matches the size of the corresponding block. Each buffer has a \"buffer head\" descriptor of type buffer_head. This descriptor contains all the information needed by the kernel to know how to handle the buffer; thus, before operating on each buffer, the kernel checks its buffer head. We will give a detailed explanation of all fields of the buffer head in Chapter 15; in the present chapter, however, we will only consider a few fields: b_page, b_data, b_blocknr, and b_bdev. The b_page field stores the page descriptor address of the page frame that includes the block buffer. If the page frame is in high memory, the b_data field stores the offset of the block buffer inside the page; otherwise, it stores the starting linear address of the block buffer itself. The b_blocknr field stores the logical block number (i.e., the index of the block inside the disk partition). Finally, the b_bdev field identifies the block device that is using the buffer head","title":"Blocks"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#segments","text":"We know that each disk I/ O operation consists of transferring the contents of some adjacent sectors from \u2014 or to \u2014 some RAM locations. In almost all cases, the data transfer is directly performed by the disk controller with a DMA operation (see the section \"Direct Memory Access (DMA)\" in Chapter 13). The block device driver simply triggers the data transfer by sending suitable commands to the disk controller; once the data transfer is finished, the controller raises an interrupt to notify the block device driver. The data transferred by a single DMA operation must belong to sectors that are adjacent on disk. This is a physical constraint: a disk controller that allows DMA transfers to non-adjacent sectors would have a poor transfer rate, because moving a read/ write head on the disk surface is quite a slow operation. Older disk controllers support \"simple\" DMA operations only: in each such operation, data is transferred from or to memory cells that are physically contiguous in RAM. Recent disk controllers, however, may also support the so-called scatter-gather DMA transfers : in each such operation, the data can be transferred from or to several noncontiguous memory areas. For each scatter-gather DMA transfer, the block device driver must send to the disk controller: The initial disk sector number and the total number of sectors to be transferred A list of descriptors of memory areas, each of which consists of an address and a length. The disk controller takes care of the whole data transfer; for instance, in a read operation the controller fetches the data from the adjacent disk sectors and scatters it into the various memory areas. To make use of scatter-gather DMA operations, block device drivers must handle the data in units called segments . A segment is simply a memory page \u2014 or a portion of a memory page \u2014 that includes the data of some adjacent disk sectors. Thus, a scatter-gather DMA operation may involve several segments at once. Notice that a block device driver does not need to know about blocks, block sizes, and block buffers. Thus, even if a segment is seen by the higher levels as a page composed of several block buffers, the block device driver does not care about it. As we\u2019ll see, the generic block layer can merge different segments if the corresponding page frames happen to be contiguous in RAM and the corresponding chunks of disk data are adjacent on disk. The larger memory area resulting from this merge operation is called physical segment. Yet another merge operation is allowed on architectures that handle the mapping between bus addresses and physical addresses through a dedicated bus circuitry (the IO-MMU; see the section \"Direct Memory Access (DMA)\" in Chapter 13). The memory area resulting from this kind of merge operation is called hardware segment . Because we will focus on the 80 \u00d7 86 architecture, which has no such dynamic mapping between bus addresses and physical addresses, we will assume in the rest of this chapter that hardware segments always coincide with physical segments . TODO - need to go read about how DMA works","title":"Segments"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#generic-block-layer","text":"","title":"Generic Block layer"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#my-questions","text":"","title":"My Questions"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/#-when-running-fio-to-what-extent-is-disk-caching-engaged","text":"","title":"- When running FIO, to what extent is disk caching engaged?"},{"location":"Notes%20on%20mdraid%20Performance%20Testing/lstopo/","text":"[root@r8402 ~]# lstopo Machine (187GB total) Package L#0 NUMANode L#0 (P#0 45GB) L3 L#0 (14MB) L2 L#0 (1024KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 PU L#0 (P#0) PU L#1 (P#40) L2 L#1 (1024KB) + L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1 PU L#2 (P#4) PU L#3 (P#44) L2 L#2 (1024KB) + L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2 PU L#4 (P#8) PU L#5 (P#48) L2 L#3 (1024KB) + L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3 PU L#6 (P#12) PU L#7 (P#52) L2 L#4 (1024KB) + L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4 PU L#8 (P#16) PU L#9 (P#56) L2 L#5 (1024KB) + L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5 PU L#10 (P#20) PU L#11 (P#60) L2 L#6 (1024KB) + L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6 PU L#12 (P#24) PU L#13 (P#64) L2 L#7 (1024KB) + L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7 PU L#14 (P#28) PU L#15 (P#68) L2 L#8 (1024KB) + L1d L#8 (32KB) + L1i L#8 (32KB) + Core L#8 PU L#16 (P#32) PU L#17 (P#72) L2 L#9 (1024KB) + L1d L#9 (32KB) + L1i L#9 (32KB) + Core L#9 PU L#18 (P#36) PU L#19 (P#76) HostBridge PCI 00:11.5 (RAID) PCI 00:17.0 (RAID) PCIBridge PCI 01:00.0 (Ethernet) Net \"eno99\" PCI 01:00.1 (Ethernet) Net \"eno100\" PCIBridge PCIBridge PCI 03:00.0 (VGA) HostBridge PCIBridge PCI 17:00.0 (Ethernet) Net \"eno145\" PCI 17:00.1 (Ethernet) Net \"eno146\" HostBridge PCIBridge PCI 25:00.0 (SATA) Block(Disk) \"sda\" Package L#1 NUMANode L#1 (P#1 47GB) L3 L#1 (14MB) L2 L#10 (1024KB) + L1d L#10 (32KB) + L1i L#10 (32KB) + Core L#10 PU L#20 (P#1) PU L#21 (P#41) L2 L#11 (1024KB) + L1d L#11 (32KB) + L1i L#11 (32KB) + Core L#11 PU L#22 (P#5) PU L#23 (P#45) L2 L#12 (1024KB) + L1d L#12 (32KB) + L1i L#12 (32KB) + Core L#12 PU L#24 (P#9) PU L#25 (P#49) L2 L#13 (1024KB) + L1d L#13 (32KB) + L1i L#13 (32KB) + Core L#13 PU L#26 (P#13) PU L#27 (P#53) L2 L#14 (1024KB) + L1d L#14 (32KB) + L1i L#14 (32KB) + Core L#14 PU L#28 (P#17) PU L#29 (P#57) L2 L#15 (1024KB) + L1d L#15 (32KB) + L1i L#15 (32KB) + Core L#15 PU L#30 (P#21) PU L#31 (P#61) L2 L#16 (1024KB) + L1d L#16 (32KB) + L1i L#16 (32KB) + Core L#16 PU L#32 (P#25) PU L#33 (P#65) L2 L#17 (1024KB) + L1d L#17 (32KB) + L1i L#17 (32KB) + Core L#17 PU L#34 (P#29) PU L#35 (P#69) L2 L#18 (1024KB) + L1d L#18 (32KB) + L1i L#18 (32KB) + Core L#18 PU L#36 (P#33) PU L#37 (P#73) L2 L#19 (1024KB) + L1d L#19 (32KB) + L1i L#19 (32KB) + Core L#19 PU L#38 (P#37) PU L#39 (P#77) HostBridge PCIBridge PCI 48:00.0 (RAID) Package L#2 NUMANode L#2 (P#2 47GB) L3 L#2 (14MB) L2 L#20 (1024KB) + L1d L#20 (32KB) + L1i L#20 (32KB) + Core L#20 PU L#40 (P#2) PU L#41 (P#42) L2 L#21 (1024KB) + L1d L#21 (32KB) + L1i L#21 (32KB) + Core L#21 PU L#42 (P#6) PU L#43 (P#46) L2 L#22 (1024KB) + L1d L#22 (32KB) + L1i L#22 (32KB) + Core L#22 PU L#44 (P#10) PU L#45 (P#50) L2 L#23 (1024KB) + L1d L#23 (32KB) + L1i L#23 (32KB) + Core L#23 PU L#46 (P#14) PU L#47 (P#54) L2 L#24 (1024KB) + L1d L#24 (32KB) + L1i L#24 (32KB) + Core L#24 PU L#48 (P#18) PU L#49 (P#58) L2 L#25 (1024KB) + L1d L#25 (32KB) + L1i L#25 (32KB) + Core L#25 PU L#50 (P#22) PU L#51 (P#62) L2 L#26 (1024KB) + L1d L#26 (32KB) + L1i L#26 (32KB) + Core L#26 PU L#52 (P#26) PU L#53 (P#66) L2 L#27 (1024KB) + L1d L#27 (32KB) + L1i L#27 (32KB) + Core L#27 PU L#54 (P#30) PU L#55 (P#70) L2 L#28 (1024KB) + L1d L#28 (32KB) + L1i L#28 (32KB) + Core L#28 PU L#56 (P#34) PU L#57 (P#74) L2 L#29 (1024KB) + L1d L#29 (32KB) + L1i L#29 (32KB) + Core L#29 PU L#58 (P#38) PU L#59 (P#78) HostBridge PCIBridge PCI 88:00.0 (NVMExp) Block(Disk) \"nvme0n1\" PCIBridge PCI 89:00.0 (NVMExp) Block(Disk) \"nvme1n1\" HostBridge PCIBridge PCI 9b:00.0 (NVMExp) Block(Disk) \"nvme2n1\" PCIBridge PCI 9c:00.0 (NVMExp) Block(Disk) \"nvme3n1\" PCIBridge PCI 9d:00.0 (NVMExp) Block(Disk) \"nvme4n1\" PCIBridge PCI 9e:00.0 (NVMExp) Block(Disk) \"nvme5n1\" Package L#3 NUMANode L#3 (P#3 47GB) L3 L#3 (14MB) L2 L#30 (1024KB) + L1d L#30 (32KB) + L1i L#30 (32KB) + Core L#30 PU L#60 (P#3) PU L#61 (P#43) L2 L#31 (1024KB) + L1d L#31 (32KB) + L1i L#31 (32KB) + Core L#31 PU L#62 (P#7) PU L#63 (P#47) L2 L#32 (1024KB) + L1d L#32 (32KB) + L1i L#32 (32KB) + Core L#32 PU L#64 (P#11) PU L#65 (P#51) L2 L#33 (1024KB) + L1d L#33 (32KB) + L1i L#33 (32KB) + Core L#33 PU L#66 (P#15) PU L#67 (P#55) L2 L#34 (1024KB) + L1d L#34 (32KB) + L1i L#34 (32KB) + Core L#34 PU L#68 (P#19) PU L#69 (P#59) L2 L#35 (1024KB) + L1d L#35 (32KB) + L1i L#35 (32KB) + Core L#35 PU L#70 (P#23) PU L#71 (P#63) L2 L#36 (1024KB) + L1d L#36 (32KB) + L1i L#36 (32KB) + Core L#36 PU L#72 (P#27) PU L#73 (P#67) L2 L#37 (1024KB) + L1d L#37 (32KB) + L1i L#37 (32KB) + Core L#37 PU L#74 (P#31) PU L#75 (P#71) L2 L#38 (1024KB) + L1d L#38 (32KB) + L1i L#38 (32KB) + Core L#38 PU L#76 (P#35) PU L#77 (P#75) L2 L#39 (1024KB) + L1d L#39 (32KB) + L1i L#39 (32KB) + Core L#39 PU L#78 (P#39) PU L#79 (P#79) HostBridge PCIBridge PCI c8:00.0 (NVMExp) Block(Disk) \"nvme6n1\" PCIBridge PCI c9:00.0 (NVMExp) Block(Disk) \"nvme7n1\" PCIBridge PCI ca:00.0 (NVMExp) Block(Disk) \"nvme8n1\" PCIBridge PCI cb:00.0 (NVMExp) Block(Disk) \"nvme9n1\" HostBridge PCIBridge PCI db:00.0 (NVMExp) Block(Disk) \"nvme10n1\" PCIBridge PCI dc:00.0 (NVMExp) Block(Disk) \"nvme11n1\" Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule) Misc(MemoryModule)","title":"Lstopo"},{"location":"Notes%20on%20nodejs/","text":"Notes on nodejs Notes on nodejs Required Javascript Arrow expressions Promises Resolve and Reject Async/Await setInterval() and setTimeout() Node The Node REPL (read-eval-print loop) Running a Program with Node Core Modules Console Module The Process Module The OS Module The Util Module NPM Create a new app nodemon Package Scope Global Packages Installing a Custom Package Modules Exporting Require Using Object Destructuring to be more Selective With require() The Events Module User Input and Output The Error Module Why Error First Callbacks The Buffer Module Readable Streams Further explanation Writable Streams Timers Modules HTTP Server The URL Module Routing Longer Example Returning a Status Code Express Request Object Properties Request Object Methods Response Object Knex.js How does exports.up and exports.down work Seed Files Babel ReactJS Importing React Required Code Components Create a Component Class The Render Function Create a Component Instance Use This in a Class Render Components with Components Importing Files and Exporting Functionality Importing Exporting Component Props Event Handler handleEvent, onEvent, and this.props.onEvent this.props.children Default Properties Component State this.setState from Another Function Component Lifecycle componentDidMount componentWillUnmount componentDidUpdate Stateless Functional Components Function Component Props React Hooks Comparison Class vs Function Update Function Component State Initialize State Use State Setter Outside of JSX Longer Example Set From Previous State Arrays in State Objects in State Longer Example Separate Hooks for Separate States Comparison The Effect Hook - useEffect React Hooks and Component Lifecycle Equivalent componentWillMount for react functional component? Function Component Effects Clean Up Effects Control When Effects are Called Fetch Data from a Server Rules of Hooks Separate Hooks for Separate Effects Stateless Components from Stateful Components Build a Stateful Component Class Don't Update props Child Components Update Their Parents' State More Complex Example Child Components Update Sibling Components One Sibling to Display, Another to Change Style Inline Styles Make a Style Object Variable Share Styles Across Multiple Components Separate Container Components from Presentational Components Create a Container Component Create a Presentational Component propTypes Apply PropTypes PropTypes in Function Components React Forms Input on Change Control vs Uncontrolled Update an Input's Value Set the Input's Initial State Dynamically Rendering Different Components without Switch: the Capitalized Reference Technique React Router BrowserRouter Route Routes Links URL Parameters Nested Routes Pass props to Router Components Good Practices for Calling APIs from ReactJS JSX JSX Elements JSX Elements And Their Surroundings Attributes In JSX Nested JSX JSX Outer Elements Rendering JSX ReactDOM.render() Passing a Variable to ReactDOM.render() class vs className Self-Closing Tags Javascript in JSX Variables in JSX Event Listeners in JSX JSX Conditionals Ternary Operator && .map in JSX List Keys React Create Element Required Javascript Arrow expressions Let\u2019s take a look at the code below. You will see two different functions defined. The first is anonymous (function is not named), and the second is named. When using an arrow expression, we do not use the function declaration. To define an arrow expression you simply use: () => { }. You can pass arguments to an arrow expression between the parenthesis (()). // Defining an anonymous arrow expression that simply logs a string to the console. console.log(() => console.log('Shhh, Im anonymous')); // Defining a named function by creating an arrow expression and saving it to a const variable helloWorld. const helloWorld = (name) => { console.log(`Welcome ${name} to Codecademy, this is an arrow expression.`) }; // Calling the helloWorld() function. helloWorld('Codey'); //Output: Welcome Codey to Codecademy, this is an Arrow Function Expression. Promises A Promise is a JavaScript object that represents the eventual outcome of an asynchronous operation. A Promise has three different outcomes: pending (the result is undefined and the expression is waiting for a result), fulfilled (the promise has been completed successfully and returned a value), and rejected (the promise did not successfully complete, the result is an error object). In the code below a new Promise is being defined and is passed a function that takes two arguments, a fulfilled condition, and a rejected condition. We then log the returned value of the Promise to the console and chain a .catch() method to handle errors. // Creating a new Promise and saving it to the testLuck variable. Two arguments are being passed, one for when the promise resolves, and one for if the promise gets rejected. const testLuck = new Promise((resolve, reject) => { if (Math.random() < 0.5) { resolve('Lucky winner!') } else { reject(new Error('Unlucky!')) } }); testLuck.then(message => { console.log(message) // Log the resolved value of the Promise }).catch(error => { console.error(error) // Log the rejected error of the Promise }); Resolve and Reject The Promise constructor method takes a function parameter called the executor function which runs automatically when the constructor is called. The executor function generally starts an asynchronous operation and dictates how the promise should be settled. The executor function has two function parameters, usually referred to as the resolve() and reject() functions. The resolve() and reject() functions aren\u2019t defined by the programmer. When the Promise constructor runs, JavaScript will pass its own resolve() and reject() functions into the executor function. resolve is a function with one argument. Under the hood, if invoked, resolve() will change the promise\u2019s status from pending to fulfilled, and the promise\u2019s resolved value will be set to the argument passed into resolve(). reject is a function that takes a reason or error as an argument. Under the hood, if invoked, reject() will change the promise\u2019s status from pending to rejected, and the promise\u2019s rejection reason will be set to the argument passed into reject(). Async/Await The async...await syntax allows developers to easily implement Promise-based code. The keyword async used in conjunction with a function declaration creates an async function that returns a Promise. Async functions allow us to use the keyword await to block the event loop until a given Promise resolves or rejects. The await keyword also allows us to assign the resolved value of a Promise to a variable. Let\u2019s take a look at the code below. In the code below an asynchronous arrow expression is defined with the async keyword. In the function body we are creating a new Promise which passes a function that is executed after 5 seconds, we await the Promise to resolve and save the value returned to finalResult, and the output of the Promise is logged to the console. // Creating a new promise that runs the function in the setTimeout after 5 seconds. const newPromise = new Promise((resolve, reject) => { setTimeout(() => resolve(\"All done!\"), 5000); }); // Creating an asynchronous function using an arrow expression and saving it to a the variable asyncFunction. const asyncFunction = async () => { // Awaiting the promise to resolve and saving the result to the variable finalResult. const finalResult = await newPromise; // Logging the result of the promise to the console console.log(finalResult); // Output: All done! } asyncFunction(); setInterval() and setTimeout() In addition to utilizing the async...await syntax, we can also use the setInterval() and setTimeout() functions. In the example code of the previous section, we created a setTimeout() instance in the Promise constructor. The setInterval() function executes a code block at a specified interval, in milliseconds. The setInterval() function requires two arguments: the name of the function (the code block that will be executed), and the number of milliseconds (how often the function will be executed). Optionally, we can pass additional arguments which will be supplied as parameters for the function that will be executed by setInterval(). The setInterval() function will continue to execute until the clearInterval() function is called or the node process is exited. In the code block below, the setInterval() function in the showAlert() function will display an alert box every 5000 milliseconds. // Defining a function that instantiates setInterval const showAlert = () => { // Calling setInterval() and passing a function that shows an alert every 5 seconds. setInterval(() => { alert('I show every 5 seconds!') }, 5000); }; // Calling the newInterval() function that calls the setInterval showAlert(); The setTimeout() function executes a code block after a specified amount of time (in milliseconds) and is only executed once. The setTimeout() function accepts the same arguments as the setInterval() function. Using the clearTimeout() function will prevent the function specified from being executed. In the code block below, a function named showTimeout() is declared as an arrow expression. The setTimeout() function is then defined and displays an alert box after 5 seconds. // Defining a function that calls setTimeout const showTimeout = () => { // Calling setTimeout() that passes a function that shows an alert after 5 seconds. setTimeout(() => { alert('I only show once after 5 seconds!'); }, 5000); }; // Calling the showTimeout() function showTimeout(); Node The Node REPL (read-eval-print loop) REPL is an abbreviation for read\u2013eval\u2013print loop. It\u2019s a program that loops, or repeatedly cycles, through three different states: a read state where the program reads input from a user, the eval state where the program evaluates the user\u2019s input, and the print state where the program prints out its evaluation to a console. Then it loops through these states again. It's just the equivalent of typing python except for javascript. Type node to get to it. To see global vars see Object.keys(global) . You can add to it with global.cat = 'thing' . Print with console.log(global.cat) If you\u2019re familiar with running JavaScript on the browser, you\u2019ve likely encountered the Window object. Here\u2019s one major way that Node differs: try to access the Window object (this will throw an error). The Window object is the JavaScript object in the browser that holds the DOM, since we don\u2019t have a DOM here, there\u2019s no Window object. Running a Program with Node node program Core Modules Include a module: // Require in the 'events' core module: const events = require('events'); Some core modules are actually used inside other core modules. For instance, the util module can be used in the console module to format messages. We\u2019ll cover these two modules in this lesson, as well as two other commonly used core modules: process and os. See all builtin modules: require('module').builtinModules Console Module Since console is a global module, its methods can be accessed from anywhere, and the require() function is not necessary. .log() - prints messages to the terminal .assert() - prints a message to the terminal if the value is falsey console.assert(petsArray.length > 5); .table() - prints out a table in the terminal from an object or array The Process Module Node has a global process object with useful methods and information about the current process. The console.log() method is a \"thin wrapper\" on the .stdout.write() method of the process object. The process.env property is an object which stores and controls information about the environment in which the process is currently running. For example, the process.env object contains a PWD property which holds a string with the directory in which the current process is located. It can be useful to have some if/else logic in a program depending on the current environment\u2014 a web application in a development phase might perform different tasks than when it\u2019s live to users. We could store this information on the process.env. One convention is to add a property to process.env with the key NODE_ENV and a value of either production or development. if (process.env.NODE_ENV === 'development'){ console.log('Testing! Testing! Does everything work?'); } The process.memoryUsage() returns information on the CPU demands of the current process. It returns a property that looks similar to this: { rss: 26247168, heapTotal: 5767168, heapUsed: 3573032, external: 8772 } process.argv holds an array of command line values provided when the current process was initiated. The OS Module const os = require('os'); os.type() \u2014 to return the computer\u2019s operating system. os.arch() \u2014 to return the operating system CPU architecture. os.networkInterfaces() \u2014 to return information about the network interfaces of the computer, such as IP and MAC address. os.homedir() \u2014 to return the current user\u2019s home directory. os.hostname() \u2014 to return the hostname of the operating system. os.uptime() \u2014 to return the system uptime, in seconds. Create an empty object const object = {}; Instantiate a dictionary: const os = require('os'); const server = {type: os.type(), architecture: os.arch(), uptime: os.uptime()}; console.table(server) The Util Module Developers sometimes classify outlier functions used to maintain code and debug certain aspects of a program\u2019s functionality as utility functions. Utility functions don\u2019t necessarily create new functionality in a program, but you can think of them as internal tools used to maintain and debug your code. The Node.js util core module contains methods specifically designed for these purposes. const util = require('util'); Get the type of an object : const util = require('util'); const today = new Date(); const earthDay = 'April 22, 2022'; console.log(util.types.isDate(today)); console.log(util.types.isDate(earthDay)); Turn callback functions into promises : Another important util method is .promisify(), which turns callback functions into promises. As you know, asynchronous programming is essential to Node.js. In the beginning, this asynchrony was achieved using error-first callback functions, which are still very prevalent in the Node ecosystem today. But since promises are often preferred over callbacks and especially nested callbacks, Node offers a way to turn these into promises. Let\u2019s take a look: function getUser (id, callback) { return setTimeout(() => { if (id === 5) { callback(null, { nickname: 'Teddy' }) } else { callback(new Error('User not found')) } }, 1000) } function callback (error, user) { if (error) { console.error(error.message) process.exit(1) } console.log(`User found! Their nickname is: ${user.nickname}`) } getUser(1, callback) // -> `User not found` getUser(5, callback) // -> `User found! Their nickname is: Teddy` You can convert the above to: const getUserPromise = util.promisify(getUser); getUserPromise(id) .then((user) => { console.log(`User found! Their nickname is: ${user.nickname}`); }) .catch((error) => { console.log('User not found', error); }); getUser(1) // -> `User not found` getUser(5) // -> `User found! Their nickname is: Teddy` We declare a getUserPromise variable that stores the getUser method turned into a promise using the .promisify() method. With that in place, we\u2019re able to use getUserPromise with .then() and .catch() methods (or we could also use the async...await syntax here) to resolve the promise returned or catch any errors. NPM Create a new app npm init Add -y to answer yes to everything. This will generate a package.json file: { \"name\": \"my-project\", \"version\": \"1.0.0\", \"description\": \"a basic project\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"author\": \"Super Coder\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.1\" }, } nodemon Automatically restart a program when a file changes. npm install nodemon The npm i <package name> command installs a package locally in a folder called node_modules/ which is created in the project directory that you ran the command from. In addition, the newly installed package will be added to the package.json file. Package Scope While most dependencies play a direct role in the functionality of your application, development dependencies are used for the purpose of making development easier or more efficient. In fact, the nodemon package is actually better suited as a development dependency since it makes developers\u2019 lives easier but makes no changes to the app itself. To install nodemon as a development dependency, we can add the --save-dev flag, or its alias, -D. npm install nodemon --save-dev Development dependencies are listed in the \"devDependencies\" field of the package.json file. This indicates that the package is being used specifically for development and will not be included in a production release of the project. { \"name\": \"my-project\", \"version\": \"1.0.0\", \"description\": \"a basic project\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.1\" }, \"devDependencies\": { \"nodemon\": \"^2.0.13\" } } Global Packages Typically, packages installed this way will be used in the command-line rather than imported into a project\u2019s code. One such example is the http-server package which allows you to spin up a zero-configuration server from anywhere in the command-line. To install a package globally, use the -g flag with the installation command: npm install http-server -g http-server is a good package to install globally since it is a general command-line utility and its purpose is not linked to any specific functionality within an app. Unlike local package dependencies or development dependencies, packages installed globally will not be listed in a projects package.json file and they will be stored in a separate global node_modules/ folder. Installing a Custom Package If you want to give someone else your package you can provide the package.json file and then they can install with npm i . Add --production to leave out the dev dependencies. Modules There are multiple ways of implementing modules depending on the runtime environment in which your code is executed. In JavaScript, there are two runtime environments and each has a preferred module implementation: The Node runtime environment and the module.exports and require() syntax. The browser\u2019s runtime environment and the ES6 import/export syntax. Exporting /* converters.js */ function celsiusToFahrenheit(celsius) { return celsius * (9/5) + 32; } module.exports.celsiusToFahrenheit = celsiusToFahrenheit; module.exports.fahrenheitToCelsius = function(fahrenheit) { return (fahrenheit - 32) * (5/9); }; At the top of the new file, converters.js, the function celsiusToFahrenheit() is declared. On the next line of code, the first approach for exporting a function from a module is shown. In this case, the already-defined function celsiusToFahrenheit() is assigned to module.exports.celsiusToFahrenheit. Below, an alternative approach for exporting a function from a module is shown. In this second case, a new function expression is declared and assigned to module.exports.fahrenheitToCelsius. This new method is designed to convert Fahrenheit values back to Celsius. Both approaches successfully store a function within the module.exports object. module.exports is an object that is built-in to the Node.js runtime environment. Other files can now import this object, and make use of these two functions, with another feature that is built-in to the Node.js runtime environment: the require() function. Require The require() function accepts a string as an argument. That string provides the file path to the module you would like to import. Let\u2019s update water-limits.js such that it uses require() to import the .celsiusToFahrenheit() method from the module.exports object within converters.js: /* water-limits.js */ const converters = require('./converters.js'); const freezingPointC = 0; const boilingPointC = 100; const freezingPointF = converters.celsiusToFahrenheit(freezingPointC); const boilingPointF = converters.celsiusToFahrenheit(boilingPointC); console.log(`The freezing point of water in Fahrenheit is ${freezingPointF}`); console.log(`The boiling point of water in Fahrenheit is ${boilingPointF}`); Using Object Destructuring to be more Selective With require() In many cases, modules will export a large number of functions but only one or two of them are needed. You can use object destructuring to extract only the needed functions. Let\u2019s update celsius-to-fahrenheit.js and only extract the .celsiusToFahrenheit() method, leaving .fahrenheitToCelsius() behind: /* celsius-to-fahrenheit.js */ const { celsiusToFahrenheit } = require('./converters.js'); const celsiusInput = process.argv[2]; const fahrenheitValue = celsiusToFahrenheit(celsiusInput); console.log(`${celsiusInput} degrees Celsius = ${fahrenheitValue} degrees Fahrenheit`); Notice that the first line used to be const converters = require('./converters.js'); and now it is specifying the exported function. The Events Module Node provides an EventEmitter class which we can access by requiring in the events core module: // Require in the 'events' core module let events = require('events'); // Create an instance of the EventEmitter class let myEmitter = new events.EventEmitter(); Each event emitter instance has an .on() method which assigns a listener callback function to a named event. The .on() method takes as its first argument the name of the event as a string and, as its second argument, the listener callback function. Each event emitter instance also has an .emit() method which announces a named event has occurred. The .emit() method takes as its first argument the name of the event as a string and, as its second argument, the data that should be passed let newUserListener = (data) => { console.log(`We have a new user: ${data}.`); }; // Assign the newUserListener function as the listener callback for 'new user' events myEmitter.on('new user', newUserListener) // Emit a 'new user' event myEmitter.emit('new user', 'Lily Pad') //newUserListener will be invoked with 'Lily Pad' Note There is no link between the variable data in the constructer for the event emitter and the new user name. User Input and Output Notice that for user input and output for something like stdin what you're really doing is registering a callback and then calling it on user input. Ex: process.stdin.on('data', (userInput) => { let input = userInput.toString() console.log(input) }); Notice the on and then here we're just defining an anonymous function. The Error Module The Node environment\u2019s error module has all the standard JavaScript errors such as EvalError, SyntaxError, RangeError, ReferenceError, TypeError, and URIError as well as the JavaScript Error class for creating new error instances. Within our own code, we can generate errors and throw them, and, with synchronous code in Node, we can use error handling techniques such as try...catch statements. Note that the error module is within the global scope\u2014there is no need to import the module with the require() statement. Many asynchronous Node APIs use error-first callback functions\u2014callback functions which have an error as the first expected argument and the data as the second argument. If the asynchronous task results in an error, it will be passed in as the first argument to the callback function. If no error was thrown, the first argument will be undefined. const errorFirstCallback = (err, data) => { if (err) { console.log(`There WAS an error: ${err}`); } else { // err was falsy console.log(`There was NO error. Event data: ${data}`); } } Why Error First Callbacks You need this because if you try something like: const api = require('./api.js'); // Not an error-first callback let callbackFunc = (data) => { console.log(`Something went right. Data: ${data}\\n`); }; try { api.naiveErrorProneAsyncFunction('problematic input', callbackFunc); } catch(err) { console.log(`Something went wrong. ${err}\\n`); } then the try-catch won't work because the error is thrown in the context of the separate thread spawned asynchronously and subsequently never caught because Javascript is a garbage programming language. The Buffer Module In Node.js, the Buffer module is used to handle binary data. The Buffer module is within the global scope, which means that Buffer objects can be accessed anywhere in the environment without importing the module with require(). A Buffer object represents a fixed amount of memory that can\u2019t be resized. Buffer objects are similar to an array of integers where each element in the array represents a byte of data. The buffer object will have a range of integers from 0 to 255 inclusive. The Buffer module provides a variety of methods to handle the binary data such as .alloc(), .toString(), .from(), and .concat(). The .alloc() method creates a new Buffer object with the size specified as the first parameter. .alloc() accepts three arguments: Size: Required. The size of the buffer Fill: Optional. A value to fill the buffer with. Default is 0. Encoding: Optional. Default is UTF-8. const buffer = Buffer.alloc(5); console.log(buffer); // Ouput: [0, 0, 0, 0, 0] The .toString() method translates the Buffer object into a human-readable string. It accepts three optional arguments: Encoding: Default is UTF-8. Start: The byte offset to begin translating in the Buffer object. Default is 0. End: The byte offset to end translating in the Buffer object. Default is the length of the buffer. The start and end of the buffer are similar to the start and end of an array, where the first element is 0 and increments upwards. const buffer = Buffer.alloc(5, 'a'); console.log(buffer.toString()); // Output: aaaaa The .from() method is provided to create a new Buffer object from the specified string, array, or buffer. The method accepts two arguments: Object: Required. An object to fill the buffer with. Encoding: Optional. Default is UTF-8. const buffer = Buffer.from('hello'); console.log(buffer); // Output: [104, 101, 108, 108, 111] The .concat() method joins all buffer objects passed in an array into one Buffer object. .concat() comes in handy because a Buffer object can\u2019t be resized. This method accepts two arguments: Array: Required. An array containing Buffer objects. Length: Optional. Specifies the length of the concatenated buffer. const buffer1 = Buffer.from('hello'); // Output: [104, 101, 108, 108, 111] const buffer2 = Buffer.from('world'); // Output:[119, 111, 114, 108, 100] const array = [buffer1, buffer2]; const bufferConcat = Buffer.concat(array); console.log(bufferConcat); // Output: [104, 101, 108, 108, 111, 119, 111, 114, 108, 100] Readable Streams const readline = require('readline'); const fs = require('fs'); const myInterface = readline.createInterface({ input: fs.createReadStream('shoppingList.txt') }); const printData = (data) => { console.log(`Item: ${data}`); }; myInterface.on('line', printData); Further explanation One of the simplest uses of streams is reading and writing to files line-by-line. To read files line-by-line, we can use the .createInterface() method from the readline core module. .createInterface() returns an EventEmitter set up to emit 'line' events: const readline = require('readline'); const fs = require('fs'); const myInterface = readline.createInterface({ input: fs.createReadStream('text.txt') }); myInterface.on('line', (fileLine) => { console.log(`The line read: ${fileLine}`); }); Let\u2019s walk through the above code: We require in the readline and fs core modules. We assign to myInterface the returned value from invoking readline.createInterface() with an object containing our designated input. We set our input to fs.createReadStream('text.txt') which will create a stream from the text.txt file. Next we assign a listener callback to execute when line events are emitted. A 'line' event will be emitted after each line from the file is read. Our listener callback will log to the console 'The line read: [fileLine]', where [fileLine] is the line just read. Writable Streams const readline = require('readline'); const fs = require('fs'); const myInterface = readline.createInterface({ input: fs.createReadStream('shoppingList.txt') }); const fileStream = fs.createWriteStream('shoppingResults.txt'); let transformData = (line) => { fileStream.write(`They were out of: ${line}\\n`); }; myInterface.on('line', transformData); Timers Modules You may already be familiar with some timer functions such as, setTimeout() and setInterval(). Timer functions in Node.js behave similarly to how they work in front-end JavaScript programs, but the difference is that they are added to the Node.js event loop. This means that the timer functions are scheduled and put into a queue. This queue is processed at every iteration of the event loop. If a timer function is executed outside of a module, the behavior will be random (non-deterministic). The setImmediate() function is often compared with the setTimeout() function. When setImmediate() is called, it executes the specified callback function after the current (poll phase) is completed. The method accepts two parameters: the callback function (required) and arguments for the callback function (optional). If you instantiate multiple setImmediate() functions, they will be queued for execution in the order that they were created. HTTP Server To process HTTP requests in JavaScript and Node.js, we can use the built-in http module. This core module is key in leveraging Node.js networking and is extremely useful in creating HTTP servers and processing HTTP requests. The http module comes with various methods that are useful when engaging with HTTP network requests. One of the most commonly used methods within the http module is the .createServer() method. This method is responsible for doing exactly what its namesake implies; it creates an HTTP server. To implement this method to create a server, the following code can be used: const server = http.createServer((req, res) => { res.end('Server is running!'); }); server.listen(8080, () => { const { address, port } = server.address(); console.log(`Server is listening on: http://${address}:${port}`); }) The .createServer() method takes a single argument in the form of a callback function. This callback function has two primary arguments; the request (commonly written as req) and the response (commonly written as res). The req object contains all of the information about an HTTP request ingested by the server. It exposes information such as the HTTP method (GET, POST, etc.), the pathname, headers, body, and so on. The res object contains methods and properties pertaining to the generation of a response by the HTTP server. This object contains methods such as .setHeader() (sets HTTP headers on the response), .statusCode (set the status code of the response), and .end() (dispatches the response to the client who made the request). In the example above, we use the .end() method to send the string \u2018Server is Running!\u2019 to the client, which will display on the web page. Once the .createServer() method has instantiated the server, it must begin listening for connections. This final step is accomplished by the .listen() method on the server instance. This method takes a port number as the first argument, which tells the server to listen for connections at the given port number. In our example above, the server has been set to listen on port 8080. Additionally, the .listen() method takes an optional callback function as a second argument, allowing it to carry out a task after the server has successfully started. Using this simple .createServer() method, in conjunction with the callback, provides the ability to process HTTP requests dynamically and dispatch responses back to their callers. The URL Module Typically, an HTTP server will require information from the request URL to accurately process a request. This request URL is located on the url property contained within the req object itself. To parse the different parts of this URL easily, Node.js provides the built-in url module. The core of the url module revolves around the URL class. A new URL object can be instantiated using the URL class as follows: const url = new URL('https://www.example.com/p/a/t/h?query=string'); Once instantiated, different parts of the URL can be accessed and modified via various properties, which include: hostname: Gets and sets the host name portion of the URL. pathname: Gets and sets the path portion of the URL. searchParams: Gets the search parameter object representing the query parameters contained within the URL. Returns an instance of the URLSearchParams class. You might recognize the URL and URLSearchParams classes if you are familiar with browser-based JavaScript. It\u2019s because they are actually the same thing! These classes are defined by the WHATWG URL specification. Both the browser and Node.js implement this API, which means developers can have a similar developer experience working with both client and server-side JavaScript. Using these properties, one can break the URL down into easily usable parts for processing the request. const host = url.hostname; // example.com const pathname = url.pathname; // /p/a/t/h const searchParams = url.searchParams; // {query: 'string'} While the url module can be used to deconstruct a URL into its constituent parts, it can also be used to construct a URL. Constructing a URL via this method relies on most of the same properties listed above to set values on the URL instead of retrieving them. This can be done by setting each of these values equal to a value for the newly constructed URL. Once all parts of the URL have been added, the composed URL can be obtained using the .toString() method. const createdUrl = new URL('https://www.example.com'); createdUrl.pathname = '/p/a/t/h'; createdUrl.search = '?query=string'; createUrl.toString(); // Creates https://www.example.com/p/a/t/h?query=string Routing To process and respond to requests appropriately, servers need to do more than look at a request and dispatch a response. Internally, a server needs to maintain a way to handle each request based on specific criteria such as method, pathname, etc. The process of handling requests in specific ways based on the information provided within the request is known as routing. The method is one important piece of information that can be used to route requests. Since each HTTP request contains a method such as GET and POST, it is a great way to discern different classes of requests based on the action intended for the server to carry out. Thus, all GET requests could be routed to a specific function for handling, while all POST requests are routed to another function to be handled. This also allows for the logical co-location of processing code with the specific verb to be handled. const server = http.createServer((req, res) => { const { method } = req; switch(method) { case 'GET': return handleGetRequest(req, res); case 'POST': return handlePostRequest(req, res); case 'DELETE': return handleDeleteRequest(req, res); case 'PUT': return handlePutRequest(req, res); default: throw new Error(`Unsupported request method: ${method}`); } }) In the above example, the HTTP method property is destructured from the req object and used to conditionally invoke a handler function built specifically for handling those types of requests. This is great at first glance, but it should soon become apparent that the routing is not specific enough. After all, how will one GET request be distinguished from another? We can distinguish one request from another of the same method through the use of the pathname. The pathname allows the server to understand what resource is being targeted. Let\u2019s take a look at the handleGetRequest handler function. function handleGetRequest(req, res) { const { pathname } = new URL(req.url); let data = {}; if (pathname === '/projects') { data = await getProjects(); res.setHeader('Content-Type', 'application/json'); return res.end(JSON.stringify(data)); } res.statusCode = 404; return res.end('Requested resource does not exist'); } Within the handleGetRequest() function, the pathname is being checked to match a known resource, '/projects'. If the pathname matches, the resource data is fetched and then subsequently dispatched from the server as a successful response. Otherwise, the .statusCode property is set to 404, indicating that the resource is not found, and a corresponding error message is dispatched. This pattern can be extrapolated to any number of conditional resource matches, allowing the server to handle many different types of requests to different resources. Longer Example const http = require('http'); // Handle get request const handleGetRequest = (req, res) => { const pathname = req.url; if (pathname === '/users') { res.end(JSON.stringify([])); } } // Creates server instance const server = http.createServer((req, res) => { const { method } = req; switch(method) { case 'GET': return handleGetRequest(req, res); default: throw new Error(`Unsupported request method: ${method}`); } }); // Starts server listening on specified port server.listen(4001, () => { const { address, port } = server.address(); console.log(`Server is listening on: http://${address}:${port}`); }); Returning a Status Code const http = require('http'); const handleGetRequest = (req, res) => { res.statusCode = 200; return res.end(JSON.stringify({ data: [] })); } const handlePostRequest = (req, res) => { res.statusCode = 500; return res.end(\"Unable to create record\"); } // Creates server instance const server = http.createServer((req, res) => { const { method } = req; switch(method) { case 'GET': return handleGetRequest(req, res); case 'POST': return handlePostRequest(req, res); default: throw new Error(`Unsupported request method: ${method}`); } }); // Starts server listening on specified port server.listen(4001, () => { const { address, port } = server.address(); console.log(`Server is listening on: http://${address}:${port}`); }); Express Request Object Properties Index Properties Description 1. req.app This is used to hold a reference to the instance of the express application that is using the middleware. 2. req.baseurl It specifies the URL path on which a router instance was mounted. 3. req.body It contains key-value pairs of data submitted in the request body. By default, it is undefined, and is populated when you use body-parsing middleware such as body-parser. 4. req.cookies When we use cookie-parser middleware, this property is an object that contains cookies sent by the request. 5. req.fresh It specifies that the request is \"fresh.\" it is the opposite of req.stale. 6. req.hostname It contains the hostname from the \"host\" http header. 7. req.ip It specifies the remote IP address of the request. 8. req.ips When the trust proxy setting is true, this property contains an array of IP addresses specified in the ?x-forwarded-for? request header. 9. req.originalurl This property is much like req.url; however, it retains the original request URL, allowing you to rewrite req.url freely for internal routing purposes. 10. req.params An object containing properties mapped to the named route ?parameters?. For example, if you have the route /user/:name, then the \"name\" property is available as req.params.name. This object defaults to {}. 11. req.path It contains the path part of the request URL. 12. req.protocol The request protocol string, \"http\" or \"https\" when requested with TLS. 13. req.query An object containing a property for each query string parameter in the route. 14. req.route The currently-matched route, a string. 15. req.secure A Boolean that is true if a TLS connection is established. 16. req.signedcookies When using cookie-parser middleware, this property contains signed cookies sent by the request, unsigned and ready for use. 17. req.stale It indicates whether the request is \"stale,\" and is the opposite of req.fresh. 18. req.subdomains It represents an array of subdomains in the domain name of the request. 19. req.xhr A Boolean value that is true if the request's \"x-requested-with\" header field is \"xmlhttprequest\", indicating that the request was issued by a client library such as jQuery Request Object Methods req.accepts This method is used to check whether the specified content types are acceptable, based on the request's Accept HTTP header field. req.accepts('html'); //=>?html? req.accepts('text/html'); // => ?text/html? req.get(field) This method returns the specified HTTP request header field. req.get('Content-Type'); // => \"text/plain\" req.get('content-type'); // => \"text/plain\" req.get('Something'); // => undefined req.is(type) // With Content-Type: text/html; charset=utf-8 req.is('html'); req.is('text/html'); req.is('text/*'); // => true req.param(name [,defaultValue]) This method is used to fetch the value of param name when present. // ?name=sasha req.param('name') // => \"sasha\" // POST name=sasha req.param('name') // => \"sasha\" // /user/sasha for /user/:name req.param('name') // => \"sasha\" Response Object Knex.js How does exports.up and exports.down work http://perkframework.com/v1/guides/database-migrations-knex.html Seed Files A seed file allows you to add data into your database without having to manually add it. This is most frequently used for database initialization or loading demo data. Babel What is Babel: https://babeljs.io/docs/en/ ReactJS Importing React Required Code import React from 'react'; This creates an object named React which contains methods necessary to use the React library. import ReactDOM from 'react-dom'; The methods imported from 'react-dom' are meant for interacting with the DOM. You are already familiar with one of them: ReactDOM.render(). The methods imported from 'react' don\u2019t deal with the DOM at all. They don\u2019t engage directly with anything that isn\u2019t part of React. To clarify: the DOM is used in React applications, but it isn\u2019t part of React. After all, the DOM is also used in countless non-React applications. Methods imported from 'react' are only for pure React purposes, such as creating components or writing JSX elements. Components Create a Component Class we can use a JavaScript class to define a new React component. We can also define components with JavaScript functions, but we\u2019ll focus on class components first. All class components will have some methods and properties in common (more on this later). Rather than rewriting those same properties over and over again every time, we extend the Component class from the React library. This way, we can use code that we import from the React library, without having to write it over and over again ourselves. After we define our class component, we can use it to render as many instances of that component as we want. What is React.Component, and how do you use it to make a component class? React.Component is a JavaScript class. To create your own component class, you must subclass React.Component. You can do this by using the syntax class YourComponentNameGoesHere extends React.Component {}. import React from 'react'; import ReactDOM from 'react-dom'; class MyComponentClass extends React.Component { render() { return <h1>Hello world</h1>; } } ReactDOM.render( <MyComponentClass />, document.getElementById('app') ); On line 4, you know that you are declaring a new component class, which is like a factory for building React components. You know that React.Component is a class, which you must subclass in order to create a component class of your own. You also know that React.Component is a property on the object which was returned by import React from 'react' on line 1. The Render Function A render method is a property whose name is render, and whose value is a function. The term \"render method\" can refer to the entire property, or to just the function part. class ComponentFactory extends React.Component { render() { return <h1>Hello world</h1>; } } Create a Component Instance To make a React component, you write a JSX element. Instead of naming your JSX element something like h1 or div like you\u2019ve done before, give it the same name as a component class. Voil\u00e0, there\u2019s your component instance! JSX elements can be either HTML-like, or component instances. JSX uses capitalization to distinguish between the two! That is the React-specific reason why component class names must begin with capital letters. In a JSX element, that capitalized first letter says, \"I will be a component instance and not an HTML tag.\" Whenever you make a component, that component inherits all of the methods of its component class. MyComponentClass has one method: MyComponentClass.render(). Therefore, also has a method named render. In order to render a component, that component needs to have a method named render. Your component has this! It inherited a method named render from MyComponentClass. To call a component\u2019s render method, you pass that component to ReactDOM.render(). Notice your component, being passed as ReactDOM.render()\u2018s first argument: ReactDOM.render( <MyComponentClass />, document.getElementById('app') ); ReactDOM.render() will tell to call its render method. will call its render method, which will return the JSX element Hello world . ReactDOM.render() will then take that resulting JSX element, and add it to the virtual DOM. This will make \"Hello world\" appear on the screen. Use This in a Class class IceCreamGuy extends React.Component { get food() { return 'ice cream'; } render() { return <h1>I like {this.food}.</h1>; } } Render Components with Components class OMG extends React.Component { render() { return <h1>Whooaa!</h1>; } } class Crazy extends React.Component { render() { return <OMG />; } } Importing Files and Exporting Functionality Importing The second important difference involves the contents of the string at the end of the statement: 'react' vs './NavBar.js'. If you use an import statement, and the string at the end begins with either a dot or a slash, then import will treat that string as a filepath. import will follow that filepath, and import the file that it finds. If your filepath doesn\u2019t have a file extension, then \".js\" is assumed. So the above example could be shortened: import { NavBar } from './NavBar'; One final, important note: None of this behavior is specific to React! Module systems of independent, importable files are a very popular way to organize code. React\u2019s specific module system comes from ES6. Exporting This is called a named export. export class NavBar extends React.Component { Component Props A component\u2019s props is an object. It holds information about that component. You can pass information to a prop via an attribute. import React from 'react'; import ReactDOM from 'react-dom'; class Greeting extends React.Component { render() { return <h1>Hi there, {this.props.firstName}!</h1>; } } ReactDOM.render( <Greeting firstName='Grant' />, document.getElementById('app') ); Event Handler import React from 'react'; import ReactDOM from 'react-dom'; import { Button } from './Button'; class Talker extends React.Component { talk() { let speech = ''; for (let i = 0; i < 10000; i++) { speech += 'blah '; } alert(speech); } render() { return <Button talk={this.talk}/>; ReactDOM.render( <Talker />, document.getElementById('app') ); // **************************************** // In Button.js import React from 'react'; export class Button extends React.Component { render() { return ( // TODO - why is it `this` here? <button onClick={this.props.talk}> Click me! </button> ); } } handleEvent, onEvent, and this.props.onEvent When you pass an event handler as a prop, as you just did, there are two names that you have to choose. Both naming choices occur in the parent component class - that is, in the component class that defines the event handler and passes it. The first name that you have to choose is the name of the event handler itself. Look at Talker.js, lines 6 through 12. This is our event handler. We chose to name it talk. The second name that you have to choose is the name of the prop that you will use to pass the event handler. This is the same thing as your attribute name. For our prop name, we also chose talk, as shown on line 15: return <Button talk={this.talk} />; These two names can be whatever you want. However, there is a naming convention that they often follow. You don\u2019t have to follow this convention, but you should understand it when you see it. Here\u2019s how the naming convention works: first, think about what type of event you are listening for. In our example, the event type was \"click.\" If you are listening for a \"click\" event, then you name your event handler handleClick. If you are listening for a \"keyPress\" event, then you name your event handler handleKeyPress: class MyClass extends React.Component { handleHover() { alert('I am an event handler.'); alert('I will be called in response to \"hover\" events.'); } } Your prop name should be the word on, plus your event type. If you are listening for a \"click\" event, then you name your prop onClick. If you are listening for a \"keyPress\" event, then you name your prop onKeyPress: class MyClass extends React.Component { handleHover() { alert('I am an event handler.'); alert('I will listen for a \"hover\" event.'); } render() { return <Child onHover={this.handleHover} />; } } this.props.children Every component\u2019s props object has a property named children. this.props.children will return everything in between a component\u2019s opening and closing JSX tags. For example: // List.js import React from 'react'; export class List extends React.Component { render() { let titleText = `Favorite ${this.props.type}`; if (this.props.children instanceof Array) { // Add an s to make it plural if there is more than one titleText += 's'; } return ( <div> <h1>{titleText}</h1> <ul>{this.props.children}</ul> </div> ); } } // App.js import React from 'react'; import ReactDOM from 'react-dom'; import { List } from './List'; class App extends React.Component { render() { return ( <div> <List type='Living Musician'> <li>Sachiko M</li> <li>Harvey Sid Fisher</li> </List> <List type='Living Cat Musician'> <li>Nora the Piano Cat</li> </List> </div> ); } } ReactDOM.render( <App />, document.getElementById('app') ); This will print: Favorite Living Musicians Sachiko M Harvey Sid Fisher Favorite Living Cat Musician Nora the Piano Cat Because in List.js, between the <ul></ul> you have {this.props.children} which grabs all the elements between <List></List> in the App class. Default Properties Used if nothing is passed into the property. import React from 'react'; import ReactDOM from 'react-dom'; class Button extends React.Component { render() { return ( <button> {this.props.text} </button> ); } } // defaultProps goes here: Button.defaultProps = {text: \"I am a button\"}; ReactDOM.render( <Button />, document.getElementById('app') ); Component State A React component can access dynamic information in two ways: props and state. Unlike props, a component\u2019s state is not passed in from the outside. A component decides its own state. To make a component have state, give the component a state property. This property should be declared inside of a constructor method, like this: class Example extends React.Component { constructor(props) { super(props); this.state = { mood: 'decent' }; } render() { return <div></div>; } } <Example /> // Access the state outside with this.state.mood // You can set the state with this.setState({mood: \"the mood\"}) What is super(props) Also: https://overreacted.io/why-do-we-write-super-props/ this.setState from Another Function You'll use a wrapper function to call this.setState from another function. Like this: class Example extends React.Component { constructor(props) { super(props); this.state = { weather: 'sunny' }; this.makeSomeFog = this.makeSomeFog.bind(this); } makeSomeFog() { this.setState({ weather: 'foggy' }); } } The line this.makeSomeFog = this.makeSomeFog.bind(this); is necessary because makeSomeFog()'s body contains the word this. It has to do with the way event handlers are bound in Javascript. If you use this without the line this.makeSomeFog = this.makeSomeFog.bind(this); with an event handler the this word will be lost so we have to bind it... because Javascript. If the function isn't used by an event handler then it won't matter. Full example import React from 'react'; import ReactDOM from 'react-dom'; const green = '#39D1B4'; const yellow = '#FFD712'; class Toggle extends React.Component { constructor(props) { super(props); this.state = {color: green}; this.changeColor = this.changeColor.bind(this); } changeColor() { if(this.state.color === yellow) { this.setState({color: green}); } else { this.setState({color: yellow}); } } render() { return ( <div style={{background: this.state.color}}> <h1> <button onClick={this.changeColor}> Change color </button> </h1> </div> ); } } ReactDOM.render(<Toggle />, document.getElementById('app')); NOTE : Anytime you call this.setState it automatically calls render as soon as the state has changed. This is why you don't have to call render again. Component Lifecycle We\u2019ve seen that React components can be highly dynamic. They get created, rendered, added to the DOM, updated, and removed. All of these steps are part of a component\u2019s lifecycle. The component lifecycle has three high-level parts: Mounting, when the component is being initialized and put into the DOM for the first time Updating, when the component updates as a result of changed state or changed props Unmounting, when the component is being removed from the DOM Every React component you\u2019ve ever interacted with does the first step at a minimum. If a component never mounted, you\u2019d never see it! Most interesting components are updated at some point. A purely static component\u2014like, for example, a logo\u2014might not ever update. But if a component\u2019s state changes, it updates. Or if different props are passed to a component, it updates. Finally, a component is unmounted when it\u2019s removed from the DOM. For example, if you have a button that hides a component, chances are that component will be unmounted. If your app has multiple screens, it\u2019s likely that each screen (and all of its child components) will be unmounted. If a component is \"alive\" for the entire lifetime of your app (say, a top-level component or a persistent navigation bar), it won\u2019t be unmounted. But most components can get unmounted one way or another! It\u2019s worth noting that each component instance has its own lifecycle. For example, if you have 3 buttons on a page, then there are 3 component instances, each with its own lifecycle. However, once a component instance is unmounted, that\u2019s it\u2014it will never be re-mounted, or updated again, or unmounted. React components have several methods, called lifecycle methods, that are called at different parts of a component\u2019s lifecycle. This is how you, the programmer, deal with the lifecycle of a component. You may not have known it, but you\u2019ve already used two of the most common lifecycle methods: constructor() and render()! constructor() is the first method called during the mounting phase. render() is called later during the mounting phase, to render the component for the first time, and during the updating phase, to re-render the component. Notice that lifecycle methods don\u2019t necessarily correspond one-to-one with part of the lifecycle. constructor() only executes during the mounting phase, but render() executes during both the mounting and updating phase. componentDidMount Say you want a component to update itself at a setInterval. You don't want to put it in the constructor because that would violate the single responsibility rule but you also don't want it in render because then it would be called on update AND on mounting. That's what componentDidMount is for. componentDidMount() is the final method called during the mounting phase. The order is: The constructor render() componentDidMount() In other words, it\u2019s called after the component is rendered. (Another method, getDerivedStateFromProps(), is called between the constructor and render(), but it is very rarely used and usually isn\u2019t the best way to achieve your goals. We won\u2019t be talking about it in this lesson.) import React from 'react'; import ReactDOM from 'react-dom'; class Clock extends React.Component { constructor(props) { super(props); this.state = { date: new Date() }; } render() { return <div>{this.state.date.toLocaleTimeString()}</div>; } componentDidMount() { const oneSecond = 1000; setInterval(() => { this.setState({ date: new Date() }); }, oneSecond); } } ReactDOM.render(<Clock />, document.getElementById('app')); componentWillUnmount In the case of our interval above, the problem is now that timer will never stop. If we want to remove it. We want to use clearInterval() to clean it up. We can call this during componentWillUnmount import React from 'react'; export class Clock extends React.Component { constructor(props) { super(props); this.state = { date: new Date() }; } render() { return <div>{this.state.date.toLocaleTimeString()}</div>; } componentDidMount() { const oneSecond = 1000; this.intervalID = setInterval(() => { this.setState({ date: new Date() }); }, oneSecond); } componentWillUnmount() { clearInterval(this.intervalID); } } componentDidUpdate When a component updates many things happen but there are two primary methods - render and componentDidUpdate. import React from 'react'; export class Clock extends React.Component { constructor(props) { super(props); this.state = { date: new Date() }; } render() { return ( <div> {this.props.isPrecise ? this.state.date.toISOString() : this.state.date.toLocaleTimeString()} </div> ); } startInterval() { let delay; if (this.props.isPrecise) { delay = 100; } else { delay = 1000; } this.intervalID = setInterval(() => { this.setState({ date: new Date() }); }, delay); } componentDidMount() { this.startInterval(); } componentDidUpdate(prevProps) { if (this.props.isPrecise === prevProps.isPrecise) { return; } clearInterval(this.intervalID); this.startInterval(); } componentWillUnmount() { clearInterval(this.intervalID); } } Stateless Functional Components We used to use classes for components but now we use functions. // Original class-based way of writing components import React from 'react'; import ReactDOM from 'react-dom'; export class Friend extends React.Component { render() { return <img src=\"https://content.codecademy.com/courses/React/react_photo-octopus.jpg\" />; } }; ReactDOM.render( <Friend />, document.getElementById('app') ); // Function Version import React from 'react'; import ReactDOM from 'react-dom'; export const Friend = () => { return <img src=\"https://content.codecademy.com/courses/React/react_photo-octopus.jpg\" />; } ReactDOM.render( <Friend />, document.getElementById('app') ); Function Component Props export function YesNoQuestion (props) { return ( <div> <p>{props.prompt}</p> <input value=\"Yes\" /> <input value=\"No\" /> </div> ); } ReactDOM.render( <YesNoQuestion prompt=\"Have you eaten an apple today?\" />, document.getElementById('app'); ); React Hooks With Hooks, we can use simple function components to do lots of the fancy things that we could only do with class components in the past. React Hooks, plainly put, are functions that let us manage the internal state of components and handle post-rendering side effects directly from our function components. Hooks don\u2019t work inside classes \u2014 they let us use fancy React features without classes. Keep in mind that function components and React Hooks do not replace class components. They are completely optional; just a new tool that we can take advantage of. Note: If you\u2019re familiar with lifecycle methods of class components, you could say that Hooks let us \"hook into\" state and lifecycle features directly from our function components. React offers a number of built-in Hooks. A few of these include useState(), useEffect(), useContext(), useReducer(), and useRef(). See the full list in the docs . With React, we feed static and dynamic data models to JSX to render a view to the screen Use Hooks to \u201chook into\u201d internal component state for managing dynamic data in function components We employ the State Hook by using the code below: currentState to reference the current value of state stateSetter to reference a function used to update the value of this state the initialState argument to initialize the value of state for the component\u2019s first render const [currentState, stateSetter] = useState( initialState ); Call state setters in event handlers Define simple event handlers inline with our JSX event listeners and define complex event handlers outside of our JSX Use a state setter callback function when our next value depends on our previous value Use arrays and objects to organize and manage related data that tends to change together Use the spread syntax on collections of dynamic data to copy the previous state into the next state like so: setArrayState((prev) => [ ...prev ]) and setObjectState((prev) => ({ ...prev })) Split state into multiple, simpler variables instead of throwing it all into one state object Comparison Class vs Function Class import React, { Component } from \"react\"; import NewTask from \"../Presentational/NewTask\"; import TasksList from \"../Presentational/TasksList\"; export default class AppClass extends Component { constructor(props) { super(props); this.state = { newTask: {}, allTasks: [] }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); this.handleDelete = this.handleDelete.bind(this); } handleChange({ target }){ const { name, value } = target; this.setState((prevState) => ({ ...prevState, newTask: { ...prevState.newTask, [name]: value, id: Date.now() } })); } handleSubmit(event){ event.preventDefault(); if (!this.state.newTask.title) return; this.setState((prevState) => ({ allTasks: [prevState.newTask, ...prevState.allTasks], newTask: {} })); } handleDelete(taskIdToRemove){ this.setState((prevState) => ({ ...prevState, allTasks: prevState.allTasks.filter((task) => task.id !== taskIdToRemove) })); } render() { return ( <main> <h1>Tasks</h1> <NewTask newTask={this.state.newTask} handleChange={this.handleChange} handleSubmit={this.handleSubmit} /> <TasksList allTasks={this.state.allTasks} handleDelete={this.handleDelete} /> </main> ); } } Function import React, { useState } from \"react\"; import NewTask from \"../Presentational/NewTask\"; import TasksList from \"../Presentational/TasksList\"; export default function AppFunction() { const [newTask, setNewTask] = useState({}); const handleChange = ({ target }) => { const { name, value } = target; setNewTask((prev) => ({ ...prev, id: Date.now(), [name]: value })); }; const [allTasks, setAllTasks] = useState([]); const handleSubmit = (event) => { event.preventDefault(); if (!newTask.title) return; setAllTasks((prev) => [newTask, ...prev]); setNewTask({}); }; const handleDelete = (taskIdToRemove) => { setAllTasks((prev) => prev.filter( (task) => task.id !== taskIdToRemove )); }; return ( <main> <h1>Tasks</h1> <NewTask newTask={newTask} handleChange={handleChange} handleSubmit={handleSubmit} /> <TasksList allTasks={allTasks} handleDelete={handleDelete} /> </main> ); } Update Function Component State Let\u2019s get started with the State Hook, the most common Hook used for building React components. The State Hook is a named export from the React library, so we import it like this: import React, { useState } from 'react'; useState() is a JavaScript function defined in the React library. When we call this function, it returns an array with two values: current state - the current value of this state state setter - a function that we can use to update the value of this state Because React returns these two values in an array, we can assign them to local variables, naming them whatever we like. For example: const [toggle, setToggle] = useState(); import React, { useState } from \"react\"; function Toggle() { const [toggle, setToggle] = useState(); return ( <div> <p>The toggle is {toggle}</p> <button onClick={() => setToggle(\"On\")}>On</button> <button onClick={() => setToggle(\"Off\")}>Off</button> </div> ); } Notice how the state setter function, setToggle(), is called by our onClick event listeners. To update the value of toggle and re-render this component with the new value, all we need to do is call the setToggle() function with the next state value as an argument. No need to worry about binding functions to class instances, working with constructors, or dealing with the this keyword. With the State Hook, updating state is as simple as calling a state setter function. Calling the state setter signals to React that the component needs to re-render, so the whole function defining the component is called again. The magic of useState() is that it allows React to keep track of the current value of state from one render to the next! More complex example: import React, { useState } from 'react'; export default function ColorPicker() { const [color, setColor] = useState(); const divStyle = {backgroundColor: color}; return ( <div style={divStyle}> <p>The color is {color}</p> <button onClick={() => setColor('Aquamarine')}> Aquamarine </button> <button onClick={() => setColor('BlueViolet')}> BlueViolet </button> <button onClick={() => setColor('Chartreuse')}> Chartreuse </button> <button onClick={() => setColor('CornflowerBlue')}> CornflowerBlue </button> </div> ); } Initialize State You can set a state at the beginning with: const [color, setColor] = useState(\"Tomato\"); . There are three ways in which this code affects our component: During the first render, the initial state argument is used. When the state setter is called, React ignores the initial state argument and uses the new value. When the component re-renders for any other reason, React continues to use the same value from the previous render. Use State Setter Outside of JSX https://www.codecademy.com/courses/react-101/lessons/the-state-hook/exercises/use-state-setter-outside-of-jsx Let\u2019s see how to manage the changing value of a string as a user types into a text input field: import React, { useState } from 'react'; export default function EmailTextInput() { const [email, setEmail] = useState(''); const handleChange = (event) => { const updatedEmail = event.target.value; setEmail(updatedEmail); } return ( // Here value={email} will set the value to the current // value in e-mail in the event hook <input value={email} onChange={handleChange} /> ); } Let\u2019s break down how this code works! The square brackets on the left side of the assignment operator signal array destructuring The local variable named email is assigned the current state value at index 0 from the array returned by useState() The local variable named setEmail() is assigned a reference to the state setter function at index 1 from the array returned by useState() It\u2019s convention to name this variable using the current state variable (email) with \"set\" prepended The JSX input tag has an event listener called onChange. This event listener calls an event handler each time the user types something in this element. In the example above, our event handler is defined inside of the definition for our function component, but outside of our JSX. Earlier in this lesson, we wrote our event handlers right in our JSX. Those inline event handlers work perfectly fine, but when we want to do something more interesting than just calling the state setter with a static value, it\u2019s a good idea to separate that logic from everything else going on in our JSX. This separation of concerns makes our code easier to read, test, and modify. You can change: const updatedEmail = event.target.value; setEmail(updatedEmail); // to this const handleChange = ({target}) => setEmail(target.value); Longer Example import React, { useState } from \"react\"; // regex to match numbers between 1 and 10 digits long const validPhoneNumber = /^\\d{1,10}$/; export default function PhoneNumber() { const [phone, setPhone] = useState(''); const handleChange = ({ target })=> { const newPhone = target.value; const isValid = validPhoneNumber.test(newPhone); if (isValid) { setPhone(newPhone); } // just ignore the event, when new value is invalid }; return ( <div className='phone'> <label for='phone-input'>Phone: </label> <input value={phone} onChange={handleChange} id='phone-input' /> </div> ); } Set From Previous State Often, the next value of our state is calculated using the current state. In this case, it is best practice to update state with a callback function. If we do not, we risk capturing outdated, or \u201cstale\u201d, state values. import React, { useState } from 'react'; export default function Counter() { const [count, setCount] = useState(0); const increment = () => setCount(prevCount => prevCount + 1); return ( <div> <p>Wow, you've clicked that button: {count} times</p> <button onClick={increment}>Click here!</button> </div> ); } When the button is pressed, the increment() event handler is called. Inside of this function, we use our setCount() state setter in a new way! Because the next value of count depends on the previous value of count, we pass a callback function as the argument for setCount() instead of a value (as we\u2019ve done in previous exercises). setCount(prevCount => prevCount + 1) When our state setter calls the callback function, this state setter callback function takes our previous count as an argument. The value returned by this state setter callback function is used as the next value of count (in this case prevCount + 1). Note: We can just call setCount(count +1) and it would work the same in this example\u2026 but for reasons that are out of scope for this lesson, it is safer to use the callback method. Arrays in State import React, { useState } from \"react\"; import ItemList from \"./ItemList\"; import { produce, pantryItems } from \"./storeItems\"; export default function GroceryCart() { // declare and initialize state const [cart, setCart] = useState([]); // addItem is the event handler and will receive the item that // gets clicked const addItem = (item) => { // setCart is the state setter // and it will tell the component to update its state. // Via the magic that is the totality of Javascript, it // will magically receive the previous state to this function // We then use spread syntax to expand the previous array // and add it with the item. setCart((prev) => { return [item, ...prev]; }); }; // This removes the item at some set index. const removeItem = (targetIndex) => { setCart((prev) => { return prev.filter((item, index) => index !== targetIndex); }); }; return ( <div> <h1>Grocery Cart</h1> <ul> {cart.map((item, index) => ( <li onClick={() => removeItem(index)} key={index}> {item} </li> ))} </ul> <h2>Produce</h2> <ItemList items={produce} onItemClick={addItem} /> <h2>Pantry Items</h2> <ItemList items={pantryItems} onItemClick={addItem} /> </div> ); } Objects in State export default function Login() { const [formState, setFormState] = useState({}); const handleChange = ({ target }) => { const { name, value } = target; setFormState((prev) => ({ ...prev, [name]: value })); }; return ( <form> <input value={formState.firstName} onChange={handleChange} name=\"firstName\" type=\"text\" /> <input value={formState.password} onChange={handleChange} type=\"password\" name=\"password\" /> </form> ); } A few things to notice: We use a state setter callback function to update state based on the previous value The spread syntax is the same for objects as for arrays: { ...oldObject, newKey: newValue } We reuse our event handler across multiple inputs by using the input tag\u2019s name attribute to identify which input the change event came from Once again, when updating the state with setFormState() inside a function component, we do not modify the same object. We must copy over the values from the previous object when setting the next value of state. Thankfully, the spread syntax makes this super easy to do! Anytime one of the input values is updated, the handleChange() function will be called. Inside of this event handler, we use object destructuring to unpack the target property from our event object, then we use object destructuring again to unpack the name and value properties from the target object. Inside of our state setter callback function, we wrap our curly brackets in parentheses like so: setFormState((prev) => ({ ...prev })). This tells JavaScript that our curly brackets refer to a new object to be returned. We use ..., the spread operator, to fill in the corresponding fields from our previous state. Finally, we overwrite the appropriate key with its updated value. Did you notice the square brackets around the name? This Computed Property Name allows us to use the string value stored by the name variable as a property key! Longer Example import React, { useState } from \"react\"; export default function EditProfile() { const [profile, setProfile] = useState({}); const handleChange = ({ target }) => { const {name, value } = target; setProfile((prevProfile) => ({ ...prevProfile, [name]: value })); }; const handleSubmit = (event) => { event.preventDefault(); alert(JSON.stringify(profile, '', 2)); }; return ( <form onSubmit={handleSubmit}> <input value={profile.firstName || ''} name=\"firstName\" type=\"text\" placeholder=\"First Name\" onChange={handleChange} /> <input value={profile.lastName || ''} type=\"text\" name=\"lastName\" placeholder=\"Last Name\" onChange={handleChange} /> <input value={profile.bday || ''} type=\"date\" name=\"bday\" onChange={handleChange} /> <input value={profile.password || ''} type=\"password\" name=\"password\" placeholder=\"Password\" onChange={handleChange} /> <button type=\"submit\">Submit</button> </form> ); } Separate Hooks for Separate States While there are times when it can be helpful to store related data in a data collection like an array or object, it can also be helpful to separate data that changes separately into completely different state variables. Managing dynamic data is much easier when we keep our data models as simple as possible. For example, if we had a single object that held state for a subject you are studying at school, it might look something like this: function Subject() { const [state, setState] = useState({ currentGrade: 'B', classmates: ['Hasan', 'Sam', 'Emma'], classDetails: {topic: 'Math', teacher: 'Ms. Barry', room: 201}; exams: [{unit: 1, score: 91}, {unit: 2, score: 88}]); }); This would work, but think about how messy it could get to copy over all the other values when we need to update something in this big state object. For example, to update the grade on an exam, we would need an event handler that did something like this: // Get the previous state in and pass that to something that is going to return a new object {} setState((prev) => ({ // Expand the previous state to grab everything ...prev, // You want the previous state, except with exams you're going to grab just exams and then map // that to a new function where you'll extract just the exam you want and change the score exams: prev.exams.map((exam) => { if( exam.unit === updatedExam.unit ){ return { ...exam, score: updatedExam.score }; } else { return exam; } }), })); Yikes! Complex code like this is likely to cause bugs! Luckily, there is another option\u2026 We can make more than one call to the State Hook. In fact, we can make as many calls to useState() as we want! It\u2019s best to split state into multiple state variables based on which values tend to change together. We can rewrite the previous example as follows\u2026 function Subject() { const [currentGrade, setGrade] = useState('B'); const [classmates, setClassmates] = useState(['Hasan', 'Sam', 'Emma']); const [classDetails, setClassDetails] = useState({topic: 'Math', teacher: 'Ms. Barry', room: 201}); const [exams, setExams] = useState([{unit: 1, score: 91}, {unit: 2, score: 88}]); // ... } See https://reactjs.org/docs/hooks-state.html#tip-using-multiple-state-variables Comparison function Musical() { const [state, setState] = useState({ title: \"Best Musical Ever\", actors: [\"George Wilson\", \"Tim Hughes\", \"Larry Clements\"], locations: { Chicago: { dates: [\"1/1\", \"2/2\"], address: \"chicago theater\"}, SanFrancisco: { dates: [\"5/2\"], address: \"sf theater\" } } }) } function MusicalRefactored() { const [title, setTitle] = useState(\"Best Musical Ever\"); const [actors, setActors] = useState([\"George Wilson\", \"Tim Hughes\", \"Larry Clements\"]); const [locations, setLocations] = useState({ Chicago: { dates: [\"1/1\", \"2/2\"], address: \"chicago theater\"}, SanFrancisco: { dates: [\"5/2\"], address: \"sf theater\" } }); } The Effect Hook - useEffect Before Hooks, function components were only used to accept data in the form of props and return some JSX to be rendered. However, as we learned in the last lesson, the State Hook allows us to manage dynamic data, in the form of component state, within our function components. In this lesson, we\u2019ll use the Effect Hook to run some JavaScript code after each render, such as: fetching data from a backend service subscribing to a stream of data managing timers and intervals reading from and making changes to the DOM Why after each render? Most interesting components will re-render multiple times throughout their lifetime and these key moments present the perfect opportunity to execute these \u201cside effects\u201d. There are three key moments when the Effect Hook can be utilized: When the component is first added, or mounted, to the DOM and renders When the state or props change, causing the component to re-render When the component is removed, or unmounted, from the DOM. React Hooks and Component Lifecycle Equivalent https://stackoverflow.com/a/53254018/4427375 componentWillMount for react functional component? https://stackoverflow.com/questions/62091146/componentwillmount-for-react-functional-component Function Component Effects import React, { useState, useEffect } from 'react'; function PageTitle() { const [name, setName] = useState(''); useEffect(() => { document.title = `Hi, ${name}`; }); return ( <div> <p>Use the input field below to rename this page!</p> <input onChange={({target}) => setName(target.value)} value={name} type='text' /> </div> ); } In our effect, we assign the value of the name variable to the document.title within a string. For more on this syntax, have a look at this explanation of the document\u2019s title property. Notice how we use the current state inside of our effect. Even though our effect is called after the component renders, we still have access to the variables in the scope of our function component! When React renders our component, it will update the DOM as usual, and then run our effect after the DOM has been updated. This happens for every render, including the first and last one. Clean Up Effects useEffect(()=>{ document.addEventListener('keydown', handleKeyPress); return () => { document.removeEventListener('keydown', handleKeyPress); }; }) If our effect didn\u2019t return a cleanup function, then a new event listener would be added to the DOM\u2019s document object every time that our component re-renders. Not only would this cause bugs, but it could cause our application performance to diminish and maybe even crash! Because effects run after every render and not just once, React calls our cleanup function before each re-render and before unmounting to clean up each effect call. If our effect returns a function, then the useEffect() Hook always treats that as a cleanup function. React will call this cleanup function before the component re-renders or unmounts. Since this cleanup function is optional, it is our responsibility to return a cleanup function from our effect when our effect code could create memory leaks. import React, { useState, useEffect } from 'react'; export default function Counter() { const [clickCount, setClickCount] = useState(0); const increment = () => setClickCount((prev) => prev + 1); useEffect(() => { document.addEventListener('mousedown', increment); return () => { document.removeEventListener('mousedown', increment); }; }); return ( <h1>Document Clicks: {clickCount}</h1> ); } Control When Effects are Called It is common, when defining function components, to run an effect only when the component mounts (renders the first time), but not when the component re-renders. The Effect Hook makes this very easy for us to do! If we want to only call our effect after the first render, we pass an empty array to useEffect() as the second argument. This second argument is called the dependency array. The dependency array is used to tell the useEffect() method when to call our effect and when to skip it. Our effect is always called after the first render but only called again if something in our dependency array has changed values between renders useEffect(() => { alert(\"component rendered for the first time\"); return () => { alert(\"component is being removed from the DOM\"); }; }, []); Fetch Data from a Server Since the effect hook is called after every render we want to be extra careful when we are fetching data from a server as this will quickly sabotage the performance of our app. When the data that our components need to render doesn\u2019t change, we can pass an empty dependency array, so that the data is fetched after the first render. When the response is received from the server, we can use a state setter from the State Hook to store the data from the server\u2019s response in our local component state for future renders. Using the State Hook and the Effect Hook together in this way is a powerful pattern that saves our components from unnecessarily fetching new data after every render! An empty dependency array signals to the Effect Hook that our effect never needs to be re-run, that it doesn\u2019t depend on anything. Specifying zero dependencies means that the result of running that effect won\u2019t change and calling our effect once is enough. A dependency array that is not empty signals to the Effect Hook that it can skip calling our effect after re-renders unless the value of one of the variables in our dependency array has changed. If the value of a dependency has changed, then the Effect Hook will call our effect again! Here\u2019s a nice example from the official React docs: useEffect(() => { document.title = `You clicked ${count} times`; }, [count]); // Only re-run the effect if the value stored by count changes Rules of Hooks There are two main rules to keep in mind when using Hooks: only call Hooks at the top level only call Hooks from React functions As we have been practicing with the State Hook and the Effect Hook, we\u2019ve been following these rules with ease, but it is helpful to keep these two rules in mind as you take your new understanding of Hooks out into the wild and begin using more Hooks in your React applications. When React builds the Virtual DOM, the library calls the functions that define our components over and over again as the user interacts with the user interface. React keeps track of the data and functions that we are managing with Hooks based on their order in the function component\u2019s definition. For this reason, we always call our Hooks at the top level; we never call hooks inside of loops, conditions, or nested functions. Instead of confusing React with code like this: if (userName !== '') { useEffect(() => { localStorage.setItem('savedUserName', userName); }); } We can accomplish the same goal, while consistently calling our Hook every time: useEffect(() => { if (userName !== '') { localStorage.setItem('savedUserName', userName); } }); Secondly, Hooks can only be used in React Functions. We cannot use Hooks in class components and we cannot use Hooks in regular JavaScript functions. We\u2019ve been working with useState() and useEffect() in function components, and this is the most common use. The only other place where Hooks can be used is within custom hooks. Custom Hooks are incredibly useful for organizing and reusing stateful logic between function components. For more on this topic, head to the React Docs. Separate Hooks for Separate Effects When multiple values are closely related and change at the same time, it can make sense to group these values in a collection like an object or array. Packaging data together can also add complexity to the code responsible for managing that data. Therefore, it is a good idea to separate concerns by managing different data with different Hooks. Compare the complexity here, where data is bundled up into a single object: // Handle both position and menuItems with one useEffect hook. const [data, setData] = useState({ position: { x: 0, y: 0 } }); useEffect(() => { get('/menu').then((response) => { setData((prev) => ({ ...prev, menuItems: response.data })); }); const handleMove = (event) => setData((prev) => ({ ...prev, position: { x: event.clientX, y: event.clientY } })); window.addEventListener('mousemove', handleMove); return () => window.removeEventListener('mousemove', handleMove); }, []); To the simplicity here, where we have separated concerns: // Handle menuItems with one useEffect hook. const [menuItems, setMenuItems] = useState(null); useEffect(() => { get('/menu').then((response) => setMenuItems(response.data)); }, []); // Handle position with a separate useEffect hook. const [position, setPosition] = useState({ x: 0, y: 0 }); useEffect(() => { const handleMove = (event) => setPosition({ x: event.clientX, y: event.clientY }); window.addEventListener('mousemove', handleMove); return () => window.removeEventListener('mousemove', handleMove); }, []); Stateless Components from Stateful Components Instead of having one, very complicated, stateful, component, we have one stateful component (App) at the top level with many stateless components in a hierarchy. The stateful component will pass its state down to the stateless components. Build a Stateful Component Class Example of passing a parent's state into a stateless child // PARENT import React from 'react'; import ReactDOM from 'react-dom'; import { Child } from './Child'; class Parent extends React.Component { constructor(props) { super(props); this.state = { name: 'Frarthur' }; } render() { return <Child name={this.state.name}/>; } } ReactDOM.render(<Parent />, document.getElementById('app')); // CHILD import React from 'react'; import ReactDOM from 'react-dom'; // We have to export this since it will be rendered by // another component export class Child extends React.Component { render() { return <h1>Hey, my name is {this.props.name}!</h1>; } } This will print: Hey, my name is Frarthur! Don't Update props A React component should use props to store information that can be changed, but can only be changed by a different component. A React component should use state to store information that the component itself can change. // BAD import React from 'react'; class Bad extends React.Component { render() { this.props.message = 'yo'; // NOOOOOOOOOOOOOO!!! return <h1>{this.props.message}</h1>; } } Child Components Update Their Parents' State How does a stateless, child component update the state of the parent component? Here\u2019s how that works: 1 The parent component class defines a method that calls this.setState(). For an example, look in Step1.js at the .handleClick() method. import React from 'react'; import ReactDOM from 'react-dom'; import { ChildClass } from './ChildClass'; class ParentClass extends React.Component { constructor(props) { super(props); this.state = { totalClicks: 0 }; } handleClick() { const total = this.state.totalClicks; // calling handleClick will // result in a state change: this.setState( { totalClicks: total + 1 } ); } } 2 The parent component binds the newly-defined method to the current instance of the component in its constructor. This ensures that when we pass the method to the child component, it will still update the parent component. For an example, look in Step2.js at the end of the constructor() method. An explanation of how this/bind work How bind works: https://stackoverflow.com/a/10115970/4427375 What is the global object Once the parent has defined a method that updates its state and bound to it, the parent then passes that method down to a child. Look in Step2.js, at the prop on line 28. import React from 'react'; import ReactDOM from 'react-dom'; import { ChildClass } from './ChildClass'; class ParentClass extends React.Component { constructor(props) { super(props); this.state = { totalClicks: 0 }; this.handleClick = this.handleClick.bind(this); } handleClick() { const total = this.state.totalClicks; // calling handleClick will // result in a state change: this.setState( { totalClicks: total + 1 } ); } // The stateful component class passes down // handleClick to a stateless component class: render() { return ( <ChildClass onClick={this.handleClick} /> ); } } 3 The child receives the passed-down function, and uses it as an event handler. Look in Step3.js. When a user clicks on the , a click event will fire. This will make the passed-down function get called, which will update the parent\u2019s state. import React from 'react'; import ReactDOM from 'react-dom'; export class ChildClass extends React.Component { render() { return ( // The stateless component class uses // the passed-down handleClick function, // accessed here as this.props.onClick, // as an event handler: <button onClick={this.props.onClick}> Click Me! </button> ); } } More Complex Example WARNING this violates the rule that components should only do one thing! We fix this in One Sibling to Display, Another to Change // CHILD import React from 'react'; export class Child extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); } handleChange(e) { const name = e.target.value; this.props.onChange(name); } render() { return ( <div> <h1> Hey my name is {this.props.name}! </h1> <select id=\"great-names\" onChange={this.handleChange}> <option value=\"Frarthur\"> Frarthur </option> <option value=\"Gromulus\"> Gromulus </option> <option value=\"Thinkpiece\"> Thinkpiece </option> </select> </div> ); } } // PARENT import React from 'react'; import ReactDOM from 'react-dom'; import { Child } from './Child'; class Parent extends React.Component { constructor(props) { super(props); this.state = { name: 'Frarthur' }; this.changeName = this.changeName.bind(this); } changeName(newName) { this.setState({ name: newName }); } render() { return <Child name={this.state.name} onChange={this.changeName} /> } } ReactDOM.render( <Parent />, document.getElementById('app') ); Child Components Update Sibling Components The Reactions component passes an event handler to the Like component. When Like is clicked, the handler is called, which causes the parent Reactions component to send a new prop to Stats. The Stats component updates with the new information. One Sibling to Display, Another to Change You will have one stateless component display information, and a different stateless component offer the ability to change that information. A stateful component class defines a function that calls this.setState. (Parent.js, lines 15-19) The stateful component passes that function down to a stateless component. (Parent.js, line 24) That stateless component class defines a function that calls the passed-down function, and that can take an event object as an argument. (Child.js, lines 10-13) The stateless component class uses this new function as an event handler. (Child.js, line 20) When an event is detected, the parent\u2019s state updates. (A user selects a new dropdown menu item) The stateful component class passes down its state, distinct from the ability to change its state, to a different stateless component. (Parent.js, line 25) That stateless component class receives the state and displays it. (Sibling.js, lines 5-10) An instance of the stateful component class is rendered. One stateless child component displays the state, and a different stateless child component displays a way to change the state. (Parent.js, lines 23-26) // PARENT import React from 'react'; import ReactDOM from 'react-dom'; import { Child } from './Child'; import { Sibling } from './Sibling'; class Parent extends React.Component { constructor(props) { super(props); this.state = { name: 'Frarthur' }; this.changeName = this.changeName.bind(this); } changeName(newName) { this.setState({ name: newName }); } render() { return ( <div> <Child onChange={this.changeName} /> <Sibling name={this.state.name}/> </div> ); } } ReactDOM.render( <Parent />, document.getElementById('app') ); // CHILD import React from 'react'; export class Child extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); } handleChange(e) { const name = e.target.value; this.props.onChange(name); } render() { return ( <div> <select id=\"great-names\" onChange={this.handleChange}> <option value=\"Frarthur\">Frarthur</option> <option value=\"Gromulus\">Gromulus</option> <option value=\"Thinkpiece\">Thinkpiece</option> </select> </div> ); } } // SIBLING import React from 'react'; export class Sibling extends React.Component { render() { const name = this.props.name; return ( <div> <h1>Hey, my name is {name}!</h1> <h2>Don't you think {name} is the prettiest name ever?</h2> <h2>Sure am glad that my parents picked {name}!</h2> </div> ); } } Style Inline Styles An inline style is a style that\u2019s written as an attribute, like this: <h1 style={{ color: 'red' }}>Hello world</h1> Notice the double curly braces. What are those for? The outer curly braces inject JavaScript into JSX. They say, \u201ceverything between us should be read as JavaScript, not JSX.\u201d The inner curly braces create a JavaScript object literal. They make this a valid JavaScript object: { color: 'red' } If you inject an object literal into JSX, and your entire injection is only that object literal, then you will end up with double curly braces. There\u2019s nothing unusual about how they work, but they look funny and can be confusing. Make a Style Object Variable Notice that here we define the style at the top level as a variable and then pass it in. In React style variable names are written camelCase. NOTE : The styles in ReactJS use numbers and the px is implied. import React from 'react'; import ReactDOM from 'react-dom'; const styles = { background: 'lightblue', color: 'darkred' marginTop: 100, fontSize: 50 }; const styleMe = <h1 style={styles}>Please style me! I am so bland!</h1>; ReactDOM.render( styleMe, document.getElementById('app') ); Share Styles Across Multiple Components // STYLES.JS const fontFamily = 'Comic Sans MS, Lucida Handwriting, cursive'; const background = 'pink url(\"https://content.codecademy.com/programs/react/images/welcome-to-my-homepage.gif\") fixed'; const fontSize = '4em'; const padding = '45px 0'; const color = 'green'; export const styles = { fontFamily: fontFamily, background: background, fontSize: fontSize, padding: padding, color: color }; // ATTENTIONGRABBER.JS import React from 'react'; import { styles } from './styles'; const h1Style = { color: styles.color, fontSize: styles.fontSize, fontFamily: styles.fontFamily, padding: styles.padding, margin: 0, }; export class AttentionGrabber extends React.Component { render() { return <h1 style={h1Style}>WELCOME TO MY HOMEPAGE!</h1>; } } // HOME.JS import React from 'react'; import ReactDOM from 'react-dom'; import { AttentionGrabber } from './AttentionGrabber'; import { styles } from './styles'; const divStyle = { background: styles.background, height: '100%' }; export class Home extends React.Component { render() { return ( <div style={divStyle}> <AttentionGrabber /> <footer>THANK YOU FOR VISITING MY HOMEPAGE!</footer> </div> ); } } ReactDOM.render( <Home />, document.getElementById('app') ); Separate Container Components from Presentational Components As you continue building your React application, you will soon realize that one component has too many responsibilities, but how do you know when you have reached that point? Separating container components from presentational components helps to answer that question. It shows you when it might be a good time to divide a component into smaller components. It also shows you how to perform that division. <GuineaPigs /> \u2018s job is to render a photo carousel of guinea pigs. It does this perfectly well! And yet, it has a problem: it does too much stuff. How might we divide this into a container component and a presentational component? import React from 'react'; import ReactDOM from 'react-dom'; const GUINEAPATHS = [ 'https://content.codecademy.com/courses/React/react_photo-guineapig-1.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-2.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-3.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-4.jpg' ]; export class GuineaPigs extends React.Component { constructor(props) { super(props); this.state = { currentGP: 0 }; this.interval = null; this.nextGP = this.nextGP.bind(this); } nextGP() { let current = this.state.currentGP; let next = ++current % GUINEAPATHS.length; this.setState({ currentGP: next }); } componentDidMount() { this.interval = setInterval(this.nextGP, 5000); } componentWillUnmount() { clearInterval(this.interval); } render() { let src = GUINEAPATHS[this.state.currentGP]; return ( <div> <h1>Cute Guinea Pigs</h1> <img src={src} /> </div> ); } } ReactDOM.render( <GuineaPigs />, document.getElementById('app') ); Create a Container Component Separating container components from presentational components is a popular React programming pattern. It is a special application of the concepts learned in the Stateless Components From Stateful Components module. If a component has to have state, make calculations based on props, or manage any other complex logic, then that component shouldn\u2019t also have to render HTML-like JSX. The functional part of a component (state, calculations, etc.) can be separated into a container component. GuineaPigs.js contains a lot of logic! It has to select the correct guinea pig to render, wait for the right amount of time before rendering, render an image, select the next correct guinea pig, and so on. Let\u2019s separate the logic from the GuineaPigs component into a container component. Create a Presentational Component The presentational component\u2019s only job is to contain HTML-like JSX. It should be an exported component and will not render itself because a presentational component will always get rendered by a container component. As a separate example, say we have Presentational and Container components. Presentational.js must export the component class (or function, when applicable): export class Presentational extends Component { Container.js must import that component: import { Presentational } from 'Presentational.js'; // GuineaPigs.js import React from 'react'; export class GuineaPigs extends React.Component { render() { let src = this.props.src; return ( <div> <h1>Cute Guinea Pigs</h1> <img src={src} /> </div> ); } } // GuineaPigsContainer.js import React from 'react'; import ReactDOM from 'react-dom'; import { GuineaPigs } from '../components/GuineaPigs'; const GUINEAPATHS = [ 'https://content.codecademy.com/courses/React/react_photo-guineapig-1.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-2.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-3.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-4.jpg' ]; class GuineaPigsContainer extends React.Component { constructor(props) { super(props); this.state = { currentGP: 0 }; this.interval = null; this.nextGP = this.nextGP.bind(this); } nextGP() { let current = this.state.currentGP; let next = ++current % GUINEAPATHS.length; this.setState({ currentGP: next }); } componentDidMount() { this.interval = setInterval(this.nextGP, 5000); } componentWillUnmount() { clearInterval(this.interval); } render() { const src = GUINEAPATHS[this.state.currentGP]; return <GuineaPigs src={src} />; } } ReactDOM.render( <GuineaPigsContainer />, document.getElementById('app') ); propTypes propTypes are useful for two reasons. The first reason is prop validation. Validation can ensure that your props are doing what they\u2019re supposed to be doing. If props are missing, or if they\u2019re present but they aren\u2019t what you\u2019re expecting, then a warning will print in the console. This is useful, but reason #2 is arguably more useful: documentation. Documenting props makes it easier to glance at a file and quickly understand the component class inside. When you have a lot of files, and you will, this can be a huge benefit. Apply PropTypes The name of each property in propTypes should be the name of an expected prop. In our case, MessageDisplayer expects a prop named message, so our property\u2019s name is message. The value of each property in propTypes should fit this pattern: PropTypes.expected_data_type_goes_here import React from 'react'; import PropTypes from 'prop-types'; export class BestSeller extends React.Component { render() { return ( <li> Title: <span> {this.props.title} </span><br /> Author: <span> {this.props.author} </span><br /> Weeks: <span> {this.props.weeksOnList} </span> </li> ); } } BestSeller.propTypes = { title: PropTypes.string.isRequired, author: PropTypes.string.isRequired, weeksOnList: PropTypes.number.isRequired }; PropTypes in Function Components // Normal way to display a prop: export class MyComponentClass extends React.Component { render() { return <h1>{this.props.title}</h1>; } } // Functional component way to display a prop: export const MyComponentClass = (props) => { return <h1>{props.title}</h1>; } // Normal way to display a prop using a variable: export class MyComponentClass extends React.component { render() { let title = this.props.title; return <h1>{title}</h1>; } } // Functional component way to display a prop using a variable: export const MyComponentClass = (props) => { let title = props.title; return <h1>{title}</h1>; } React Forms Think about how forms work in a typical, non-React environment. A user types some data into a form\u2019s input fields, and the server doesn\u2019t know about it. The server remains clueless until the user hits a \u201csubmit\u201d button, which sends all of the form\u2019s data over to the server simultaneously. In React, as in many other JavaScript environments, this is not the best way of doing things. The problem is the period of time during which a form thinks that a user has typed one thing, but the server thinks that the user has typed a different thing. What if, during that time, a third part of the website needs to know what a user has typed? It could ask the form or the server and get two different answers. In a complex JavaScript app with many moving, interdependent parts, this kind of conflict can easily lead to problems. In a React form, you want the server to know about every new character or deletion, as soon as it happens. That way, your screen will always be in sync with the rest of your application. Input on Change A traditional form doesn\u2019t update the server until a user hits \u201csubmit.\u201d But you want to update the server any time a user enters or deletes any character. import React from 'react'; export class Example extends React.Component { constructor(props) { super(props); this.state = { userInput: '' }; this.handleChange = this.handleChange.bind(this); } handleChange(e) { this.setState({ userInput: e.target.value }); } render() { return ( <input onChange={this.handleChange} type=\"text\" /> ); } } Control vs Uncontrolled There are two terms that will probably come up when you talk about React forms: controlled component and uncontrolled component. Like automatic binding, controlled vs uncontrolled components is a topic that you should be familiar with, but don\u2019t need to understand deeply at this point. An uncontrolled component is a component that maintains its own internal state. A controlled component is a component that does not maintain any internal state. Since a controlled component has no state, it must be controlled by someone else. Think of a typical <input type='text' /> element. It appears onscreen as a text box. If you need to know what text is currently in the box, then you can ask the <input /> , possibly with some code like this: let input = document.querySelector('input[type=\"text\"]'); let typedText = input.value; // input.value will be equal to whatever text is currently in the text box. The important thing here is that the <input /> keeps track of its own text. You can ask it what its text is at any time, and it will be able to tell you. The fact that <input /> keeps track of information makes it an uncontrolled component. It maintains its own internal state, by remembering data about itself. A controlled component, on the other hand, has no memory. If you ask it for information about itself, then it will have to get that information through props. Most React components are controlled. In React, when you give an <input /> a value attribute, then something strange happens: the <input /> BECOMES controlled. It stops using its internal storage. This is a more \u2018React\u2019 way of doing things. Update an Input's Value When a user types or deletes in the <input /> , then that will trigger a change event, which will call handleUserInput. That\u2019s good! handleUserInput will set this.state.userInput equal to whatever text is currently in the input field. That\u2019s also good! There\u2019s only one problem: you can set this.state.userInput to whatever you want, but <input /> won\u2019t care. You need to somehow make the <input /> \u2018s text responsive to this.state.userInput. Easy enough! You can control an <input /> \u2018s text by setting its value attribute. Set the Input's Initial State Good! Any time that someone types or deletes in <input /> , the .handleUserInput() method will update this.state.userInput with the <input /> \u2018s text. Since you\u2019re using this.setState, that means that Input needs an initial state! What should this.state\u2018s initial value be? Well, this.state.userInput will be displayed in the <input /> . What should the initial text in the <input /> be, when a user first visits the page? The initial text should be blank! Otherwise it would look like someone had already typed something. Dynamically Rendering Different Components without Switch: the Capitalized Reference Technique See: https://j5bot.medium.com/react-dynamically-rendering-different-components-without-switch-the-capitalized-reference-e668d89e460b React Router https://ui.dev/react-router-tutorial BrowserRouter Naturally, in order to do its thing, React Router needs to be both aware and in control of your app's location. The way it does this is with its BrowserRouter component. Under the hood, BrowserRouter uses both the history library as well as React Context . The history library helps React Router keep track of the browsing history of the application using the browser's built-in history stack, and React Context helps make history available wherever React Router needs it. There's not much to BrowserRouter, you just need to make sure that if you're using React Router on the web, you wrap your app inside of the BrowserRouter import ReactDOM from 'react-dom' import * as React from 'react' import { BrowserRouter } from 'react-router-dom' import App from './App` ReactDOM.render( <BrowserRouter> <App /> </BrowserRouter> , document.getElementById('app)) Route Put simply, Route allows you to map your app's location to different React components. For example, say we wanted to render a Dashboard component whenever a user navigated to the /dashboard path. To do so, we'd render a Route that looked like this. <Route path=\"/dashboard\" element={<Dashboard />} /> The mental model I use for Route is that it always has to render something \u2013 either its element prop if the path matches the app's current location or null, if it doesn't. You can render as many Routes as you'd like. <Route path=\"/\" element={<Home />} /> <Route path=\"/about\" element={<About />} /> <Route path=\"/settings\" element={<Settings />} /> You can even render nested routes, which we'll talk about later on in this post. With our Route elements in this configuration, it's possible for multiple routes to match on a single URL. You might want to do that sometimes, but most often you want React Router to only render the route that matches best. Fortunately, we can easily do that with Routes. Routes You can think of Routes as the metaphorical conductor of your routes. Whenever you have one or more Routes, you'll most likely want to wrap them in a Routes. import { Routes, Route } from \"react-router-dom\"; function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/about\" element={<About />} /> <Route path=\"/settings\" element={<Settings />} /> <Route path=\"*\" element={<NotFound />} /> </Routes> ); } The reason for this is because it's Routes job is to understand all of its children Route elements, and intelligently choose which ones are the best to render. Though it's not shown in the simple example above, once we start adding more complex Routes to our application, Routes will start to do more work like enabling intelligent rendering and relative paths. We'll see these scenarios in a bit. Next up, linking between pages. Links Now that you know how to map the app's location to certain React components using Routes and Route, the next step is being able to navigate between them. This is the purpose of the Link component. To tell Link what path to take the user to when clicked, you pass it a to prop. <nav> <Link to=\"/\">Home</Link> <Link to=\"/about\">About</Link> <Link to=\"/settings\">Settings</Link> </nav> If you need more control over Link, you can also pass to as an object. Doing so allows you to add a query string via the search property or pass along any data to the new route via state. <nav> <Link to=\"/\">Home</Link> <Link to=\"/about\">About</Link> <Link to={{ pathname: \"/settings\", search: \"?sort=date\", state: { fromHome: true }, }} > Settings </Link> </nav> URL Parameters Like function parameters allow you to declare placeholders when you define a function, URL Parameters allow you to declare placeholders for portions of a URL. Take Wikipedia for example. When you visit a topic on Wikipedia, you'll notice that the URL pattern is always the same, wikipedia.com/wiki/{topicId}. Instead of defining a route for every topic on the site, they can declare one route with a placeholder for the topic's id. The way you tell React Router that a certain portion of the URL is a placeholder (or URL Parameter), is by using a : in the Route's path prop. <Route path=\"/wiki/:topicId\" element={<Article />} /> Now whenever anyone visits a URL that matches the /wiki/:topicId pattern (/wiki/javascript, /wiki/Brendan_Eich, /wiki/anything) , the Article component is rendered. Now the question becomes, how do you access the dynamic portion of the URL \u2013 in this case, topicId \u2013 in the component that's rendered? As of v5.1, React Router comes with a useParams Hook that returns an object with a mapping between the URL parameter(s) and its value. import * as React from 'react' import { useParams } from 'react-router-dom' import { getArticle } from '../utils' function Article () { const [article, setArticle] = React.useState(null) const { topicId } = useParams() React.useEffect(() => { getArticle(topicId) .then(setUser) }, [topicId]) return ( ... ) } Nested Routes Nested Routes allow the parent Route to act as a wrapper and control the rendering of a child Route. A real-life example of this UI could look similar to Twitter's /messages route. When you go to /messages, you see all of your previous conversations on the left side of the screen. Then, when you go to /messages/:id, you still see all your messages, but you also see your chat history for :id. Let's look at how we could implement this sort of nested routes pattern with React Router. We'll start off with some basic Routes. // App.js function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/messages\" element={<Messages />} /> <Route path=\"/settings\" element={<Settings />} /> </Routes> ); } Now, if we want Messages to be in control of rendering a child Routes, what's stopping us from just rendering another Routes component inside Messages? Something like this: function Messages() { return ( <Container> <Conversations /> <Routes> <Route path=\":id\" element={<Chat />} /> </Routes> </Container> ); } Now when the user navigates to /messages, React Router renders the Messages component. From there, Messages shows all our conversations via the Conversations component and then renders another Routes with a Route that maps /messages/:id to the Chat component. Relative Routes Notice that we don't have to include the full /messages/:id path in the nested Route. This is because Routes is intelligent and by leaving off the leading /, it assumes we want this path to be relative to the parent's location, /messages. Looks good, but there's one subtle issue. Can you spot it? Messages only gets rendered when the user is at /messages. When they visit a URL that matches the /messages/:id pattern, Messages no longer matches and therefore, our nested Routes never gets rendered. To fix this, naturally, we need a way to tell React Router that we want to render Messages both when the user is at /messages or any other location that matches the /messages/* pattern. Wait. What if we just update our path to be /messages/*? // App.js function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/messages/*\" element={<Messages />} /> <Route path=\"/settings\" element={<Settings />} /> </Routes> ); } Much to our delight, that'll work. By appending a / to the end of our /messages path, we're essentially telling React Router that Messages has a nested Routes component and our parent path should match for /messages as well as any other location that matches the /messages/ pattern. Exactly what we wanted. At this point, we've looked at how you can create nested routes by appending /* to our Route's path and rendering, literally, a nested Routes component. This works when you want your child Route in control of rendering the nested Routes, but what if we wanted our App component to contain all the information it needed to create our nested routes rather than having to do it inside of Messages? Because this is a common preference, React Router supports this way of creating nested routes as well. Here's what it looks like. function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/messages\" element={<Messages />}> <Route path=\":id\" element={<Chats />} /> </Route> <Route path=\"/settings\" element={<Settings />} /> </Routes> ); } You declaratively nest the child Route as a children of the parent Route. Like before, the child Route is now relative to the parent, so you don't need to include the parent (/messages) path. Now, the last thing you need to do is tell React Router where in the parent Route (Messages) should it render the child Route (Chats). To do this, you use React Router's Outlet component. import { Outlet } from \"react-router-dom\"; function Messages() { return ( <Container> <Conversations /> <Outlet /> </Container> ); } If the app's location matches the nested Route's path, this Outlet component will render the Route's element. So based on our Routes above, if we were at /messages, the Outlet component would render null, but if we were at /messages/1, it would render the component. Pass props to Router Components In previous versions of React Router (v4), this was non-trivial since React Router was in charge of creating the React element. However, with React Router v6, since you're in charge of creating the element, you just pass a prop to the component as you normally would. <Route path=\"/dashboard\" element={<Dashboard authed={true} />} /> Good Practices for Calling APIs from ReactJS https://medium.com/weekly-webtips/patterns-for-doing-api-calls-in-reactjs-8fd9a42ac7d4 JSX JSX is a syntax extension for JavaScript. It was written to be used with React. JSX code looks a lot like HTML. What does \"syntax extension\" mean? In this case, it means that JSX is not valid JavaScript. Web browsers can\u2019t read it! If a JavaScript file contains JSX code, then that file will have to be compiled. That means that before the file reaches a web browser, a JSX compiler will translate any JSX into regular JavaScript. JSX Elements A basic unit of JSX is called a JSX element. Here\u2019s an example of a JSX element: <h1>Hello world</h1> JSX Elements And Their Surroundings JSX elements are treated as JavaScript expressions. They can go anywhere that JavaScript expressions can go. That means that a JSX element can be saved in a variable, passed to a function, stored in an object or array\u2026you name it. Here\u2019s an example of a JSX element being saved in a variable: const navBar = <nav>I am a nav bar</nav>; const myTeam = { center: <li>Benzo Walli</li>, powerForward: <li>Rasha Loa</li>, smallForward: <li>Tayshaun Dasmoto</li>, shootingGuard: <li>Colmar Cumberbatch</li>, pointGuard: <li>Femi Billon</li> }; Attributes In JSX JSX elements can have attributes, just like HTML elements can. A JSX attribute is written using HTML-like syntax: a name, followed by an equals sign, followed by a value. The value should be wrapped in quotes, like this: my-attribute-name=\"my-attribute-value\" <a href='http://www.example.com'>Welcome to the Web</a>; const title = <h1 id='title'>Introduction to React.js: Part I</h1>; const panda = <img src='images/panda.jpg' alt='panda' width='500px' height='500px' />; Nested JSX If a JSX expression takes up more than one line, then you must wrap the multi-line JSX expression in parentheses. This looks strange at first, but you get used to it: const theExample = ( <a href=\"https://www.example.com\"> <h1> Click me! </h1> </a> ) JSX Outer Elements There\u2019s a rule that we haven\u2019t mentioned: a JSX expression must have exactly one outermost element. In other words, this code will work: const paragraphs = ( <div id=\"i-am-the-outermost-element\"> <p>I am a paragraph.</p> <p>I, too, am a paragraph.</p> </div> ); // But this code will not work: const paragraphs = ( <p>I am a paragraph.</p> <p>I, too, am a paragraph.</p> ); Rendering JSX The following code will render a JSX expression: ReactDOM.render(<h1>Hello world</h1>, document.getElementById('app')); ReactDOM.render() ReactDOM is the name of a JavaScript library. This library contains several React-specific methods, all of which deal with the DOM in some way or another. When a web page is loaded, the browser creates a Document Object Model of the page. The HTML DOM model is constructed as a tree of Objects: ReactDOM.render() is the most common way to render JSX. It takes a JSX expression, creates a corresponding tree of DOM nodes, and adds that tree to the DOM. That is the way to make a JSX expression appear onscreen. In the code ReactDOM.render(<h1>Render me!</h1>, document.getElementById('app')); the expression <h1>Render me!</h1> is what you want rendered. The second argument document.getElementById('app') indicates where you want to append the first argument in the DOM. Ex: if you had the following HTML: <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <link rel=\"stylesheet\" href=\"/styles.css\"> <title>Learn ReactJS</title> </head> <body> <main id=\"app\"></main> <script src=\"https://content.codecademy.com/courses/React/react-course-bundle.min.js\"></script> <script src=\"/app.compiled.js\"></script> </body> </html> The element with the ID would be selected and the DOM added to it. One special thing about ReactDOM.render() is that it only updates DOM elements that have changed. That means that if you render the exact same thing twice in a row, the second render will do nothing. Passing a Variable to ReactDOM.render() ReactDOM.render()\u2018s first argument should evaluate to a JSX expression, it doesn\u2019t have to literally be a JSX expression. The first argument could also be a variable, so long as that variable evaluates to a JSX expression. class vs className <h1 class=\"big\">Hey</h1> In JSX, you can\u2019t use the word class! You have to use className instead: <h1 className=\"big\">Hey</h1> Self-Closing Tags With self closing tags you MUST include the slash in JSX. Ex: <br /> . The trailing / isn't optional. Javascript in JSX Te render Javascript in JSX, you have to use curly braces. Ex: import React from 'react'; import ReactDOM from 'react-dom'; // Write code here: ReactDOM.render( <h1>{2 + 3}</h1>, document.getElementById('app') ); Variables in JSX When you inject JavaScript into JSX, that JavaScript is part of the same environment as the rest of the JavaScript in your file. That means that you can access variables while inside of a JSX expression, even if those variables were declared on the outside. You can set HTML attributes with curly braces like this: // Use a variable to set the `height` and `width` attributes: const sideLength = \"200px\"; const panda = ( <img src=\"images/panda.jpg\" alt=\"panda\" height={sideLength} width={sideLength} /> ); Event Listeners in JSX JSX elements can have event listeners, just like HTML elements can. Programming in React means constantly working with event listeners. You create an event listener by giving a JSX element a special attribute. Here\u2019s an example: <img onClick={myFunc} /> An event listener attribute\u2019s name should be something like onClick or onMouseOver: the word on, plus the type of event that you\u2019re listening for. You can see a list of valid event names here . An event listener attribute\u2019s value should be a function. The above example would only work if myFunc were a valid function that had been defined elsewhere: function myFunc() { alert('Make myFunc the pFunc... omg that was horrible i am so sorry'); } <img onClick={myFunc} /> JSX Conditionals This code will break: ( <h1> { if (purchase.complete) { 'Thank you for placing an order!' } } </h1> ) The reason why has to do with the way that JSX is compiled. You don\u2019t need to understand the mechanics of it for now, but if you\u2019re interested then you can learn more in the React documentation . How can you write a conditional, if you can\u2019t inject an if statement into JSX? Well, one option is to write an if statement, and not inject it into JSX. Look at if.js. Follow the if statement, all the way from line 6 down to line 18. if.js works, because the words if and else are not injected in between JSX tags. The if statement is on the outside, and no JavaScript injection is necessary. import React from 'react'; import ReactDOM from 'react-dom'; let message; if (user.age >= drinkingAge) { message = ( <h1> Hey, check out this alcoholic beverage! </h1> ); } else { message = ( <h1> Hey, check out these earrings I got at Claire's! </h1> ); } ReactDOM.render( message, document.getElementById('app') ); Ternary Operator Recall how it works: you write x ? y : z, where x, y, and z are all JavaScript expressions. When your code is executed, x is evaluated as either \"truthy\" or \"falsy.\" If x is truthy, then the entire ternary operator returns y. If x is falsy, then the entire ternary operator returns z. Here\u2019s a nice explanation if you need a refresher. const headline = ( <h1> { age >= drinkingAge ? 'Buy Drink' : 'Do Teen Stuff' } </h1> ); && && works best in conditionals that will sometimes do an action, but other times do nothing at all. Here\u2019s an example: const tasty = ( <ul> <li>Applesauce</li> { !baby && <li>Pizza</li> } { age > 15 && <li>Brussels Sprouts</li> } { age > 20 && <li>Oysters</li> } { age > 25 && <li>Grappa</li> } </ul> ); If the expression on the left of the && evaluates as true, then the JSX on the right of the && will be rendered. If the first expression is false, however, then the JSX to the right of the && will be ignored and not rendered. .map in JSX If you want to create a list of JSX elements, then .map() is often your best bet. It can look odd at first: const strings = ['Home', 'Shop', 'About Me']; const listItems = strings.map(string => <li>{string}</li>); <ul>{listItems}</ul> In the above example, we start out with an array of strings. We call .map() on this array of strings, and the .map() call returns a new array of s. If you want the index you can do: const listItems = strings.map((string, i) => <li>{string}</li>); List Keys When you make a list in JSX, sometimes your list will need to include something called keys: <ul> <li key=\"li-01\">Example1</li> <li key=\"li-02\">Example2</li> <li key=\"li-03\">Example3</li> </ul> A key is a JSX attribute. The attribute\u2019s name is key. The attribute\u2019s value should be something unique, similar to an id attribute. keys don\u2019t do anything that you can see! React uses them internally to keep track of lists. If you don\u2019t use keys when you\u2019re supposed to, React might accidentally scramble your list-items into the wrong order. Not all lists need to have keys. A list needs keys if either of the following are true: The list-items have memory from one render to the next. For instance, when a to-do list renders, each item must \"remember\" whether it was checked off. The items shouldn\u2019t get amnesia when they render. A list\u2019s order might be shuffled. For instance, a list of search results might be shuffled from one render to the next. import React from 'react'; import ReactDOM from 'react-dom'; const people = ['Rowe', 'Prevost', 'Gare']; const peopleLis = people.map((person, i) => // expression goes here: <li key={'person_' + i}>{person}</li> ); // ReactDOM.render goes here: ReactDOM.render(<ul>{peopleLis}</ul>, document.getElementById('app')) React Create Element You can write React code without using JSX at all! The majority of React programmers do use JSX, and we will use it for the remainder of this tutorial, but you should understand that it is possible to write React code without it. The following JSX expression: const h1 = <h1>Hello world</h1>; can be rewritten without JSX, like this: const h1 = React.createElement( \"h1\", null, \"Hello world\" ); When a JSX element is compiled, the compiler transforms the JSX element into the method that you see above: React.createElement(). Every JSX element is secretly a call to React.createElement().","title":"Notes on nodejs"},{"location":"Notes%20on%20nodejs/#notes-on-nodejs","text":"Notes on nodejs Required Javascript Arrow expressions Promises Resolve and Reject Async/Await setInterval() and setTimeout() Node The Node REPL (read-eval-print loop) Running a Program with Node Core Modules Console Module The Process Module The OS Module The Util Module NPM Create a new app nodemon Package Scope Global Packages Installing a Custom Package Modules Exporting Require Using Object Destructuring to be more Selective With require() The Events Module User Input and Output The Error Module Why Error First Callbacks The Buffer Module Readable Streams Further explanation Writable Streams Timers Modules HTTP Server The URL Module Routing Longer Example Returning a Status Code Express Request Object Properties Request Object Methods Response Object Knex.js How does exports.up and exports.down work Seed Files Babel ReactJS Importing React Required Code Components Create a Component Class The Render Function Create a Component Instance Use This in a Class Render Components with Components Importing Files and Exporting Functionality Importing Exporting Component Props Event Handler handleEvent, onEvent, and this.props.onEvent this.props.children Default Properties Component State this.setState from Another Function Component Lifecycle componentDidMount componentWillUnmount componentDidUpdate Stateless Functional Components Function Component Props React Hooks Comparison Class vs Function Update Function Component State Initialize State Use State Setter Outside of JSX Longer Example Set From Previous State Arrays in State Objects in State Longer Example Separate Hooks for Separate States Comparison The Effect Hook - useEffect React Hooks and Component Lifecycle Equivalent componentWillMount for react functional component? Function Component Effects Clean Up Effects Control When Effects are Called Fetch Data from a Server Rules of Hooks Separate Hooks for Separate Effects Stateless Components from Stateful Components Build a Stateful Component Class Don't Update props Child Components Update Their Parents' State More Complex Example Child Components Update Sibling Components One Sibling to Display, Another to Change Style Inline Styles Make a Style Object Variable Share Styles Across Multiple Components Separate Container Components from Presentational Components Create a Container Component Create a Presentational Component propTypes Apply PropTypes PropTypes in Function Components React Forms Input on Change Control vs Uncontrolled Update an Input's Value Set the Input's Initial State Dynamically Rendering Different Components without Switch: the Capitalized Reference Technique React Router BrowserRouter Route Routes Links URL Parameters Nested Routes Pass props to Router Components Good Practices for Calling APIs from ReactJS JSX JSX Elements JSX Elements And Their Surroundings Attributes In JSX Nested JSX JSX Outer Elements Rendering JSX ReactDOM.render() Passing a Variable to ReactDOM.render() class vs className Self-Closing Tags Javascript in JSX Variables in JSX Event Listeners in JSX JSX Conditionals Ternary Operator && .map in JSX List Keys React Create Element","title":"Notes on nodejs"},{"location":"Notes%20on%20nodejs/#required-javascript","text":"","title":"Required Javascript"},{"location":"Notes%20on%20nodejs/#arrow-expressions","text":"Let\u2019s take a look at the code below. You will see two different functions defined. The first is anonymous (function is not named), and the second is named. When using an arrow expression, we do not use the function declaration. To define an arrow expression you simply use: () => { }. You can pass arguments to an arrow expression between the parenthesis (()). // Defining an anonymous arrow expression that simply logs a string to the console. console.log(() => console.log('Shhh, Im anonymous')); // Defining a named function by creating an arrow expression and saving it to a const variable helloWorld. const helloWorld = (name) => { console.log(`Welcome ${name} to Codecademy, this is an arrow expression.`) }; // Calling the helloWorld() function. helloWorld('Codey'); //Output: Welcome Codey to Codecademy, this is an Arrow Function Expression.","title":"Arrow expressions"},{"location":"Notes%20on%20nodejs/#promises","text":"A Promise is a JavaScript object that represents the eventual outcome of an asynchronous operation. A Promise has three different outcomes: pending (the result is undefined and the expression is waiting for a result), fulfilled (the promise has been completed successfully and returned a value), and rejected (the promise did not successfully complete, the result is an error object). In the code below a new Promise is being defined and is passed a function that takes two arguments, a fulfilled condition, and a rejected condition. We then log the returned value of the Promise to the console and chain a .catch() method to handle errors. // Creating a new Promise and saving it to the testLuck variable. Two arguments are being passed, one for when the promise resolves, and one for if the promise gets rejected. const testLuck = new Promise((resolve, reject) => { if (Math.random() < 0.5) { resolve('Lucky winner!') } else { reject(new Error('Unlucky!')) } }); testLuck.then(message => { console.log(message) // Log the resolved value of the Promise }).catch(error => { console.error(error) // Log the rejected error of the Promise });","title":"Promises"},{"location":"Notes%20on%20nodejs/#resolve-and-reject","text":"The Promise constructor method takes a function parameter called the executor function which runs automatically when the constructor is called. The executor function generally starts an asynchronous operation and dictates how the promise should be settled. The executor function has two function parameters, usually referred to as the resolve() and reject() functions. The resolve() and reject() functions aren\u2019t defined by the programmer. When the Promise constructor runs, JavaScript will pass its own resolve() and reject() functions into the executor function. resolve is a function with one argument. Under the hood, if invoked, resolve() will change the promise\u2019s status from pending to fulfilled, and the promise\u2019s resolved value will be set to the argument passed into resolve(). reject is a function that takes a reason or error as an argument. Under the hood, if invoked, reject() will change the promise\u2019s status from pending to rejected, and the promise\u2019s rejection reason will be set to the argument passed into reject().","title":"Resolve and Reject"},{"location":"Notes%20on%20nodejs/#asyncawait","text":"The async...await syntax allows developers to easily implement Promise-based code. The keyword async used in conjunction with a function declaration creates an async function that returns a Promise. Async functions allow us to use the keyword await to block the event loop until a given Promise resolves or rejects. The await keyword also allows us to assign the resolved value of a Promise to a variable. Let\u2019s take a look at the code below. In the code below an asynchronous arrow expression is defined with the async keyword. In the function body we are creating a new Promise which passes a function that is executed after 5 seconds, we await the Promise to resolve and save the value returned to finalResult, and the output of the Promise is logged to the console. // Creating a new promise that runs the function in the setTimeout after 5 seconds. const newPromise = new Promise((resolve, reject) => { setTimeout(() => resolve(\"All done!\"), 5000); }); // Creating an asynchronous function using an arrow expression and saving it to a the variable asyncFunction. const asyncFunction = async () => { // Awaiting the promise to resolve and saving the result to the variable finalResult. const finalResult = await newPromise; // Logging the result of the promise to the console console.log(finalResult); // Output: All done! } asyncFunction();","title":"Async/Await"},{"location":"Notes%20on%20nodejs/#setinterval-and-settimeout","text":"In addition to utilizing the async...await syntax, we can also use the setInterval() and setTimeout() functions. In the example code of the previous section, we created a setTimeout() instance in the Promise constructor. The setInterval() function executes a code block at a specified interval, in milliseconds. The setInterval() function requires two arguments: the name of the function (the code block that will be executed), and the number of milliseconds (how often the function will be executed). Optionally, we can pass additional arguments which will be supplied as parameters for the function that will be executed by setInterval(). The setInterval() function will continue to execute until the clearInterval() function is called or the node process is exited. In the code block below, the setInterval() function in the showAlert() function will display an alert box every 5000 milliseconds. // Defining a function that instantiates setInterval const showAlert = () => { // Calling setInterval() and passing a function that shows an alert every 5 seconds. setInterval(() => { alert('I show every 5 seconds!') }, 5000); }; // Calling the newInterval() function that calls the setInterval showAlert(); The setTimeout() function executes a code block after a specified amount of time (in milliseconds) and is only executed once. The setTimeout() function accepts the same arguments as the setInterval() function. Using the clearTimeout() function will prevent the function specified from being executed. In the code block below, a function named showTimeout() is declared as an arrow expression. The setTimeout() function is then defined and displays an alert box after 5 seconds. // Defining a function that calls setTimeout const showTimeout = () => { // Calling setTimeout() that passes a function that shows an alert after 5 seconds. setTimeout(() => { alert('I only show once after 5 seconds!'); }, 5000); }; // Calling the showTimeout() function showTimeout();","title":"setInterval() and setTimeout()"},{"location":"Notes%20on%20nodejs/#node","text":"","title":"Node"},{"location":"Notes%20on%20nodejs/#the-node-repl-read-eval-print-loop","text":"REPL is an abbreviation for read\u2013eval\u2013print loop. It\u2019s a program that loops, or repeatedly cycles, through three different states: a read state where the program reads input from a user, the eval state where the program evaluates the user\u2019s input, and the print state where the program prints out its evaluation to a console. Then it loops through these states again. It's just the equivalent of typing python except for javascript. Type node to get to it. To see global vars see Object.keys(global) . You can add to it with global.cat = 'thing' . Print with console.log(global.cat) If you\u2019re familiar with running JavaScript on the browser, you\u2019ve likely encountered the Window object. Here\u2019s one major way that Node differs: try to access the Window object (this will throw an error). The Window object is the JavaScript object in the browser that holds the DOM, since we don\u2019t have a DOM here, there\u2019s no Window object.","title":"The Node REPL (read-eval-print loop)"},{"location":"Notes%20on%20nodejs/#running-a-program-with-node","text":"node program","title":"Running a Program with Node"},{"location":"Notes%20on%20nodejs/#core-modules","text":"Include a module: // Require in the 'events' core module: const events = require('events'); Some core modules are actually used inside other core modules. For instance, the util module can be used in the console module to format messages. We\u2019ll cover these two modules in this lesson, as well as two other commonly used core modules: process and os. See all builtin modules: require('module').builtinModules","title":"Core Modules"},{"location":"Notes%20on%20nodejs/#console-module","text":"Since console is a global module, its methods can be accessed from anywhere, and the require() function is not necessary. .log() - prints messages to the terminal .assert() - prints a message to the terminal if the value is falsey console.assert(petsArray.length > 5); .table() - prints out a table in the terminal from an object or array","title":"Console Module"},{"location":"Notes%20on%20nodejs/#the-process-module","text":"Node has a global process object with useful methods and information about the current process. The console.log() method is a \"thin wrapper\" on the .stdout.write() method of the process object. The process.env property is an object which stores and controls information about the environment in which the process is currently running. For example, the process.env object contains a PWD property which holds a string with the directory in which the current process is located. It can be useful to have some if/else logic in a program depending on the current environment\u2014 a web application in a development phase might perform different tasks than when it\u2019s live to users. We could store this information on the process.env. One convention is to add a property to process.env with the key NODE_ENV and a value of either production or development. if (process.env.NODE_ENV === 'development'){ console.log('Testing! Testing! Does everything work?'); } The process.memoryUsage() returns information on the CPU demands of the current process. It returns a property that looks similar to this: { rss: 26247168, heapTotal: 5767168, heapUsed: 3573032, external: 8772 } process.argv holds an array of command line values provided when the current process was initiated.","title":"The Process Module"},{"location":"Notes%20on%20nodejs/#the-os-module","text":"const os = require('os'); os.type() \u2014 to return the computer\u2019s operating system. os.arch() \u2014 to return the operating system CPU architecture. os.networkInterfaces() \u2014 to return information about the network interfaces of the computer, such as IP and MAC address. os.homedir() \u2014 to return the current user\u2019s home directory. os.hostname() \u2014 to return the hostname of the operating system. os.uptime() \u2014 to return the system uptime, in seconds. Create an empty object const object = {}; Instantiate a dictionary: const os = require('os'); const server = {type: os.type(), architecture: os.arch(), uptime: os.uptime()}; console.table(server)","title":"The OS Module"},{"location":"Notes%20on%20nodejs/#the-util-module","text":"Developers sometimes classify outlier functions used to maintain code and debug certain aspects of a program\u2019s functionality as utility functions. Utility functions don\u2019t necessarily create new functionality in a program, but you can think of them as internal tools used to maintain and debug your code. The Node.js util core module contains methods specifically designed for these purposes. const util = require('util'); Get the type of an object : const util = require('util'); const today = new Date(); const earthDay = 'April 22, 2022'; console.log(util.types.isDate(today)); console.log(util.types.isDate(earthDay)); Turn callback functions into promises : Another important util method is .promisify(), which turns callback functions into promises. As you know, asynchronous programming is essential to Node.js. In the beginning, this asynchrony was achieved using error-first callback functions, which are still very prevalent in the Node ecosystem today. But since promises are often preferred over callbacks and especially nested callbacks, Node offers a way to turn these into promises. Let\u2019s take a look: function getUser (id, callback) { return setTimeout(() => { if (id === 5) { callback(null, { nickname: 'Teddy' }) } else { callback(new Error('User not found')) } }, 1000) } function callback (error, user) { if (error) { console.error(error.message) process.exit(1) } console.log(`User found! Their nickname is: ${user.nickname}`) } getUser(1, callback) // -> `User not found` getUser(5, callback) // -> `User found! Their nickname is: Teddy` You can convert the above to: const getUserPromise = util.promisify(getUser); getUserPromise(id) .then((user) => { console.log(`User found! Their nickname is: ${user.nickname}`); }) .catch((error) => { console.log('User not found', error); }); getUser(1) // -> `User not found` getUser(5) // -> `User found! Their nickname is: Teddy` We declare a getUserPromise variable that stores the getUser method turned into a promise using the .promisify() method. With that in place, we\u2019re able to use getUserPromise with .then() and .catch() methods (or we could also use the async...await syntax here) to resolve the promise returned or catch any errors.","title":"The Util Module"},{"location":"Notes%20on%20nodejs/#npm","text":"","title":"NPM"},{"location":"Notes%20on%20nodejs/#create-a-new-app","text":"npm init Add -y to answer yes to everything. This will generate a package.json file: { \"name\": \"my-project\", \"version\": \"1.0.0\", \"description\": \"a basic project\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"author\": \"Super Coder\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.1\" }, }","title":"Create a new app"},{"location":"Notes%20on%20nodejs/#nodemon","text":"Automatically restart a program when a file changes. npm install nodemon The npm i <package name> command installs a package locally in a folder called node_modules/ which is created in the project directory that you ran the command from. In addition, the newly installed package will be added to the package.json file.","title":"nodemon"},{"location":"Notes%20on%20nodejs/#package-scope","text":"While most dependencies play a direct role in the functionality of your application, development dependencies are used for the purpose of making development easier or more efficient. In fact, the nodemon package is actually better suited as a development dependency since it makes developers\u2019 lives easier but makes no changes to the app itself. To install nodemon as a development dependency, we can add the --save-dev flag, or its alias, -D. npm install nodemon --save-dev Development dependencies are listed in the \"devDependencies\" field of the package.json file. This indicates that the package is being used specifically for development and will not be included in a production release of the project. { \"name\": \"my-project\", \"version\": \"1.0.0\", \"description\": \"a basic project\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.1\" }, \"devDependencies\": { \"nodemon\": \"^2.0.13\" } }","title":"Package Scope"},{"location":"Notes%20on%20nodejs/#global-packages","text":"Typically, packages installed this way will be used in the command-line rather than imported into a project\u2019s code. One such example is the http-server package which allows you to spin up a zero-configuration server from anywhere in the command-line. To install a package globally, use the -g flag with the installation command: npm install http-server -g http-server is a good package to install globally since it is a general command-line utility and its purpose is not linked to any specific functionality within an app. Unlike local package dependencies or development dependencies, packages installed globally will not be listed in a projects package.json file and they will be stored in a separate global node_modules/ folder.","title":"Global Packages"},{"location":"Notes%20on%20nodejs/#installing-a-custom-package","text":"If you want to give someone else your package you can provide the package.json file and then they can install with npm i . Add --production to leave out the dev dependencies.","title":"Installing a Custom Package"},{"location":"Notes%20on%20nodejs/#modules","text":"There are multiple ways of implementing modules depending on the runtime environment in which your code is executed. In JavaScript, there are two runtime environments and each has a preferred module implementation: The Node runtime environment and the module.exports and require() syntax. The browser\u2019s runtime environment and the ES6 import/export syntax.","title":"Modules"},{"location":"Notes%20on%20nodejs/#exporting","text":"/* converters.js */ function celsiusToFahrenheit(celsius) { return celsius * (9/5) + 32; } module.exports.celsiusToFahrenheit = celsiusToFahrenheit; module.exports.fahrenheitToCelsius = function(fahrenheit) { return (fahrenheit - 32) * (5/9); }; At the top of the new file, converters.js, the function celsiusToFahrenheit() is declared. On the next line of code, the first approach for exporting a function from a module is shown. In this case, the already-defined function celsiusToFahrenheit() is assigned to module.exports.celsiusToFahrenheit. Below, an alternative approach for exporting a function from a module is shown. In this second case, a new function expression is declared and assigned to module.exports.fahrenheitToCelsius. This new method is designed to convert Fahrenheit values back to Celsius. Both approaches successfully store a function within the module.exports object. module.exports is an object that is built-in to the Node.js runtime environment. Other files can now import this object, and make use of these two functions, with another feature that is built-in to the Node.js runtime environment: the require() function.","title":"Exporting"},{"location":"Notes%20on%20nodejs/#require","text":"The require() function accepts a string as an argument. That string provides the file path to the module you would like to import. Let\u2019s update water-limits.js such that it uses require() to import the .celsiusToFahrenheit() method from the module.exports object within converters.js: /* water-limits.js */ const converters = require('./converters.js'); const freezingPointC = 0; const boilingPointC = 100; const freezingPointF = converters.celsiusToFahrenheit(freezingPointC); const boilingPointF = converters.celsiusToFahrenheit(boilingPointC); console.log(`The freezing point of water in Fahrenheit is ${freezingPointF}`); console.log(`The boiling point of water in Fahrenheit is ${boilingPointF}`);","title":"Require"},{"location":"Notes%20on%20nodejs/#using-object-destructuring-to-be-more-selective-with-require","text":"In many cases, modules will export a large number of functions but only one or two of them are needed. You can use object destructuring to extract only the needed functions. Let\u2019s update celsius-to-fahrenheit.js and only extract the .celsiusToFahrenheit() method, leaving .fahrenheitToCelsius() behind: /* celsius-to-fahrenheit.js */ const { celsiusToFahrenheit } = require('./converters.js'); const celsiusInput = process.argv[2]; const fahrenheitValue = celsiusToFahrenheit(celsiusInput); console.log(`${celsiusInput} degrees Celsius = ${fahrenheitValue} degrees Fahrenheit`); Notice that the first line used to be const converters = require('./converters.js'); and now it is specifying the exported function.","title":"Using Object Destructuring to be more Selective With require()"},{"location":"Notes%20on%20nodejs/#the-events-module","text":"Node provides an EventEmitter class which we can access by requiring in the events core module: // Require in the 'events' core module let events = require('events'); // Create an instance of the EventEmitter class let myEmitter = new events.EventEmitter(); Each event emitter instance has an .on() method which assigns a listener callback function to a named event. The .on() method takes as its first argument the name of the event as a string and, as its second argument, the listener callback function. Each event emitter instance also has an .emit() method which announces a named event has occurred. The .emit() method takes as its first argument the name of the event as a string and, as its second argument, the data that should be passed let newUserListener = (data) => { console.log(`We have a new user: ${data}.`); }; // Assign the newUserListener function as the listener callback for 'new user' events myEmitter.on('new user', newUserListener) // Emit a 'new user' event myEmitter.emit('new user', 'Lily Pad') //newUserListener will be invoked with 'Lily Pad' Note There is no link between the variable data in the constructer for the event emitter and the new user name.","title":"The Events Module"},{"location":"Notes%20on%20nodejs/#user-input-and-output","text":"Notice that for user input and output for something like stdin what you're really doing is registering a callback and then calling it on user input. Ex: process.stdin.on('data', (userInput) => { let input = userInput.toString() console.log(input) }); Notice the on and then here we're just defining an anonymous function.","title":"User Input and Output"},{"location":"Notes%20on%20nodejs/#the-error-module","text":"The Node environment\u2019s error module has all the standard JavaScript errors such as EvalError, SyntaxError, RangeError, ReferenceError, TypeError, and URIError as well as the JavaScript Error class for creating new error instances. Within our own code, we can generate errors and throw them, and, with synchronous code in Node, we can use error handling techniques such as try...catch statements. Note that the error module is within the global scope\u2014there is no need to import the module with the require() statement. Many asynchronous Node APIs use error-first callback functions\u2014callback functions which have an error as the first expected argument and the data as the second argument. If the asynchronous task results in an error, it will be passed in as the first argument to the callback function. If no error was thrown, the first argument will be undefined. const errorFirstCallback = (err, data) => { if (err) { console.log(`There WAS an error: ${err}`); } else { // err was falsy console.log(`There was NO error. Event data: ${data}`); } }","title":"The Error Module"},{"location":"Notes%20on%20nodejs/#why-error-first-callbacks","text":"You need this because if you try something like: const api = require('./api.js'); // Not an error-first callback let callbackFunc = (data) => { console.log(`Something went right. Data: ${data}\\n`); }; try { api.naiveErrorProneAsyncFunction('problematic input', callbackFunc); } catch(err) { console.log(`Something went wrong. ${err}\\n`); } then the try-catch won't work because the error is thrown in the context of the separate thread spawned asynchronously and subsequently never caught because Javascript is a garbage programming language.","title":"Why Error First Callbacks"},{"location":"Notes%20on%20nodejs/#the-buffer-module","text":"In Node.js, the Buffer module is used to handle binary data. The Buffer module is within the global scope, which means that Buffer objects can be accessed anywhere in the environment without importing the module with require(). A Buffer object represents a fixed amount of memory that can\u2019t be resized. Buffer objects are similar to an array of integers where each element in the array represents a byte of data. The buffer object will have a range of integers from 0 to 255 inclusive. The Buffer module provides a variety of methods to handle the binary data such as .alloc(), .toString(), .from(), and .concat(). The .alloc() method creates a new Buffer object with the size specified as the first parameter. .alloc() accepts three arguments: Size: Required. The size of the buffer Fill: Optional. A value to fill the buffer with. Default is 0. Encoding: Optional. Default is UTF-8. const buffer = Buffer.alloc(5); console.log(buffer); // Ouput: [0, 0, 0, 0, 0] The .toString() method translates the Buffer object into a human-readable string. It accepts three optional arguments: Encoding: Default is UTF-8. Start: The byte offset to begin translating in the Buffer object. Default is 0. End: The byte offset to end translating in the Buffer object. Default is the length of the buffer. The start and end of the buffer are similar to the start and end of an array, where the first element is 0 and increments upwards. const buffer = Buffer.alloc(5, 'a'); console.log(buffer.toString()); // Output: aaaaa The .from() method is provided to create a new Buffer object from the specified string, array, or buffer. The method accepts two arguments: Object: Required. An object to fill the buffer with. Encoding: Optional. Default is UTF-8. const buffer = Buffer.from('hello'); console.log(buffer); // Output: [104, 101, 108, 108, 111] The .concat() method joins all buffer objects passed in an array into one Buffer object. .concat() comes in handy because a Buffer object can\u2019t be resized. This method accepts two arguments: Array: Required. An array containing Buffer objects. Length: Optional. Specifies the length of the concatenated buffer. const buffer1 = Buffer.from('hello'); // Output: [104, 101, 108, 108, 111] const buffer2 = Buffer.from('world'); // Output:[119, 111, 114, 108, 100] const array = [buffer1, buffer2]; const bufferConcat = Buffer.concat(array); console.log(bufferConcat); // Output: [104, 101, 108, 108, 111, 119, 111, 114, 108, 100]","title":"The Buffer Module"},{"location":"Notes%20on%20nodejs/#readable-streams","text":"const readline = require('readline'); const fs = require('fs'); const myInterface = readline.createInterface({ input: fs.createReadStream('shoppingList.txt') }); const printData = (data) => { console.log(`Item: ${data}`); }; myInterface.on('line', printData);","title":"Readable Streams"},{"location":"Notes%20on%20nodejs/#further-explanation","text":"One of the simplest uses of streams is reading and writing to files line-by-line. To read files line-by-line, we can use the .createInterface() method from the readline core module. .createInterface() returns an EventEmitter set up to emit 'line' events: const readline = require('readline'); const fs = require('fs'); const myInterface = readline.createInterface({ input: fs.createReadStream('text.txt') }); myInterface.on('line', (fileLine) => { console.log(`The line read: ${fileLine}`); }); Let\u2019s walk through the above code: We require in the readline and fs core modules. We assign to myInterface the returned value from invoking readline.createInterface() with an object containing our designated input. We set our input to fs.createReadStream('text.txt') which will create a stream from the text.txt file. Next we assign a listener callback to execute when line events are emitted. A 'line' event will be emitted after each line from the file is read. Our listener callback will log to the console 'The line read: [fileLine]', where [fileLine] is the line just read.","title":"Further explanation"},{"location":"Notes%20on%20nodejs/#writable-streams","text":"const readline = require('readline'); const fs = require('fs'); const myInterface = readline.createInterface({ input: fs.createReadStream('shoppingList.txt') }); const fileStream = fs.createWriteStream('shoppingResults.txt'); let transformData = (line) => { fileStream.write(`They were out of: ${line}\\n`); }; myInterface.on('line', transformData);","title":"Writable Streams"},{"location":"Notes%20on%20nodejs/#timers-modules","text":"You may already be familiar with some timer functions such as, setTimeout() and setInterval(). Timer functions in Node.js behave similarly to how they work in front-end JavaScript programs, but the difference is that they are added to the Node.js event loop. This means that the timer functions are scheduled and put into a queue. This queue is processed at every iteration of the event loop. If a timer function is executed outside of a module, the behavior will be random (non-deterministic). The setImmediate() function is often compared with the setTimeout() function. When setImmediate() is called, it executes the specified callback function after the current (poll phase) is completed. The method accepts two parameters: the callback function (required) and arguments for the callback function (optional). If you instantiate multiple setImmediate() functions, they will be queued for execution in the order that they were created.","title":"Timers Modules"},{"location":"Notes%20on%20nodejs/#http-server","text":"To process HTTP requests in JavaScript and Node.js, we can use the built-in http module. This core module is key in leveraging Node.js networking and is extremely useful in creating HTTP servers and processing HTTP requests. The http module comes with various methods that are useful when engaging with HTTP network requests. One of the most commonly used methods within the http module is the .createServer() method. This method is responsible for doing exactly what its namesake implies; it creates an HTTP server. To implement this method to create a server, the following code can be used: const server = http.createServer((req, res) => { res.end('Server is running!'); }); server.listen(8080, () => { const { address, port } = server.address(); console.log(`Server is listening on: http://${address}:${port}`); }) The .createServer() method takes a single argument in the form of a callback function. This callback function has two primary arguments; the request (commonly written as req) and the response (commonly written as res). The req object contains all of the information about an HTTP request ingested by the server. It exposes information such as the HTTP method (GET, POST, etc.), the pathname, headers, body, and so on. The res object contains methods and properties pertaining to the generation of a response by the HTTP server. This object contains methods such as .setHeader() (sets HTTP headers on the response), .statusCode (set the status code of the response), and .end() (dispatches the response to the client who made the request). In the example above, we use the .end() method to send the string \u2018Server is Running!\u2019 to the client, which will display on the web page. Once the .createServer() method has instantiated the server, it must begin listening for connections. This final step is accomplished by the .listen() method on the server instance. This method takes a port number as the first argument, which tells the server to listen for connections at the given port number. In our example above, the server has been set to listen on port 8080. Additionally, the .listen() method takes an optional callback function as a second argument, allowing it to carry out a task after the server has successfully started. Using this simple .createServer() method, in conjunction with the callback, provides the ability to process HTTP requests dynamically and dispatch responses back to their callers.","title":"HTTP Server"},{"location":"Notes%20on%20nodejs/#the-url-module","text":"Typically, an HTTP server will require information from the request URL to accurately process a request. This request URL is located on the url property contained within the req object itself. To parse the different parts of this URL easily, Node.js provides the built-in url module. The core of the url module revolves around the URL class. A new URL object can be instantiated using the URL class as follows: const url = new URL('https://www.example.com/p/a/t/h?query=string'); Once instantiated, different parts of the URL can be accessed and modified via various properties, which include: hostname: Gets and sets the host name portion of the URL. pathname: Gets and sets the path portion of the URL. searchParams: Gets the search parameter object representing the query parameters contained within the URL. Returns an instance of the URLSearchParams class. You might recognize the URL and URLSearchParams classes if you are familiar with browser-based JavaScript. It\u2019s because they are actually the same thing! These classes are defined by the WHATWG URL specification. Both the browser and Node.js implement this API, which means developers can have a similar developer experience working with both client and server-side JavaScript. Using these properties, one can break the URL down into easily usable parts for processing the request. const host = url.hostname; // example.com const pathname = url.pathname; // /p/a/t/h const searchParams = url.searchParams; // {query: 'string'} While the url module can be used to deconstruct a URL into its constituent parts, it can also be used to construct a URL. Constructing a URL via this method relies on most of the same properties listed above to set values on the URL instead of retrieving them. This can be done by setting each of these values equal to a value for the newly constructed URL. Once all parts of the URL have been added, the composed URL can be obtained using the .toString() method. const createdUrl = new URL('https://www.example.com'); createdUrl.pathname = '/p/a/t/h'; createdUrl.search = '?query=string'; createUrl.toString(); // Creates https://www.example.com/p/a/t/h?query=string","title":"The URL Module"},{"location":"Notes%20on%20nodejs/#routing","text":"To process and respond to requests appropriately, servers need to do more than look at a request and dispatch a response. Internally, a server needs to maintain a way to handle each request based on specific criteria such as method, pathname, etc. The process of handling requests in specific ways based on the information provided within the request is known as routing. The method is one important piece of information that can be used to route requests. Since each HTTP request contains a method such as GET and POST, it is a great way to discern different classes of requests based on the action intended for the server to carry out. Thus, all GET requests could be routed to a specific function for handling, while all POST requests are routed to another function to be handled. This also allows for the logical co-location of processing code with the specific verb to be handled. const server = http.createServer((req, res) => { const { method } = req; switch(method) { case 'GET': return handleGetRequest(req, res); case 'POST': return handlePostRequest(req, res); case 'DELETE': return handleDeleteRequest(req, res); case 'PUT': return handlePutRequest(req, res); default: throw new Error(`Unsupported request method: ${method}`); } }) In the above example, the HTTP method property is destructured from the req object and used to conditionally invoke a handler function built specifically for handling those types of requests. This is great at first glance, but it should soon become apparent that the routing is not specific enough. After all, how will one GET request be distinguished from another? We can distinguish one request from another of the same method through the use of the pathname. The pathname allows the server to understand what resource is being targeted. Let\u2019s take a look at the handleGetRequest handler function. function handleGetRequest(req, res) { const { pathname } = new URL(req.url); let data = {}; if (pathname === '/projects') { data = await getProjects(); res.setHeader('Content-Type', 'application/json'); return res.end(JSON.stringify(data)); } res.statusCode = 404; return res.end('Requested resource does not exist'); } Within the handleGetRequest() function, the pathname is being checked to match a known resource, '/projects'. If the pathname matches, the resource data is fetched and then subsequently dispatched from the server as a successful response. Otherwise, the .statusCode property is set to 404, indicating that the resource is not found, and a corresponding error message is dispatched. This pattern can be extrapolated to any number of conditional resource matches, allowing the server to handle many different types of requests to different resources.","title":"Routing"},{"location":"Notes%20on%20nodejs/#longer-example","text":"const http = require('http'); // Handle get request const handleGetRequest = (req, res) => { const pathname = req.url; if (pathname === '/users') { res.end(JSON.stringify([])); } } // Creates server instance const server = http.createServer((req, res) => { const { method } = req; switch(method) { case 'GET': return handleGetRequest(req, res); default: throw new Error(`Unsupported request method: ${method}`); } }); // Starts server listening on specified port server.listen(4001, () => { const { address, port } = server.address(); console.log(`Server is listening on: http://${address}:${port}`); });","title":"Longer Example"},{"location":"Notes%20on%20nodejs/#returning-a-status-code","text":"const http = require('http'); const handleGetRequest = (req, res) => { res.statusCode = 200; return res.end(JSON.stringify({ data: [] })); } const handlePostRequest = (req, res) => { res.statusCode = 500; return res.end(\"Unable to create record\"); } // Creates server instance const server = http.createServer((req, res) => { const { method } = req; switch(method) { case 'GET': return handleGetRequest(req, res); case 'POST': return handlePostRequest(req, res); default: throw new Error(`Unsupported request method: ${method}`); } }); // Starts server listening on specified port server.listen(4001, () => { const { address, port } = server.address(); console.log(`Server is listening on: http://${address}:${port}`); });","title":"Returning a Status Code"},{"location":"Notes%20on%20nodejs/#express","text":"","title":"Express"},{"location":"Notes%20on%20nodejs/#request-object-properties","text":"Index Properties Description 1. req.app This is used to hold a reference to the instance of the express application that is using the middleware. 2. req.baseurl It specifies the URL path on which a router instance was mounted. 3. req.body It contains key-value pairs of data submitted in the request body. By default, it is undefined, and is populated when you use body-parsing middleware such as body-parser. 4. req.cookies When we use cookie-parser middleware, this property is an object that contains cookies sent by the request. 5. req.fresh It specifies that the request is \"fresh.\" it is the opposite of req.stale. 6. req.hostname It contains the hostname from the \"host\" http header. 7. req.ip It specifies the remote IP address of the request. 8. req.ips When the trust proxy setting is true, this property contains an array of IP addresses specified in the ?x-forwarded-for? request header. 9. req.originalurl This property is much like req.url; however, it retains the original request URL, allowing you to rewrite req.url freely for internal routing purposes. 10. req.params An object containing properties mapped to the named route ?parameters?. For example, if you have the route /user/:name, then the \"name\" property is available as req.params.name. This object defaults to {}. 11. req.path It contains the path part of the request URL. 12. req.protocol The request protocol string, \"http\" or \"https\" when requested with TLS. 13. req.query An object containing a property for each query string parameter in the route. 14. req.route The currently-matched route, a string. 15. req.secure A Boolean that is true if a TLS connection is established. 16. req.signedcookies When using cookie-parser middleware, this property contains signed cookies sent by the request, unsigned and ready for use. 17. req.stale It indicates whether the request is \"stale,\" and is the opposite of req.fresh. 18. req.subdomains It represents an array of subdomains in the domain name of the request. 19. req.xhr A Boolean value that is true if the request's \"x-requested-with\" header field is \"xmlhttprequest\", indicating that the request was issued by a client library such as jQuery","title":"Request Object Properties"},{"location":"Notes%20on%20nodejs/#request-object-methods","text":"req.accepts This method is used to check whether the specified content types are acceptable, based on the request's Accept HTTP header field. req.accepts('html'); //=>?html? req.accepts('text/html'); // => ?text/html? req.get(field) This method returns the specified HTTP request header field. req.get('Content-Type'); // => \"text/plain\" req.get('content-type'); // => \"text/plain\" req.get('Something'); // => undefined req.is(type) // With Content-Type: text/html; charset=utf-8 req.is('html'); req.is('text/html'); req.is('text/*'); // => true req.param(name [,defaultValue]) This method is used to fetch the value of param name when present. // ?name=sasha req.param('name') // => \"sasha\" // POST name=sasha req.param('name') // => \"sasha\" // /user/sasha for /user/:name req.param('name') // => \"sasha\"","title":"Request Object Methods"},{"location":"Notes%20on%20nodejs/#response-object","text":"","title":"Response Object"},{"location":"Notes%20on%20nodejs/#knexjs","text":"","title":"Knex.js"},{"location":"Notes%20on%20nodejs/#how-does-exportsup-and-exportsdown-work","text":"http://perkframework.com/v1/guides/database-migrations-knex.html","title":"How does exports.up and exports.down work"},{"location":"Notes%20on%20nodejs/#seed-files","text":"A seed file allows you to add data into your database without having to manually add it. This is most frequently used for database initialization or loading demo data.","title":"Seed Files"},{"location":"Notes%20on%20nodejs/#babel","text":"What is Babel: https://babeljs.io/docs/en/","title":"Babel"},{"location":"Notes%20on%20nodejs/#reactjs","text":"","title":"ReactJS"},{"location":"Notes%20on%20nodejs/#importing-react-required-code","text":"import React from 'react'; This creates an object named React which contains methods necessary to use the React library. import ReactDOM from 'react-dom'; The methods imported from 'react-dom' are meant for interacting with the DOM. You are already familiar with one of them: ReactDOM.render(). The methods imported from 'react' don\u2019t deal with the DOM at all. They don\u2019t engage directly with anything that isn\u2019t part of React. To clarify: the DOM is used in React applications, but it isn\u2019t part of React. After all, the DOM is also used in countless non-React applications. Methods imported from 'react' are only for pure React purposes, such as creating components or writing JSX elements.","title":"Importing React Required Code"},{"location":"Notes%20on%20nodejs/#components","text":"","title":"Components"},{"location":"Notes%20on%20nodejs/#create-a-component-class","text":"we can use a JavaScript class to define a new React component. We can also define components with JavaScript functions, but we\u2019ll focus on class components first. All class components will have some methods and properties in common (more on this later). Rather than rewriting those same properties over and over again every time, we extend the Component class from the React library. This way, we can use code that we import from the React library, without having to write it over and over again ourselves. After we define our class component, we can use it to render as many instances of that component as we want. What is React.Component, and how do you use it to make a component class? React.Component is a JavaScript class. To create your own component class, you must subclass React.Component. You can do this by using the syntax class YourComponentNameGoesHere extends React.Component {}. import React from 'react'; import ReactDOM from 'react-dom'; class MyComponentClass extends React.Component { render() { return <h1>Hello world</h1>; } } ReactDOM.render( <MyComponentClass />, document.getElementById('app') ); On line 4, you know that you are declaring a new component class, which is like a factory for building React components. You know that React.Component is a class, which you must subclass in order to create a component class of your own. You also know that React.Component is a property on the object which was returned by import React from 'react' on line 1.","title":"Create a Component Class"},{"location":"Notes%20on%20nodejs/#the-render-function","text":"A render method is a property whose name is render, and whose value is a function. The term \"render method\" can refer to the entire property, or to just the function part. class ComponentFactory extends React.Component { render() { return <h1>Hello world</h1>; } }","title":"The Render Function"},{"location":"Notes%20on%20nodejs/#create-a-component-instance","text":"To make a React component, you write a JSX element. Instead of naming your JSX element something like h1 or div like you\u2019ve done before, give it the same name as a component class. Voil\u00e0, there\u2019s your component instance! JSX elements can be either HTML-like, or component instances. JSX uses capitalization to distinguish between the two! That is the React-specific reason why component class names must begin with capital letters. In a JSX element, that capitalized first letter says, \"I will be a component instance and not an HTML tag.\" Whenever you make a component, that component inherits all of the methods of its component class. MyComponentClass has one method: MyComponentClass.render(). Therefore, also has a method named render. In order to render a component, that component needs to have a method named render. Your component has this! It inherited a method named render from MyComponentClass. To call a component\u2019s render method, you pass that component to ReactDOM.render(). Notice your component, being passed as ReactDOM.render()\u2018s first argument: ReactDOM.render( <MyComponentClass />, document.getElementById('app') ); ReactDOM.render() will tell to call its render method. will call its render method, which will return the JSX element","title":"Create a Component Instance"},{"location":"Notes%20on%20nodejs/#use-this-in-a-class","text":"class IceCreamGuy extends React.Component { get food() { return 'ice cream'; } render() { return <h1>I like {this.food}.</h1>; } }","title":"Use This in a Class"},{"location":"Notes%20on%20nodejs/#render-components-with-components","text":"class OMG extends React.Component { render() { return <h1>Whooaa!</h1>; } } class Crazy extends React.Component { render() { return <OMG />; } }","title":"Render Components with Components"},{"location":"Notes%20on%20nodejs/#importing-files-and-exporting-functionality","text":"","title":"Importing Files and Exporting Functionality"},{"location":"Notes%20on%20nodejs/#importing","text":"The second important difference involves the contents of the string at the end of the statement: 'react' vs './NavBar.js'. If you use an import statement, and the string at the end begins with either a dot or a slash, then import will treat that string as a filepath. import will follow that filepath, and import the file that it finds. If your filepath doesn\u2019t have a file extension, then \".js\" is assumed. So the above example could be shortened: import { NavBar } from './NavBar'; One final, important note: None of this behavior is specific to React! Module systems of independent, importable files are a very popular way to organize code. React\u2019s specific module system comes from ES6.","title":"Importing"},{"location":"Notes%20on%20nodejs/#exporting_1","text":"This is called a named export. export class NavBar extends React.Component {","title":"Exporting"},{"location":"Notes%20on%20nodejs/#component-props","text":"A component\u2019s props is an object. It holds information about that component. You can pass information to a prop via an attribute. import React from 'react'; import ReactDOM from 'react-dom'; class Greeting extends React.Component { render() { return <h1>Hi there, {this.props.firstName}!</h1>; } } ReactDOM.render( <Greeting firstName='Grant' />, document.getElementById('app') );","title":"Component Props"},{"location":"Notes%20on%20nodejs/#event-handler","text":"import React from 'react'; import ReactDOM from 'react-dom'; import { Button } from './Button'; class Talker extends React.Component { talk() { let speech = ''; for (let i = 0; i < 10000; i++) { speech += 'blah '; } alert(speech); } render() { return <Button talk={this.talk}/>; ReactDOM.render( <Talker />, document.getElementById('app') ); // **************************************** // In Button.js import React from 'react'; export class Button extends React.Component { render() { return ( // TODO - why is it `this` here? <button onClick={this.props.talk}> Click me! </button> ); } }","title":"Event Handler"},{"location":"Notes%20on%20nodejs/#handleevent-onevent-and-thispropsonevent","text":"When you pass an event handler as a prop, as you just did, there are two names that you have to choose. Both naming choices occur in the parent component class - that is, in the component class that defines the event handler and passes it. The first name that you have to choose is the name of the event handler itself. Look at Talker.js, lines 6 through 12. This is our event handler. We chose to name it talk. The second name that you have to choose is the name of the prop that you will use to pass the event handler. This is the same thing as your attribute name. For our prop name, we also chose talk, as shown on line 15: return <Button talk={this.talk} />; These two names can be whatever you want. However, there is a naming convention that they often follow. You don\u2019t have to follow this convention, but you should understand it when you see it. Here\u2019s how the naming convention works: first, think about what type of event you are listening for. In our example, the event type was \"click.\" If you are listening for a \"click\" event, then you name your event handler handleClick. If you are listening for a \"keyPress\" event, then you name your event handler handleKeyPress: class MyClass extends React.Component { handleHover() { alert('I am an event handler.'); alert('I will be called in response to \"hover\" events.'); } } Your prop name should be the word on, plus your event type. If you are listening for a \"click\" event, then you name your prop onClick. If you are listening for a \"keyPress\" event, then you name your prop onKeyPress: class MyClass extends React.Component { handleHover() { alert('I am an event handler.'); alert('I will listen for a \"hover\" event.'); } render() { return <Child onHover={this.handleHover} />; } }","title":"handleEvent, onEvent, and this.props.onEvent"},{"location":"Notes%20on%20nodejs/#thispropschildren","text":"Every component\u2019s props object has a property named children. this.props.children will return everything in between a component\u2019s opening and closing JSX tags. For example: // List.js import React from 'react'; export class List extends React.Component { render() { let titleText = `Favorite ${this.props.type}`; if (this.props.children instanceof Array) { // Add an s to make it plural if there is more than one titleText += 's'; } return ( <div> <h1>{titleText}</h1> <ul>{this.props.children}</ul> </div> ); } } // App.js import React from 'react'; import ReactDOM from 'react-dom'; import { List } from './List'; class App extends React.Component { render() { return ( <div> <List type='Living Musician'> <li>Sachiko M</li> <li>Harvey Sid Fisher</li> </List> <List type='Living Cat Musician'> <li>Nora the Piano Cat</li> </List> </div> ); } } ReactDOM.render( <App />, document.getElementById('app') ); This will print: Favorite Living Musicians Sachiko M Harvey Sid Fisher Favorite Living Cat Musician Nora the Piano Cat Because in List.js, between the <ul></ul> you have {this.props.children} which grabs all the elements between <List></List> in the App class.","title":"this.props.children"},{"location":"Notes%20on%20nodejs/#default-properties","text":"Used if nothing is passed into the property. import React from 'react'; import ReactDOM from 'react-dom'; class Button extends React.Component { render() { return ( <button> {this.props.text} </button> ); } } // defaultProps goes here: Button.defaultProps = {text: \"I am a button\"}; ReactDOM.render( <Button />, document.getElementById('app') );","title":"Default Properties"},{"location":"Notes%20on%20nodejs/#component-state","text":"A React component can access dynamic information in two ways: props and state. Unlike props, a component\u2019s state is not passed in from the outside. A component decides its own state. To make a component have state, give the component a state property. This property should be declared inside of a constructor method, like this: class Example extends React.Component { constructor(props) { super(props); this.state = { mood: 'decent' }; } render() { return <div></div>; } } <Example /> // Access the state outside with this.state.mood // You can set the state with this.setState({mood: \"the mood\"}) What is super(props) Also: https://overreacted.io/why-do-we-write-super-props/","title":"Component State"},{"location":"Notes%20on%20nodejs/#thissetstate-from-another-function","text":"You'll use a wrapper function to call this.setState from another function. Like this: class Example extends React.Component { constructor(props) { super(props); this.state = { weather: 'sunny' }; this.makeSomeFog = this.makeSomeFog.bind(this); } makeSomeFog() { this.setState({ weather: 'foggy' }); } } The line this.makeSomeFog = this.makeSomeFog.bind(this); is necessary because makeSomeFog()'s body contains the word this. It has to do with the way event handlers are bound in Javascript. If you use this without the line this.makeSomeFog = this.makeSomeFog.bind(this); with an event handler the this word will be lost so we have to bind it... because Javascript. If the function isn't used by an event handler then it won't matter. Full example import React from 'react'; import ReactDOM from 'react-dom'; const green = '#39D1B4'; const yellow = '#FFD712'; class Toggle extends React.Component { constructor(props) { super(props); this.state = {color: green}; this.changeColor = this.changeColor.bind(this); } changeColor() { if(this.state.color === yellow) { this.setState({color: green}); } else { this.setState({color: yellow}); } } render() { return ( <div style={{background: this.state.color}}> <h1> <button onClick={this.changeColor}> Change color </button> </h1> </div> ); } } ReactDOM.render(<Toggle />, document.getElementById('app')); NOTE : Anytime you call this.setState it automatically calls render as soon as the state has changed. This is why you don't have to call render again.","title":"this.setState from Another Function"},{"location":"Notes%20on%20nodejs/#component-lifecycle","text":"We\u2019ve seen that React components can be highly dynamic. They get created, rendered, added to the DOM, updated, and removed. All of these steps are part of a component\u2019s lifecycle. The component lifecycle has three high-level parts: Mounting, when the component is being initialized and put into the DOM for the first time Updating, when the component updates as a result of changed state or changed props Unmounting, when the component is being removed from the DOM Every React component you\u2019ve ever interacted with does the first step at a minimum. If a component never mounted, you\u2019d never see it! Most interesting components are updated at some point. A purely static component\u2014like, for example, a logo\u2014might not ever update. But if a component\u2019s state changes, it updates. Or if different props are passed to a component, it updates. Finally, a component is unmounted when it\u2019s removed from the DOM. For example, if you have a button that hides a component, chances are that component will be unmounted. If your app has multiple screens, it\u2019s likely that each screen (and all of its child components) will be unmounted. If a component is \"alive\" for the entire lifetime of your app (say, a top-level component or a persistent navigation bar), it won\u2019t be unmounted. But most components can get unmounted one way or another! It\u2019s worth noting that each component instance has its own lifecycle. For example, if you have 3 buttons on a page, then there are 3 component instances, each with its own lifecycle. However, once a component instance is unmounted, that\u2019s it\u2014it will never be re-mounted, or updated again, or unmounted. React components have several methods, called lifecycle methods, that are called at different parts of a component\u2019s lifecycle. This is how you, the programmer, deal with the lifecycle of a component. You may not have known it, but you\u2019ve already used two of the most common lifecycle methods: constructor() and render()! constructor() is the first method called during the mounting phase. render() is called later during the mounting phase, to render the component for the first time, and during the updating phase, to re-render the component. Notice that lifecycle methods don\u2019t necessarily correspond one-to-one with part of the lifecycle. constructor() only executes during the mounting phase, but render() executes during both the mounting and updating phase.","title":"Component Lifecycle"},{"location":"Notes%20on%20nodejs/#componentdidmount","text":"Say you want a component to update itself at a setInterval. You don't want to put it in the constructor because that would violate the single responsibility rule but you also don't want it in render because then it would be called on update AND on mounting. That's what componentDidMount is for. componentDidMount() is the final method called during the mounting phase. The order is: The constructor render() componentDidMount() In other words, it\u2019s called after the component is rendered. (Another method, getDerivedStateFromProps(), is called between the constructor and render(), but it is very rarely used and usually isn\u2019t the best way to achieve your goals. We won\u2019t be talking about it in this lesson.) import React from 'react'; import ReactDOM from 'react-dom'; class Clock extends React.Component { constructor(props) { super(props); this.state = { date: new Date() }; } render() { return <div>{this.state.date.toLocaleTimeString()}</div>; } componentDidMount() { const oneSecond = 1000; setInterval(() => { this.setState({ date: new Date() }); }, oneSecond); } } ReactDOM.render(<Clock />, document.getElementById('app'));","title":"componentDidMount"},{"location":"Notes%20on%20nodejs/#componentwillunmount","text":"In the case of our interval above, the problem is now that timer will never stop. If we want to remove it. We want to use clearInterval() to clean it up. We can call this during componentWillUnmount import React from 'react'; export class Clock extends React.Component { constructor(props) { super(props); this.state = { date: new Date() }; } render() { return <div>{this.state.date.toLocaleTimeString()}</div>; } componentDidMount() { const oneSecond = 1000; this.intervalID = setInterval(() => { this.setState({ date: new Date() }); }, oneSecond); } componentWillUnmount() { clearInterval(this.intervalID); } }","title":"componentWillUnmount"},{"location":"Notes%20on%20nodejs/#componentdidupdate","text":"When a component updates many things happen but there are two primary methods - render and componentDidUpdate. import React from 'react'; export class Clock extends React.Component { constructor(props) { super(props); this.state = { date: new Date() }; } render() { return ( <div> {this.props.isPrecise ? this.state.date.toISOString() : this.state.date.toLocaleTimeString()} </div> ); } startInterval() { let delay; if (this.props.isPrecise) { delay = 100; } else { delay = 1000; } this.intervalID = setInterval(() => { this.setState({ date: new Date() }); }, delay); } componentDidMount() { this.startInterval(); } componentDidUpdate(prevProps) { if (this.props.isPrecise === prevProps.isPrecise) { return; } clearInterval(this.intervalID); this.startInterval(); } componentWillUnmount() { clearInterval(this.intervalID); } }","title":"componentDidUpdate"},{"location":"Notes%20on%20nodejs/#stateless-functional-components","text":"We used to use classes for components but now we use functions. // Original class-based way of writing components import React from 'react'; import ReactDOM from 'react-dom'; export class Friend extends React.Component { render() { return <img src=\"https://content.codecademy.com/courses/React/react_photo-octopus.jpg\" />; } }; ReactDOM.render( <Friend />, document.getElementById('app') ); // Function Version import React from 'react'; import ReactDOM from 'react-dom'; export const Friend = () => { return <img src=\"https://content.codecademy.com/courses/React/react_photo-octopus.jpg\" />; } ReactDOM.render( <Friend />, document.getElementById('app') );","title":"Stateless Functional Components"},{"location":"Notes%20on%20nodejs/#function-component-props","text":"export function YesNoQuestion (props) { return ( <div> <p>{props.prompt}</p> <input value=\"Yes\" /> <input value=\"No\" /> </div> ); } ReactDOM.render( <YesNoQuestion prompt=\"Have you eaten an apple today?\" />, document.getElementById('app'); );","title":"Function Component Props"},{"location":"Notes%20on%20nodejs/#react-hooks","text":"With Hooks, we can use simple function components to do lots of the fancy things that we could only do with class components in the past. React Hooks, plainly put, are functions that let us manage the internal state of components and handle post-rendering side effects directly from our function components. Hooks don\u2019t work inside classes \u2014 they let us use fancy React features without classes. Keep in mind that function components and React Hooks do not replace class components. They are completely optional; just a new tool that we can take advantage of. Note: If you\u2019re familiar with lifecycle methods of class components, you could say that Hooks let us \"hook into\" state and lifecycle features directly from our function components. React offers a number of built-in Hooks. A few of these include useState(), useEffect(), useContext(), useReducer(), and useRef(). See the full list in the docs . With React, we feed static and dynamic data models to JSX to render a view to the screen Use Hooks to \u201chook into\u201d internal component state for managing dynamic data in function components We employ the State Hook by using the code below: currentState to reference the current value of state stateSetter to reference a function used to update the value of this state the initialState argument to initialize the value of state for the component\u2019s first render const [currentState, stateSetter] = useState( initialState ); Call state setters in event handlers Define simple event handlers inline with our JSX event listeners and define complex event handlers outside of our JSX Use a state setter callback function when our next value depends on our previous value Use arrays and objects to organize and manage related data that tends to change together Use the spread syntax on collections of dynamic data to copy the previous state into the next state like so: setArrayState((prev) => [ ...prev ]) and setObjectState((prev) => ({ ...prev })) Split state into multiple, simpler variables instead of throwing it all into one state object","title":"React Hooks"},{"location":"Notes%20on%20nodejs/#comparison-class-vs-function","text":"Class import React, { Component } from \"react\"; import NewTask from \"../Presentational/NewTask\"; import TasksList from \"../Presentational/TasksList\"; export default class AppClass extends Component { constructor(props) { super(props); this.state = { newTask: {}, allTasks: [] }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); this.handleDelete = this.handleDelete.bind(this); } handleChange({ target }){ const { name, value } = target; this.setState((prevState) => ({ ...prevState, newTask: { ...prevState.newTask, [name]: value, id: Date.now() } })); } handleSubmit(event){ event.preventDefault(); if (!this.state.newTask.title) return; this.setState((prevState) => ({ allTasks: [prevState.newTask, ...prevState.allTasks], newTask: {} })); } handleDelete(taskIdToRemove){ this.setState((prevState) => ({ ...prevState, allTasks: prevState.allTasks.filter((task) => task.id !== taskIdToRemove) })); } render() { return ( <main> <h1>Tasks</h1> <NewTask newTask={this.state.newTask} handleChange={this.handleChange} handleSubmit={this.handleSubmit} /> <TasksList allTasks={this.state.allTasks} handleDelete={this.handleDelete} /> </main> ); } } Function import React, { useState } from \"react\"; import NewTask from \"../Presentational/NewTask\"; import TasksList from \"../Presentational/TasksList\"; export default function AppFunction() { const [newTask, setNewTask] = useState({}); const handleChange = ({ target }) => { const { name, value } = target; setNewTask((prev) => ({ ...prev, id: Date.now(), [name]: value })); }; const [allTasks, setAllTasks] = useState([]); const handleSubmit = (event) => { event.preventDefault(); if (!newTask.title) return; setAllTasks((prev) => [newTask, ...prev]); setNewTask({}); }; const handleDelete = (taskIdToRemove) => { setAllTasks((prev) => prev.filter( (task) => task.id !== taskIdToRemove )); }; return ( <main> <h1>Tasks</h1> <NewTask newTask={newTask} handleChange={handleChange} handleSubmit={handleSubmit} /> <TasksList allTasks={allTasks} handleDelete={handleDelete} /> </main> ); }","title":"Comparison Class vs Function"},{"location":"Notes%20on%20nodejs/#update-function-component-state","text":"Let\u2019s get started with the State Hook, the most common Hook used for building React components. The State Hook is a named export from the React library, so we import it like this: import React, { useState } from 'react'; useState() is a JavaScript function defined in the React library. When we call this function, it returns an array with two values: current state - the current value of this state state setter - a function that we can use to update the value of this state Because React returns these two values in an array, we can assign them to local variables, naming them whatever we like. For example: const [toggle, setToggle] = useState(); import React, { useState } from \"react\"; function Toggle() { const [toggle, setToggle] = useState(); return ( <div> <p>The toggle is {toggle}</p> <button onClick={() => setToggle(\"On\")}>On</button> <button onClick={() => setToggle(\"Off\")}>Off</button> </div> ); } Notice how the state setter function, setToggle(), is called by our onClick event listeners. To update the value of toggle and re-render this component with the new value, all we need to do is call the setToggle() function with the next state value as an argument. No need to worry about binding functions to class instances, working with constructors, or dealing with the this keyword. With the State Hook, updating state is as simple as calling a state setter function. Calling the state setter signals to React that the component needs to re-render, so the whole function defining the component is called again. The magic of useState() is that it allows React to keep track of the current value of state from one render to the next! More complex example: import React, { useState } from 'react'; export default function ColorPicker() { const [color, setColor] = useState(); const divStyle = {backgroundColor: color}; return ( <div style={divStyle}> <p>The color is {color}</p> <button onClick={() => setColor('Aquamarine')}> Aquamarine </button> <button onClick={() => setColor('BlueViolet')}> BlueViolet </button> <button onClick={() => setColor('Chartreuse')}> Chartreuse </button> <button onClick={() => setColor('CornflowerBlue')}> CornflowerBlue </button> </div> ); }","title":"Update Function Component State"},{"location":"Notes%20on%20nodejs/#initialize-state","text":"You can set a state at the beginning with: const [color, setColor] = useState(\"Tomato\"); . There are three ways in which this code affects our component: During the first render, the initial state argument is used. When the state setter is called, React ignores the initial state argument and uses the new value. When the component re-renders for any other reason, React continues to use the same value from the previous render.","title":"Initialize State"},{"location":"Notes%20on%20nodejs/#use-state-setter-outside-of-jsx","text":"https://www.codecademy.com/courses/react-101/lessons/the-state-hook/exercises/use-state-setter-outside-of-jsx Let\u2019s see how to manage the changing value of a string as a user types into a text input field: import React, { useState } from 'react'; export default function EmailTextInput() { const [email, setEmail] = useState(''); const handleChange = (event) => { const updatedEmail = event.target.value; setEmail(updatedEmail); } return ( // Here value={email} will set the value to the current // value in e-mail in the event hook <input value={email} onChange={handleChange} /> ); } Let\u2019s break down how this code works! The square brackets on the left side of the assignment operator signal array destructuring The local variable named email is assigned the current state value at index 0 from the array returned by useState() The local variable named setEmail() is assigned a reference to the state setter function at index 1 from the array returned by useState() It\u2019s convention to name this variable using the current state variable (email) with \"set\" prepended The JSX input tag has an event listener called onChange. This event listener calls an event handler each time the user types something in this element. In the example above, our event handler is defined inside of the definition for our function component, but outside of our JSX. Earlier in this lesson, we wrote our event handlers right in our JSX. Those inline event handlers work perfectly fine, but when we want to do something more interesting than just calling the state setter with a static value, it\u2019s a good idea to separate that logic from everything else going on in our JSX. This separation of concerns makes our code easier to read, test, and modify. You can change: const updatedEmail = event.target.value; setEmail(updatedEmail); // to this const handleChange = ({target}) => setEmail(target.value);","title":"Use State Setter Outside of JSX"},{"location":"Notes%20on%20nodejs/#longer-example_1","text":"import React, { useState } from \"react\"; // regex to match numbers between 1 and 10 digits long const validPhoneNumber = /^\\d{1,10}$/; export default function PhoneNumber() { const [phone, setPhone] = useState(''); const handleChange = ({ target })=> { const newPhone = target.value; const isValid = validPhoneNumber.test(newPhone); if (isValid) { setPhone(newPhone); } // just ignore the event, when new value is invalid }; return ( <div className='phone'> <label for='phone-input'>Phone: </label> <input value={phone} onChange={handleChange} id='phone-input' /> </div> ); }","title":"Longer Example"},{"location":"Notes%20on%20nodejs/#set-from-previous-state","text":"Often, the next value of our state is calculated using the current state. In this case, it is best practice to update state with a callback function. If we do not, we risk capturing outdated, or \u201cstale\u201d, state values. import React, { useState } from 'react'; export default function Counter() { const [count, setCount] = useState(0); const increment = () => setCount(prevCount => prevCount + 1); return ( <div> <p>Wow, you've clicked that button: {count} times</p> <button onClick={increment}>Click here!</button> </div> ); } When the button is pressed, the increment() event handler is called. Inside of this function, we use our setCount() state setter in a new way! Because the next value of count depends on the previous value of count, we pass a callback function as the argument for setCount() instead of a value (as we\u2019ve done in previous exercises). setCount(prevCount => prevCount + 1) When our state setter calls the callback function, this state setter callback function takes our previous count as an argument. The value returned by this state setter callback function is used as the next value of count (in this case prevCount + 1). Note: We can just call setCount(count +1) and it would work the same in this example\u2026 but for reasons that are out of scope for this lesson, it is safer to use the callback method.","title":"Set From Previous State"},{"location":"Notes%20on%20nodejs/#arrays-in-state","text":"import React, { useState } from \"react\"; import ItemList from \"./ItemList\"; import { produce, pantryItems } from \"./storeItems\"; export default function GroceryCart() { // declare and initialize state const [cart, setCart] = useState([]); // addItem is the event handler and will receive the item that // gets clicked const addItem = (item) => { // setCart is the state setter // and it will tell the component to update its state. // Via the magic that is the totality of Javascript, it // will magically receive the previous state to this function // We then use spread syntax to expand the previous array // and add it with the item. setCart((prev) => { return [item, ...prev]; }); }; // This removes the item at some set index. const removeItem = (targetIndex) => { setCart((prev) => { return prev.filter((item, index) => index !== targetIndex); }); }; return ( <div> <h1>Grocery Cart</h1> <ul> {cart.map((item, index) => ( <li onClick={() => removeItem(index)} key={index}> {item} </li> ))} </ul> <h2>Produce</h2> <ItemList items={produce} onItemClick={addItem} /> <h2>Pantry Items</h2> <ItemList items={pantryItems} onItemClick={addItem} /> </div> ); }","title":"Arrays in State"},{"location":"Notes%20on%20nodejs/#objects-in-state","text":"export default function Login() { const [formState, setFormState] = useState({}); const handleChange = ({ target }) => { const { name, value } = target; setFormState((prev) => ({ ...prev, [name]: value })); }; return ( <form> <input value={formState.firstName} onChange={handleChange} name=\"firstName\" type=\"text\" /> <input value={formState.password} onChange={handleChange} type=\"password\" name=\"password\" /> </form> ); } A few things to notice: We use a state setter callback function to update state based on the previous value The spread syntax is the same for objects as for arrays: { ...oldObject, newKey: newValue } We reuse our event handler across multiple inputs by using the input tag\u2019s name attribute to identify which input the change event came from Once again, when updating the state with setFormState() inside a function component, we do not modify the same object. We must copy over the values from the previous object when setting the next value of state. Thankfully, the spread syntax makes this super easy to do! Anytime one of the input values is updated, the handleChange() function will be called. Inside of this event handler, we use object destructuring to unpack the target property from our event object, then we use object destructuring again to unpack the name and value properties from the target object. Inside of our state setter callback function, we wrap our curly brackets in parentheses like so: setFormState((prev) => ({ ...prev })). This tells JavaScript that our curly brackets refer to a new object to be returned. We use ..., the spread operator, to fill in the corresponding fields from our previous state. Finally, we overwrite the appropriate key with its updated value. Did you notice the square brackets around the name? This Computed Property Name allows us to use the string value stored by the name variable as a property key!","title":"Objects in State"},{"location":"Notes%20on%20nodejs/#longer-example_2","text":"import React, { useState } from \"react\"; export default function EditProfile() { const [profile, setProfile] = useState({}); const handleChange = ({ target }) => { const {name, value } = target; setProfile((prevProfile) => ({ ...prevProfile, [name]: value })); }; const handleSubmit = (event) => { event.preventDefault(); alert(JSON.stringify(profile, '', 2)); }; return ( <form onSubmit={handleSubmit}> <input value={profile.firstName || ''} name=\"firstName\" type=\"text\" placeholder=\"First Name\" onChange={handleChange} /> <input value={profile.lastName || ''} type=\"text\" name=\"lastName\" placeholder=\"Last Name\" onChange={handleChange} /> <input value={profile.bday || ''} type=\"date\" name=\"bday\" onChange={handleChange} /> <input value={profile.password || ''} type=\"password\" name=\"password\" placeholder=\"Password\" onChange={handleChange} /> <button type=\"submit\">Submit</button> </form> ); }","title":"Longer Example"},{"location":"Notes%20on%20nodejs/#separate-hooks-for-separate-states","text":"While there are times when it can be helpful to store related data in a data collection like an array or object, it can also be helpful to separate data that changes separately into completely different state variables. Managing dynamic data is much easier when we keep our data models as simple as possible. For example, if we had a single object that held state for a subject you are studying at school, it might look something like this: function Subject() { const [state, setState] = useState({ currentGrade: 'B', classmates: ['Hasan', 'Sam', 'Emma'], classDetails: {topic: 'Math', teacher: 'Ms. Barry', room: 201}; exams: [{unit: 1, score: 91}, {unit: 2, score: 88}]); }); This would work, but think about how messy it could get to copy over all the other values when we need to update something in this big state object. For example, to update the grade on an exam, we would need an event handler that did something like this: // Get the previous state in and pass that to something that is going to return a new object {} setState((prev) => ({ // Expand the previous state to grab everything ...prev, // You want the previous state, except with exams you're going to grab just exams and then map // that to a new function where you'll extract just the exam you want and change the score exams: prev.exams.map((exam) => { if( exam.unit === updatedExam.unit ){ return { ...exam, score: updatedExam.score }; } else { return exam; } }), })); Yikes! Complex code like this is likely to cause bugs! Luckily, there is another option\u2026 We can make more than one call to the State Hook. In fact, we can make as many calls to useState() as we want! It\u2019s best to split state into multiple state variables based on which values tend to change together. We can rewrite the previous example as follows\u2026 function Subject() { const [currentGrade, setGrade] = useState('B'); const [classmates, setClassmates] = useState(['Hasan', 'Sam', 'Emma']); const [classDetails, setClassDetails] = useState({topic: 'Math', teacher: 'Ms. Barry', room: 201}); const [exams, setExams] = useState([{unit: 1, score: 91}, {unit: 2, score: 88}]); // ... } See https://reactjs.org/docs/hooks-state.html#tip-using-multiple-state-variables","title":"Separate Hooks for Separate States"},{"location":"Notes%20on%20nodejs/#comparison","text":"function Musical() { const [state, setState] = useState({ title: \"Best Musical Ever\", actors: [\"George Wilson\", \"Tim Hughes\", \"Larry Clements\"], locations: { Chicago: { dates: [\"1/1\", \"2/2\"], address: \"chicago theater\"}, SanFrancisco: { dates: [\"5/2\"], address: \"sf theater\" } } }) } function MusicalRefactored() { const [title, setTitle] = useState(\"Best Musical Ever\"); const [actors, setActors] = useState([\"George Wilson\", \"Tim Hughes\", \"Larry Clements\"]); const [locations, setLocations] = useState({ Chicago: { dates: [\"1/1\", \"2/2\"], address: \"chicago theater\"}, SanFrancisco: { dates: [\"5/2\"], address: \"sf theater\" } }); }","title":"Comparison"},{"location":"Notes%20on%20nodejs/#the-effect-hook-useeffect","text":"Before Hooks, function components were only used to accept data in the form of props and return some JSX to be rendered. However, as we learned in the last lesson, the State Hook allows us to manage dynamic data, in the form of component state, within our function components. In this lesson, we\u2019ll use the Effect Hook to run some JavaScript code after each render, such as: fetching data from a backend service subscribing to a stream of data managing timers and intervals reading from and making changes to the DOM Why after each render? Most interesting components will re-render multiple times throughout their lifetime and these key moments present the perfect opportunity to execute these \u201cside effects\u201d. There are three key moments when the Effect Hook can be utilized: When the component is first added, or mounted, to the DOM and renders When the state or props change, causing the component to re-render When the component is removed, or unmounted, from the DOM.","title":"The Effect Hook - useEffect"},{"location":"Notes%20on%20nodejs/#react-hooks-and-component-lifecycle-equivalent","text":"https://stackoverflow.com/a/53254018/4427375","title":"React Hooks and Component Lifecycle Equivalent"},{"location":"Notes%20on%20nodejs/#componentwillmount-for-react-functional-component","text":"https://stackoverflow.com/questions/62091146/componentwillmount-for-react-functional-component","title":"componentWillMount for react functional component?"},{"location":"Notes%20on%20nodejs/#function-component-effects","text":"import React, { useState, useEffect } from 'react'; function PageTitle() { const [name, setName] = useState(''); useEffect(() => { document.title = `Hi, ${name}`; }); return ( <div> <p>Use the input field below to rename this page!</p> <input onChange={({target}) => setName(target.value)} value={name} type='text' /> </div> ); } In our effect, we assign the value of the name variable to the document.title within a string. For more on this syntax, have a look at this explanation of the document\u2019s title property. Notice how we use the current state inside of our effect. Even though our effect is called after the component renders, we still have access to the variables in the scope of our function component! When React renders our component, it will update the DOM as usual, and then run our effect after the DOM has been updated. This happens for every render, including the first and last one.","title":"Function Component Effects"},{"location":"Notes%20on%20nodejs/#clean-up-effects","text":"useEffect(()=>{ document.addEventListener('keydown', handleKeyPress); return () => { document.removeEventListener('keydown', handleKeyPress); }; }) If our effect didn\u2019t return a cleanup function, then a new event listener would be added to the DOM\u2019s document object every time that our component re-renders. Not only would this cause bugs, but it could cause our application performance to diminish and maybe even crash! Because effects run after every render and not just once, React calls our cleanup function before each re-render and before unmounting to clean up each effect call. If our effect returns a function, then the useEffect() Hook always treats that as a cleanup function. React will call this cleanup function before the component re-renders or unmounts. Since this cleanup function is optional, it is our responsibility to return a cleanup function from our effect when our effect code could create memory leaks. import React, { useState, useEffect } from 'react'; export default function Counter() { const [clickCount, setClickCount] = useState(0); const increment = () => setClickCount((prev) => prev + 1); useEffect(() => { document.addEventListener('mousedown', increment); return () => { document.removeEventListener('mousedown', increment); }; }); return ( <h1>Document Clicks: {clickCount}</h1> ); }","title":"Clean Up Effects"},{"location":"Notes%20on%20nodejs/#control-when-effects-are-called","text":"It is common, when defining function components, to run an effect only when the component mounts (renders the first time), but not when the component re-renders. The Effect Hook makes this very easy for us to do! If we want to only call our effect after the first render, we pass an empty array to useEffect() as the second argument. This second argument is called the dependency array. The dependency array is used to tell the useEffect() method when to call our effect and when to skip it. Our effect is always called after the first render but only called again if something in our dependency array has changed values between renders useEffect(() => { alert(\"component rendered for the first time\"); return () => { alert(\"component is being removed from the DOM\"); }; }, []);","title":"Control When Effects are Called"},{"location":"Notes%20on%20nodejs/#fetch-data-from-a-server","text":"Since the effect hook is called after every render we want to be extra careful when we are fetching data from a server as this will quickly sabotage the performance of our app. When the data that our components need to render doesn\u2019t change, we can pass an empty dependency array, so that the data is fetched after the first render. When the response is received from the server, we can use a state setter from the State Hook to store the data from the server\u2019s response in our local component state for future renders. Using the State Hook and the Effect Hook together in this way is a powerful pattern that saves our components from unnecessarily fetching new data after every render! An empty dependency array signals to the Effect Hook that our effect never needs to be re-run, that it doesn\u2019t depend on anything. Specifying zero dependencies means that the result of running that effect won\u2019t change and calling our effect once is enough. A dependency array that is not empty signals to the Effect Hook that it can skip calling our effect after re-renders unless the value of one of the variables in our dependency array has changed. If the value of a dependency has changed, then the Effect Hook will call our effect again! Here\u2019s a nice example from the official React docs: useEffect(() => { document.title = `You clicked ${count} times`; }, [count]); // Only re-run the effect if the value stored by count changes","title":"Fetch Data from a Server"},{"location":"Notes%20on%20nodejs/#rules-of-hooks","text":"There are two main rules to keep in mind when using Hooks: only call Hooks at the top level only call Hooks from React functions As we have been practicing with the State Hook and the Effect Hook, we\u2019ve been following these rules with ease, but it is helpful to keep these two rules in mind as you take your new understanding of Hooks out into the wild and begin using more Hooks in your React applications. When React builds the Virtual DOM, the library calls the functions that define our components over and over again as the user interacts with the user interface. React keeps track of the data and functions that we are managing with Hooks based on their order in the function component\u2019s definition. For this reason, we always call our Hooks at the top level; we never call hooks inside of loops, conditions, or nested functions. Instead of confusing React with code like this: if (userName !== '') { useEffect(() => { localStorage.setItem('savedUserName', userName); }); } We can accomplish the same goal, while consistently calling our Hook every time: useEffect(() => { if (userName !== '') { localStorage.setItem('savedUserName', userName); } }); Secondly, Hooks can only be used in React Functions. We cannot use Hooks in class components and we cannot use Hooks in regular JavaScript functions. We\u2019ve been working with useState() and useEffect() in function components, and this is the most common use. The only other place where Hooks can be used is within custom hooks. Custom Hooks are incredibly useful for organizing and reusing stateful logic between function components. For more on this topic, head to the React Docs.","title":"Rules of Hooks"},{"location":"Notes%20on%20nodejs/#separate-hooks-for-separate-effects","text":"When multiple values are closely related and change at the same time, it can make sense to group these values in a collection like an object or array. Packaging data together can also add complexity to the code responsible for managing that data. Therefore, it is a good idea to separate concerns by managing different data with different Hooks. Compare the complexity here, where data is bundled up into a single object: // Handle both position and menuItems with one useEffect hook. const [data, setData] = useState({ position: { x: 0, y: 0 } }); useEffect(() => { get('/menu').then((response) => { setData((prev) => ({ ...prev, menuItems: response.data })); }); const handleMove = (event) => setData((prev) => ({ ...prev, position: { x: event.clientX, y: event.clientY } })); window.addEventListener('mousemove', handleMove); return () => window.removeEventListener('mousemove', handleMove); }, []); To the simplicity here, where we have separated concerns: // Handle menuItems with one useEffect hook. const [menuItems, setMenuItems] = useState(null); useEffect(() => { get('/menu').then((response) => setMenuItems(response.data)); }, []); // Handle position with a separate useEffect hook. const [position, setPosition] = useState({ x: 0, y: 0 }); useEffect(() => { const handleMove = (event) => setPosition({ x: event.clientX, y: event.clientY }); window.addEventListener('mousemove', handleMove); return () => window.removeEventListener('mousemove', handleMove); }, []);","title":"Separate Hooks for Separate Effects"},{"location":"Notes%20on%20nodejs/#stateless-components-from-stateful-components","text":"Instead of having one, very complicated, stateful, component, we have one stateful component (App) at the top level with many stateless components in a hierarchy. The stateful component will pass its state down to the stateless components.","title":"Stateless Components from Stateful Components"},{"location":"Notes%20on%20nodejs/#build-a-stateful-component-class","text":"Example of passing a parent's state into a stateless child // PARENT import React from 'react'; import ReactDOM from 'react-dom'; import { Child } from './Child'; class Parent extends React.Component { constructor(props) { super(props); this.state = { name: 'Frarthur' }; } render() { return <Child name={this.state.name}/>; } } ReactDOM.render(<Parent />, document.getElementById('app')); // CHILD import React from 'react'; import ReactDOM from 'react-dom'; // We have to export this since it will be rendered by // another component export class Child extends React.Component { render() { return <h1>Hey, my name is {this.props.name}!</h1>; } } This will print: Hey, my name is Frarthur!","title":"Build a Stateful Component Class"},{"location":"Notes%20on%20nodejs/#dont-update-props","text":"A React component should use props to store information that can be changed, but can only be changed by a different component. A React component should use state to store information that the component itself can change. // BAD import React from 'react'; class Bad extends React.Component { render() { this.props.message = 'yo'; // NOOOOOOOOOOOOOO!!! return <h1>{this.props.message}</h1>; } }","title":"Don't Update props"},{"location":"Notes%20on%20nodejs/#child-components-update-their-parents-state","text":"How does a stateless, child component update the state of the parent component? Here\u2019s how that works: 1 The parent component class defines a method that calls this.setState(). For an example, look in Step1.js at the .handleClick() method. import React from 'react'; import ReactDOM from 'react-dom'; import { ChildClass } from './ChildClass'; class ParentClass extends React.Component { constructor(props) { super(props); this.state = { totalClicks: 0 }; } handleClick() { const total = this.state.totalClicks; // calling handleClick will // result in a state change: this.setState( { totalClicks: total + 1 } ); } } 2 The parent component binds the newly-defined method to the current instance of the component in its constructor. This ensures that when we pass the method to the child component, it will still update the parent component. For an example, look in Step2.js at the end of the constructor() method. An explanation of how this/bind work How bind works: https://stackoverflow.com/a/10115970/4427375 What is the global object Once the parent has defined a method that updates its state and bound to it, the parent then passes that method down to a child. Look in Step2.js, at the prop on line 28. import React from 'react'; import ReactDOM from 'react-dom'; import { ChildClass } from './ChildClass'; class ParentClass extends React.Component { constructor(props) { super(props); this.state = { totalClicks: 0 }; this.handleClick = this.handleClick.bind(this); } handleClick() { const total = this.state.totalClicks; // calling handleClick will // result in a state change: this.setState( { totalClicks: total + 1 } ); } // The stateful component class passes down // handleClick to a stateless component class: render() { return ( <ChildClass onClick={this.handleClick} /> ); } } 3 The child receives the passed-down function, and uses it as an event handler. Look in Step3.js. When a user clicks on the , a click event will fire. This will make the passed-down function get called, which will update the parent\u2019s state. import React from 'react'; import ReactDOM from 'react-dom'; export class ChildClass extends React.Component { render() { return ( // The stateless component class uses // the passed-down handleClick function, // accessed here as this.props.onClick, // as an event handler: <button onClick={this.props.onClick}> Click Me! </button> ); } }","title":"Child Components Update Their Parents' State"},{"location":"Notes%20on%20nodejs/#more-complex-example","text":"WARNING this violates the rule that components should only do one thing! We fix this in One Sibling to Display, Another to Change // CHILD import React from 'react'; export class Child extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); } handleChange(e) { const name = e.target.value; this.props.onChange(name); } render() { return ( <div> <h1> Hey my name is {this.props.name}! </h1> <select id=\"great-names\" onChange={this.handleChange}> <option value=\"Frarthur\"> Frarthur </option> <option value=\"Gromulus\"> Gromulus </option> <option value=\"Thinkpiece\"> Thinkpiece </option> </select> </div> ); } } // PARENT import React from 'react'; import ReactDOM from 'react-dom'; import { Child } from './Child'; class Parent extends React.Component { constructor(props) { super(props); this.state = { name: 'Frarthur' }; this.changeName = this.changeName.bind(this); } changeName(newName) { this.setState({ name: newName }); } render() { return <Child name={this.state.name} onChange={this.changeName} /> } } ReactDOM.render( <Parent />, document.getElementById('app') );","title":"More Complex Example"},{"location":"Notes%20on%20nodejs/#child-components-update-sibling-components","text":"The Reactions component passes an event handler to the Like component. When Like is clicked, the handler is called, which causes the parent Reactions component to send a new prop to Stats. The Stats component updates with the new information.","title":"Child Components Update Sibling Components"},{"location":"Notes%20on%20nodejs/#one-sibling-to-display-another-to-change","text":"You will have one stateless component display information, and a different stateless component offer the ability to change that information. A stateful component class defines a function that calls this.setState. (Parent.js, lines 15-19) The stateful component passes that function down to a stateless component. (Parent.js, line 24) That stateless component class defines a function that calls the passed-down function, and that can take an event object as an argument. (Child.js, lines 10-13) The stateless component class uses this new function as an event handler. (Child.js, line 20) When an event is detected, the parent\u2019s state updates. (A user selects a new dropdown menu item) The stateful component class passes down its state, distinct from the ability to change its state, to a different stateless component. (Parent.js, line 25) That stateless component class receives the state and displays it. (Sibling.js, lines 5-10) An instance of the stateful component class is rendered. One stateless child component displays the state, and a different stateless child component displays a way to change the state. (Parent.js, lines 23-26) // PARENT import React from 'react'; import ReactDOM from 'react-dom'; import { Child } from './Child'; import { Sibling } from './Sibling'; class Parent extends React.Component { constructor(props) { super(props); this.state = { name: 'Frarthur' }; this.changeName = this.changeName.bind(this); } changeName(newName) { this.setState({ name: newName }); } render() { return ( <div> <Child onChange={this.changeName} /> <Sibling name={this.state.name}/> </div> ); } } ReactDOM.render( <Parent />, document.getElementById('app') ); // CHILD import React from 'react'; export class Child extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); } handleChange(e) { const name = e.target.value; this.props.onChange(name); } render() { return ( <div> <select id=\"great-names\" onChange={this.handleChange}> <option value=\"Frarthur\">Frarthur</option> <option value=\"Gromulus\">Gromulus</option> <option value=\"Thinkpiece\">Thinkpiece</option> </select> </div> ); } } // SIBLING import React from 'react'; export class Sibling extends React.Component { render() { const name = this.props.name; return ( <div> <h1>Hey, my name is {name}!</h1> <h2>Don't you think {name} is the prettiest name ever?</h2> <h2>Sure am glad that my parents picked {name}!</h2> </div> ); } }","title":"One Sibling to Display, Another to Change"},{"location":"Notes%20on%20nodejs/#style","text":"","title":"Style"},{"location":"Notes%20on%20nodejs/#inline-styles","text":"An inline style is a style that\u2019s written as an attribute, like this: <h1 style={{ color: 'red' }}>Hello world</h1> Notice the double curly braces. What are those for? The outer curly braces inject JavaScript into JSX. They say, \u201ceverything between us should be read as JavaScript, not JSX.\u201d The inner curly braces create a JavaScript object literal. They make this a valid JavaScript object: { color: 'red' } If you inject an object literal into JSX, and your entire injection is only that object literal, then you will end up with double curly braces. There\u2019s nothing unusual about how they work, but they look funny and can be confusing.","title":"Inline Styles"},{"location":"Notes%20on%20nodejs/#make-a-style-object-variable","text":"Notice that here we define the style at the top level as a variable and then pass it in. In React style variable names are written camelCase. NOTE : The styles in ReactJS use numbers and the px is implied. import React from 'react'; import ReactDOM from 'react-dom'; const styles = { background: 'lightblue', color: 'darkred' marginTop: 100, fontSize: 50 }; const styleMe = <h1 style={styles}>Please style me! I am so bland!</h1>; ReactDOM.render( styleMe, document.getElementById('app') );","title":"Make a Style Object Variable"},{"location":"Notes%20on%20nodejs/#share-styles-across-multiple-components","text":"// STYLES.JS const fontFamily = 'Comic Sans MS, Lucida Handwriting, cursive'; const background = 'pink url(\"https://content.codecademy.com/programs/react/images/welcome-to-my-homepage.gif\") fixed'; const fontSize = '4em'; const padding = '45px 0'; const color = 'green'; export const styles = { fontFamily: fontFamily, background: background, fontSize: fontSize, padding: padding, color: color }; // ATTENTIONGRABBER.JS import React from 'react'; import { styles } from './styles'; const h1Style = { color: styles.color, fontSize: styles.fontSize, fontFamily: styles.fontFamily, padding: styles.padding, margin: 0, }; export class AttentionGrabber extends React.Component { render() { return <h1 style={h1Style}>WELCOME TO MY HOMEPAGE!</h1>; } } // HOME.JS import React from 'react'; import ReactDOM from 'react-dom'; import { AttentionGrabber } from './AttentionGrabber'; import { styles } from './styles'; const divStyle = { background: styles.background, height: '100%' }; export class Home extends React.Component { render() { return ( <div style={divStyle}> <AttentionGrabber /> <footer>THANK YOU FOR VISITING MY HOMEPAGE!</footer> </div> ); } } ReactDOM.render( <Home />, document.getElementById('app') );","title":"Share Styles Across Multiple Components"},{"location":"Notes%20on%20nodejs/#separate-container-components-from-presentational-components","text":"As you continue building your React application, you will soon realize that one component has too many responsibilities, but how do you know when you have reached that point? Separating container components from presentational components helps to answer that question. It shows you when it might be a good time to divide a component into smaller components. It also shows you how to perform that division. <GuineaPigs /> \u2018s job is to render a photo carousel of guinea pigs. It does this perfectly well! And yet, it has a problem: it does too much stuff. How might we divide this into a container component and a presentational component? import React from 'react'; import ReactDOM from 'react-dom'; const GUINEAPATHS = [ 'https://content.codecademy.com/courses/React/react_photo-guineapig-1.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-2.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-3.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-4.jpg' ]; export class GuineaPigs extends React.Component { constructor(props) { super(props); this.state = { currentGP: 0 }; this.interval = null; this.nextGP = this.nextGP.bind(this); } nextGP() { let current = this.state.currentGP; let next = ++current % GUINEAPATHS.length; this.setState({ currentGP: next }); } componentDidMount() { this.interval = setInterval(this.nextGP, 5000); } componentWillUnmount() { clearInterval(this.interval); } render() { let src = GUINEAPATHS[this.state.currentGP]; return ( <div> <h1>Cute Guinea Pigs</h1> <img src={src} /> </div> ); } } ReactDOM.render( <GuineaPigs />, document.getElementById('app') );","title":"Separate Container Components from Presentational Components"},{"location":"Notes%20on%20nodejs/#create-a-container-component","text":"Separating container components from presentational components is a popular React programming pattern. It is a special application of the concepts learned in the Stateless Components From Stateful Components module. If a component has to have state, make calculations based on props, or manage any other complex logic, then that component shouldn\u2019t also have to render HTML-like JSX. The functional part of a component (state, calculations, etc.) can be separated into a container component. GuineaPigs.js contains a lot of logic! It has to select the correct guinea pig to render, wait for the right amount of time before rendering, render an image, select the next correct guinea pig, and so on. Let\u2019s separate the logic from the GuineaPigs component into a container component.","title":"Create a Container Component"},{"location":"Notes%20on%20nodejs/#create-a-presentational-component","text":"The presentational component\u2019s only job is to contain HTML-like JSX. It should be an exported component and will not render itself because a presentational component will always get rendered by a container component. As a separate example, say we have Presentational and Container components. Presentational.js must export the component class (or function, when applicable): export class Presentational extends Component { Container.js must import that component: import { Presentational } from 'Presentational.js'; // GuineaPigs.js import React from 'react'; export class GuineaPigs extends React.Component { render() { let src = this.props.src; return ( <div> <h1>Cute Guinea Pigs</h1> <img src={src} /> </div> ); } } // GuineaPigsContainer.js import React from 'react'; import ReactDOM from 'react-dom'; import { GuineaPigs } from '../components/GuineaPigs'; const GUINEAPATHS = [ 'https://content.codecademy.com/courses/React/react_photo-guineapig-1.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-2.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-3.jpg', 'https://content.codecademy.com/courses/React/react_photo-guineapig-4.jpg' ]; class GuineaPigsContainer extends React.Component { constructor(props) { super(props); this.state = { currentGP: 0 }; this.interval = null; this.nextGP = this.nextGP.bind(this); } nextGP() { let current = this.state.currentGP; let next = ++current % GUINEAPATHS.length; this.setState({ currentGP: next }); } componentDidMount() { this.interval = setInterval(this.nextGP, 5000); } componentWillUnmount() { clearInterval(this.interval); } render() { const src = GUINEAPATHS[this.state.currentGP]; return <GuineaPigs src={src} />; } } ReactDOM.render( <GuineaPigsContainer />, document.getElementById('app') );","title":"Create a Presentational Component"},{"location":"Notes%20on%20nodejs/#proptypes","text":"propTypes are useful for two reasons. The first reason is prop validation. Validation can ensure that your props are doing what they\u2019re supposed to be doing. If props are missing, or if they\u2019re present but they aren\u2019t what you\u2019re expecting, then a warning will print in the console. This is useful, but reason #2 is arguably more useful: documentation. Documenting props makes it easier to glance at a file and quickly understand the component class inside. When you have a lot of files, and you will, this can be a huge benefit.","title":"propTypes"},{"location":"Notes%20on%20nodejs/#apply-proptypes","text":"The name of each property in propTypes should be the name of an expected prop. In our case, MessageDisplayer expects a prop named message, so our property\u2019s name is message. The value of each property in propTypes should fit this pattern: PropTypes.expected_data_type_goes_here import React from 'react'; import PropTypes from 'prop-types'; export class BestSeller extends React.Component { render() { return ( <li> Title: <span> {this.props.title} </span><br /> Author: <span> {this.props.author} </span><br /> Weeks: <span> {this.props.weeksOnList} </span> </li> ); } } BestSeller.propTypes = { title: PropTypes.string.isRequired, author: PropTypes.string.isRequired, weeksOnList: PropTypes.number.isRequired };","title":"Apply PropTypes"},{"location":"Notes%20on%20nodejs/#proptypes-in-function-components","text":"// Normal way to display a prop: export class MyComponentClass extends React.Component { render() { return <h1>{this.props.title}</h1>; } } // Functional component way to display a prop: export const MyComponentClass = (props) => { return <h1>{props.title}</h1>; } // Normal way to display a prop using a variable: export class MyComponentClass extends React.component { render() { let title = this.props.title; return <h1>{title}</h1>; } } // Functional component way to display a prop using a variable: export const MyComponentClass = (props) => { let title = props.title; return <h1>{title}</h1>; }","title":"PropTypes in Function Components"},{"location":"Notes%20on%20nodejs/#react-forms","text":"Think about how forms work in a typical, non-React environment. A user types some data into a form\u2019s input fields, and the server doesn\u2019t know about it. The server remains clueless until the user hits a \u201csubmit\u201d button, which sends all of the form\u2019s data over to the server simultaneously. In React, as in many other JavaScript environments, this is not the best way of doing things. The problem is the period of time during which a form thinks that a user has typed one thing, but the server thinks that the user has typed a different thing. What if, during that time, a third part of the website needs to know what a user has typed? It could ask the form or the server and get two different answers. In a complex JavaScript app with many moving, interdependent parts, this kind of conflict can easily lead to problems. In a React form, you want the server to know about every new character or deletion, as soon as it happens. That way, your screen will always be in sync with the rest of your application.","title":"React Forms"},{"location":"Notes%20on%20nodejs/#input-on-change","text":"A traditional form doesn\u2019t update the server until a user hits \u201csubmit.\u201d But you want to update the server any time a user enters or deletes any character. import React from 'react'; export class Example extends React.Component { constructor(props) { super(props); this.state = { userInput: '' }; this.handleChange = this.handleChange.bind(this); } handleChange(e) { this.setState({ userInput: e.target.value }); } render() { return ( <input onChange={this.handleChange} type=\"text\" /> ); } }","title":"Input on Change"},{"location":"Notes%20on%20nodejs/#control-vs-uncontrolled","text":"There are two terms that will probably come up when you talk about React forms: controlled component and uncontrolled component. Like automatic binding, controlled vs uncontrolled components is a topic that you should be familiar with, but don\u2019t need to understand deeply at this point. An uncontrolled component is a component that maintains its own internal state. A controlled component is a component that does not maintain any internal state. Since a controlled component has no state, it must be controlled by someone else. Think of a typical <input type='text' /> element. It appears onscreen as a text box. If you need to know what text is currently in the box, then you can ask the <input /> , possibly with some code like this: let input = document.querySelector('input[type=\"text\"]'); let typedText = input.value; // input.value will be equal to whatever text is currently in the text box. The important thing here is that the <input /> keeps track of its own text. You can ask it what its text is at any time, and it will be able to tell you. The fact that <input /> keeps track of information makes it an uncontrolled component. It maintains its own internal state, by remembering data about itself. A controlled component, on the other hand, has no memory. If you ask it for information about itself, then it will have to get that information through props. Most React components are controlled. In React, when you give an <input /> a value attribute, then something strange happens: the <input /> BECOMES controlled. It stops using its internal storage. This is a more \u2018React\u2019 way of doing things.","title":"Control vs Uncontrolled"},{"location":"Notes%20on%20nodejs/#update-an-inputs-value","text":"When a user types or deletes in the <input /> , then that will trigger a change event, which will call handleUserInput. That\u2019s good! handleUserInput will set this.state.userInput equal to whatever text is currently in the input field. That\u2019s also good! There\u2019s only one problem: you can set this.state.userInput to whatever you want, but <input /> won\u2019t care. You need to somehow make the <input /> \u2018s text responsive to this.state.userInput. Easy enough! You can control an <input /> \u2018s text by setting its value attribute.","title":"Update an Input's Value"},{"location":"Notes%20on%20nodejs/#set-the-inputs-initial-state","text":"Good! Any time that someone types or deletes in <input /> , the .handleUserInput() method will update this.state.userInput with the <input /> \u2018s text. Since you\u2019re using this.setState, that means that Input needs an initial state! What should this.state\u2018s initial value be? Well, this.state.userInput will be displayed in the <input /> . What should the initial text in the <input /> be, when a user first visits the page? The initial text should be blank! Otherwise it would look like someone had already typed something.","title":"Set the Input's Initial State"},{"location":"Notes%20on%20nodejs/#dynamically-rendering-different-components-without-switch-the-capitalized-reference-technique","text":"See: https://j5bot.medium.com/react-dynamically-rendering-different-components-without-switch-the-capitalized-reference-e668d89e460b","title":"Dynamically Rendering Different Components without Switch: the Capitalized Reference Technique"},{"location":"Notes%20on%20nodejs/#react-router","text":"https://ui.dev/react-router-tutorial","title":"React Router"},{"location":"Notes%20on%20nodejs/#browserrouter","text":"Naturally, in order to do its thing, React Router needs to be both aware and in control of your app's location. The way it does this is with its BrowserRouter component. Under the hood, BrowserRouter uses both the history library as well as React Context . The history library helps React Router keep track of the browsing history of the application using the browser's built-in history stack, and React Context helps make history available wherever React Router needs it. There's not much to BrowserRouter, you just need to make sure that if you're using React Router on the web, you wrap your app inside of the BrowserRouter import ReactDOM from 'react-dom' import * as React from 'react' import { BrowserRouter } from 'react-router-dom' import App from './App` ReactDOM.render( <BrowserRouter> <App /> </BrowserRouter> , document.getElementById('app))","title":"BrowserRouter"},{"location":"Notes%20on%20nodejs/#route","text":"Put simply, Route allows you to map your app's location to different React components. For example, say we wanted to render a Dashboard component whenever a user navigated to the /dashboard path. To do so, we'd render a Route that looked like this. <Route path=\"/dashboard\" element={<Dashboard />} /> The mental model I use for Route is that it always has to render something \u2013 either its element prop if the path matches the app's current location or null, if it doesn't. You can render as many Routes as you'd like. <Route path=\"/\" element={<Home />} /> <Route path=\"/about\" element={<About />} /> <Route path=\"/settings\" element={<Settings />} /> You can even render nested routes, which we'll talk about later on in this post. With our Route elements in this configuration, it's possible for multiple routes to match on a single URL. You might want to do that sometimes, but most often you want React Router to only render the route that matches best. Fortunately, we can easily do that with Routes.","title":"Route"},{"location":"Notes%20on%20nodejs/#routes","text":"You can think of Routes as the metaphorical conductor of your routes. Whenever you have one or more Routes, you'll most likely want to wrap them in a Routes. import { Routes, Route } from \"react-router-dom\"; function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/about\" element={<About />} /> <Route path=\"/settings\" element={<Settings />} /> <Route path=\"*\" element={<NotFound />} /> </Routes> ); } The reason for this is because it's Routes job is to understand all of its children Route elements, and intelligently choose which ones are the best to render. Though it's not shown in the simple example above, once we start adding more complex Routes to our application, Routes will start to do more work like enabling intelligent rendering and relative paths. We'll see these scenarios in a bit. Next up, linking between pages.","title":"Routes"},{"location":"Notes%20on%20nodejs/#links","text":"Now that you know how to map the app's location to certain React components using Routes and Route, the next step is being able to navigate between them. This is the purpose of the Link component. To tell Link what path to take the user to when clicked, you pass it a to prop. <nav> <Link to=\"/\">Home</Link> <Link to=\"/about\">About</Link> <Link to=\"/settings\">Settings</Link> </nav> If you need more control over Link, you can also pass to as an object. Doing so allows you to add a query string via the search property or pass along any data to the new route via state. <nav> <Link to=\"/\">Home</Link> <Link to=\"/about\">About</Link> <Link to={{ pathname: \"/settings\", search: \"?sort=date\", state: { fromHome: true }, }} > Settings </Link> </nav>","title":"Links"},{"location":"Notes%20on%20nodejs/#url-parameters","text":"Like function parameters allow you to declare placeholders when you define a function, URL Parameters allow you to declare placeholders for portions of a URL. Take Wikipedia for example. When you visit a topic on Wikipedia, you'll notice that the URL pattern is always the same, wikipedia.com/wiki/{topicId}. Instead of defining a route for every topic on the site, they can declare one route with a placeholder for the topic's id. The way you tell React Router that a certain portion of the URL is a placeholder (or URL Parameter), is by using a : in the Route's path prop. <Route path=\"/wiki/:topicId\" element={<Article />} /> Now whenever anyone visits a URL that matches the /wiki/:topicId pattern (/wiki/javascript, /wiki/Brendan_Eich, /wiki/anything) , the Article component is rendered. Now the question becomes, how do you access the dynamic portion of the URL \u2013 in this case, topicId \u2013 in the component that's rendered? As of v5.1, React Router comes with a useParams Hook that returns an object with a mapping between the URL parameter(s) and its value. import * as React from 'react' import { useParams } from 'react-router-dom' import { getArticle } from '../utils' function Article () { const [article, setArticle] = React.useState(null) const { topicId } = useParams() React.useEffect(() => { getArticle(topicId) .then(setUser) }, [topicId]) return ( ... ) }","title":"URL Parameters"},{"location":"Notes%20on%20nodejs/#nested-routes","text":"Nested Routes allow the parent Route to act as a wrapper and control the rendering of a child Route. A real-life example of this UI could look similar to Twitter's /messages route. When you go to /messages, you see all of your previous conversations on the left side of the screen. Then, when you go to /messages/:id, you still see all your messages, but you also see your chat history for :id. Let's look at how we could implement this sort of nested routes pattern with React Router. We'll start off with some basic Routes. // App.js function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/messages\" element={<Messages />} /> <Route path=\"/settings\" element={<Settings />} /> </Routes> ); } Now, if we want Messages to be in control of rendering a child Routes, what's stopping us from just rendering another Routes component inside Messages? Something like this: function Messages() { return ( <Container> <Conversations /> <Routes> <Route path=\":id\" element={<Chat />} /> </Routes> </Container> ); } Now when the user navigates to /messages, React Router renders the Messages component. From there, Messages shows all our conversations via the Conversations component and then renders another Routes with a Route that maps /messages/:id to the Chat component. Relative Routes Notice that we don't have to include the full /messages/:id path in the nested Route. This is because Routes is intelligent and by leaving off the leading /, it assumes we want this path to be relative to the parent's location, /messages. Looks good, but there's one subtle issue. Can you spot it? Messages only gets rendered when the user is at /messages. When they visit a URL that matches the /messages/:id pattern, Messages no longer matches and therefore, our nested Routes never gets rendered. To fix this, naturally, we need a way to tell React Router that we want to render Messages both when the user is at /messages or any other location that matches the /messages/* pattern. Wait. What if we just update our path to be /messages/*? // App.js function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/messages/*\" element={<Messages />} /> <Route path=\"/settings\" element={<Settings />} /> </Routes> ); } Much to our delight, that'll work. By appending a / to the end of our /messages path, we're essentially telling React Router that Messages has a nested Routes component and our parent path should match for /messages as well as any other location that matches the /messages/ pattern. Exactly what we wanted. At this point, we've looked at how you can create nested routes by appending /* to our Route's path and rendering, literally, a nested Routes component. This works when you want your child Route in control of rendering the nested Routes, but what if we wanted our App component to contain all the information it needed to create our nested routes rather than having to do it inside of Messages? Because this is a common preference, React Router supports this way of creating nested routes as well. Here's what it looks like. function App() { return ( <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/messages\" element={<Messages />}> <Route path=\":id\" element={<Chats />} /> </Route> <Route path=\"/settings\" element={<Settings />} /> </Routes> ); } You declaratively nest the child Route as a children of the parent Route. Like before, the child Route is now relative to the parent, so you don't need to include the parent (/messages) path. Now, the last thing you need to do is tell React Router where in the parent Route (Messages) should it render the child Route (Chats). To do this, you use React Router's Outlet component. import { Outlet } from \"react-router-dom\"; function Messages() { return ( <Container> <Conversations /> <Outlet /> </Container> ); } If the app's location matches the nested Route's path, this Outlet component will render the Route's element. So based on our Routes above, if we were at /messages, the Outlet component would render null, but if we were at /messages/1, it would render the component.","title":"Nested Routes"},{"location":"Notes%20on%20nodejs/#pass-props-to-router-components","text":"In previous versions of React Router (v4), this was non-trivial since React Router was in charge of creating the React element. However, with React Router v6, since you're in charge of creating the element, you just pass a prop to the component as you normally would. <Route path=\"/dashboard\" element={<Dashboard authed={true} />} />","title":"Pass props to Router Components"},{"location":"Notes%20on%20nodejs/#good-practices-for-calling-apis-from-reactjs","text":"https://medium.com/weekly-webtips/patterns-for-doing-api-calls-in-reactjs-8fd9a42ac7d4","title":"Good Practices for Calling APIs from ReactJS"},{"location":"Notes%20on%20nodejs/#jsx","text":"JSX is a syntax extension for JavaScript. It was written to be used with React. JSX code looks a lot like HTML. What does \"syntax extension\" mean? In this case, it means that JSX is not valid JavaScript. Web browsers can\u2019t read it! If a JavaScript file contains JSX code, then that file will have to be compiled. That means that before the file reaches a web browser, a JSX compiler will translate any JSX into regular JavaScript.","title":"JSX"},{"location":"Notes%20on%20nodejs/#jsx-elements","text":"A basic unit of JSX is called a JSX element. Here\u2019s an example of a JSX element: <h1>Hello world</h1>","title":"JSX Elements"},{"location":"Notes%20on%20nodejs/#jsx-elements-and-their-surroundings","text":"JSX elements are treated as JavaScript expressions. They can go anywhere that JavaScript expressions can go. That means that a JSX element can be saved in a variable, passed to a function, stored in an object or array\u2026you name it. Here\u2019s an example of a JSX element being saved in a variable: const navBar = <nav>I am a nav bar</nav>; const myTeam = { center: <li>Benzo Walli</li>, powerForward: <li>Rasha Loa</li>, smallForward: <li>Tayshaun Dasmoto</li>, shootingGuard: <li>Colmar Cumberbatch</li>, pointGuard: <li>Femi Billon</li> };","title":"JSX Elements And Their Surroundings"},{"location":"Notes%20on%20nodejs/#attributes-in-jsx","text":"JSX elements can have attributes, just like HTML elements can. A JSX attribute is written using HTML-like syntax: a name, followed by an equals sign, followed by a value. The value should be wrapped in quotes, like this: my-attribute-name=\"my-attribute-value\" <a href='http://www.example.com'>Welcome to the Web</a>; const title = <h1 id='title'>Introduction to React.js: Part I</h1>; const panda = <img src='images/panda.jpg' alt='panda' width='500px' height='500px' />;","title":"Attributes In JSX"},{"location":"Notes%20on%20nodejs/#nested-jsx","text":"If a JSX expression takes up more than one line, then you must wrap the multi-line JSX expression in parentheses. This looks strange at first, but you get used to it: const theExample = ( <a href=\"https://www.example.com\"> <h1> Click me! </h1> </a> )","title":"Nested JSX"},{"location":"Notes%20on%20nodejs/#jsx-outer-elements","text":"There\u2019s a rule that we haven\u2019t mentioned: a JSX expression must have exactly one outermost element. In other words, this code will work: const paragraphs = ( <div id=\"i-am-the-outermost-element\"> <p>I am a paragraph.</p> <p>I, too, am a paragraph.</p> </div> ); // But this code will not work: const paragraphs = ( <p>I am a paragraph.</p> <p>I, too, am a paragraph.</p> );","title":"JSX Outer Elements"},{"location":"Notes%20on%20nodejs/#rendering-jsx","text":"The following code will render a JSX expression: ReactDOM.render(<h1>Hello world</h1>, document.getElementById('app'));","title":"Rendering JSX"},{"location":"Notes%20on%20nodejs/#reactdomrender","text":"ReactDOM is the name of a JavaScript library. This library contains several React-specific methods, all of which deal with the DOM in some way or another. When a web page is loaded, the browser creates a Document Object Model of the page. The HTML DOM model is constructed as a tree of Objects: ReactDOM.render() is the most common way to render JSX. It takes a JSX expression, creates a corresponding tree of DOM nodes, and adds that tree to the DOM. That is the way to make a JSX expression appear onscreen. In the code ReactDOM.render(<h1>Render me!</h1>, document.getElementById('app')); the expression <h1>Render me!</h1> is what you want rendered. The second argument document.getElementById('app') indicates where you want to append the first argument in the DOM. Ex: if you had the following HTML: <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\"> <link rel=\"stylesheet\" href=\"/styles.css\"> <title>Learn ReactJS</title> </head> <body> <main id=\"app\"></main> <script src=\"https://content.codecademy.com/courses/React/react-course-bundle.min.js\"></script> <script src=\"/app.compiled.js\"></script> </body> </html> The element with the ID would be selected and the DOM added to it. One special thing about ReactDOM.render() is that it only updates DOM elements that have changed. That means that if you render the exact same thing twice in a row, the second render will do nothing.","title":"ReactDOM.render()"},{"location":"Notes%20on%20nodejs/#passing-a-variable-to-reactdomrender","text":"ReactDOM.render()\u2018s first argument should evaluate to a JSX expression, it doesn\u2019t have to literally be a JSX expression. The first argument could also be a variable, so long as that variable evaluates to a JSX expression.","title":"Passing a Variable to ReactDOM.render()"},{"location":"Notes%20on%20nodejs/#class-vs-classname","text":"<h1 class=\"big\">Hey</h1> In JSX, you can\u2019t use the word class! You have to use className instead: <h1 className=\"big\">Hey</h1>","title":"class vs className"},{"location":"Notes%20on%20nodejs/#self-closing-tags","text":"With self closing tags you MUST include the slash in JSX. Ex: <br /> . The trailing / isn't optional.","title":"Self-Closing Tags"},{"location":"Notes%20on%20nodejs/#javascript-in-jsx","text":"Te render Javascript in JSX, you have to use curly braces. Ex: import React from 'react'; import ReactDOM from 'react-dom'; // Write code here: ReactDOM.render( <h1>{2 + 3}</h1>, document.getElementById('app') );","title":"Javascript in JSX"},{"location":"Notes%20on%20nodejs/#variables-in-jsx","text":"When you inject JavaScript into JSX, that JavaScript is part of the same environment as the rest of the JavaScript in your file. That means that you can access variables while inside of a JSX expression, even if those variables were declared on the outside. You can set HTML attributes with curly braces like this: // Use a variable to set the `height` and `width` attributes: const sideLength = \"200px\"; const panda = ( <img src=\"images/panda.jpg\" alt=\"panda\" height={sideLength} width={sideLength} /> );","title":"Variables in JSX"},{"location":"Notes%20on%20nodejs/#event-listeners-in-jsx","text":"JSX elements can have event listeners, just like HTML elements can. Programming in React means constantly working with event listeners. You create an event listener by giving a JSX element a special attribute. Here\u2019s an example: <img onClick={myFunc} /> An event listener attribute\u2019s name should be something like onClick or onMouseOver: the word on, plus the type of event that you\u2019re listening for. You can see a list of valid event names here . An event listener attribute\u2019s value should be a function. The above example would only work if myFunc were a valid function that had been defined elsewhere: function myFunc() { alert('Make myFunc the pFunc... omg that was horrible i am so sorry'); } <img onClick={myFunc} />","title":"Event Listeners in JSX"},{"location":"Notes%20on%20nodejs/#jsx-conditionals","text":"This code will break: ( <h1> { if (purchase.complete) { 'Thank you for placing an order!' } } </h1> ) The reason why has to do with the way that JSX is compiled. You don\u2019t need to understand the mechanics of it for now, but if you\u2019re interested then you can learn more in the React documentation . How can you write a conditional, if you can\u2019t inject an if statement into JSX? Well, one option is to write an if statement, and not inject it into JSX. Look at if.js. Follow the if statement, all the way from line 6 down to line 18. if.js works, because the words if and else are not injected in between JSX tags. The if statement is on the outside, and no JavaScript injection is necessary. import React from 'react'; import ReactDOM from 'react-dom'; let message; if (user.age >= drinkingAge) { message = ( <h1> Hey, check out this alcoholic beverage! </h1> ); } else { message = ( <h1> Hey, check out these earrings I got at Claire's! </h1> ); } ReactDOM.render( message, document.getElementById('app') );","title":"JSX Conditionals"},{"location":"Notes%20on%20nodejs/#ternary-operator","text":"Recall how it works: you write x ? y : z, where x, y, and z are all JavaScript expressions. When your code is executed, x is evaluated as either \"truthy\" or \"falsy.\" If x is truthy, then the entire ternary operator returns y. If x is falsy, then the entire ternary operator returns z. Here\u2019s a nice explanation if you need a refresher. const headline = ( <h1> { age >= drinkingAge ? 'Buy Drink' : 'Do Teen Stuff' } </h1> );","title":"Ternary Operator"},{"location":"Notes%20on%20nodejs/#_1","text":"&& works best in conditionals that will sometimes do an action, but other times do nothing at all. Here\u2019s an example: const tasty = ( <ul> <li>Applesauce</li> { !baby && <li>Pizza</li> } { age > 15 && <li>Brussels Sprouts</li> } { age > 20 && <li>Oysters</li> } { age > 25 && <li>Grappa</li> } </ul> ); If the expression on the left of the && evaluates as true, then the JSX on the right of the && will be rendered. If the first expression is false, however, then the JSX to the right of the && will be ignored and not rendered.","title":"&amp;&amp;"},{"location":"Notes%20on%20nodejs/#map-in-jsx","text":"If you want to create a list of JSX elements, then .map() is often your best bet. It can look odd at first: const strings = ['Home', 'Shop', 'About Me']; const listItems = strings.map(string => <li>{string}</li>); <ul>{listItems}</ul> In the above example, we start out with an array of strings. We call .map() on this array of strings, and the .map() call returns a new array of s. If you want the index you can do: const listItems = strings.map((string, i) => <li>{string}</li>);","title":".map in JSX"},{"location":"Notes%20on%20nodejs/#list-keys","text":"When you make a list in JSX, sometimes your list will need to include something called keys: <ul> <li key=\"li-01\">Example1</li> <li key=\"li-02\">Example2</li> <li key=\"li-03\">Example3</li> </ul> A key is a JSX attribute. The attribute\u2019s name is key. The attribute\u2019s value should be something unique, similar to an id attribute. keys don\u2019t do anything that you can see! React uses them internally to keep track of lists. If you don\u2019t use keys when you\u2019re supposed to, React might accidentally scramble your list-items into the wrong order. Not all lists need to have keys. A list needs keys if either of the following are true: The list-items have memory from one render to the next. For instance, when a to-do list renders, each item must \"remember\" whether it was checked off. The items shouldn\u2019t get amnesia when they render. A list\u2019s order might be shuffled. For instance, a list of search results might be shuffled from one render to the next. import React from 'react'; import ReactDOM from 'react-dom'; const people = ['Rowe', 'Prevost', 'Gare']; const peopleLis = people.map((person, i) => // expression goes here: <li key={'person_' + i}>{person}</li> ); // ReactDOM.render goes here: ReactDOM.render(<ul>{peopleLis}</ul>, document.getElementById('app'))","title":"List Keys"},{"location":"Notes%20on%20nodejs/#react-create-element","text":"You can write React code without using JSX at all! The majority of React programmers do use JSX, and we will use it for the remainder of this tutorial, but you should understand that it is possible to write React code without it. The following JSX expression: const h1 = <h1>Hello world</h1>; can be rewritten without JSX, like this: const h1 = React.createElement( \"h1\", null, \"Hello world\" ); When a JSX element is compiled, the compiler transforms the JSX element into the method that you see above: React.createElement(). Every JSX element is secretly a call to React.createElement().","title":"React Create Element"},{"location":"Nvidia%20GRID%20Notes/","text":"Nvidia GRID Notes Nvidia GRID Notes Useful Resources GPUs which Support vGPU Creation on VMWare vGPU Architecture Diagram How does SR-IOV work? Multi-Instance GPU Nvidia Professional Technologies How Does GRID Manager Integrate with the Hypervisor Where do profiles fit in the stack? What is a Profile Selecting a GPU Two General Types of Users Which Type of GPU? Dell GPUs and Upgrade Path Nvidia GPUs GPUs for Power Users Desktop Hosting Models vGPU License Decision Tree Useful Resources Nvidia vGPU Validated Solutions Nvidia Product Support Matrix for Operating Systems Add an NVIDIA GRID vGPU to a Virtual Machine Introduction to Nvidia Virtual GPU - Part 1 - Intro, Which GPU & License? NVIDIA Virtual GPU Software Packaging, Pricing, and Licensing Guide GPUs which Support vGPU Creation on VMWare Here are all the GPUs which support creating vGPU instances on VMWare: https://docs.nvidia.com/grid/13.0/grid-vgpu-release-notes-vmware-vsphere/index.html#hardware-configuration vGPU Architecture Diagram vGPU is exposed via SR-IOV . SR-IOV is an extension of the PCIe specification. It allows you to take one physical entity like a GPU or NIC and split it up into multiple virtual devices. How does SR-IOV work? In the case of SR-IOV, things are split into a Physical Function (PF) and a PCIe Virtual Function (VF) which represent the physical device and a virtual instance of that device which exposes some subset of the physical resources respectively. Usually a PCIe device has a single Requester ID (RID) which allows it to communicate over PCIe. This functions more or less like an IP address. However, with SR-IOV each physical function and virtual function gets its own RID. This allows the I/O Memory Management Unit (IOMMU) to differentiate between the different VFs. Note: The IOMMU connects any device with DMA capability (ex: NIC/GPU) to main memory directly instead of routing it through the CPU. This system allows the hypervisor to deliver IO from the VF directly to a VM without going through any software switching in the hypervisor. Multi-Instance GPU Nvidia calls this segmentation of the GPU Multi-Instance GPU (MIG). MIG enables a physical GPU to be securely partitioned into multiple separate GPU instances, providing multiple users with separate GPU resources to accelerate their applications. Nvidia Professional Technologies This is from Introduction to NVIDIA Virtual GPU - Part 1 - Intro, Which GPU & License? While a bit out of date it does a good job of showing where what technologies fit and what licenses are relevant. How Does GRID Manager Integrate with the Hypervisor Each vGPU in a VM gets a time slice on the actual GPU along with its own dedicated memory (the frame buffer). You\u2019ll have the aforementioned GPU manager that\u2019s part of the hypervisor and then each VM will run a standard Nvidia driver. Nvidia says that doing full PCIe passthrough vs giving the same resources via a vGPU is a negligible performance difference - a couple of percentage points max. Nvidia maintains a compatibility matrix on their website with what platforms and card combinations are available Where do profiles fit in the stack? This images is helpful because it shows where GPU profiles fit in the stack. What is a Profile Profiles are the means by which we define how much resources and the types of capabilities a vGPU has. Selecting a GPU Two General Types of Users Which Type of GPU? Dell GPUs and Upgrade Path Nvidia GPUs NOTE : These are from the aforementioned YouTube lecture which is a bit out of date but I thought it was helpful to see it broken out. GPUs for Power Users Desktop Hosting Models There are two general ways to present virtual desktops XenApp you have one instance of Windows Server and multiple people using it. You generally need a large frame buffer for this. Everyone else uses this model where you have multiple desktops running simultaneously. Licensing: There\u2019s an Nvidia license server that runs and as you create virtual desktops it will consume licenses. Which license depends on what you\u2019re doing and the type of physical GPU. vGPU License Decision Tree","title":"Nvidia GRID Notes"},{"location":"Nvidia%20GRID%20Notes/#nvidia-grid-notes","text":"Nvidia GRID Notes Useful Resources GPUs which Support vGPU Creation on VMWare vGPU Architecture Diagram How does SR-IOV work? Multi-Instance GPU Nvidia Professional Technologies How Does GRID Manager Integrate with the Hypervisor Where do profiles fit in the stack? What is a Profile Selecting a GPU Two General Types of Users Which Type of GPU? Dell GPUs and Upgrade Path Nvidia GPUs GPUs for Power Users Desktop Hosting Models vGPU License Decision Tree","title":"Nvidia GRID Notes"},{"location":"Nvidia%20GRID%20Notes/#useful-resources","text":"Nvidia vGPU Validated Solutions Nvidia Product Support Matrix for Operating Systems Add an NVIDIA GRID vGPU to a Virtual Machine Introduction to Nvidia Virtual GPU - Part 1 - Intro, Which GPU & License? NVIDIA Virtual GPU Software Packaging, Pricing, and Licensing Guide","title":"Useful Resources"},{"location":"Nvidia%20GRID%20Notes/#gpus-which-support-vgpu-creation-on-vmware","text":"Here are all the GPUs which support creating vGPU instances on VMWare: https://docs.nvidia.com/grid/13.0/grid-vgpu-release-notes-vmware-vsphere/index.html#hardware-configuration","title":"GPUs which Support vGPU Creation on VMWare"},{"location":"Nvidia%20GRID%20Notes/#vgpu-architecture-diagram","text":"vGPU is exposed via SR-IOV . SR-IOV is an extension of the PCIe specification. It allows you to take one physical entity like a GPU or NIC and split it up into multiple virtual devices.","title":"vGPU Architecture Diagram"},{"location":"Nvidia%20GRID%20Notes/#how-does-sr-iov-work","text":"In the case of SR-IOV, things are split into a Physical Function (PF) and a PCIe Virtual Function (VF) which represent the physical device and a virtual instance of that device which exposes some subset of the physical resources respectively. Usually a PCIe device has a single Requester ID (RID) which allows it to communicate over PCIe. This functions more or less like an IP address. However, with SR-IOV each physical function and virtual function gets its own RID. This allows the I/O Memory Management Unit (IOMMU) to differentiate between the different VFs. Note: The IOMMU connects any device with DMA capability (ex: NIC/GPU) to main memory directly instead of routing it through the CPU. This system allows the hypervisor to deliver IO from the VF directly to a VM without going through any software switching in the hypervisor.","title":"How does SR-IOV work?"},{"location":"Nvidia%20GRID%20Notes/#multi-instance-gpu","text":"Nvidia calls this segmentation of the GPU Multi-Instance GPU (MIG). MIG enables a physical GPU to be securely partitioned into multiple separate GPU instances, providing multiple users with separate GPU resources to accelerate their applications.","title":"Multi-Instance GPU"},{"location":"Nvidia%20GRID%20Notes/#nvidia-professional-technologies","text":"This is from Introduction to NVIDIA Virtual GPU - Part 1 - Intro, Which GPU & License? While a bit out of date it does a good job of showing where what technologies fit and what licenses are relevant.","title":"Nvidia Professional Technologies"},{"location":"Nvidia%20GRID%20Notes/#how-does-grid-manager-integrate-with-the-hypervisor","text":"Each vGPU in a VM gets a time slice on the actual GPU along with its own dedicated memory (the frame buffer). You\u2019ll have the aforementioned GPU manager that\u2019s part of the hypervisor and then each VM will run a standard Nvidia driver. Nvidia says that doing full PCIe passthrough vs giving the same resources via a vGPU is a negligible performance difference - a couple of percentage points max. Nvidia maintains a compatibility matrix on their website with what platforms and card combinations are available","title":"How Does GRID Manager Integrate with the Hypervisor"},{"location":"Nvidia%20GRID%20Notes/#where-do-profiles-fit-in-the-stack","text":"This images is helpful because it shows where GPU profiles fit in the stack.","title":"Where do profiles fit in the stack?"},{"location":"Nvidia%20GRID%20Notes/#what-is-a-profile","text":"Profiles are the means by which we define how much resources and the types of capabilities a vGPU has.","title":"What is a Profile"},{"location":"Nvidia%20GRID%20Notes/#selecting-a-gpu","text":"","title":"Selecting a GPU"},{"location":"Nvidia%20GRID%20Notes/#two-general-types-of-users","text":"","title":"Two General Types of Users"},{"location":"Nvidia%20GRID%20Notes/#which-type-of-gpu","text":"","title":"Which Type of GPU?"},{"location":"Nvidia%20GRID%20Notes/#dell-gpus-and-upgrade-path","text":"","title":"Dell GPUs and Upgrade Path"},{"location":"Nvidia%20GRID%20Notes/#nvidia-gpus","text":"NOTE : These are from the aforementioned YouTube lecture which is a bit out of date but I thought it was helpful to see it broken out.","title":"Nvidia GPUs"},{"location":"Nvidia%20GRID%20Notes/#gpus-for-power-users","text":"","title":"GPUs for Power Users"},{"location":"Nvidia%20GRID%20Notes/#desktop-hosting-models","text":"There are two general ways to present virtual desktops XenApp you have one instance of Windows Server and multiple people using it. You generally need a large frame buffer for this. Everyone else uses this model where you have multiple desktops running simultaneously. Licensing: There\u2019s an Nvidia license server that runs and as you create virtual desktops it will consume licenses. Which license depends on what you\u2019re doing and the type of physical GPU.","title":"Desktop Hosting Models"},{"location":"Nvidia%20GRID%20Notes/#vgpu-license-decision-tree","text":"","title":"vGPU License Decision Tree"},{"location":"OME%20Bug/","text":"OME Bug OME Version 3.7.0 (Build 82) Description OME Does not correctly handle the @odata.nextLink attribute for /api/DeviceService/Devices when passed specific IDs. For example: https://10.55.160.130/api/DeviceService/Devices?Id=13878,16669,16697,16698,16700,16701,16705,16707,16711,16712,16803,16846,16852,16975,16976,16982,16983,17002,17006,17007,17008,17020,17021,17255,17288,17289,17750,17752,17753,17755,17780,17781,17821,17822,17824,17825,17826,17829,17834,17835,17836,17838,17847,17848,17850,17851,17852,17856,17857,17864,17865,17868,17869,17870,17892,17893,17895,17896,17897,17902,17903,17904,17924,17934,17956,17970,17971,17992,18016,18017,18021,18023,18027,18075,18167,18417,18418,18419,18420,18421,18422,18423,18442,18443,18444,18445,18446,18447,18448,18449,18450,18451,18452,18453,18454,18455,18456,18457,18458,18459,18460,18461,18462,18463,18464,18465,18466,18467,18468,18469,18470,18471,18472,18473,18474,18475,18476,18477,18478,18479,18480,18481,18482,18483,18484,18485,18486,18487,18488,18489,18490,18491,18492,18493,18494,18495,18496,18497,18498,18499,18500,18501,18502,18503,18504,18505,18506,18507,18509,18510,18511,18512,18513,18514 The first page of 50 results works as expected. However, after retrieval of the first set of 50 machines the nextLink url is trunkated to '/api/DeviceService/Devices?$skip=50&$top=50' instead of properly including the IDs listed in the original URL. This leads to automated code looping over the totality of the OME inventory instead of some list of specified IDs.","title":"OME Bug"},{"location":"OME%20Bug/#ome-bug","text":"","title":"OME Bug"},{"location":"OME%20Bug/#ome-version","text":"3.7.0 (Build 82)","title":"OME Version"},{"location":"OME%20Bug/#description","text":"OME Does not correctly handle the @odata.nextLink attribute for /api/DeviceService/Devices when passed specific IDs. For example: https://10.55.160.130/api/DeviceService/Devices?Id=13878,16669,16697,16698,16700,16701,16705,16707,16711,16712,16803,16846,16852,16975,16976,16982,16983,17002,17006,17007,17008,17020,17021,17255,17288,17289,17750,17752,17753,17755,17780,17781,17821,17822,17824,17825,17826,17829,17834,17835,17836,17838,17847,17848,17850,17851,17852,17856,17857,17864,17865,17868,17869,17870,17892,17893,17895,17896,17897,17902,17903,17904,17924,17934,17956,17970,17971,17992,18016,18017,18021,18023,18027,18075,18167,18417,18418,18419,18420,18421,18422,18423,18442,18443,18444,18445,18446,18447,18448,18449,18450,18451,18452,18453,18454,18455,18456,18457,18458,18459,18460,18461,18462,18463,18464,18465,18466,18467,18468,18469,18470,18471,18472,18473,18474,18475,18476,18477,18478,18479,18480,18481,18482,18483,18484,18485,18486,18487,18488,18489,18490,18491,18492,18493,18494,18495,18496,18497,18498,18499,18500,18501,18502,18503,18504,18505,18506,18507,18509,18510,18511,18512,18513,18514 The first page of 50 results works as expected. However, after retrieval of the first set of 50 machines the nextLink url is trunkated to '/api/DeviceService/Devices?$skip=50&$top=50' instead of properly including the IDs listed in the original URL. This leads to automated code looping over the totality of the OME inventory instead of some list of specified IDs.","title":"Description"},{"location":"OME%20Integration%20for%20VMWare/","text":"OME Integration for VMWare Installation Download from https://www.dell.com/support/kbdoc/en-us/000176981/openmanage-integration-for-vmware-vcenter#Downloads Open the ZIP file and run the installer. This is a self unpacking executable","title":"OME Integration for VMWare"},{"location":"OME%20Integration%20for%20VMWare/#ome-integration-for-vmware","text":"","title":"OME Integration for VMWare"},{"location":"OME%20Integration%20for%20VMWare/#installation","text":"Download from https://www.dell.com/support/kbdoc/en-us/000176981/openmanage-integration-for-vmware-vcenter#Downloads Open the ZIP file and run the installer. This is a self unpacking executable","title":"Installation"},{"location":"OS10%20Password%20Recovery%20Bug/","text":"OS10 Password Recovery Bug YouTube Reproduction https://youtu.be/b5MJiLTl9KE Update It looks like the instructions are set up to take care of this, but they need to be updated - step 8 tells you to run a sed command that looks like it is targeted at reloving the problem, but it only tells you to run it on 10.5.1.0. When I went through this procedure I just ignored it because the customer was on 10.5.1.3 Description Follow Password recovery instructions to get into the switch at boot. During step 9: /opt/dell/os10/bin/recover_linuxadmin_password.sh produces mount: special device /dev/mapper/OS10-CONFIG does not exist . This is due to a previous configuration of OS10 when tho configuration was mounted on its own logical volume. It has since been moved to SYSROOT. Removing the below lines resolves the issue:","title":"OS10 Password Recovery Bug"},{"location":"OS10%20Password%20Recovery%20Bug/#os10-password-recovery-bug","text":"","title":"OS10 Password Recovery Bug"},{"location":"OS10%20Password%20Recovery%20Bug/#youtube-reproduction","text":"https://youtu.be/b5MJiLTl9KE","title":"YouTube Reproduction"},{"location":"OS10%20Password%20Recovery%20Bug/#update","text":"It looks like the instructions are set up to take care of this, but they need to be updated - step 8 tells you to run a sed command that looks like it is targeted at reloving the problem, but it only tells you to run it on 10.5.1.0. When I went through this procedure I just ignored it because the customer was on 10.5.1.3","title":"Update"},{"location":"OS10%20Password%20Recovery%20Bug/#description","text":"Follow Password recovery instructions to get into the switch at boot. During step 9: /opt/dell/os10/bin/recover_linuxadmin_password.sh produces mount: special device /dev/mapper/OS10-CONFIG does not exist . This is due to a previous configuration of OS10 when tho configuration was mounted on its own logical volume. It has since been moved to SYSROOT. Removing the below lines resolves the issue:","title":"Description"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/","text":"Offline Updates with OpenManage Enterprise Versions My Operating System [root@dellrepo html]# cat /etc/*-release CentOS Linux release 8.3.2011 NAME=\"CentOS Linux\" VERSION=\"8\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"8\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"CentOS Linux 8\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:8\" HOME_URL=\"https://centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-8\" CENTOS_MANTISBT_PROJECT_VERSION=\"8\" CentOS Linux release 8.3.2011 CentOS Linux release 8.3.2011 OME Version Instructions Download Dell Repository Manager Run it with /opt/dell/dellemcrepositorymanager/drm.sh NOTE: Running it with root does not work! You will get an error: GUI interface is not supported by this operating system. Click add repository Select the systems for which you want to download updates under select systems Make sure you select Windows-64 as one of the types which will be available chmod +x <binary name> then run with ./<binary_name> . I chose to distribute the repository using HTTP with Apache dnf install httpd sudo systemctl start --now httpd Next you have to synchronize the repository by clicking download. I downloaded my files to /opt/dell/catalogs/fc640 You then have to go open the Dell EMC Repository Manager -> Export -> Export. You will need to select which repositories you want to export and then you will want to select share and a save location. WARNING You have to download the Windows 64 bit versions of the updates for it to work! Even if you are using Linux the idrac only accepts the Windows EXE files. The export will generate a catalog file when you export. This is what OME will need to reference when you add the catalog. I have included a copy of mine so you can see what it looks like. You can see the progress of the export in the jobs manager: Now go to OME catalog management and hit add (Firmware compliance -> catalog Management -> Add) Configure your repository Share Address: (nothing else) Catalog File Path: /catalog.xml (cannot have anything else) 1. NOTE: The catalog my have a different name depending on how you exported it! Go back to Firmware Compliance -> Create Baseline Select your local catalog Give it a name Add the hosts you discovered Here is what it looks like in action https://youtu.be/p7pxMX-UAJw Example With Subfolder I wanted to confirm an old bug had been cleared out so I also ran it using a subfolder. See https://www.youtube.com/watch?v=iKuCgkBAzu0 to see a BIOS upgrade from start to finish. Note : In all instances the baseLocation field for me was empty.","title":"Offline Updates with OpenManage Enterprise"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/#offline-updates-with-openmanage-enterprise","text":"","title":"Offline Updates with OpenManage Enterprise"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/#versions","text":"","title":"Versions"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/#my-operating-system","text":"[root@dellrepo html]# cat /etc/*-release CentOS Linux release 8.3.2011 NAME=\"CentOS Linux\" VERSION=\"8\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"8\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"CentOS Linux 8\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:8\" HOME_URL=\"https://centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-8\" CENTOS_MANTISBT_PROJECT_VERSION=\"8\" CentOS Linux release 8.3.2011 CentOS Linux release 8.3.2011","title":"My Operating System"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/#ome-version","text":"","title":"OME Version"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/#instructions","text":"Download Dell Repository Manager Run it with /opt/dell/dellemcrepositorymanager/drm.sh NOTE: Running it with root does not work! You will get an error: GUI interface is not supported by this operating system. Click add repository Select the systems for which you want to download updates under select systems Make sure you select Windows-64 as one of the types which will be available chmod +x <binary name> then run with ./<binary_name> . I chose to distribute the repository using HTTP with Apache dnf install httpd sudo systemctl start --now httpd Next you have to synchronize the repository by clicking download. I downloaded my files to /opt/dell/catalogs/fc640 You then have to go open the Dell EMC Repository Manager -> Export -> Export. You will need to select which repositories you want to export and then you will want to select share and a save location. WARNING You have to download the Windows 64 bit versions of the updates for it to work! Even if you are using Linux the idrac only accepts the Windows EXE files. The export will generate a catalog file when you export. This is what OME will need to reference when you add the catalog. I have included a copy of mine so you can see what it looks like. You can see the progress of the export in the jobs manager: Now go to OME catalog management and hit add (Firmware compliance -> catalog Management -> Add) Configure your repository Share Address: (nothing else) Catalog File Path: /catalog.xml (cannot have anything else) 1. NOTE: The catalog my have a different name depending on how you exported it! Go back to Firmware Compliance -> Create Baseline Select your local catalog Give it a name Add the hosts you discovered Here is what it looks like in action https://youtu.be/p7pxMX-UAJw","title":"Instructions"},{"location":"Offline%20Updates%20with%20OpenManage%20Enterprise/#example-with-subfolder","text":"I wanted to confirm an old bug had been cleared out so I also ran it using a subfolder. See https://www.youtube.com/watch?v=iKuCgkBAzu0 to see a BIOS upgrade from start to finish. Note : In all instances the baseLocation field for me was empty.","title":"Example With Subfolder"},{"location":"OpenFlow%20on%204112F-ON/","text":"OpenFlow on 4112F-ON Create OpenFlow Load Balancer Files Reading Material Overview My Configuration Switch Version Info Setup Setup Controller On Host Workstation Setup OpenFlow on the Switch Enable OpenFlow Configure Management Configure OpenFlow Controller Running the Code Supported Protocols Helpful Commands Personal Notes Things We Want Protocols Things to mention Use Cases Problems Files See here for a listing of files and source code. Reading Material Open Flow Switch Specification v1.3.1 Dell OpenFlow Deployment and User Guide 3.0 OS10 Setup Instructions Overview My Configuration Controller is running on Windows in PyCharm while I'm testing. I'll move it to RHEL when I'm done. I am using a S4112F-ON I am using a Ryu OpenFlow controller Switch Version Info Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.1.0 Build Version: 10.5.1.0.124 Build Time: 2020-02-12T09:05:20+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:52 Setup Setup Controller pip install -r requirements.txt On Host Workstation ** Make sure you use sudo or things will go wrong ** curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt-get install -y nodejs sudo npm install -g @angular/cli sudo ng add @angular/material You can drop the -g if you want to install angular locally in the directory instead of globally. You will have to prefix your commands with npx -p @angular/cli ng To setup debugging do the following: Go to https://marketplace.visualstudio.com/items?itemName=msjsdiag.debugger-for-chrome and install the addon for Visual Studio Code Go to the debugging tab in Visual Studio code, hit the down arrow next to launch program and click launch Chrome. I used the following configuration: { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"chrome\", \"request\": \"launch\", \"name\": \"Launch Chrome against localhost\", \"url\": \"http://localhost:4200\", \"webRoot\": \"c:\\\\Users\\\\grant\\\\Documents\\\\trafficshaper\\\\angular\" } ] } Setup OpenFlow on the Switch Enable OpenFlow On the switch run: OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# mode openflow-only Configurations not relevant to openflow mode will be removed from the startup-configuration and system will be rebooted. Do you want to proceed? [confirm yes/no]:yes Configure Management OS10(conf-if-ma-1/1/1)# interface mgmt 1/1/1 OS10(conf-if-ma-1/1/1)# ip address <SOME MANAGEMENT IP>/24 OS10(conf-if-ma-1/1/1)# no shutdown OS10(conf-if-ma-1/1/1)# exit Configure OpenFlow Controller OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# switch of-switch-1 OS10(config-openflow-switch)# controller ipv4 <YOUR_CONTROLLER_IP> port 6633 OS10(config-openflow-switch)# protocol-version 1.3 OS10(config-openflow-switch)# no shutdown Running the Code python main.py Supported Protocols TCP UDP ICMP Helpful Commands Personal Notes Things We Want Protocols HTTP TLS DNS SSH Things to mention Inline decryption possibilities Use Cases I want to tie a sensor directly to a DC. So all things for that DC go to one sensor A couple of dropdown boxes in a statement and an execute button. One of those things could be an IP address, or a port, or a protocol, physical port Problems need to make sure we don't receive a reject message need to make it so outports and inports persist if something is an input port do we want to stop them from using redirect port I need to go back and make sure that when compressed tiles move to the next line I need to handle getting flows for the openflow controller's interface Need to add error handling if the server is unavailable Need to update the getPorts documentation","title":"OpenFlow on 4112F-ON"},{"location":"OpenFlow%20on%204112F-ON/#openflow-on-4112f-on","text":"Create OpenFlow Load Balancer Files Reading Material Overview My Configuration Switch Version Info Setup Setup Controller On Host Workstation Setup OpenFlow on the Switch Enable OpenFlow Configure Management Configure OpenFlow Controller Running the Code Supported Protocols Helpful Commands Personal Notes Things We Want Protocols Things to mention Use Cases Problems","title":"OpenFlow on 4112F-ON"},{"location":"OpenFlow%20on%204112F-ON/#files","text":"See here for a listing of files and source code.","title":"Files"},{"location":"OpenFlow%20on%204112F-ON/#reading-material","text":"Open Flow Switch Specification v1.3.1 Dell OpenFlow Deployment and User Guide 3.0 OS10 Setup Instructions","title":"Reading Material"},{"location":"OpenFlow%20on%204112F-ON/#overview","text":"","title":"Overview"},{"location":"OpenFlow%20on%204112F-ON/#my-configuration","text":"Controller is running on Windows in PyCharm while I'm testing. I'll move it to RHEL when I'm done. I am using a S4112F-ON I am using a Ryu OpenFlow controller","title":"My Configuration"},{"location":"OpenFlow%20on%204112F-ON/#switch-version-info","text":"Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.1.0 Build Version: 10.5.1.0.124 Build Time: 2020-02-12T09:05:20+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 00:03:52","title":"Switch Version Info"},{"location":"OpenFlow%20on%204112F-ON/#setup","text":"","title":"Setup"},{"location":"OpenFlow%20on%204112F-ON/#setup-controller","text":"pip install -r requirements.txt","title":"Setup Controller"},{"location":"OpenFlow%20on%204112F-ON/#on-host-workstation","text":"** Make sure you use sudo or things will go wrong ** curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt-get install -y nodejs sudo npm install -g @angular/cli sudo ng add @angular/material You can drop the -g if you want to install angular locally in the directory instead of globally. You will have to prefix your commands with npx -p @angular/cli ng To setup debugging do the following: Go to https://marketplace.visualstudio.com/items?itemName=msjsdiag.debugger-for-chrome and install the addon for Visual Studio Code Go to the debugging tab in Visual Studio code, hit the down arrow next to launch program and click launch Chrome. I used the following configuration: { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"chrome\", \"request\": \"launch\", \"name\": \"Launch Chrome against localhost\", \"url\": \"http://localhost:4200\", \"webRoot\": \"c:\\\\Users\\\\grant\\\\Documents\\\\trafficshaper\\\\angular\" } ] }","title":"On Host Workstation"},{"location":"OpenFlow%20on%204112F-ON/#setup-openflow-on-the-switch","text":"","title":"Setup OpenFlow on the Switch"},{"location":"OpenFlow%20on%204112F-ON/#enable-openflow","text":"On the switch run: OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# mode openflow-only Configurations not relevant to openflow mode will be removed from the startup-configuration and system will be rebooted. Do you want to proceed? [confirm yes/no]:yes","title":"Enable OpenFlow"},{"location":"OpenFlow%20on%204112F-ON/#configure-management","text":"OS10(conf-if-ma-1/1/1)# interface mgmt 1/1/1 OS10(conf-if-ma-1/1/1)# ip address <SOME MANAGEMENT IP>/24 OS10(conf-if-ma-1/1/1)# no shutdown OS10(conf-if-ma-1/1/1)# exit","title":"Configure Management"},{"location":"OpenFlow%20on%204112F-ON/#configure-openflow-controller","text":"OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# switch of-switch-1 OS10(config-openflow-switch)# controller ipv4 <YOUR_CONTROLLER_IP> port 6633 OS10(config-openflow-switch)# protocol-version 1.3 OS10(config-openflow-switch)# no shutdown","title":"Configure OpenFlow Controller"},{"location":"OpenFlow%20on%204112F-ON/#running-the-code","text":"python main.py","title":"Running the Code"},{"location":"OpenFlow%20on%204112F-ON/#supported-protocols","text":"TCP UDP ICMP","title":"Supported Protocols"},{"location":"OpenFlow%20on%204112F-ON/#helpful-commands","text":"","title":"Helpful Commands"},{"location":"OpenFlow%20on%204112F-ON/#personal-notes","text":"","title":"Personal Notes"},{"location":"OpenFlow%20on%204112F-ON/#things-we-want","text":"","title":"Things We Want"},{"location":"OpenFlow%20on%204112F-ON/#protocols","text":"HTTP TLS DNS SSH","title":"Protocols"},{"location":"OpenFlow%20on%204112F-ON/#things-to-mention","text":"Inline decryption possibilities","title":"Things to mention"},{"location":"OpenFlow%20on%204112F-ON/#use-cases","text":"I want to tie a sensor directly to a DC. So all things for that DC go to one sensor A couple of dropdown boxes in a statement and an execute button. One of those things could be an IP address, or a port, or a protocol, physical port","title":"Use Cases"},{"location":"OpenFlow%20on%204112F-ON/#problems","text":"need to make sure we don't receive a reject message need to make it so outports and inports persist if something is an input port do we want to stop them from using redirect port I need to go back and make sure that when compressed tiles move to the next line I need to handle getting flows for the openflow controller's interface Need to add error handling if the server is unavailable Need to update the getPorts documentation","title":"Problems"},{"location":"OpenFlow%20on%204112F-ON/angular/","text":"Trafficshapergui This project was generated with Angular CLI version 9.1.1. Development server Run ng serve for a dev server. Navigate to http://localhost:4200/ . The app will automatically reload if you change any of the source files. Code scaffolding Run ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module . Build Run ng build to build the project. The build artifacts will be stored in the dist/ directory. Use the --prod flag for a production build. Running unit tests Run ng test to execute the unit tests via Karma . Running end-to-end tests Run ng e2e to execute the end-to-end tests via Protractor . Further help To get more help on the Angular CLI use ng help or go check out the Angular CLI README .","title":"Trafficshapergui"},{"location":"OpenFlow%20on%204112F-ON/angular/#trafficshapergui","text":"This project was generated with Angular CLI version 9.1.1.","title":"Trafficshapergui"},{"location":"OpenFlow%20on%204112F-ON/angular/#development-server","text":"Run ng serve for a dev server. Navigate to http://localhost:4200/ . The app will automatically reload if you change any of the source files.","title":"Development server"},{"location":"OpenFlow%20on%204112F-ON/angular/#code-scaffolding","text":"Run ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module .","title":"Code scaffolding"},{"location":"OpenFlow%20on%204112F-ON/angular/#build","text":"Run ng build to build the project. The build artifacts will be stored in the dist/ directory. Use the --prod flag for a production build.","title":"Build"},{"location":"OpenFlow%20on%204112F-ON/angular/#running-unit-tests","text":"Run ng test to execute the unit tests via Karma .","title":"Running unit tests"},{"location":"OpenFlow%20on%204112F-ON/angular/#running-end-to-end-tests","text":"Run ng e2e to execute the end-to-end tests via Protractor .","title":"Running end-to-end tests"},{"location":"OpenFlow%20on%204112F-ON/angular/#further-help","text":"To get more help on the Angular CLI use ng help or go check out the Angular CLI README .","title":"Further help"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/","text":"Bug in Ryu datapath_id Overview Problem Ryu incorrectly truncates datapath_id from 16 characters to 15. I found the problem while testing this Ryu example . Proof of Concept Running the code in debug mode produces the below: You can see that the switch ID 150013889525632 which is only 15 characters instead of the required 16. To confirm that the problem was not with what the switch was sending I captured the response in Wireshark. You can see the switch correctly adheres to the 64bit datapath_id requirement. Detailed Troubleshooting I found the problem when none of the routes ran when browsing to the address: http://127.0.0.1:8080/simpleswitch/mactable/150013889525632 I eventually realized it is because of the following line: @route('/simpleswitch', url, methods=['PUT'], requirements={'dpid': dpid_lib.DPID_PATTERN}) DPID_PATTERN's definition is as follows: _DPID_LEN = 16 _DPID_FMT = '%0{0}x'.format(_DPID_LEN) DPID_PATTERN = r'[0-9a-f]{%d}' % _DPID_LEN You can see this more directly by looking at the regex as it is used in the WSGI call produced from the above line. As you can see from {16} the switch ID Ryu produces does not match because it is a character short. You can fix the problem by using the URL: http://127.0.0.1:8080/simpleswitch/mactable/0150013889525632 However, that then causes other code to fail because it is is looking for the original switch ID of 150013889525632. Reproducing My Configuration Controller is running on Windows in PyCharm Controller: Ryu Switch: 4112F-ON Switch Version Info Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.1.0 Build Version: 10.5.1.0.124 Build Time: 2020-02-12T09:05:20+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 4 days 09:16:43 Setup Enable OpenFlow on the Switch On the switch run: OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# mode openflow-only Configurations not relevant to openflow mode will be removed from the startup-configuration and system will be rebooted. Do you want to proceed? [confirm yes/no]:yes Configure OpenFlow OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# switch of-switch-1 OS10(config-openflow-switch)# controller ipv4 <YOUR_CONTROLLER_IP> port 6633 OS10(config-openflow-switch)# no shutdown See the switch config for details. Run the Code Run pip install ryu to install Ryu and its dependencies. I have included my Ryu app as it currently was when I found the bug in the file main.py . I used PyCharm to perform debugging which required me to adjust the debug configuration to the below: This will allow you to use PyCharm's debugger. Alternatively, you can delete everything after line 358 in main.py and use ryu-manager to run the application. To run the code there is an application called ryu-manager . To run the code you have to run ryu-manager main.py .","title":"Bug in Ryu datapath_id"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#bug-in-ryu-datapath_id","text":"","title":"Bug in Ryu datapath_id"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#overview","text":"","title":"Overview"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#problem","text":"Ryu incorrectly truncates datapath_id from 16 characters to 15. I found the problem while testing this Ryu example .","title":"Problem"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#proof-of-concept","text":"Running the code in debug mode produces the below: You can see that the switch ID 150013889525632 which is only 15 characters instead of the required 16. To confirm that the problem was not with what the switch was sending I captured the response in Wireshark. You can see the switch correctly adheres to the 64bit datapath_id requirement.","title":"Proof of Concept"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#detailed-troubleshooting","text":"I found the problem when none of the routes ran when browsing to the address: http://127.0.0.1:8080/simpleswitch/mactable/150013889525632 I eventually realized it is because of the following line: @route('/simpleswitch', url, methods=['PUT'], requirements={'dpid': dpid_lib.DPID_PATTERN}) DPID_PATTERN's definition is as follows: _DPID_LEN = 16 _DPID_FMT = '%0{0}x'.format(_DPID_LEN) DPID_PATTERN = r'[0-9a-f]{%d}' % _DPID_LEN You can see this more directly by looking at the regex as it is used in the WSGI call produced from the above line. As you can see from {16} the switch ID Ryu produces does not match because it is a character short. You can fix the problem by using the URL: http://127.0.0.1:8080/simpleswitch/mactable/0150013889525632 However, that then causes other code to fail because it is is looking for the original switch ID of 150013889525632.","title":"Detailed Troubleshooting"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#reproducing","text":"","title":"Reproducing"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#my-configuration","text":"Controller is running on Windows in PyCharm Controller: Ryu Switch: 4112F-ON","title":"My Configuration"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#switch-version-info","text":"Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.1.0 Build Version: 10.5.1.0.124 Build Time: 2020-02-12T09:05:20+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 4 days 09:16:43","title":"Switch Version Info"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#setup","text":"","title":"Setup"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#enable-openflow-on-the-switch","text":"On the switch run: OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# mode openflow-only Configurations not relevant to openflow mode will be removed from the startup-configuration and system will be rebooted. Do you want to proceed? [confirm yes/no]:yes","title":"Enable OpenFlow on the Switch"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#configure-openflow","text":"OS10# configure terminal OS10(config)# openflow OS10(config-openflow)# switch of-switch-1 OS10(config-openflow-switch)# controller ipv4 <YOUR_CONTROLLER_IP> port 6633 OS10(config-openflow-switch)# no shutdown See the switch config for details.","title":"Configure OpenFlow"},{"location":"OpenFlow%20on%204112F-ON/openflow_bug/#run-the-code","text":"Run pip install ryu to install Ryu and its dependencies. I have included my Ryu app as it currently was when I found the bug in the file main.py . I used PyCharm to perform debugging which required me to adjust the debug configuration to the below: This will allow you to use PyCharm's debugger. Alternatively, you can delete everything after line 358 in main.py and use ryu-manager to run the application. To run the code there is an application called ryu-manager . To run the code you have to run ryu-manager main.py .","title":"Run the Code"},{"location":"PCIev3%20vs%20v4/","text":"PCIev3 vs v4 PCIe v3 vs v4 PCIev3 Speed Per lane: 1GB/s unidirectional PCIev3 Max unidirectional speed: 16GB/s PCIev4 Speed per lane: 2GB/s unidirectional PCIev4 Max unidirectional speed: 32GB/s Samsung NF1 Drive According to this article a single NF1 drive runs at 3,000MB/s sequential read speed and a 1900 MB/s sequential write speed. Xeon Second Gen Scalable Procs According to this article a second gen xeon proc provides 48 PCIe v3 lanes. Two procs would mean 96. This means that a 2 proc server with these chips could theoretically run up to 96GB/s unidirectional speed. 96-36 = 60 64 SuperMicro 1029P-NMR36L Dual socket Xeon gen 2 procs with space for 32 hot-swap pci-e3 nf1 drives plus 4 SATA 3 M.2 drive bays. In a scenario where only drives were in the box and under theoretical perfect conditions, you could see a 96GB/s read speed. (Bascially impossible you'd ever actually see that)","title":"PCIev3 vs v4"},{"location":"PCIev3%20vs%20v4/#pciev3-vs-v4","text":"","title":"PCIev3 vs v4"},{"location":"PCIev3%20vs%20v4/#pcie-v3-vs-v4","text":"PCIev3 Speed Per lane: 1GB/s unidirectional PCIev3 Max unidirectional speed: 16GB/s PCIev4 Speed per lane: 2GB/s unidirectional PCIev4 Max unidirectional speed: 32GB/s","title":"PCIe v3 vs v4"},{"location":"PCIev3%20vs%20v4/#samsung-nf1-drive","text":"According to this article a single NF1 drive runs at 3,000MB/s sequential read speed and a 1900 MB/s sequential write speed.","title":"Samsung NF1 Drive"},{"location":"PCIev3%20vs%20v4/#xeon-second-gen-scalable-procs","text":"According to this article a second gen xeon proc provides 48 PCIe v3 lanes. Two procs would mean 96. This means that a 2 proc server with these chips could theoretically run up to 96GB/s unidirectional speed. 96-36 = 60 64","title":"Xeon Second Gen Scalable Procs"},{"location":"PCIev3%20vs%20v4/#supermicro-1029p-nmr36l","text":"Dual socket Xeon gen 2 procs with space for 32 hot-swap pci-e3 nf1 drives plus 4 SATA 3 M.2 drive bays. In a scenario where only drives were in the box and under theoretical perfect conditions, you could see a 96GB/s read speed. (Bascially impossible you'd ever actually see that)","title":"SuperMicro 1029P-NMR36L"},{"location":"Playing%20with%20virsh/","text":"Playing with virsh VMs List all VMs virsh list --all Network Stuff Get network info virsh net-info Dump network info virsh net-dumpxml xhubnet List all networks virsh net-list --all IPables Heads up, iptables -L does not truly list all the rules. It just lists the rules in the current table. If you want to see the NAT rules you can run: iptables -t nat -L Heads up, iptables will by default try to resolve names. To skip this do: iptables -t nat -vnL Adding a destination NAT rule: iptables -t nat -A PREROUTING -p tcp --dport 8000 -j DNAT --to 10.125.120.21 Delete a rule from iptables: iptables -t nat -D POSTROUTING -p tcp --dport 50000 -j SNAT --to 5.136.13.37","title":"Playing with virsh"},{"location":"Playing%20with%20virsh/#playing-with-virsh","text":"","title":"Playing with virsh"},{"location":"Playing%20with%20virsh/#vms","text":"List all VMs virsh list --all","title":"VMs"},{"location":"Playing%20with%20virsh/#network-stuff","text":"Get network info virsh net-info Dump network info virsh net-dumpxml xhubnet List all networks virsh net-list --all","title":"Network Stuff"},{"location":"Playing%20with%20virsh/#ipables","text":"Heads up, iptables -L does not truly list all the rules. It just lists the rules in the current table. If you want to see the NAT rules you can run: iptables -t nat -L Heads up, iptables will by default try to resolve names. To skip this do: iptables -t nat -vnL Adding a destination NAT rule: iptables -t nat -A PREROUTING -p tcp --dport 8000 -j DNAT --to 10.125.120.21 Delete a rule from iptables: iptables -t nat -D POSTROUTING -p tcp --dport 50000 -j SNAT --to 5.136.13.37","title":"IPables"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/","text":"PowerScale - Configure with Kubernetes RKE2 advertises itself as an automatic K8s installer. That is... sort of true based on my experience. It is certainly simpler than what I had to do 7 years ago, but significant assembly by someone who knows Kubernetes and networking was still required. PowerScale - Configure with Kubernetes My IPs Install RKE2 on Server Set Up a K8s Node Install Helm Install Cert Manager Install Rancher Install a Load Balancer for Bare Metal (metallb) PowerScale Setting Up the PowerScale Install the CSI Driver Troubleshooting Flannel Issues Firewalld Ports I tried Getting Kubernetes Status Testing NFS Mount Quickly Checking ACLs Get ACLs List See a Specific User's Privileges My IPs K8s Master - 10.10.25.135 (k8s-server.lan) K8s Worker - 10.10.25.136 (k8s-agent1.lan) Isilon - 10.10.25.80 Install RKE2 on Server I recommend just making life easy and doing an su - and just doing everything as root. Note: after heavy experimentation to include writing the below code that does this I still found flannel choked with firewalld on so ultimately I just ran systemctl disable --now firewalld . See Troubleshooting Flannel Issues . Since it's a lab I decided the juice wasn't worth the squeeze because I think the problem is in the internal masquerade rules. The firewall rules I tried are in firewall ports I tried curl -sfL https://get.rke2.io | sudo sh - sudo systemectl disable --now firewalld sudo systemctl enable rke2-server.service sudo systemctl start rke2-server.service cd /var/lib/rancher/rke2/bin echo 'export KUBECONFIG=/etc/rancher/rke2/rke2.yaml' >> ~/.bashrc echo 'export PATH=$PATH:/var/lib/rancher/rke2/bin' >> ~/.bashrc source ~/.bashrc The rke2 server process listens on port 9345 for new nodes to register. The Kubernetes API is still served on port 6443, as normal. Set Up a K8s Node sudo curl -sfL https://get.rke2.io | sudo INSTALL_RKE2_TYPE=\"agent\" sh - systemctl disable --now firewalld sudo systemctl enable rke2-agent.service mkdir -p /etc/rancher/rke2/ echo 'export PATH=$PATH:/var/lib/rancher/rke2/bin' >> ~/.bashrc source ~/.bashrc vim /etc/rancher/rke2/config.yaml Note: If you don't update bashrc and source it, none of the kubectl commands will run correctly because RKE2 uses a custom API port (6443) whereas the Kubernetes default is 8080. Next you have to populate the config file with your server's token info. You get the token by logging into the server and running: [root@k8s-server tmp]# cat /var/lib/rancher/rke2/server/node-token K1016508dd12aa27c24f9898fdebd534a7f2dc5b8cd719d1f6cf131edb799247d0e::server:ede9908e983065b06dfabcd9ba45d7ab Then you put that token in the aforementioned config file: server: https://k8s-server.lan:9345 token: K1016508dd12aa27c24f9898fdebd534a7f2dc5b8cd719d1f6cf131edb799247d0e::server:ede9908e983065b06dfabcd9ba45d7ab After you do this and save it I strongly suggest running shutdown -r now and giving things a reboot. I noticed on my setup, for some reason, flannel failed to come up. You can check if this is the case by running ip a s . You should see: [grant@k8s-agent1 ~]$ ip a s 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:50:56:8a:b2:8c brd ff:ff:ff:ff:ff:ff altname enp2s1 inet 10.10.25.136/24 brd 10.10.25.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::250:56ff:fe8a:b28c/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: calia304d00df8c@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-fef0629e-72af-acbf-9e2e-27a43f48407e inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 4: calib76b9de74c6@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-60486c79-4e9c-14fd-be02-c8243d382b4a inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 5: cali4fbea555e83@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-5c1b74d4-961c-6f3c-950b-4c910cf5c8d6 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 6: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 12:6d:b8:f6:c8:66 brd ff:ff:ff:ff:ff:ff inet 10.42.1.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::106d:b8ff:fef6:c866/64 scope link valid_lft forever preferred_lft forever 9: calid194e3ad4a3@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-5f9c0ded-120d-b035-fe1d-6eab65c96d11 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 10: calia758d43a129@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-97f784af-18ec-46df-ce3f-6607efa71a7f inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 11: calie1439757d80@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-a65f26af-89c4-e98c-1248-64b0f4a6cef8 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever Notice that flannel.1 is present along with the calico interfaces. If you don't see that, try the reboot. After the server setup I noticed it took quite some time to come up. You can track progress with journalctl -u rke2-server -f . My logs looked like this: Nov 29 14:21:37 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:37-05:00\" level=info msg=\"Pod for kube-apiserver not synced (waiting for termination of old pod sandbox), retrying\" Nov 29 14:21:38 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:38-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:43 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:43-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:48 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:48-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:53 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:53-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:57 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:57-05:00\" level=info msg=\"Pod for etcd is synced\" Nov 29 14:21:57 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:57-05:00\" level=info msg=\"Pod for kube-apiserver not synced (waiting for termination of old pod sandbox), retrying\" Nov 29 14:21:58 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:58-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:03 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:03-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:08 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:08-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:13 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:13-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Pod for etcd is synced\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Pod for kube-apiserver is synced\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"ETCD server is now running\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"rke2 is up and running\" Nov 29 14:22:17 k8s-server.lan systemd[1]: Started Rancher Kubernetes Engine v2 (server). Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Failed to get existing traefik HelmChart\" error=\"helmcharts.helm.cattle.io \\\"traefik\\\" not found\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Reconciling ETCDSnapshotFile resources\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Tunnel server egress proxy mode: agent\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Starting managed etcd node metadata controller\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Reconciliation of ETCDSnapshotFile resources complete\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Starting k3s.cattle.io/v1, Kind=Addon controller\" You can see you get constant 500 errors until it eventually fixes itself. When everything has settled down make sure that you see nodes: [root@k8s-server bin]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-agent1.lan Ready <none> 11m v1.26.10+rke2r2 k8s-server.lan Ready control-plane,etcd,master 60m v1.26.10+rke2r2 Install Helm On the server: cd /tmp wget https://get.helm.sh/helm-v3.13.2-linux-amd64.tar.gz # Update version as needed tar xzf helm-v3.13.2-linux-amd64.tar.gz sudo mv linux-amd64/helm /usr/local/bin/helm helm version Install Cert Manager On the server: helm repo add jetstack https://charts.jetstack.io helm repo update helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.13.2 \\ --set installCRDs=true Install Rancher On the server: helm repo add rancher-stable https://releases.rancher.com/server-charts/stable kubectl create namespace cattle-system helm install rancher rancher-stable/rancher --namespace cattle-system --set hostname=k8s-server.lan --set bootstrapPassword=PASSWORD --set ingress.tls.source=rancher # YOU HAVE TO UPDATE THIS echo https://k8s-server.lan/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}') Install a Load Balancer for Bare Metal (metallb) kubectl create namespace metallb-system kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml Run vim metallb.yaml and create a file with these contents: --- apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: nat namespace: metallb-system spec: addresses: - 10.10.25.140-10.10.25.149 --- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: empty namespace: metallb-system After you create the file run kubectl apply -f metallb.yaml Now we need to make sure Rancher uses metallb: WARNING: you need to change the hostname to your hostname WARNING: make sure Rancher is healthy before continuing! helm upgrade rancher rancher-stable/rancher --namespace cattle-system --set hostname=k8s-server.lan --set rancher.service.type=LoadBalancer kubectl patch svc rancher -n cattle-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' PowerScale Setting Up the PowerScale See PowerScale Setup . Install the CSI Driver I started by following this tutorial Enable NFSv4 Create a directory Create NFS export Move these files onto your system secret.yaml empty-secret.yaml my-isilon-settings.yaml isilon.yml test-pvc.yaml test-pod.yaml Do the following sudo dnf install -y git && git clone -b v2.8.0 https://github.com/dell/csi-powerscale.git cd csi-powerscale/ wget -O my-isilon-settings.yaml https://raw.githubusercontent.com/dell/helm-charts/csi-isilon-2.8.0/charts/csi-isilon/values.yaml kubectl create namespace isilon kubectl create -f empty-secret.yml kubectl create secret generic isilon-creds -n isilon --from-file=config=secret.yaml On the Isilon you have to run isi_gconfig -t web-config auth_basic=true because I was lazy and I used basic auth and not session based auth. Deploy the CSI driver with ./csi-install.sh --namespace isilon --values my-isilon-settings.yaml WARNING YOU MUST ENABLE ignoreUnresolvableHosts: True in the current version. We are currently investigating the issue and are not exactly sure where the problem is, but the NFS mount from K8s shows up on the Isilon as an IP even with DNS enabled. This will cause the Isilon to reject it and when you attempt to write to the mount it will fail. Next deploy the storage class with kubectl apply -f ./isilon.yml Check it worked with kubectl get storageclass and kubectl describe storageclass isilon Build a test pvc with kubectl apply -f test-pvc.yaml (this should run against the test-pvc file you transferred). Make sure it bound with kubectl get pvc test-pvc On all servers run dnf install -y nfs-utils . IF YOU DO NOT DO THIS YOU WILL SEE AN ERROR ABOUT LOCKS . The package is nfs-common on Debian-based systems. Troubleshooting Flannel Issues My rancher install failed with no output from the installer. You can manually pull the logs by examining the rancher pod with kubectl logs -n cattle-system rancher-64cf6ddd96-2x2ms This got me: 2023/11/29 21:04:33 [ERROR] [updateClusterHealth] Failed to update cluster [local]: Internal error occurred: failed calling webhook \"rancher.cattle.io.clusters.management.cattle.io\": failed to call webhook: Post \"https://rancher-webhook.cattle-system.svc:443/v1/webhook/mutation/clusters.management.cattle.io?timeout=10s\": context deadline exceeded 2023/11/29 21:04:33 [ERROR] Failed to connect to peer wss://10.42.0.8/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.0.8:443: connect: no route to host 2023/11/29 21:04:34 [ERROR] Failed to connect to peer wss://10.42.1.21/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.1.21:443: connect: no route to host 2023/11/29 21:04:38 [ERROR] Failed to connect to peer wss://10.42.0.8/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.0.8:443: connect: no route to host 2023/11/29 21:04:39 [ERROR] Failed to connect to peer wss://10.42.1.21/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.1.21:443: connect: no route to host 2023/11/29 21:04:43 [ERROR] Failed to connect to peer wss://10.42.0.8/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.0.8:443: connect: no route to host 2023/11/29 21:04:44 [ERROR] Failed to connect to peer wss://10.42.1.21/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.1.21:443: connect: no route to host on repeat. 10.42.1.21 is an internal flannel address so the next step is to figure out who owns it with kubectl get pods --all-namespaces -o wide : [root@k8s-server ~]# kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES cattle-fleet-system fleet-controller-56968b86b6-tctjr 1/1 Running 0 44m 10.42.1.24 k8s-agent1.lan <none> <none> cattle-fleet-system gitjob-7d68454468-bk7fh 1/1 Running 0 44m 10.42.1.25 k8s-agent1.lan <none> <none> cattle-provisioning-capi-system capi-controller-manager-6f87d6bd74-v489n 1/1 Running 0 41m 10.42.1.30 k8s-agent1.lan <none> <none> cattle-system helm-operation-64xf7 0/2 Completed 0 42m 10.42.1.29 k8s-agent1.lan <none> <none> cattle-system helm-operation-h88vn 1/2 Error 0 41m 10.42.1.34 k8s-agent1.lan <none> <none> cattle-system helm-operation-jndl9 1/2 Error 0 41m 10.42.1.33 k8s-agent1.lan <none> <none> cattle-system helm-operation-k757h 0/2 Completed 0 44m 10.42.1.23 k8s-agent1.lan <none> <none> cattle-system helm-operation-ldnkm 0/2 Completed 0 45m 10.42.1.22 k8s-agent1.lan <none> <none> cattle-system helm-operation-sv5ts 0/2 Completed 0 43m 10.42.1.28 k8s-agent1.lan <none> <none> cattle-system helm-operation-thct7 0/2 Completed 0 43m 10.42.1.27 k8s-agent1.lan <none> <none> cattle-system rancher-64cf6ddd96-2x2ms 1/1 Running 1 (45m ago) 46m 10.42.1.20 k8s-agent1.lan <none> <none> cattle-system rancher-64cf6ddd96-drrzr 1/1 Running 0 46m 10.42.0.8 k8s-server.lan <none> <none> cattle-system rancher-64cf6ddd96-qq64g 1/1 Running 0 46m 10.42.1.21 k8s-agent1.lan <none> <none> cattle-system rancher-webhook-58d68fb97d-b5sn8 1/1 Running 0 41m 10.42.1.32 k8s-agent1.lan <none> <none> cert-manager cert-manager-startupapicheck-fvp9t 0/1 Completed 1 52m 10.42.1.19 k8s-agent1.lan <none> <none> kube-system cloud-controller-manager-k8s-server.lan 1/1 Running 3 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system etcd-k8s-server.lan 1/1 Running 1 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system helm-install-rke2-canal-k8b4d 0/1 Completed 0 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system helm-install-rke2-coredns-f59dz 0/1 Completed 0 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system helm-install-rke2-ingress-nginx-gpt7q 0/1 Completed 0 139m 10.42.0.2 k8s-server.lan <none> <none> kube-system helm-install-rke2-metrics-server-q9jwf 0/1 Completed 0 139m 10.42.0.6 k8s-server.lan <none> <none> kube-system helm-install-rke2-snapshot-controller-6pqpg 0/1 Completed 2 139m 10.42.0.4 k8s-server.lan <none> <none> kube-system helm-install-rke2-snapshot-controller-crd-k6klp 0/1 Completed 0 139m 10.42.0.10 k8s-server.lan <none> <none> kube-system helm-install-rke2-snapshot-validation-webhook-hrv5n 0/1 Completed 0 139m 10.42.0.3 k8s-server.lan <none> <none> kube-system kube-apiserver-k8s-server.lan 1/1 Running 1 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system kube-controller-manager-k8s-server.lan 1/1 Running 2 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system kube-proxy-k8s-agent1.lan 1/1 Running 0 90m 10.10.25.136 k8s-agent1.lan <none> <none> kube-system kube-proxy-k8s-server.lan 1/1 Running 2 (104m ago) 103m 10.10.25.135 k8s-server.lan <none> <none> kube-system kube-scheduler-k8s-server.lan 1/1 Running 1 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system rke2-canal-7p5hz 2/2 Running 2 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system rke2-canal-9wg57 2/2 Running 0 90m 10.10.25.136 k8s-agent1.lan <none> <none> kube-system rke2-coredns-rke2-coredns-565dfc7d75-n96xs 1/1 Running 0 90m 10.42.1.2 k8s-agent1.lan <none> <none> kube-system rke2-coredns-rke2-coredns-565dfc7d75-xv92q 1/1 Running 1 (105m ago) 139m 10.42.0.3 k8s-server.lan <none> <none> kube-system rke2-coredns-rke2-coredns-autoscaler-6c48c95bf9-mh279 1/1 Running 1 (105m ago) 139m 10.42.0.2 k8s-server.lan <none> <none> kube-system rke2-ingress-nginx-controller-89d4c 1/1 Running 0 89m 10.42.1.3 k8s-agent1.lan <none> <none> kube-system rke2-ingress-nginx-controller-zctxb 1/1 Running 1 (105m ago) 139m 10.42.0.5 k8s-server.lan <none> <none> kube-system rke2-metrics-server-c9c78bd66-ndcxs 1/1 Running 1 (105m ago) 139m 10.42.0.4 k8s-server.lan <none> <none> kube-system rke2-snapshot-controller-6f7bbb497d-xfk9x 1/1 Running 1 (105m ago) 139m 10.42.0.6 k8s-server.lan <none> <none> kube-system rke2-snapshot-validation-webhook-65b5675d5c-sfqb2 1/1 Running 1 (105m ago) 139m 10.42.0.7 k8s-server.lan <none> <none> We can see that 10.42.0.8 and 10.42.1.21 are the two rancher containers which confirms for us that as per usual, flannel is not able to complete even its most basic of functions (VXLAN) successfully and its up to us to fix it. cattle-system rancher-64cf6ddd96-drrzr 1/1 Running 0 46m 10.42.0.8 k8s-server.lan <none> <none> cattle-system rancher-64cf6ddd96-qq64g 1/1 Running 0 46m 10.42.1.21 k8s-agent1.lan <none> <none> We can get shells in these containers with kubectl exec -it -n cattle-system rancher-64cf6ddd96-drrzr -- /bin/bash . I fished around in here and found nothing. Ultimately I tcpdumped the flannel network and discovered that we were missing some other specific ports it needed: [root@k8s-agent1 ~]# tcpdump -i flannel.1 dropped privs to tcpdump tcpdump: verbose output suppressed, use -v[v]... for full protocol decode listening on flannel.1, link-type EN10MB (Ethernet), snapshot length 262144 bytes 16:17:38.793476 IP 10.42.0.0.58822 > 10.42.1.32.tungsten-https: Flags [S], seq 3219974389, win 64860, options [mss 1410,sackOK,TS val 2506628321 ecr 0,nop,wscale 7], length 0 16:17:38.793509 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:39.143985 IP 10.42.0.0.41502 > 10.42.1.32.tungsten-https: Flags [S], seq 1965118956, win 64860, options [mss 1410,sackOK,TS val 2506628671 ecr 0,nop,wscale 7], length 0 16:17:39.144008 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:39.847986 IP 10.42.0.0.58822 > 10.42.1.32.tungsten-https: Flags [S], seq 3219974389, win 64860, options [mss 1410,sackOK,TS val 2506629375 ecr 0,nop,wscale 7], length 0 16:17:39.848008 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:40.679004 IP 10.42.0.0.47680 > 10.42.1.32.tungsten-https: Flags [S], seq 1291962979, win 64860, options [mss 1410,sackOK,TS val 2506630206 ecr 0,nop,wscale 7], length 0 16:17:40.679028 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:41.894997 IP 10.42.0.0.58822 > 10.42.1.32.tungsten-https: Flags [S], seq 3219974389, win 64860, options [mss 1410,sackOK,TS val 2506631422 ecr 0,nop,wscale 7], length 0 16:17:41.895024 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:42.727005 IP 10.42.0.0.54136 > 10.42.1.32.tungsten-https: Flags [S], seq 1383176303, win 64860, options [mss 1410,sackOK Ultimately even after opening the ports I wasn't able to get it to work so I disabled firewalld altogether. Firewalld Ports I tried Firewall rules I tried on server: # Kubernetes API Server firewall-cmd --permanent --add-port=6443/tcp # RKE2 Server firewall-cmd --permanent --add-port=9345/tcp # etcd server client API firewall-cmd --permanent --add-port=2379/tcp firewall-cmd --permanent --add-port=2380/tcp # HTTPS firewall-cmd --permanent --add-port=443/tcp # NodePort Services firewall-cmd --permanent --add-port=30000-32767/tcp # Kubelet API firewall-cmd --permanent --add-port=10250/tcp # kube-scheduler firewall-cmd --permanent --add-port=10251/tcp # kube-controller-manager firewall-cmd --permanent --add-port=10252/tcp # Flannel firewall-cmd --permanent --add-port=8285/udp firewall-cmd --permanent --add-port=8472/udp # Additional ports required for Kubernetes firewall-cmd --permanent --add-port=10255/tcp # Read-only Kubelet API firewall-cmd --permanent --add-port=30000-32767/tcp # NodePort Services range firewall-cmd --permanent --add-port=6783/tcp # Flannel firewall-cmd --permanent --add-port=6783/udp # Flannel firewall-cmd --permanent --add-port=6784/udp # Flannel firewall-cmd --add-masquerade --permanent firewall-cmd --reload systemctl restart firewalld Firewall rules I tried on agent: Firewall rules I've tried # Kubelet API and Flannel ports firewall-cmd --permanent --add-port=10250/tcp firewall-cmd --permanent --add-port=8285/udp firewall-cmd --permanent --add-port=8472/udp # NodePort Services firewall-cmd --permanent --add-port=30000-32767/tcp # Additional ports required for Kubernetes firewall-cmd --permanent --add-port=10255/tcp # Read-only Kubelet API firewall-cmd --permanent --add-port=6783/tcp # Flannel firewall-cmd --permanent --add-port=6783/udp # Flannel firewall-cmd --permanent --add-port=6784/udp # Flannel firewall-cmd --add-masquerade --permanent firewall-cmd --reload systemctl restart firewalld Getting Kubernetes Status Get Node status kubectl get nodes Get Detailed Node Status kubectl describe nodes Check all pods status kubectl get pods --all-namespaces Check specific pod status kubectl get pods -n cert-manager Get detailed info for a specific pod kubectl describe pod -n cert-manager cert-manager-6f799f7ff8-xx68n Get the logs from a specific pod kubectl logs -n kube-system rke2-ingress-nginx-controller-89d4c Check to see if metallb is giving a service an external IP address kubectl get svc -n cattle-system Check metellb config kubectl get configmap -n metallb-system config -o yaml Check the metallb speaker output to see if there was an error giving out an IP address kubectl logs -l component=controller -n metallb-system Edit a config file inside of K8s kubectl edit configmap config -n metallb-system Restart metallb after a config change kubectl rollout restart daemonset -n metallb-system speaker kubectl rollout restart deployment -n metallb-system controller Restart a target service Sometimes this helps get an IP unstuck from pending kubectl rollout restart deployment rancher -n cattle-system Testing NFS Mount Quickly If you get an access denied error you will see something like the below in the pod description mounting arguments: -t nfs -o rw 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 /var/lib/kubelet/pods/e1bb5844-f482-4dfa-b4b0-0aa8225a316b/volumes/kubernetes.io~csi/k8s-5b6cb091d0/mount output: mount.nfs: access denied by server while mounting 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 Under the hood the container is just running a generic nfs mount command which you can use for testing. For example, the above would become: mount -t nfs -o rw 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 /var/lib/kubelet/pods/e1bb5844-f482-4dfa-b4b0-0aa8225a316b/volumes/kubernetes.io~csi/k8s-5b6cb091d0/mount <MOUNT_POINT> You can use this to quickly test without restarting the containers. Checking ACLs Get ACLs List You can check ACL permissions with ls -led <target> : grantcluster-1# ls -led /ifs/data/rancher-storage/k8s-7e21fa52bb drwxrwxrwx 2 root wheel 25 Dec 6 20:11 /ifs/data/rancher-storage/k8s-7e21fa52bb OWNER: user:root GROUP: group:wheel SYNTHETIC ACL 0: user:root allow dir_gen_read,dir_gen_write,dir_gen_execute,std_write_dac,delete_child 1: group:wheel allow dir_gen_read,dir_gen_write,dir_gen_execute,delete_child 2: everyone allow dir_gen_read,dir_gen_write,dir_gen_execute,delete_child See a Specific User's Privileges grantcluster-1# isi auth access root /ifs/data/rancher-storage/k8s-7e21fa52bb User Name: root UID: 0 SID: SID:S-1-22-1-0 File Owner Name: root ID: UID:0 Group Name: wheel ID: GID:0 Effective Path: /ifs/data/rancher-storage/k8s-7e21fa52bb File Permissions: root level permissions were found for this user and this file. Mode: drwxrwxrwx Relevant Mode: drwx------ Snapshot Path: No Delete Child: The parent directory allows delete_child for this user, the user may delete the file. Ownership: User is owner and can view and modify file's security descriptor.","title":"PowerScale - Configure with Kubernetes"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#powerscale-configure-with-kubernetes","text":"RKE2 advertises itself as an automatic K8s installer. That is... sort of true based on my experience. It is certainly simpler than what I had to do 7 years ago, but significant assembly by someone who knows Kubernetes and networking was still required. PowerScale - Configure with Kubernetes My IPs Install RKE2 on Server Set Up a K8s Node Install Helm Install Cert Manager Install Rancher Install a Load Balancer for Bare Metal (metallb) PowerScale Setting Up the PowerScale Install the CSI Driver Troubleshooting Flannel Issues Firewalld Ports I tried Getting Kubernetes Status Testing NFS Mount Quickly Checking ACLs Get ACLs List See a Specific User's Privileges","title":"PowerScale - Configure with Kubernetes"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#my-ips","text":"K8s Master - 10.10.25.135 (k8s-server.lan) K8s Worker - 10.10.25.136 (k8s-agent1.lan) Isilon - 10.10.25.80","title":"My IPs"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#install-rke2-on-server","text":"I recommend just making life easy and doing an su - and just doing everything as root. Note: after heavy experimentation to include writing the below code that does this I still found flannel choked with firewalld on so ultimately I just ran systemctl disable --now firewalld . See Troubleshooting Flannel Issues . Since it's a lab I decided the juice wasn't worth the squeeze because I think the problem is in the internal masquerade rules. The firewall rules I tried are in firewall ports I tried curl -sfL https://get.rke2.io | sudo sh - sudo systemectl disable --now firewalld sudo systemctl enable rke2-server.service sudo systemctl start rke2-server.service cd /var/lib/rancher/rke2/bin echo 'export KUBECONFIG=/etc/rancher/rke2/rke2.yaml' >> ~/.bashrc echo 'export PATH=$PATH:/var/lib/rancher/rke2/bin' >> ~/.bashrc source ~/.bashrc The rke2 server process listens on port 9345 for new nodes to register. The Kubernetes API is still served on port 6443, as normal.","title":"Install RKE2 on Server"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#set-up-a-k8s-node","text":"sudo curl -sfL https://get.rke2.io | sudo INSTALL_RKE2_TYPE=\"agent\" sh - systemctl disable --now firewalld sudo systemctl enable rke2-agent.service mkdir -p /etc/rancher/rke2/ echo 'export PATH=$PATH:/var/lib/rancher/rke2/bin' >> ~/.bashrc source ~/.bashrc vim /etc/rancher/rke2/config.yaml Note: If you don't update bashrc and source it, none of the kubectl commands will run correctly because RKE2 uses a custom API port (6443) whereas the Kubernetes default is 8080. Next you have to populate the config file with your server's token info. You get the token by logging into the server and running: [root@k8s-server tmp]# cat /var/lib/rancher/rke2/server/node-token K1016508dd12aa27c24f9898fdebd534a7f2dc5b8cd719d1f6cf131edb799247d0e::server:ede9908e983065b06dfabcd9ba45d7ab Then you put that token in the aforementioned config file: server: https://k8s-server.lan:9345 token: K1016508dd12aa27c24f9898fdebd534a7f2dc5b8cd719d1f6cf131edb799247d0e::server:ede9908e983065b06dfabcd9ba45d7ab After you do this and save it I strongly suggest running shutdown -r now and giving things a reboot. I noticed on my setup, for some reason, flannel failed to come up. You can check if this is the case by running ip a s . You should see: [grant@k8s-agent1 ~]$ ip a s 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:50:56:8a:b2:8c brd ff:ff:ff:ff:ff:ff altname enp2s1 inet 10.10.25.136/24 brd 10.10.25.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::250:56ff:fe8a:b28c/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: calia304d00df8c@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-fef0629e-72af-acbf-9e2e-27a43f48407e inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 4: calib76b9de74c6@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-60486c79-4e9c-14fd-be02-c8243d382b4a inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 5: cali4fbea555e83@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-5c1b74d4-961c-6f3c-950b-4c910cf5c8d6 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 6: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 12:6d:b8:f6:c8:66 brd ff:ff:ff:ff:ff:ff inet 10.42.1.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::106d:b8ff:fef6:c866/64 scope link valid_lft forever preferred_lft forever 9: calid194e3ad4a3@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-5f9c0ded-120d-b035-fe1d-6eab65c96d11 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 10: calia758d43a129@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-97f784af-18ec-46df-ce3f-6607efa71a7f inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 11: calie1439757d80@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-a65f26af-89c4-e98c-1248-64b0f4a6cef8 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever Notice that flannel.1 is present along with the calico interfaces. If you don't see that, try the reboot. After the server setup I noticed it took quite some time to come up. You can track progress with journalctl -u rke2-server -f . My logs looked like this: Nov 29 14:21:37 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:37-05:00\" level=info msg=\"Pod for kube-apiserver not synced (waiting for termination of old pod sandbox), retrying\" Nov 29 14:21:38 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:38-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:43 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:43-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:48 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:48-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:53 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:53-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:21:57 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:57-05:00\" level=info msg=\"Pod for etcd is synced\" Nov 29 14:21:57 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:57-05:00\" level=info msg=\"Pod for kube-apiserver not synced (waiting for termination of old pod sandbox), retrying\" Nov 29 14:21:58 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:21:58-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:03 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:03-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:08 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:08-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:13 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:13-05:00\" level=info msg=\"Waiting to retrieve kube-proxy configuration; server is not ready: https://127.0.0.1:9345/v1-rke2/readyz: 500 Internal Server Error\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Pod for etcd is synced\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Pod for kube-apiserver is synced\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"ETCD server is now running\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"rke2 is up and running\" Nov 29 14:22:17 k8s-server.lan systemd[1]: Started Rancher Kubernetes Engine v2 (server). Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Failed to get existing traefik HelmChart\" error=\"helmcharts.helm.cattle.io \\\"traefik\\\" not found\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Reconciling ETCDSnapshotFile resources\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Tunnel server egress proxy mode: agent\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Starting managed etcd node metadata controller\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Reconciliation of ETCDSnapshotFile resources complete\" Nov 29 14:22:17 k8s-server.lan rke2[1016]: time=\"2023-11-29T14:22:17-05:00\" level=info msg=\"Starting k3s.cattle.io/v1, Kind=Addon controller\" You can see you get constant 500 errors until it eventually fixes itself. When everything has settled down make sure that you see nodes: [root@k8s-server bin]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-agent1.lan Ready <none> 11m v1.26.10+rke2r2 k8s-server.lan Ready control-plane,etcd,master 60m v1.26.10+rke2r2","title":"Set Up a K8s Node"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#install-helm","text":"On the server: cd /tmp wget https://get.helm.sh/helm-v3.13.2-linux-amd64.tar.gz # Update version as needed tar xzf helm-v3.13.2-linux-amd64.tar.gz sudo mv linux-amd64/helm /usr/local/bin/helm helm version","title":"Install Helm"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#install-cert-manager","text":"On the server: helm repo add jetstack https://charts.jetstack.io helm repo update helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.13.2 \\ --set installCRDs=true","title":"Install Cert Manager"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#install-rancher","text":"On the server: helm repo add rancher-stable https://releases.rancher.com/server-charts/stable kubectl create namespace cattle-system helm install rancher rancher-stable/rancher --namespace cattle-system --set hostname=k8s-server.lan --set bootstrapPassword=PASSWORD --set ingress.tls.source=rancher # YOU HAVE TO UPDATE THIS echo https://k8s-server.lan/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}')","title":"Install Rancher"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#install-a-load-balancer-for-bare-metal-metallb","text":"kubectl create namespace metallb-system kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml Run vim metallb.yaml and create a file with these contents: --- apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: nat namespace: metallb-system spec: addresses: - 10.10.25.140-10.10.25.149 --- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: empty namespace: metallb-system After you create the file run kubectl apply -f metallb.yaml Now we need to make sure Rancher uses metallb: WARNING: you need to change the hostname to your hostname WARNING: make sure Rancher is healthy before continuing! helm upgrade rancher rancher-stable/rancher --namespace cattle-system --set hostname=k8s-server.lan --set rancher.service.type=LoadBalancer kubectl patch svc rancher -n cattle-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}'","title":"Install a Load Balancer for Bare Metal (metallb)"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#powerscale","text":"","title":"PowerScale"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#setting-up-the-powerscale","text":"See PowerScale Setup .","title":"Setting Up the PowerScale"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#install-the-csi-driver","text":"I started by following this tutorial Enable NFSv4 Create a directory Create NFS export Move these files onto your system secret.yaml empty-secret.yaml my-isilon-settings.yaml isilon.yml test-pvc.yaml test-pod.yaml Do the following sudo dnf install -y git && git clone -b v2.8.0 https://github.com/dell/csi-powerscale.git cd csi-powerscale/ wget -O my-isilon-settings.yaml https://raw.githubusercontent.com/dell/helm-charts/csi-isilon-2.8.0/charts/csi-isilon/values.yaml kubectl create namespace isilon kubectl create -f empty-secret.yml kubectl create secret generic isilon-creds -n isilon --from-file=config=secret.yaml On the Isilon you have to run isi_gconfig -t web-config auth_basic=true because I was lazy and I used basic auth and not session based auth. Deploy the CSI driver with ./csi-install.sh --namespace isilon --values my-isilon-settings.yaml WARNING YOU MUST ENABLE ignoreUnresolvableHosts: True in the current version. We are currently investigating the issue and are not exactly sure where the problem is, but the NFS mount from K8s shows up on the Isilon as an IP even with DNS enabled. This will cause the Isilon to reject it and when you attempt to write to the mount it will fail. Next deploy the storage class with kubectl apply -f ./isilon.yml Check it worked with kubectl get storageclass and kubectl describe storageclass isilon Build a test pvc with kubectl apply -f test-pvc.yaml (this should run against the test-pvc file you transferred). Make sure it bound with kubectl get pvc test-pvc On all servers run dnf install -y nfs-utils . IF YOU DO NOT DO THIS YOU WILL SEE AN ERROR ABOUT LOCKS . The package is nfs-common on Debian-based systems.","title":"Install the CSI Driver"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#flannel-issues","text":"My rancher install failed with no output from the installer. You can manually pull the logs by examining the rancher pod with kubectl logs -n cattle-system rancher-64cf6ddd96-2x2ms This got me: 2023/11/29 21:04:33 [ERROR] [updateClusterHealth] Failed to update cluster [local]: Internal error occurred: failed calling webhook \"rancher.cattle.io.clusters.management.cattle.io\": failed to call webhook: Post \"https://rancher-webhook.cattle-system.svc:443/v1/webhook/mutation/clusters.management.cattle.io?timeout=10s\": context deadline exceeded 2023/11/29 21:04:33 [ERROR] Failed to connect to peer wss://10.42.0.8/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.0.8:443: connect: no route to host 2023/11/29 21:04:34 [ERROR] Failed to connect to peer wss://10.42.1.21/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.1.21:443: connect: no route to host 2023/11/29 21:04:38 [ERROR] Failed to connect to peer wss://10.42.0.8/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.0.8:443: connect: no route to host 2023/11/29 21:04:39 [ERROR] Failed to connect to peer wss://10.42.1.21/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.1.21:443: connect: no route to host 2023/11/29 21:04:43 [ERROR] Failed to connect to peer wss://10.42.0.8/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.0.8:443: connect: no route to host 2023/11/29 21:04:44 [ERROR] Failed to connect to peer wss://10.42.1.21/v3/connect [local ID=10.42.1.20]: dial tcp 10.42.1.21:443: connect: no route to host on repeat. 10.42.1.21 is an internal flannel address so the next step is to figure out who owns it with kubectl get pods --all-namespaces -o wide : [root@k8s-server ~]# kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES cattle-fleet-system fleet-controller-56968b86b6-tctjr 1/1 Running 0 44m 10.42.1.24 k8s-agent1.lan <none> <none> cattle-fleet-system gitjob-7d68454468-bk7fh 1/1 Running 0 44m 10.42.1.25 k8s-agent1.lan <none> <none> cattle-provisioning-capi-system capi-controller-manager-6f87d6bd74-v489n 1/1 Running 0 41m 10.42.1.30 k8s-agent1.lan <none> <none> cattle-system helm-operation-64xf7 0/2 Completed 0 42m 10.42.1.29 k8s-agent1.lan <none> <none> cattle-system helm-operation-h88vn 1/2 Error 0 41m 10.42.1.34 k8s-agent1.lan <none> <none> cattle-system helm-operation-jndl9 1/2 Error 0 41m 10.42.1.33 k8s-agent1.lan <none> <none> cattle-system helm-operation-k757h 0/2 Completed 0 44m 10.42.1.23 k8s-agent1.lan <none> <none> cattle-system helm-operation-ldnkm 0/2 Completed 0 45m 10.42.1.22 k8s-agent1.lan <none> <none> cattle-system helm-operation-sv5ts 0/2 Completed 0 43m 10.42.1.28 k8s-agent1.lan <none> <none> cattle-system helm-operation-thct7 0/2 Completed 0 43m 10.42.1.27 k8s-agent1.lan <none> <none> cattle-system rancher-64cf6ddd96-2x2ms 1/1 Running 1 (45m ago) 46m 10.42.1.20 k8s-agent1.lan <none> <none> cattle-system rancher-64cf6ddd96-drrzr 1/1 Running 0 46m 10.42.0.8 k8s-server.lan <none> <none> cattle-system rancher-64cf6ddd96-qq64g 1/1 Running 0 46m 10.42.1.21 k8s-agent1.lan <none> <none> cattle-system rancher-webhook-58d68fb97d-b5sn8 1/1 Running 0 41m 10.42.1.32 k8s-agent1.lan <none> <none> cert-manager cert-manager-startupapicheck-fvp9t 0/1 Completed 1 52m 10.42.1.19 k8s-agent1.lan <none> <none> kube-system cloud-controller-manager-k8s-server.lan 1/1 Running 3 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system etcd-k8s-server.lan 1/1 Running 1 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system helm-install-rke2-canal-k8b4d 0/1 Completed 0 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system helm-install-rke2-coredns-f59dz 0/1 Completed 0 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system helm-install-rke2-ingress-nginx-gpt7q 0/1 Completed 0 139m 10.42.0.2 k8s-server.lan <none> <none> kube-system helm-install-rke2-metrics-server-q9jwf 0/1 Completed 0 139m 10.42.0.6 k8s-server.lan <none> <none> kube-system helm-install-rke2-snapshot-controller-6pqpg 0/1 Completed 2 139m 10.42.0.4 k8s-server.lan <none> <none> kube-system helm-install-rke2-snapshot-controller-crd-k6klp 0/1 Completed 0 139m 10.42.0.10 k8s-server.lan <none> <none> kube-system helm-install-rke2-snapshot-validation-webhook-hrv5n 0/1 Completed 0 139m 10.42.0.3 k8s-server.lan <none> <none> kube-system kube-apiserver-k8s-server.lan 1/1 Running 1 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system kube-controller-manager-k8s-server.lan 1/1 Running 2 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system kube-proxy-k8s-agent1.lan 1/1 Running 0 90m 10.10.25.136 k8s-agent1.lan <none> <none> kube-system kube-proxy-k8s-server.lan 1/1 Running 2 (104m ago) 103m 10.10.25.135 k8s-server.lan <none> <none> kube-system kube-scheduler-k8s-server.lan 1/1 Running 1 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system rke2-canal-7p5hz 2/2 Running 2 (105m ago) 139m 10.10.25.135 k8s-server.lan <none> <none> kube-system rke2-canal-9wg57 2/2 Running 0 90m 10.10.25.136 k8s-agent1.lan <none> <none> kube-system rke2-coredns-rke2-coredns-565dfc7d75-n96xs 1/1 Running 0 90m 10.42.1.2 k8s-agent1.lan <none> <none> kube-system rke2-coredns-rke2-coredns-565dfc7d75-xv92q 1/1 Running 1 (105m ago) 139m 10.42.0.3 k8s-server.lan <none> <none> kube-system rke2-coredns-rke2-coredns-autoscaler-6c48c95bf9-mh279 1/1 Running 1 (105m ago) 139m 10.42.0.2 k8s-server.lan <none> <none> kube-system rke2-ingress-nginx-controller-89d4c 1/1 Running 0 89m 10.42.1.3 k8s-agent1.lan <none> <none> kube-system rke2-ingress-nginx-controller-zctxb 1/1 Running 1 (105m ago) 139m 10.42.0.5 k8s-server.lan <none> <none> kube-system rke2-metrics-server-c9c78bd66-ndcxs 1/1 Running 1 (105m ago) 139m 10.42.0.4 k8s-server.lan <none> <none> kube-system rke2-snapshot-controller-6f7bbb497d-xfk9x 1/1 Running 1 (105m ago) 139m 10.42.0.6 k8s-server.lan <none> <none> kube-system rke2-snapshot-validation-webhook-65b5675d5c-sfqb2 1/1 Running 1 (105m ago) 139m 10.42.0.7 k8s-server.lan <none> <none> We can see that 10.42.0.8 and 10.42.1.21 are the two rancher containers which confirms for us that as per usual, flannel is not able to complete even its most basic of functions (VXLAN) successfully and its up to us to fix it. cattle-system rancher-64cf6ddd96-drrzr 1/1 Running 0 46m 10.42.0.8 k8s-server.lan <none> <none> cattle-system rancher-64cf6ddd96-qq64g 1/1 Running 0 46m 10.42.1.21 k8s-agent1.lan <none> <none> We can get shells in these containers with kubectl exec -it -n cattle-system rancher-64cf6ddd96-drrzr -- /bin/bash . I fished around in here and found nothing. Ultimately I tcpdumped the flannel network and discovered that we were missing some other specific ports it needed: [root@k8s-agent1 ~]# tcpdump -i flannel.1 dropped privs to tcpdump tcpdump: verbose output suppressed, use -v[v]... for full protocol decode listening on flannel.1, link-type EN10MB (Ethernet), snapshot length 262144 bytes 16:17:38.793476 IP 10.42.0.0.58822 > 10.42.1.32.tungsten-https: Flags [S], seq 3219974389, win 64860, options [mss 1410,sackOK,TS val 2506628321 ecr 0,nop,wscale 7], length 0 16:17:38.793509 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:39.143985 IP 10.42.0.0.41502 > 10.42.1.32.tungsten-https: Flags [S], seq 1965118956, win 64860, options [mss 1410,sackOK,TS val 2506628671 ecr 0,nop,wscale 7], length 0 16:17:39.144008 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:39.847986 IP 10.42.0.0.58822 > 10.42.1.32.tungsten-https: Flags [S], seq 3219974389, win 64860, options [mss 1410,sackOK,TS val 2506629375 ecr 0,nop,wscale 7], length 0 16:17:39.848008 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:40.679004 IP 10.42.0.0.47680 > 10.42.1.32.tungsten-https: Flags [S], seq 1291962979, win 64860, options [mss 1410,sackOK,TS val 2506630206 ecr 0,nop,wscale 7], length 0 16:17:40.679028 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:41.894997 IP 10.42.0.0.58822 > 10.42.1.32.tungsten-https: Flags [S], seq 3219974389, win 64860, options [mss 1410,sackOK,TS val 2506631422 ecr 0,nop,wscale 7], length 0 16:17:41.895024 IP k8s-agent1.lan > 10.42.0.0: ICMP host 10.42.1.32 unreachable - admin prohibited filter, length 68 16:17:42.727005 IP 10.42.0.0.54136 > 10.42.1.32.tungsten-https: Flags [S], seq 1383176303, win 64860, options [mss 1410,sackOK Ultimately even after opening the ports I wasn't able to get it to work so I disabled firewalld altogether.","title":"Flannel Issues"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#firewalld-ports-i-tried","text":"Firewall rules I tried on server: # Kubernetes API Server firewall-cmd --permanent --add-port=6443/tcp # RKE2 Server firewall-cmd --permanent --add-port=9345/tcp # etcd server client API firewall-cmd --permanent --add-port=2379/tcp firewall-cmd --permanent --add-port=2380/tcp # HTTPS firewall-cmd --permanent --add-port=443/tcp # NodePort Services firewall-cmd --permanent --add-port=30000-32767/tcp # Kubelet API firewall-cmd --permanent --add-port=10250/tcp # kube-scheduler firewall-cmd --permanent --add-port=10251/tcp # kube-controller-manager firewall-cmd --permanent --add-port=10252/tcp # Flannel firewall-cmd --permanent --add-port=8285/udp firewall-cmd --permanent --add-port=8472/udp # Additional ports required for Kubernetes firewall-cmd --permanent --add-port=10255/tcp # Read-only Kubelet API firewall-cmd --permanent --add-port=30000-32767/tcp # NodePort Services range firewall-cmd --permanent --add-port=6783/tcp # Flannel firewall-cmd --permanent --add-port=6783/udp # Flannel firewall-cmd --permanent --add-port=6784/udp # Flannel firewall-cmd --add-masquerade --permanent firewall-cmd --reload systemctl restart firewalld Firewall rules I tried on agent: Firewall rules I've tried # Kubelet API and Flannel ports firewall-cmd --permanent --add-port=10250/tcp firewall-cmd --permanent --add-port=8285/udp firewall-cmd --permanent --add-port=8472/udp # NodePort Services firewall-cmd --permanent --add-port=30000-32767/tcp # Additional ports required for Kubernetes firewall-cmd --permanent --add-port=10255/tcp # Read-only Kubelet API firewall-cmd --permanent --add-port=6783/tcp # Flannel firewall-cmd --permanent --add-port=6783/udp # Flannel firewall-cmd --permanent --add-port=6784/udp # Flannel firewall-cmd --add-masquerade --permanent firewall-cmd --reload systemctl restart firewalld","title":"Firewalld Ports I tried"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#getting-kubernetes-status","text":"Get Node status kubectl get nodes Get Detailed Node Status kubectl describe nodes Check all pods status kubectl get pods --all-namespaces Check specific pod status kubectl get pods -n cert-manager Get detailed info for a specific pod kubectl describe pod -n cert-manager cert-manager-6f799f7ff8-xx68n Get the logs from a specific pod kubectl logs -n kube-system rke2-ingress-nginx-controller-89d4c Check to see if metallb is giving a service an external IP address kubectl get svc -n cattle-system Check metellb config kubectl get configmap -n metallb-system config -o yaml Check the metallb speaker output to see if there was an error giving out an IP address kubectl logs -l component=controller -n metallb-system Edit a config file inside of K8s kubectl edit configmap config -n metallb-system Restart metallb after a config change kubectl rollout restart daemonset -n metallb-system speaker kubectl rollout restart deployment -n metallb-system controller Restart a target service Sometimes this helps get an IP unstuck from pending kubectl rollout restart deployment rancher -n cattle-system","title":"Getting Kubernetes Status"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#testing-nfs-mount-quickly","text":"If you get an access denied error you will see something like the below in the pod description mounting arguments: -t nfs -o rw 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 /var/lib/kubelet/pods/e1bb5844-f482-4dfa-b4b0-0aa8225a316b/volumes/kubernetes.io~csi/k8s-5b6cb091d0/mount output: mount.nfs: access denied by server while mounting 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 Under the hood the container is just running a generic nfs mount command which you can use for testing. For example, the above would become: mount -t nfs -o rw 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 /var/lib/kubelet/pods/e1bb5844-f482-4dfa-b4b0-0aa8225a316b/volumes/kubernetes.io~csi/k8s-5b6cb091d0/mount <MOUNT_POINT> You can use this to quickly test without restarting the containers.","title":"Testing NFS Mount Quickly"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#checking-acls","text":"","title":"Checking ACLs"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#get-acls-list","text":"You can check ACL permissions with ls -led <target> : grantcluster-1# ls -led /ifs/data/rancher-storage/k8s-7e21fa52bb drwxrwxrwx 2 root wheel 25 Dec 6 20:11 /ifs/data/rancher-storage/k8s-7e21fa52bb OWNER: user:root GROUP: group:wheel SYNTHETIC ACL 0: user:root allow dir_gen_read,dir_gen_write,dir_gen_execute,std_write_dac,delete_child 1: group:wheel allow dir_gen_read,dir_gen_write,dir_gen_execute,delete_child 2: everyone allow dir_gen_read,dir_gen_write,dir_gen_execute,delete_child","title":"Get ACLs List"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/#see-a-specific-users-privileges","text":"grantcluster-1# isi auth access root /ifs/data/rancher-storage/k8s-7e21fa52bb User Name: root UID: 0 SID: SID:S-1-22-1-0 File Owner Name: root ID: UID:0 Group Name: wheel ID: GID:0 Effective Path: /ifs/data/rancher-storage/k8s-7e21fa52bb File Permissions: root level permissions were found for this user and this file. Mode: drwxrwxrwx Relevant Mode: drwx------ Snapshot Path: No Delete Child: The parent directory allows delete_child for this user, the user may delete the file. Ownership: User is owner and can view and modify file's security descriptor.","title":"See a Specific User's Privileges"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/","text":"Powerscale CSI Bug Powerscale CSI Bug Problem Description Permanent Fix Problems with Permanent Fix Details Isilon Server Config K8s Config Problem Description Customer reporting that when they attempt to write to an NFS mount via CSI driver inside a container they immediately receive access denied. We are unsure of root cause but Dell staff were able to reproduce and when working with the developers determined the fix action is to use IP addresses in the NFS export: Permanent Fix Instead of manually updating each export users can enable ignoreUnresolvableHosts in their values.yml file during installation. By doing this the CSI driver will always use IP addresses fixing the issue until we completely a root cause analysis. Problems with Permanent Fix If the K8s worker node IPs change, the PVC must be refreshed (this likely will happen anyway when you change the IP) or the PVC mounts on PowerScale must be manually updated. Details Confirm PVC is built [root@k8s-server tmp]# kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-pvc Bound k8s-5b6cb091d0 1Gi RWO isilon 4h4m Create a test pod which outputs anything to NFS mount: [root@k8s-server tmp]# cat test-pod.yaml apiVersion: v1 kind: Pod metadata: name: test-pod spec: containers: - name: test-container image: busybox command: [\"/bin/sh\", \"-ec\", \"while :; do echo $(date) >> /mnt/data/out.txt; sleep 5; done\"] volumeMounts: - name: test-volume mountPath: /mnt/data volumes: - name: test-volume persistentVolumeClaim: claimName: test-pvc [root@k8s-server tmp]# kubectl apply -f test-pod.yaml pod/test-pod created Check test pod - confirm access denied [root@k8s-server tmp]# kubectl describe test-pod error: the server doesn't have a resource type \"test-pod\" [root@k8s-server tmp]# kubectl describe pod test-pod Name: test-pod Namespace: default Priority: 0 Service Account: default Node: k8s-agent1.lan/10.10.25.136 Start Time: Tue, 05 Dec 2023 21:26:11 -0500 Labels: <none> Annotations: <none> Status: Pending IP: IPs: <none> Containers: test-container: Container ID: Image: busybox Image ID: Port: <none> Host Port: <none> Command: /bin/sh -ec while :; do echo $(date) >> /mnt/data/out.txt; sleep 5; done State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: <none> Mounts: /mnt/data from test-volume (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2n2rn (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: test-volume: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: test-pvc ReadOnly: false kube-api-access-2n2rn: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: <nil> DownwardAPI: true QoS Class: BestEffort Node-Selectors: <none> Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 19s default-scheduler Successfully assigned default/test-pod to k8s-agent1.lan Normal SuccessfulAttachVolume 19s attachdetach-controller AttachVolume.Attach succeeded for volume \"k8s-5b6cb091d0\" Warning FailedMount 2s kubelet MountVolume.SetUp failed for volume \"k8s-5b6cb091d0\" : rpc error: code = Unknown desc = mount failed: exit status 32 mounting arguments: -t nfs -o rw 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 /var/lib/kubelet/pods/e1bb5844-f482-4dfa-b4b0-0aa8225a316b/volumes/kubernetes.io~csi/k8s-5b6cb091d0/mount output: mount.nfs: access denied by server while mounting 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 Isilon Server Config Permissions for the mounted PVC folder NFS Zone Settings Global NFS Settings K8s Config Exactly how I built the K8s cluster is available here","title":"Powerscale CSI Bug"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#powerscale-csi-bug","text":"Powerscale CSI Bug Problem Description Permanent Fix Problems with Permanent Fix Details Isilon Server Config K8s Config","title":"Powerscale CSI Bug"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#problem-description","text":"Customer reporting that when they attempt to write to an NFS mount via CSI driver inside a container they immediately receive access denied. We are unsure of root cause but Dell staff were able to reproduce and when working with the developers determined the fix action is to use IP addresses in the NFS export:","title":"Problem Description"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#permanent-fix","text":"Instead of manually updating each export users can enable ignoreUnresolvableHosts in their values.yml file during installation. By doing this the CSI driver will always use IP addresses fixing the issue until we completely a root cause analysis.","title":"Permanent Fix"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#problems-with-permanent-fix","text":"If the K8s worker node IPs change, the PVC must be refreshed (this likely will happen anyway when you change the IP) or the PVC mounts on PowerScale must be manually updated.","title":"Problems with Permanent Fix"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#details","text":"Confirm PVC is built [root@k8s-server tmp]# kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-pvc Bound k8s-5b6cb091d0 1Gi RWO isilon 4h4m Create a test pod which outputs anything to NFS mount: [root@k8s-server tmp]# cat test-pod.yaml apiVersion: v1 kind: Pod metadata: name: test-pod spec: containers: - name: test-container image: busybox command: [\"/bin/sh\", \"-ec\", \"while :; do echo $(date) >> /mnt/data/out.txt; sleep 5; done\"] volumeMounts: - name: test-volume mountPath: /mnt/data volumes: - name: test-volume persistentVolumeClaim: claimName: test-pvc [root@k8s-server tmp]# kubectl apply -f test-pod.yaml pod/test-pod created Check test pod - confirm access denied [root@k8s-server tmp]# kubectl describe test-pod error: the server doesn't have a resource type \"test-pod\" [root@k8s-server tmp]# kubectl describe pod test-pod Name: test-pod Namespace: default Priority: 0 Service Account: default Node: k8s-agent1.lan/10.10.25.136 Start Time: Tue, 05 Dec 2023 21:26:11 -0500 Labels: <none> Annotations: <none> Status: Pending IP: IPs: <none> Containers: test-container: Container ID: Image: busybox Image ID: Port: <none> Host Port: <none> Command: /bin/sh -ec while :; do echo $(date) >> /mnt/data/out.txt; sleep 5; done State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: <none> Mounts: /mnt/data from test-volume (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2n2rn (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: test-volume: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: test-pvc ReadOnly: false kube-api-access-2n2rn: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: <nil> DownwardAPI: true QoS Class: BestEffort Node-Selectors: <none> Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 19s default-scheduler Successfully assigned default/test-pod to k8s-agent1.lan Normal SuccessfulAttachVolume 19s attachdetach-controller AttachVolume.Attach succeeded for volume \"k8s-5b6cb091d0\" Warning FailedMount 2s kubelet MountVolume.SetUp failed for volume \"k8s-5b6cb091d0\" : rpc error: code = Unknown desc = mount failed: exit status 32 mounting arguments: -t nfs -o rw 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0 /var/lib/kubelet/pods/e1bb5844-f482-4dfa-b4b0-0aa8225a316b/volumes/kubernetes.io~csi/k8s-5b6cb091d0/mount output: mount.nfs: access denied by server while mounting 10.10.25.80:/ifs/data/rancher-storage/k8s-5b6cb091d0","title":"Details"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#isilon-server-config","text":"Permissions for the mounted PVC folder NFS Zone Settings Global NFS Settings","title":"Isilon Server Config"},{"location":"PowerScale%20-%20Configure%20with%20Kubernetes/powerscale_bug/#k8s-config","text":"Exactly how I built the K8s cluster is available here","title":"K8s Config"},{"location":"PowerScale%20Failed%20Authentication/","text":"PowerScale Failed Authentication PowerScale Failed Authentication Problem Summary Problem Details Expected Behavior Reproduction Demonstration Cluster Setup Rebuild Initial Setup Code for Testing Authentication Mechanisms Concepts Super Block Quorum How Do Session Teardowns Work? Problem Summary PowerScale OneOS inaccurately reports authentication failures when the number of concurrent sessions is exceeded. Problem Details If --concurrent-session-limit=LIMIT is set with isi auth settings global modify --concurrent-session-limit=15 and that limit is exceeded the logs will say: HTTP Error Log tail -f /var/log/apache2/webui_httpd_error.log 2023-11-28T17:39:39.572651+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34421640960] [client 172.16.5.155:62570] (STATUS_ACCESS_DENIED (0xC0000022) HTTP error: 401) Failed issuing a new JWT from the JWT service., referer: https://10.10.25.80:8080 2023-11-28T17:39:39.572673+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34421640960] [client 172.16.5.155:62570] (401) Unable to create session., referer: https://10.10.25.80:8080 ...SNIP... 2023-11-28T17:39:39.603718+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34422848768] [client 172.16.5.155:62559] (STATUS_ACCESS_DENIED (0xC0000022) HTTP error: 401) Failed issuing a new JWT from the JWT service., referer: https://10.10.25.80:8080 2023-11-28T17:39:39.603728+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34422848768] [client 172.16.5.155:62559] (401) Unable to create session., referer: https://10.10.25.80:8080 HTTP Access Log tail -f /var/log/apache2/webui_httpd_access.log 2023-11-28T17:41:43.101276+00:00 <19.6> grantcluster-1(id1) httpd[98697]: 172.16.5.155 - - [28/Nov/2023:17:41:43 +0000] \"POST /session/1/session HTTP/1.1\" 401 40 \"https://10.10.25.80:8080\" \"python-requests/2.28.1\" REST API Response Total Successful Sessions: 0 Authentication Failed: Status Code 401, Error: Unable to create session. While this is accurate, technically, it is extremely misleading and has lead to a substantial waste of resources investigating authentication failures when in reality the problem is that concurrent sessions was exceeded. Expected Behavior The errors in Problem Details are misleading to both technicians and users. If the number of concurrent sessions is exceeded both the logs and the API responses should reflect that the issue is that the concurrent sessions have been exceeded instead of reporting an authentication error even if generating JWT tokens is the actual product of exceeding concurrent sessions. The error message should make it so technicians resolve the problem without having to rely on developer support. Reproduction The below Python script will reproduce the problem. Replace the credentials with your PowerScale credentials and then run. It will generate 30 threads each of which will hold a session open for 10 seconds. If the number of concurrent sessions is below 30 it will fail. import requests import threading import time import urllib3 urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) def session_cookie_authentication(ip_address, username, password): \"\"\" Authenticate using Session Cookie and return the session cookies if successful. \"\"\" base_url = f\"https://{ip_address}:8080\" session_url = f\"{base_url}/session/1/session\" credentials = {\"username\": username, \"password\": password, \"services\": [\"platform\", \"namespace\"]} headers = {\"Content-Type\": \"application/json\", \"Referer\": base_url} try: response = requests.post(session_url, headers=headers, json=credentials, verify=False) if response.status_code == 201 and 'isisessid' in response.cookies: return response.cookies else: error_message = response.json().get('message', 'No detailed error message provided.') return f\"Authentication Failed: Status Code {response.status_code}, Error: {error_message}\" except Exception as e: return f\"Error during Session Cookie Authentication: {e}\" def create_and_hold_session(ip_address, username, password, hold_time, results): \"\"\" Create a session and hold it open for a specified duration. \"\"\" session_result = session_cookie_authentication(ip_address, username, password) if isinstance(session_result, requests.cookies.RequestsCookieJar): time.sleep(hold_time) # Hold the session results.append(\"Session created and held successfully.\") else: results.append(session_result) def main(): ip_address = \"10.10.25.80\" # Replace with the actual IP address of the PowerScale username = \"root\" password = \"YOUR_PASSWORD\" hold_time = 10 # Hold time in seconds session_threads = [] results = [] # Create 30 concurrent sessions for _ in range(30): thread = threading.Thread(target=create_and_hold_session, args=(ip_address, username, password, hold_time, results)) thread.start() session_threads.append(thread) # Wait for all threads to complete for thread in session_threads: thread.join() # Analyze results and print summary success_count = results.count(\"Session created and held successfully.\") print(f\"Total Successful Sessions: {success_count}\") error_messages = set([result for result in results if result != \"Session created and held successfully.\"]) for error in error_messages: print(error) if __name__ == \"__main__\": main() Demonstration Confirm concurrent sessions is fixed at 15: grantcluster-1# isi auth settings global view Send NTLMv2: No Space Replacement: Workgroup: WORKGROUP Provider Hostname Lookup: disabled Alloc Retries: 5 User Object Cache Size: 47.68M On Disk Identity: native RPC Block Time: Now RPC Max Requests: 64 RPC Timeout: 30s Default LDAP TLS Revocation Check Level: none System GID Threshold: 80 System UID Threshold: 80 Min Mapped Rid: 2147483648 Group UID: 4294967292 Null GID: 4294967293 Null UID: 4294967293 Unknown GID: 4294967294 Unknown UID: 4294967294 Failed Login Delay Time: Now Concurrent Session Limit: 15 Now we run the above Python script: C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python310\\python.exe \"C:\\Users\\grant\\Documents\\code\\grantcurell.github.io\\docs\\PowerScale Failed Authentication\\multiple_sessions_test.py\" Total Successful Sessions: 0 Authentication Failed: Status Code 401, Error: Unable to create session. Change the concurrent sessions to 31: grantcluster-1# isi auth settings global modify --concurrent-session-limit=31 grantcluster-1# isi auth settings global view Send NTLMv2: No Space Replacement: Workgroup: WORKGROUP Provider Hostname Lookup: disabled Alloc Retries: 5 User Object Cache Size: 47.68M On Disk Identity: native RPC Block Time: Now RPC Max Requests: 64 RPC Timeout: 30s Default LDAP TLS Revocation Check Level: none System GID Threshold: 80 System UID Threshold: 80 Min Mapped Rid: 2147483648 Group UID: 4294967292 Null GID: 4294967293 Null UID: 4294967293 Unknown GID: 4294967294 Unknown UID: 4294967294 Failed Login Delay Time: Now Concurrent Session Limit: 31 Rerun the script: C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python310\\python.exe \"C:\\Users\\grant\\Documents\\code\\grantcurell.github.io\\docs\\PowerScale Failed Authentication\\multiple_sessions_test.py\" Total Successful Sessions: 30 Process finished with exit code 0 Cluster Setup Rebuild I hopped on an old cluster I used for testing and ran isi_reformat_node Initial Setup These are the settings I used for my build. Since I was building this in a lab I told it to use the internal IP addresses for external as well instead of making them separate sets. Configuration Item Value Cluster name grantcluster Encoding utf-8 int-a netmask 255.255.255.0 int-a IP ranges { 10.10.25.80-10.10.25.89 } int-a IP range { 10.10.25.80-10.10.25.89 } int-a gateway 10.10.25.1 SmartConnect zone name onefs DNS servers { 10.10.25.120 } Search domains { grant.lan, lan } After I joined the nodes together I confirmed they had a quorum: grantcluster-1# sysctl efs.gmp.has_quorum efs.gmp.has_quorum: 1 grantcluster-1# sysctl efs.gmp.has_super_block_quorum efs.gmp.has_super_block_quorum: 1 1 indicates success whereas 0 indicates that there is no quorum. Super Blocks are described here . Code for Testing Authentication Mechanisms I used this code to test the different authentication mechanisms to confirm valid credentials. Concepts Super Block Quorum Referred to as efs.gmp.has_super_block_quorum , is a property that ensures the file system's integrity by requiring more than half of the nodes in the cluster to be available and in agreement over the internal network. This quorum prevents data conflicts, such as conflicting versions of the same file if two groups of nodes become unsynchronized. If a node is unreachable, OneFS will separate it from the cluster, known as splitting. Operations can continue as long as a quorum of nodes remains connected. If the split nodes can reconnect and re-synchronize, they rejoin the majority group in a process known as merging. The superblock quorum status can be checked by connecting to a node via SSH and running the sysctl efs.gmp.has_super_block_quorum command-line tool as root. How Do Session Teardowns Work? See Session Teardown Reverse Engineering","title":"PowerScale Failed Authentication"},{"location":"PowerScale%20Failed%20Authentication/#powerscale-failed-authentication","text":"PowerScale Failed Authentication Problem Summary Problem Details Expected Behavior Reproduction Demonstration Cluster Setup Rebuild Initial Setup Code for Testing Authentication Mechanisms Concepts Super Block Quorum How Do Session Teardowns Work?","title":"PowerScale Failed Authentication"},{"location":"PowerScale%20Failed%20Authentication/#problem-summary","text":"PowerScale OneOS inaccurately reports authentication failures when the number of concurrent sessions is exceeded.","title":"Problem Summary"},{"location":"PowerScale%20Failed%20Authentication/#problem-details","text":"If --concurrent-session-limit=LIMIT is set with isi auth settings global modify --concurrent-session-limit=15 and that limit is exceeded the logs will say: HTTP Error Log tail -f /var/log/apache2/webui_httpd_error.log 2023-11-28T17:39:39.572651+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34421640960] [client 172.16.5.155:62570] (STATUS_ACCESS_DENIED (0xC0000022) HTTP error: 401) Failed issuing a new JWT from the JWT service., referer: https://10.10.25.80:8080 2023-11-28T17:39:39.572673+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34421640960] [client 172.16.5.155:62570] (401) Unable to create session., referer: https://10.10.25.80:8080 ...SNIP... 2023-11-28T17:39:39.603718+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34422848768] [client 172.16.5.155:62559] (STATUS_ACCESS_DENIED (0xC0000022) HTTP error: 401) Failed issuing a new JWT from the JWT service., referer: https://10.10.25.80:8080 2023-11-28T17:39:39.603728+00:00 <18.3> grantcluster-1(id1) httpd[98700]: [auth_isilon:error] [pid 98700:tid 34422848768] [client 172.16.5.155:62559] (401) Unable to create session., referer: https://10.10.25.80:8080 HTTP Access Log tail -f /var/log/apache2/webui_httpd_access.log 2023-11-28T17:41:43.101276+00:00 <19.6> grantcluster-1(id1) httpd[98697]: 172.16.5.155 - - [28/Nov/2023:17:41:43 +0000] \"POST /session/1/session HTTP/1.1\" 401 40 \"https://10.10.25.80:8080\" \"python-requests/2.28.1\" REST API Response Total Successful Sessions: 0 Authentication Failed: Status Code 401, Error: Unable to create session. While this is accurate, technically, it is extremely misleading and has lead to a substantial waste of resources investigating authentication failures when in reality the problem is that concurrent sessions was exceeded.","title":"Problem Details"},{"location":"PowerScale%20Failed%20Authentication/#expected-behavior","text":"The errors in Problem Details are misleading to both technicians and users. If the number of concurrent sessions is exceeded both the logs and the API responses should reflect that the issue is that the concurrent sessions have been exceeded instead of reporting an authentication error even if generating JWT tokens is the actual product of exceeding concurrent sessions. The error message should make it so technicians resolve the problem without having to rely on developer support.","title":"Expected Behavior"},{"location":"PowerScale%20Failed%20Authentication/#reproduction","text":"The below Python script will reproduce the problem. Replace the credentials with your PowerScale credentials and then run. It will generate 30 threads each of which will hold a session open for 10 seconds. If the number of concurrent sessions is below 30 it will fail. import requests import threading import time import urllib3 urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) def session_cookie_authentication(ip_address, username, password): \"\"\" Authenticate using Session Cookie and return the session cookies if successful. \"\"\" base_url = f\"https://{ip_address}:8080\" session_url = f\"{base_url}/session/1/session\" credentials = {\"username\": username, \"password\": password, \"services\": [\"platform\", \"namespace\"]} headers = {\"Content-Type\": \"application/json\", \"Referer\": base_url} try: response = requests.post(session_url, headers=headers, json=credentials, verify=False) if response.status_code == 201 and 'isisessid' in response.cookies: return response.cookies else: error_message = response.json().get('message', 'No detailed error message provided.') return f\"Authentication Failed: Status Code {response.status_code}, Error: {error_message}\" except Exception as e: return f\"Error during Session Cookie Authentication: {e}\" def create_and_hold_session(ip_address, username, password, hold_time, results): \"\"\" Create a session and hold it open for a specified duration. \"\"\" session_result = session_cookie_authentication(ip_address, username, password) if isinstance(session_result, requests.cookies.RequestsCookieJar): time.sleep(hold_time) # Hold the session results.append(\"Session created and held successfully.\") else: results.append(session_result) def main(): ip_address = \"10.10.25.80\" # Replace with the actual IP address of the PowerScale username = \"root\" password = \"YOUR_PASSWORD\" hold_time = 10 # Hold time in seconds session_threads = [] results = [] # Create 30 concurrent sessions for _ in range(30): thread = threading.Thread(target=create_and_hold_session, args=(ip_address, username, password, hold_time, results)) thread.start() session_threads.append(thread) # Wait for all threads to complete for thread in session_threads: thread.join() # Analyze results and print summary success_count = results.count(\"Session created and held successfully.\") print(f\"Total Successful Sessions: {success_count}\") error_messages = set([result for result in results if result != \"Session created and held successfully.\"]) for error in error_messages: print(error) if __name__ == \"__main__\": main()","title":"Reproduction"},{"location":"PowerScale%20Failed%20Authentication/#demonstration","text":"Confirm concurrent sessions is fixed at 15: grantcluster-1# isi auth settings global view Send NTLMv2: No Space Replacement: Workgroup: WORKGROUP Provider Hostname Lookup: disabled Alloc Retries: 5 User Object Cache Size: 47.68M On Disk Identity: native RPC Block Time: Now RPC Max Requests: 64 RPC Timeout: 30s Default LDAP TLS Revocation Check Level: none System GID Threshold: 80 System UID Threshold: 80 Min Mapped Rid: 2147483648 Group UID: 4294967292 Null GID: 4294967293 Null UID: 4294967293 Unknown GID: 4294967294 Unknown UID: 4294967294 Failed Login Delay Time: Now Concurrent Session Limit: 15 Now we run the above Python script: C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python310\\python.exe \"C:\\Users\\grant\\Documents\\code\\grantcurell.github.io\\docs\\PowerScale Failed Authentication\\multiple_sessions_test.py\" Total Successful Sessions: 0 Authentication Failed: Status Code 401, Error: Unable to create session. Change the concurrent sessions to 31: grantcluster-1# isi auth settings global modify --concurrent-session-limit=31 grantcluster-1# isi auth settings global view Send NTLMv2: No Space Replacement: Workgroup: WORKGROUP Provider Hostname Lookup: disabled Alloc Retries: 5 User Object Cache Size: 47.68M On Disk Identity: native RPC Block Time: Now RPC Max Requests: 64 RPC Timeout: 30s Default LDAP TLS Revocation Check Level: none System GID Threshold: 80 System UID Threshold: 80 Min Mapped Rid: 2147483648 Group UID: 4294967292 Null GID: 4294967293 Null UID: 4294967293 Unknown GID: 4294967294 Unknown UID: 4294967294 Failed Login Delay Time: Now Concurrent Session Limit: 31 Rerun the script: C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python310\\python.exe \"C:\\Users\\grant\\Documents\\code\\grantcurell.github.io\\docs\\PowerScale Failed Authentication\\multiple_sessions_test.py\" Total Successful Sessions: 30 Process finished with exit code 0","title":"Demonstration"},{"location":"PowerScale%20Failed%20Authentication/#cluster-setup","text":"","title":"Cluster Setup"},{"location":"PowerScale%20Failed%20Authentication/#rebuild","text":"I hopped on an old cluster I used for testing and ran isi_reformat_node","title":"Rebuild"},{"location":"PowerScale%20Failed%20Authentication/#initial-setup","text":"These are the settings I used for my build. Since I was building this in a lab I told it to use the internal IP addresses for external as well instead of making them separate sets. Configuration Item Value Cluster name grantcluster Encoding utf-8 int-a netmask 255.255.255.0 int-a IP ranges { 10.10.25.80-10.10.25.89 } int-a IP range { 10.10.25.80-10.10.25.89 } int-a gateway 10.10.25.1 SmartConnect zone name onefs DNS servers { 10.10.25.120 } Search domains { grant.lan, lan } After I joined the nodes together I confirmed they had a quorum: grantcluster-1# sysctl efs.gmp.has_quorum efs.gmp.has_quorum: 1 grantcluster-1# sysctl efs.gmp.has_super_block_quorum efs.gmp.has_super_block_quorum: 1 1 indicates success whereas 0 indicates that there is no quorum. Super Blocks are described here .","title":"Initial Setup"},{"location":"PowerScale%20Failed%20Authentication/#code-for-testing-authentication-mechanisms","text":"I used this code to test the different authentication mechanisms to confirm valid credentials.","title":"Code for Testing Authentication Mechanisms"},{"location":"PowerScale%20Failed%20Authentication/#concepts","text":"","title":"Concepts"},{"location":"PowerScale%20Failed%20Authentication/#super-block-quorum","text":"Referred to as efs.gmp.has_super_block_quorum , is a property that ensures the file system's integrity by requiring more than half of the nodes in the cluster to be available and in agreement over the internal network. This quorum prevents data conflicts, such as conflicting versions of the same file if two groups of nodes become unsynchronized. If a node is unreachable, OneFS will separate it from the cluster, known as splitting. Operations can continue as long as a quorum of nodes remains connected. If the split nodes can reconnect and re-synchronize, they rejoin the majority group in a process known as merging. The superblock quorum status can be checked by connecting to a node via SSH and running the sysctl efs.gmp.has_super_block_quorum command-line tool as root.","title":"Super Block Quorum"},{"location":"PowerScale%20Failed%20Authentication/#how-do-session-teardowns-work","text":"See Session Teardown Reverse Engineering","title":"How Do Session Teardowns Work?"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/","text":"How Does Session Teardown Work? I received a question about how the PowerScale does session teardown so below I walk through a mid-level overview of what that looks like. PowerScale leverages Apache so let's first understand what session teardown looks like from the webserver perspective. Session Teardown in Apache A highly detailed technical explanation of how Apache server handles session teardown, leading to a 204 response, involves understanding both the HTTP protocol and the specific implementation of session management in Apache. HTTP Protocol and the 204 Response 204 No Content : In HTTP, a 204 status code indicates that the server has successfully processed the request, but is not returning any content. This is often used in situations where the server's response itself is not important, but the confirmation of successful processing is. Request Reception : When a request to terminate a session (typically a DELETE request) is received, Apache first parses and interprets the HTTP request. Session Identification : Apache identifies the session to be terminated. This is done with a session identifier. Session Management : Apache uses modules for session management. These modules are responsible for creating, maintaining, and destroying sessions. When a session teardown is requested, the relevant module locates the session in its storage (which could be memory, a database, etc.). Session Validation : Before proceeding with the teardown, Apache checks if the session exists and whether the client making the request has the right to terminate it. Resource Cleanup : Upon successful validation, Apache instructs the session management module to release any resources associated with the session. This includes things like freeing memory, deleting session data from any running applications, and revoking authentication tokens. Session Destruction : The session is then marked for destruction. This means it's effectively invalidated and cannot be used for further requests. Client Notification : After the session is terminated, Apache sends a response back to the client. If there is no additional content to return (which is typical for session teardown), a 204 No Content response is used. This response is merely an acknowledgment that the request was successfully processed and the session was terminated. Logging and Monitoring : Apache logs this interaction for administrative and security purposes. This could include information about the request, the client IP, the session identifier, and the outcome of the operation. To demonstrate this I wrote trace_teardown.py . It sets up a session with the PowerScale and then tears it down. Now we can't see the guts of the PowerScale with this code (I'll get to that) but we can see all the Apache-side handling. C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python310\\python.exe \"C:\\Users\\grant\\Documents\\code\\grantcurell.github.io\\docs\\PowerScale Failed Authentication\\trace_teardown.py\" DEBUG:__main__:Attempting to authenticate and create a session... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): 10.10.25.80:8080 DEBUG:urllib3.connectionpool:https://10.10.25.80:8080 \"POST /session/1/session HTTP/1.1\" 201 104 DEBUG:__main__:Authentication response: 201, {\"services\":[\"platform\",\"namespace\"],\"timeout_absolute\":14400,\"timeout_inactive\":900,\"username\":\"root\"} DEBUG:__main__:Session successfully created. Cookies: {'isicsrf': '25cd0346-4204-4c5d-be1d-49630c78c4ff', 'isisessid': 'eyJhbGciOiJQUzUxMiJ9.eyJhdWQiOlsicGxhdGZvcm0iLCJuYW1lc3BhY2UiXSwiZXhwIjoxNzAxMjA5NDM4LCJpYXQiOjE3MDExOTUwMzgsIm9uZWZzL2NzcmYiOiIyNWNkMDM0Ni00MjA0LTRjNWQtYmUxZC00OTYzMGM3OGM0ZmYiLCJvbmVmcy9pcCI6IjE3Mi4xNi41LjE1NSIsIm9uZWZzL25vbmNlIjozOTM4NzI5NDg2NTQ2MDY1NjU2LCJvbmVmcy9zZXNzaW9uIjoiZThkYzYyM2ItOWM5Yy00YmE3LWE2MjAtYzQzZTdkNzBhMzlhIiwib25lZnMvdWEiOiJweXRob24tcmVxdWVzdHMvMi4yOC4xIiwib25lZnMvemlkIjoxLCJzdWIiOiJyb290In0K.nnaDPBOw6ZSHT66mguImZZL57PsMkodUG9S2Nop0_B3r3oSwgX-1CkL4R70_oGRDMPztaskMOVSbc0YsvHXERI9IqEdE2jZaseIAZIOmUEaqPDgpjEZzkBMAiqsAcp9kFAxhDInZHzJobJn7kSa3RBKFD1rr6fi8_MljtennkX8IWpwPOWutkVMN6MNGM0YUAPPLD6qnQ1VcbFeYZU6unljhj7-n7eLrvoOfWprWjTh6vtT1jHF-Ecu_uD5Tue5IMkivsAEFnti5-TCas1qatmWYG2jlXrOoHEH7q0fEv5ZUWO6T-jGxGLZtp4E01EBJzudlaSfCZqTpL4JPaZOgbJEyFiQU2BQp7Ik0lRkLqTUO40f1lJDDnIK4xDbiN_4cIGowQjq0yTcKlu-FW9hIC2xGajoICIAuMBIJz9mEh4R_Gcvap_K1vPo796Hib3xyM-fgdeUzS3GwTVBuBWPczZQP2UMLmKSFeJuuMDbsB3_tu4V_xqnsmxWSyP-E_Btudwi75lEOJNnA7N-vrU1VK8IyBEsNU2TIJ4f_BjTE3gMvyRsk-BXayqmQ4u9PwPOTISLKGpDGuAAgYEryb9N48O_AKojglMcGEdonHLI-ep4ajWV3es6KWCmpvblQ2tpP8mTVhIRVi4xefYUG_ZCF23CrtOgoYur843lz7Mx5iS0%3D'} DEBUG:__main__:Attempting to close the session... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): 10.10.25.80:8080 DEBUG:urllib3.connectionpool:https://10.10.25.80:8080 \"DELETE /session/1/session HTTP/1.1\" 204 0 DEBUG:__main__:Session closure response: 204, DEBUG:__main__:Session successfully closed. Here you can see the steps listed above play out to include visibility on both the session ID and the Cross-Site Request Forgery (CSRF) token. Now in addition to the above PowerScale is going to do a whole bunch of things internally and tracing each line of what happens would be an extremely long essay so we'll hit the highlights. Below is a copy of PowerScale's webui_http.conf which defines Apache's behaviors for any given thing. From this we have a very clear idea of how session teardown works on the PowerScale. The provided configuration file for PowerScale, which is leveraging Apache, offers insights into how Apache is configured and potentially how it handles sessions in this environment. Let\u2019s break down some key parts of the configuration related to session management and their implications: Session Authentication Modules : mod_auth_isilon - PowerScale's custom auth handler. This is handled by the shared library mod_auth_isilon.so . Now we don't have visibility into the code here, but realistically, these things follow design patterns that are pretty constant. If we were so inclined we could attach a debugger here, but the reality is we can make some pretty safe assumptions just based on how everyone does auth with Apache. The module is going to have all the code related to user authentication incluing the JWT tokens mentioned here README.md , it will handle session management and expiry, and it will likely make calls out to some other service for things like RBAC. IsiAuthSessionSecurity ip_check agent_check indicates additional security checks for session validation, like IP address and user-agent consistency. Worker Module Configuration : mpm_worker_module is used, which tells us it's a multi-threaded processing model. This module allows efficient handling of multiple concurrent connections, crucial for session management in a high-traffic environment. FastCGI for External Handlers : FastCGI ( mod_fastcgi ) is configured to communicate with external servers/processes like isi_papi_d , isi_rsapi_d , and isi_object_d . These external servers are responsible for handling other parts of the session lifecycle. Session-Specific Directives : <Location /session/1/session> tells us that session management (creation, validation, teardown) is handled by a specific handler ( SetHandler session-service ). IsiAuthSessionTimeoutInactive and IsiAuthSessionTimeoutAbsolute directives give session timeout settings Virtual Host Configuration : Within the <VirtualHost> section, you can see session-specific details. We see that SSL is enforced CSP is present There are a series of custom error documents which can be returned There are a lot of custom URL rewrites Specific URLs are handled by FastCGI . This includes all the APIs ErrorDocument Directives : Custom error documents for various HTTP status codes, including those that might be relevant to session handling (e.g., 401 Unauthorized). Understanding Session Teardown Apache itself, as configured here, doesn't directly reveal the mechanisms of session teardown. However, the combination of the worker module, SSL settings, custom authentication module, and external FastCGI processes suggests a complex session handling mechanism that is likely controlled both by Apache and additional PowerScale components. Teardown Process: Session Termination Request : A request to terminate a session (a DELETE request to the session endpoint) is received by Apache. Request Handling : Apache, through its worker module, accepts and processes the request Custom Authentication Module Processing : The mod_auth_isilon module, along with any session-related directives, validate the session and the request, ensuring that it's legitimate and authorized. Communication with External Handlers : If session management is partially offloaded to external processes (as seen in the FastCGI configuration), Apache forwards the relevant information to these processes. Session Invalidating and Cleanup : The responsible component (Apache module or external handler) invalidates the session, cleans up associated resources, and updates any necessary data stores. Response to Client : Once the session is successfully terminated, a response is sent back to the client. In the case of a successful teardown without further content, a 204 No Content response. Apache Config # X: ---------------- # X: This file is automatically generated and should not be # X: edited directly. If you must make changes to the # X: contents of this file it should be done via the PowerScale # X: Web UI, or via the template file located at # X: /etc/mcp/templates/webui_httpd.conf # X: ---------------- # ================================================= # Basic settings # ================================================= Listen 8080 https # ================================================= # Modules # ================================================= LoadModule unixd_module modules/mod_unixd.so LoadModule ssl_module modules/mod_ssl.so LoadModule authz_core_module modules/mod_authz_core.so LoadModule authn_core_module modules/mod_authn_core.so LoadModule authz_host_module modules/mod_authz_host.so LoadModule authz_user_module modules/mod_authz_user.so LoadModule mpm_worker_module modules/mod_mpm_worker.so LoadModule auth_isilon_module modules/mod_auth_isilon.so LoadModule cgid_module modules/mod_cgid.so LoadModule fastcgi_module modules/mod_fastcgi.so LoadModule alias_module modules/mod_alias.so LoadModule deflate_module modules/mod_deflate.so LoadModule dir_module modules/mod_dir.so LoadModule filter_module modules/mod_filter.so LoadModule headers_module modules/mod_headers.so LoadModule log_config_module modules/mod_log_config.so LoadModule mime_module modules/mod_mime.so LoadModule reqtimeout_module modules/mod_reqtimeout.so LoadModule rewrite_module modules/mod_rewrite.so LoadModule setenvif_module modules/mod_setenvif.so User daemon Group daemon UseCanonicalName On ServerRoot \"/usr/local/apache2\" DocumentRoot \"/usr/local/www/static\" PidFile \"/var/apache2/run/webui_httpd.pid\" Mutex flock:/var/apache2/run mpm-accept EnableMMAP Off EnableSendfile On KeepAlive On MaxKeepAliveRequests 500 KeepAliveTimeout 15 ## Implementing Clickjacking protection Header always set X-Frame-Options \"sameorigin\" ## MIME types advertised in the Content-Type headers should not be changed ## requires mod_headers.so (don't comment this line out) Header always set X-Content-Type-Options \"nosniff\" Header always set X-XSS-Protection \"1; mode=block\" #Hiding apache version in http header ServerTokens Prod ServerSignature Off ### Fix for CVE-2003-1567: HTTP TRACE / TRACK Methods Allowed ### TraceEnable off # Enable/Disable IsiAuthSessionSecurity agent_check and ip_check # IsiAuthSessionSecurity ip_check -> ip_check enabled # IsiAuthSessionSecurity -ip_check -> ip_check disabled # IsiAuthSessionSecurity agent_check -> agent_check enabled # IsiAuthSessionSecurity -agent_check -> agent_check disabled IsiAuthSessionSecurity ip_check agent_check # We must use a single process, multi-threaded server to correctly # cache user credentials (fds) across Platform API sessions. # StartServers: initial number of server processes to start # MaxRequestWorkers: maximum number of simultaneous client connections # MinSpareThreads: minimum number of worker threads which are kept spare # MaxSpareThreads: maximum number of worker threads which are kept spare # ThreadsPerChild: constant number of worker threads in each server process # MaxConnectionsPerChild: maximum number of requests a server process serves <IfModule mpm_worker_module> ServerLimit 1 StartServers 1 MaxRequestWorkers 64 MinSpareThreads 10 MaxSpareThreads 25 ThreadsPerChild 64 MaxConnectionsPerChild 0 </IfModule> # ================================================= # REQTIMEOUT # ================================================= <IfModule reqtimeout_module> RequestReadTimeout handshake=0 header=20-40,MinRate=500 body=20,MinRate=500 </IfModule> # ================================================= # Logging, Errors, User Agent # ================================================= LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined # Log errors with syslog to /var/log/apache2/webui_httpd_error.log ErrorLog syslog:local2 LogLevel error ErrorDocument 500 /httpd/500Text.html ErrorDocument 400 /httpd/400Text.html SetEnvIf User-Agent \".*MSIE.*\" \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 # ================================================= # Platform API # ================================================= <IfModule fastcgi_module> FastCgiExternalServer /usr/sbin/isi_papi_d -socket /var/run/papi.sock -pass-cred -idle-timeout 600 </IfModule> # ================================================= # Remote-Service API # ================================================= <IfModule fastcgi_module> FastCgiExternalServer /usr/sbin/isi_rsapi_d -socket /var/run/isi_rsapi_d.sock -pass-cred -idle-timeout 600 </IfModule> # ================================================= # Object API # ================================================= <IfModule fastcgi_module> FastCgiExternalServer /usr/sbin/isi_object_d -pass-cred -idle-timeout 2147483647 -socket /var/run/isi_object_d.sock </IfModule> # ================================================= # Files # ================================================= AcceptFilter http none AcceptFilter https none <IfModule dir_module> DirectoryIndex isilonnoindex.none </IfModule> <Directory /> Options FollowSymLinks AllowOverride None Require all denied </Directory> <Directory \"/usr/local/www/static\"> Options Indexes FollowSymLinks MultiViews AllowOverride None <LimitExcept GET POST DELETE HEAD> Require all denied </LimitExcept> </Directory> <FilesMatch \"^\\.ht\"> Require all denied </FilesMatch> <IfModule mime_module> TypesConfig conf/mime.types AddEncoding gzip .gz AddEncoding x-compress .Z AddType application/x-compress .Z AddType application/x-gzip .gz .tgz </IfModule> # ================================================= # SSL # ================================================= <IfModule ssl_module> AddType application/x-x509-ca-cert .crt AddType application/x-pkcs7-crl .crl SSLPassPhraseDialog builtin #SSLSessionCache dbm:/var/run/ssl_scache SSLSessionCache none SSLSessionCacheTimeout 300 Mutex flock:/var/apache2/run ssl-cache SSLRandomSeed startup file:/dev/urandom 1024 SSLRandomSeed connect file:/dev/urandom 1024 SSLProtocol -all -TLSv1.1 +TLSv1.2 SSLCipherSuite ECDHE+aRSA+AES:DHE+aRSA+AES:ECDHE+ECDSA+AES:@STRENGTH SSLHonorCipherOrder on SSLCompression off SSLSessionTickets off SSLPassPhraseDialog exec:/etc/mcp/scripts/httpd_keypass.py SSLProxyCheckPeerCN off SSLProxyCheckPeerName off SSLProxyCheckPeerExpire off SSLOpenSSLConfCmd DHParameters /usr/local/apache24/conf/webui_dhparams.pem SSLOpenSSLConfCmd Curves prime256v1:secp384r1:secp521r1 </IfModule> # ================================================= # Platform API Virtual Hosts # ================================================= <VirtualHost _default_:8080> SSLEngine on SSLCertificateFile /ifs/.ifsvar/modules/isi_certs/system/server/zone_1/certs/794429aa484f2be3114356307ea2ff0bf004a8fbaa66e3e9c8647a923720f1ba.crt SSLCertificateKeyFile /ifs/.ifsvar/modules/isi_certs/system/server/zone_1/private/794429aa484f2be3114356307ea2ff0bf004a8fbaa66e3e9c8647a923720f1ba.key DocumentRoot \"/usr/local/www/static\" ServerAdmin support@isilon.com Header set Content-Security-Policy \"default-src 'self' 'unsafe-inline' 'unsafe-eval' data:; script-src 'self' 'unsafe-eval'; style-src 'unsafe-inline' 'self'; \" # Log access with syslog to /var/log/apache2/webui_httpd_access.log CustomLog \"|$ logger -t httpd -p local3.info\" combined AddOutputFilterByType DEFLATE text/css text/javascript application/javascript application/x-javascript BrowserMatch ^Mozilla/4 gzip-only-text/html BrowserMatch ^Mozilla/4\\.0[678] no-gzip BrowserMatch \\bMSIE !no-gzip !gzip-only-text/html AllowEncodedSlashes On ErrorDocument 503 /httpd/503Text.html ErrorDocument 400 /httpd/400WebUIText.html ErrorDocument 401 /httpd/401WebUIText.html ErrorDocument 403 /httpd/403WebUIText.html ErrorDocument 404 /httpd/404WebUIText.html ErrorDocument 405 /httpd/405WebUIText.html ErrorDocument 422 /httpd/422WebUIText.html ErrorDocument 423 /httpd/423WebUIText.html ErrorDocument 424 /httpd/424WebUIText.html ErrorDocument 500 /httpd/500WebUIText.html <IfModule rewrite_module> RewriteEngine On #Uncomment these lines to debug rewrite rules #RewriteLog \"/var/log/apache2/webui_httpd_error.log\" #RewriteLogLevel 9 # Redirect internal subrequests to an error to prevent them from being # redirected to another module and causing another authentication. RewriteCond %{IS_SUBREQ} t RewriteRule ^ - [G] # Restrict unnecessary http methods RewriteCond %{REQUEST_METHOD} ^(PATCH|OPTIONS|TRACK|CONNECT|TRACE|COPY|LINK|UNLINK|PURGE|LOCK|UNLOCK|PROPFIND|VIEW) RewriteRule .* - [L,R=405] RewriteCond %{REQUEST_METHOD} ^(PATCH|OPTIONS|TRACK|CONNECT|TRACE|COPY|LINK|UNLINK|PURGE|LOCK|UNLOCK|PROPFIND|VIEW) RewriteRule .* - [L,R=405] RewriteCond %{REQUEST_METHOD} ^(PATCH|OPTIONS|TRACK|CONNECT|TRACE|COPY|LINK|UNLINK|PURGE|LOCK|UNLOCK|PROPFIND|VIEW) RewriteRule .* - [L,R=405] # Older UI versions will redirect to (legacy) Login # after an upgrade. Force them into the new system RewriteRule ^/$ /v2/html/OneFS.html RewriteRule ^/Login.* /v2/html/OneFS.html RewriteRule ^/cloudpool_eula.* /v2/html/cloudpool_eula.txt RewriteRule ^/OneFS$ /v2/html/OneFS.html # Reroute legacy /Status to base URI RewriteRule ^/Status* https://%{SERVER_ADDR}:8080/ [L,R] RewriteCond %{DOCUMENT_ROOT}%{REQUEST_FILENAME}.gz -f RewriteRule (.*\\.(html|js|css))$ $1.gz [L] # Rewrite all request past /OneFS to v3 RewriteRule ^/OneFS/(.*) /v3/$1 # For v3 requests, if the file exists on disk, serve it RewriteCond %{REQUEST_FILENAME} ^/v3 [NC] RewriteCond %{DOCUMENT_ROOT}%{REQUEST_FILENAME}.gz -f RewriteRule (.*)$ $1.gz [L] RewriteCond %{REQUEST_FILENAME} ^/v3 [NC] RewriteCond %{DOCUMENT_ROOT}%{REQUEST_FILENAME} -f RewriteRule ^ - [L] # For all request to v3 that do no exists (like 404) return the index file so # the app can handle them RewriteRule ^/v3 /v3/index.html.gz [L] # Stop requests for static files RewriteRule ^/(json|v2|vasa-catalog|httpd)/.* $0 [L] RewriteRule ^/namespace(.*) /namespace$1 [PT] RewriteRule ^/object(.*) - [R=503] RewriteRule ^/webhdfs(.*) - [R=503] RewriteRule ^/imagetransfer(.*) - [R=503] RewriteRule ^/jmx(.*) - [R=503] RewriteRule ^/authenticate /session/1/session [P] RewriteRule ^/objectstore(.*) /object$1 [PT] RewriteRule ^/favicon.ico /v2/images/favicon.ico [L] RewriteRule ^/MIBs/(.*) \"/usr/share/snmp/mibs/$1\" [L] RewriteRule ^/MIBs-DEFs/(.*) \"/usr/share/snmp/defs/$1\" [L] RewriteRule ^/platform(.*) /platform$1 [PT] RewriteRule ^/remote-service(.*) /remote-service$1 [PT] RewriteRule ^/session(.*) /session$1 [PT] RewriteRule ^/mod_ssl:error:HTTP-request https://%{SERVER_ADDR}:8080/ [L,R] </IfModule> <FilesMatch .*\\.html.gz> ForceType text/html </FilesMatch> <FilesMatch .*\\.css.gz> ForceType text/css </FilesMatch> <FilesMatch .*\\.js.gz> ForceType application/javascript </FilesMatch> <Directory \"/usr/share/snmp/mibs\"> Options Indexes MultiViews ForceType application/octet-stream AllowOverride None Require all granted </Directory> <Directory \"/usr/share/snmp/defs\"> Options Indexes MultiViews ForceType application/octet-stream AllowOverride None Require all granted </Directory> <Location /webhdfs> RemoveEncoding .gz .Z </Location> Header always add Strict-Transport-Security: \"max-age=31536000;\" # ================================================= # Platform API # ================================================= Alias /platform /usr/sbin/isi_papi_d <Location /platform> AuthType Isilon IsiAuthName \"platform\" IsiAuthTypeBasic Off IsiAuthTypeSessionCookie On IsiDisabledZoneAllow Off IsiMultiZoneAllow On IsiCsrfCheck On Require valid-user SetHandler fastcgi-script Options +ExecCGI ErrorDocument 400 /httpd/400PAPIText.html ErrorDocument 401 /httpd/401PAPIText.html ErrorDocument 403 /httpd/403PAPIText.html ErrorDocument 404 /httpd/404PAPIText.html ErrorDocument 405 /httpd/405PAPIText.html ErrorDocument 422 /httpd/422PAPIText.html ErrorDocument 423 /httpd/423PAPIText.html ErrorDocument 424 /httpd/424PAPIText.html ErrorDocument 500 /httpd/500PAPIText.html </Location> <Location /session/1/session> SetHandler session-service IsiAuthServices platform remote-service namespace ForceType text/plain ErrorDocument 401 /json/401.json </Location> <Location /session/1/saml/logout/slostatus> SetHandler saml-logout-slo ErrorDocument 401 /json/401.json </Location> <Location /session/1/saml/logout/session> SetHandler saml-logout-session ErrorDocument 401 /json/401.json </Location> # Authentication is not required to access these resources <Location /platform/*/cluster/identity> IsiAuthIgnore GET </Location> <Location /platform/*/cluster/identity/> IsiAuthIgnore GET </Location> <Location /platform/*/cluster/brand> IsiAuthIgnore GET </Location> <Location /platform/*/auth/users/*/change-password> IsiAuthIgnore PUT </Location> <Location /platform/*/auth/providers/saml-services/settings> IsiAuthIgnore GET </Location> <Location /platform/*/auth/providers/saml-services> IsiAuthIgnore GET </Location> <Location /platform/*/upgrade/cluster/mixed-mode> IsiAuthIgnore GET </Location> <Location /platform/*/cluster/version> IsiAuthIgnore GET </Location> # ================================================= # Object API # ================================================= Alias /namespace /usr/sbin/isi_object_d <Location /namespace> AuthType Isilon IsiAuthName \"namespace\" IsiAuthTypeBasic Off IsiAuthTypeSessionCookie On IsiDisabledZoneAllow Off IsiMultiZoneAllow On IsiCsrfCheck On Require valid-user SetHandler fastcgi-script Options +ExecCGI ErrorDocument 401 /json/401.json Header set Content-Security-Policy \"default-src 'none'\" </Location> # ================================================= # Remote-Service API # ================================================= Alias /remote-service /usr/sbin/isi_rsapi_d <Location /remote-service> AuthType Isilon IsiAuthName \"remote-service\" IsiAuthTypeBasic Off IsiAuthTypeSessionCookie On Require valid-user SetHandler fastcgi-script Options +ExecCGI ErrorDocument 401 /json/401.json </Location> # Session timeouts IsiAuthSessionTimeoutInactive 900 IsiAuthSessionTimeoutAbsolute 14400 Timeout 500 </VirtualHost>","title":"How Does Session Teardown Work?"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/#how-does-session-teardown-work","text":"I received a question about how the PowerScale does session teardown so below I walk through a mid-level overview of what that looks like. PowerScale leverages Apache so let's first understand what session teardown looks like from the webserver perspective.","title":"How Does Session Teardown Work?"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/#session-teardown-in-apache","text":"A highly detailed technical explanation of how Apache server handles session teardown, leading to a 204 response, involves understanding both the HTTP protocol and the specific implementation of session management in Apache.","title":"Session Teardown in Apache"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/#http-protocol-and-the-204-response","text":"204 No Content : In HTTP, a 204 status code indicates that the server has successfully processed the request, but is not returning any content. This is often used in situations where the server's response itself is not important, but the confirmation of successful processing is. Request Reception : When a request to terminate a session (typically a DELETE request) is received, Apache first parses and interprets the HTTP request. Session Identification : Apache identifies the session to be terminated. This is done with a session identifier. Session Management : Apache uses modules for session management. These modules are responsible for creating, maintaining, and destroying sessions. When a session teardown is requested, the relevant module locates the session in its storage (which could be memory, a database, etc.). Session Validation : Before proceeding with the teardown, Apache checks if the session exists and whether the client making the request has the right to terminate it. Resource Cleanup : Upon successful validation, Apache instructs the session management module to release any resources associated with the session. This includes things like freeing memory, deleting session data from any running applications, and revoking authentication tokens. Session Destruction : The session is then marked for destruction. This means it's effectively invalidated and cannot be used for further requests. Client Notification : After the session is terminated, Apache sends a response back to the client. If there is no additional content to return (which is typical for session teardown), a 204 No Content response is used. This response is merely an acknowledgment that the request was successfully processed and the session was terminated. Logging and Monitoring : Apache logs this interaction for administrative and security purposes. This could include information about the request, the client IP, the session identifier, and the outcome of the operation. To demonstrate this I wrote trace_teardown.py . It sets up a session with the PowerScale and then tears it down. Now we can't see the guts of the PowerScale with this code (I'll get to that) but we can see all the Apache-side handling. C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python310\\python.exe \"C:\\Users\\grant\\Documents\\code\\grantcurell.github.io\\docs\\PowerScale Failed Authentication\\trace_teardown.py\" DEBUG:__main__:Attempting to authenticate and create a session... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): 10.10.25.80:8080 DEBUG:urllib3.connectionpool:https://10.10.25.80:8080 \"POST /session/1/session HTTP/1.1\" 201 104 DEBUG:__main__:Authentication response: 201, {\"services\":[\"platform\",\"namespace\"],\"timeout_absolute\":14400,\"timeout_inactive\":900,\"username\":\"root\"} DEBUG:__main__:Session successfully created. Cookies: {'isicsrf': '25cd0346-4204-4c5d-be1d-49630c78c4ff', 'isisessid': 'eyJhbGciOiJQUzUxMiJ9.eyJhdWQiOlsicGxhdGZvcm0iLCJuYW1lc3BhY2UiXSwiZXhwIjoxNzAxMjA5NDM4LCJpYXQiOjE3MDExOTUwMzgsIm9uZWZzL2NzcmYiOiIyNWNkMDM0Ni00MjA0LTRjNWQtYmUxZC00OTYzMGM3OGM0ZmYiLCJvbmVmcy9pcCI6IjE3Mi4xNi41LjE1NSIsIm9uZWZzL25vbmNlIjozOTM4NzI5NDg2NTQ2MDY1NjU2LCJvbmVmcy9zZXNzaW9uIjoiZThkYzYyM2ItOWM5Yy00YmE3LWE2MjAtYzQzZTdkNzBhMzlhIiwib25lZnMvdWEiOiJweXRob24tcmVxdWVzdHMvMi4yOC4xIiwib25lZnMvemlkIjoxLCJzdWIiOiJyb290In0K.nnaDPBOw6ZSHT66mguImZZL57PsMkodUG9S2Nop0_B3r3oSwgX-1CkL4R70_oGRDMPztaskMOVSbc0YsvHXERI9IqEdE2jZaseIAZIOmUEaqPDgpjEZzkBMAiqsAcp9kFAxhDInZHzJobJn7kSa3RBKFD1rr6fi8_MljtennkX8IWpwPOWutkVMN6MNGM0YUAPPLD6qnQ1VcbFeYZU6unljhj7-n7eLrvoOfWprWjTh6vtT1jHF-Ecu_uD5Tue5IMkivsAEFnti5-TCas1qatmWYG2jlXrOoHEH7q0fEv5ZUWO6T-jGxGLZtp4E01EBJzudlaSfCZqTpL4JPaZOgbJEyFiQU2BQp7Ik0lRkLqTUO40f1lJDDnIK4xDbiN_4cIGowQjq0yTcKlu-FW9hIC2xGajoICIAuMBIJz9mEh4R_Gcvap_K1vPo796Hib3xyM-fgdeUzS3GwTVBuBWPczZQP2UMLmKSFeJuuMDbsB3_tu4V_xqnsmxWSyP-E_Btudwi75lEOJNnA7N-vrU1VK8IyBEsNU2TIJ4f_BjTE3gMvyRsk-BXayqmQ4u9PwPOTISLKGpDGuAAgYEryb9N48O_AKojglMcGEdonHLI-ep4ajWV3es6KWCmpvblQ2tpP8mTVhIRVi4xefYUG_ZCF23CrtOgoYur843lz7Mx5iS0%3D'} DEBUG:__main__:Attempting to close the session... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): 10.10.25.80:8080 DEBUG:urllib3.connectionpool:https://10.10.25.80:8080 \"DELETE /session/1/session HTTP/1.1\" 204 0 DEBUG:__main__:Session closure response: 204, DEBUG:__main__:Session successfully closed. Here you can see the steps listed above play out to include visibility on both the session ID and the Cross-Site Request Forgery (CSRF) token. Now in addition to the above PowerScale is going to do a whole bunch of things internally and tracing each line of what happens would be an extremely long essay so we'll hit the highlights. Below is a copy of PowerScale's webui_http.conf which defines Apache's behaviors for any given thing. From this we have a very clear idea of how session teardown works on the PowerScale. The provided configuration file for PowerScale, which is leveraging Apache, offers insights into how Apache is configured and potentially how it handles sessions in this environment. Let\u2019s break down some key parts of the configuration related to session management and their implications: Session Authentication Modules : mod_auth_isilon - PowerScale's custom auth handler. This is handled by the shared library mod_auth_isilon.so . Now we don't have visibility into the code here, but realistically, these things follow design patterns that are pretty constant. If we were so inclined we could attach a debugger here, but the reality is we can make some pretty safe assumptions just based on how everyone does auth with Apache. The module is going to have all the code related to user authentication incluing the JWT tokens mentioned here README.md , it will handle session management and expiry, and it will likely make calls out to some other service for things like RBAC. IsiAuthSessionSecurity ip_check agent_check indicates additional security checks for session validation, like IP address and user-agent consistency. Worker Module Configuration : mpm_worker_module is used, which tells us it's a multi-threaded processing model. This module allows efficient handling of multiple concurrent connections, crucial for session management in a high-traffic environment. FastCGI for External Handlers : FastCGI ( mod_fastcgi ) is configured to communicate with external servers/processes like isi_papi_d , isi_rsapi_d , and isi_object_d . These external servers are responsible for handling other parts of the session lifecycle. Session-Specific Directives : <Location /session/1/session> tells us that session management (creation, validation, teardown) is handled by a specific handler ( SetHandler session-service ). IsiAuthSessionTimeoutInactive and IsiAuthSessionTimeoutAbsolute directives give session timeout settings Virtual Host Configuration : Within the <VirtualHost> section, you can see session-specific details. We see that SSL is enforced CSP is present There are a series of custom error documents which can be returned There are a lot of custom URL rewrites Specific URLs are handled by FastCGI . This includes all the APIs ErrorDocument Directives : Custom error documents for various HTTP status codes, including those that might be relevant to session handling (e.g., 401 Unauthorized).","title":"HTTP Protocol and the 204 Response"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/#understanding-session-teardown","text":"Apache itself, as configured here, doesn't directly reveal the mechanisms of session teardown. However, the combination of the worker module, SSL settings, custom authentication module, and external FastCGI processes suggests a complex session handling mechanism that is likely controlled both by Apache and additional PowerScale components.","title":"Understanding Session Teardown"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/#teardown-process","text":"Session Termination Request : A request to terminate a session (a DELETE request to the session endpoint) is received by Apache. Request Handling : Apache, through its worker module, accepts and processes the request Custom Authentication Module Processing : The mod_auth_isilon module, along with any session-related directives, validate the session and the request, ensuring that it's legitimate and authorized. Communication with External Handlers : If session management is partially offloaded to external processes (as seen in the FastCGI configuration), Apache forwards the relevant information to these processes. Session Invalidating and Cleanup : The responsible component (Apache module or external handler) invalidates the session, cleans up associated resources, and updates any necessary data stores. Response to Client : Once the session is successfully terminated, a response is sent back to the client. In the case of a successful teardown without further content, a 204 No Content response.","title":"Teardown Process:"},{"location":"PowerScale%20Failed%20Authentication/session_teardown_reverse_engineering/#apache-config","text":"# X: ---------------- # X: This file is automatically generated and should not be # X: edited directly. If you must make changes to the # X: contents of this file it should be done via the PowerScale # X: Web UI, or via the template file located at # X: /etc/mcp/templates/webui_httpd.conf # X: ---------------- # ================================================= # Basic settings # ================================================= Listen 8080 https # ================================================= # Modules # ================================================= LoadModule unixd_module modules/mod_unixd.so LoadModule ssl_module modules/mod_ssl.so LoadModule authz_core_module modules/mod_authz_core.so LoadModule authn_core_module modules/mod_authn_core.so LoadModule authz_host_module modules/mod_authz_host.so LoadModule authz_user_module modules/mod_authz_user.so LoadModule mpm_worker_module modules/mod_mpm_worker.so LoadModule auth_isilon_module modules/mod_auth_isilon.so LoadModule cgid_module modules/mod_cgid.so LoadModule fastcgi_module modules/mod_fastcgi.so LoadModule alias_module modules/mod_alias.so LoadModule deflate_module modules/mod_deflate.so LoadModule dir_module modules/mod_dir.so LoadModule filter_module modules/mod_filter.so LoadModule headers_module modules/mod_headers.so LoadModule log_config_module modules/mod_log_config.so LoadModule mime_module modules/mod_mime.so LoadModule reqtimeout_module modules/mod_reqtimeout.so LoadModule rewrite_module modules/mod_rewrite.so LoadModule setenvif_module modules/mod_setenvif.so User daemon Group daemon UseCanonicalName On ServerRoot \"/usr/local/apache2\" DocumentRoot \"/usr/local/www/static\" PidFile \"/var/apache2/run/webui_httpd.pid\" Mutex flock:/var/apache2/run mpm-accept EnableMMAP Off EnableSendfile On KeepAlive On MaxKeepAliveRequests 500 KeepAliveTimeout 15 ## Implementing Clickjacking protection Header always set X-Frame-Options \"sameorigin\" ## MIME types advertised in the Content-Type headers should not be changed ## requires mod_headers.so (don't comment this line out) Header always set X-Content-Type-Options \"nosniff\" Header always set X-XSS-Protection \"1; mode=block\" #Hiding apache version in http header ServerTokens Prod ServerSignature Off ### Fix for CVE-2003-1567: HTTP TRACE / TRACK Methods Allowed ### TraceEnable off # Enable/Disable IsiAuthSessionSecurity agent_check and ip_check # IsiAuthSessionSecurity ip_check -> ip_check enabled # IsiAuthSessionSecurity -ip_check -> ip_check disabled # IsiAuthSessionSecurity agent_check -> agent_check enabled # IsiAuthSessionSecurity -agent_check -> agent_check disabled IsiAuthSessionSecurity ip_check agent_check # We must use a single process, multi-threaded server to correctly # cache user credentials (fds) across Platform API sessions. # StartServers: initial number of server processes to start # MaxRequestWorkers: maximum number of simultaneous client connections # MinSpareThreads: minimum number of worker threads which are kept spare # MaxSpareThreads: maximum number of worker threads which are kept spare # ThreadsPerChild: constant number of worker threads in each server process # MaxConnectionsPerChild: maximum number of requests a server process serves <IfModule mpm_worker_module> ServerLimit 1 StartServers 1 MaxRequestWorkers 64 MinSpareThreads 10 MaxSpareThreads 25 ThreadsPerChild 64 MaxConnectionsPerChild 0 </IfModule> # ================================================= # REQTIMEOUT # ================================================= <IfModule reqtimeout_module> RequestReadTimeout handshake=0 header=20-40,MinRate=500 body=20,MinRate=500 </IfModule> # ================================================= # Logging, Errors, User Agent # ================================================= LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined # Log errors with syslog to /var/log/apache2/webui_httpd_error.log ErrorLog syslog:local2 LogLevel error ErrorDocument 500 /httpd/500Text.html ErrorDocument 400 /httpd/400Text.html SetEnvIf User-Agent \".*MSIE.*\" \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 # ================================================= # Platform API # ================================================= <IfModule fastcgi_module> FastCgiExternalServer /usr/sbin/isi_papi_d -socket /var/run/papi.sock -pass-cred -idle-timeout 600 </IfModule> # ================================================= # Remote-Service API # ================================================= <IfModule fastcgi_module> FastCgiExternalServer /usr/sbin/isi_rsapi_d -socket /var/run/isi_rsapi_d.sock -pass-cred -idle-timeout 600 </IfModule> # ================================================= # Object API # ================================================= <IfModule fastcgi_module> FastCgiExternalServer /usr/sbin/isi_object_d -pass-cred -idle-timeout 2147483647 -socket /var/run/isi_object_d.sock </IfModule> # ================================================= # Files # ================================================= AcceptFilter http none AcceptFilter https none <IfModule dir_module> DirectoryIndex isilonnoindex.none </IfModule> <Directory /> Options FollowSymLinks AllowOverride None Require all denied </Directory> <Directory \"/usr/local/www/static\"> Options Indexes FollowSymLinks MultiViews AllowOverride None <LimitExcept GET POST DELETE HEAD> Require all denied </LimitExcept> </Directory> <FilesMatch \"^\\.ht\"> Require all denied </FilesMatch> <IfModule mime_module> TypesConfig conf/mime.types AddEncoding gzip .gz AddEncoding x-compress .Z AddType application/x-compress .Z AddType application/x-gzip .gz .tgz </IfModule> # ================================================= # SSL # ================================================= <IfModule ssl_module> AddType application/x-x509-ca-cert .crt AddType application/x-pkcs7-crl .crl SSLPassPhraseDialog builtin #SSLSessionCache dbm:/var/run/ssl_scache SSLSessionCache none SSLSessionCacheTimeout 300 Mutex flock:/var/apache2/run ssl-cache SSLRandomSeed startup file:/dev/urandom 1024 SSLRandomSeed connect file:/dev/urandom 1024 SSLProtocol -all -TLSv1.1 +TLSv1.2 SSLCipherSuite ECDHE+aRSA+AES:DHE+aRSA+AES:ECDHE+ECDSA+AES:@STRENGTH SSLHonorCipherOrder on SSLCompression off SSLSessionTickets off SSLPassPhraseDialog exec:/etc/mcp/scripts/httpd_keypass.py SSLProxyCheckPeerCN off SSLProxyCheckPeerName off SSLProxyCheckPeerExpire off SSLOpenSSLConfCmd DHParameters /usr/local/apache24/conf/webui_dhparams.pem SSLOpenSSLConfCmd Curves prime256v1:secp384r1:secp521r1 </IfModule> # ================================================= # Platform API Virtual Hosts # ================================================= <VirtualHost _default_:8080> SSLEngine on SSLCertificateFile /ifs/.ifsvar/modules/isi_certs/system/server/zone_1/certs/794429aa484f2be3114356307ea2ff0bf004a8fbaa66e3e9c8647a923720f1ba.crt SSLCertificateKeyFile /ifs/.ifsvar/modules/isi_certs/system/server/zone_1/private/794429aa484f2be3114356307ea2ff0bf004a8fbaa66e3e9c8647a923720f1ba.key DocumentRoot \"/usr/local/www/static\" ServerAdmin support@isilon.com Header set Content-Security-Policy \"default-src 'self' 'unsafe-inline' 'unsafe-eval' data:; script-src 'self' 'unsafe-eval'; style-src 'unsafe-inline' 'self'; \" # Log access with syslog to /var/log/apache2/webui_httpd_access.log CustomLog \"|$ logger -t httpd -p local3.info\" combined AddOutputFilterByType DEFLATE text/css text/javascript application/javascript application/x-javascript BrowserMatch ^Mozilla/4 gzip-only-text/html BrowserMatch ^Mozilla/4\\.0[678] no-gzip BrowserMatch \\bMSIE !no-gzip !gzip-only-text/html AllowEncodedSlashes On ErrorDocument 503 /httpd/503Text.html ErrorDocument 400 /httpd/400WebUIText.html ErrorDocument 401 /httpd/401WebUIText.html ErrorDocument 403 /httpd/403WebUIText.html ErrorDocument 404 /httpd/404WebUIText.html ErrorDocument 405 /httpd/405WebUIText.html ErrorDocument 422 /httpd/422WebUIText.html ErrorDocument 423 /httpd/423WebUIText.html ErrorDocument 424 /httpd/424WebUIText.html ErrorDocument 500 /httpd/500WebUIText.html <IfModule rewrite_module> RewriteEngine On #Uncomment these lines to debug rewrite rules #RewriteLog \"/var/log/apache2/webui_httpd_error.log\" #RewriteLogLevel 9 # Redirect internal subrequests to an error to prevent them from being # redirected to another module and causing another authentication. RewriteCond %{IS_SUBREQ} t RewriteRule ^ - [G] # Restrict unnecessary http methods RewriteCond %{REQUEST_METHOD} ^(PATCH|OPTIONS|TRACK|CONNECT|TRACE|COPY|LINK|UNLINK|PURGE|LOCK|UNLOCK|PROPFIND|VIEW) RewriteRule .* - [L,R=405] RewriteCond %{REQUEST_METHOD} ^(PATCH|OPTIONS|TRACK|CONNECT|TRACE|COPY|LINK|UNLINK|PURGE|LOCK|UNLOCK|PROPFIND|VIEW) RewriteRule .* - [L,R=405] RewriteCond %{REQUEST_METHOD} ^(PATCH|OPTIONS|TRACK|CONNECT|TRACE|COPY|LINK|UNLINK|PURGE|LOCK|UNLOCK|PROPFIND|VIEW) RewriteRule .* - [L,R=405] # Older UI versions will redirect to (legacy) Login # after an upgrade. Force them into the new system RewriteRule ^/$ /v2/html/OneFS.html RewriteRule ^/Login.* /v2/html/OneFS.html RewriteRule ^/cloudpool_eula.* /v2/html/cloudpool_eula.txt RewriteRule ^/OneFS$ /v2/html/OneFS.html # Reroute legacy /Status to base URI RewriteRule ^/Status* https://%{SERVER_ADDR}:8080/ [L,R] RewriteCond %{DOCUMENT_ROOT}%{REQUEST_FILENAME}.gz -f RewriteRule (.*\\.(html|js|css))$ $1.gz [L] # Rewrite all request past /OneFS to v3 RewriteRule ^/OneFS/(.*) /v3/$1 # For v3 requests, if the file exists on disk, serve it RewriteCond %{REQUEST_FILENAME} ^/v3 [NC] RewriteCond %{DOCUMENT_ROOT}%{REQUEST_FILENAME}.gz -f RewriteRule (.*)$ $1.gz [L] RewriteCond %{REQUEST_FILENAME} ^/v3 [NC] RewriteCond %{DOCUMENT_ROOT}%{REQUEST_FILENAME} -f RewriteRule ^ - [L] # For all request to v3 that do no exists (like 404) return the index file so # the app can handle them RewriteRule ^/v3 /v3/index.html.gz [L] # Stop requests for static files RewriteRule ^/(json|v2|vasa-catalog|httpd)/.* $0 [L] RewriteRule ^/namespace(.*) /namespace$1 [PT] RewriteRule ^/object(.*) - [R=503] RewriteRule ^/webhdfs(.*) - [R=503] RewriteRule ^/imagetransfer(.*) - [R=503] RewriteRule ^/jmx(.*) - [R=503] RewriteRule ^/authenticate /session/1/session [P] RewriteRule ^/objectstore(.*) /object$1 [PT] RewriteRule ^/favicon.ico /v2/images/favicon.ico [L] RewriteRule ^/MIBs/(.*) \"/usr/share/snmp/mibs/$1\" [L] RewriteRule ^/MIBs-DEFs/(.*) \"/usr/share/snmp/defs/$1\" [L] RewriteRule ^/platform(.*) /platform$1 [PT] RewriteRule ^/remote-service(.*) /remote-service$1 [PT] RewriteRule ^/session(.*) /session$1 [PT] RewriteRule ^/mod_ssl:error:HTTP-request https://%{SERVER_ADDR}:8080/ [L,R] </IfModule> <FilesMatch .*\\.html.gz> ForceType text/html </FilesMatch> <FilesMatch .*\\.css.gz> ForceType text/css </FilesMatch> <FilesMatch .*\\.js.gz> ForceType application/javascript </FilesMatch> <Directory \"/usr/share/snmp/mibs\"> Options Indexes MultiViews ForceType application/octet-stream AllowOverride None Require all granted </Directory> <Directory \"/usr/share/snmp/defs\"> Options Indexes MultiViews ForceType application/octet-stream AllowOverride None Require all granted </Directory> <Location /webhdfs> RemoveEncoding .gz .Z </Location> Header always add Strict-Transport-Security: \"max-age=31536000;\" # ================================================= # Platform API # ================================================= Alias /platform /usr/sbin/isi_papi_d <Location /platform> AuthType Isilon IsiAuthName \"platform\" IsiAuthTypeBasic Off IsiAuthTypeSessionCookie On IsiDisabledZoneAllow Off IsiMultiZoneAllow On IsiCsrfCheck On Require valid-user SetHandler fastcgi-script Options +ExecCGI ErrorDocument 400 /httpd/400PAPIText.html ErrorDocument 401 /httpd/401PAPIText.html ErrorDocument 403 /httpd/403PAPIText.html ErrorDocument 404 /httpd/404PAPIText.html ErrorDocument 405 /httpd/405PAPIText.html ErrorDocument 422 /httpd/422PAPIText.html ErrorDocument 423 /httpd/423PAPIText.html ErrorDocument 424 /httpd/424PAPIText.html ErrorDocument 500 /httpd/500PAPIText.html </Location> <Location /session/1/session> SetHandler session-service IsiAuthServices platform remote-service namespace ForceType text/plain ErrorDocument 401 /json/401.json </Location> <Location /session/1/saml/logout/slostatus> SetHandler saml-logout-slo ErrorDocument 401 /json/401.json </Location> <Location /session/1/saml/logout/session> SetHandler saml-logout-session ErrorDocument 401 /json/401.json </Location> # Authentication is not required to access these resources <Location /platform/*/cluster/identity> IsiAuthIgnore GET </Location> <Location /platform/*/cluster/identity/> IsiAuthIgnore GET </Location> <Location /platform/*/cluster/brand> IsiAuthIgnore GET </Location> <Location /platform/*/auth/users/*/change-password> IsiAuthIgnore PUT </Location> <Location /platform/*/auth/providers/saml-services/settings> IsiAuthIgnore GET </Location> <Location /platform/*/auth/providers/saml-services> IsiAuthIgnore GET </Location> <Location /platform/*/upgrade/cluster/mixed-mode> IsiAuthIgnore GET </Location> <Location /platform/*/cluster/version> IsiAuthIgnore GET </Location> # ================================================= # Object API # ================================================= Alias /namespace /usr/sbin/isi_object_d <Location /namespace> AuthType Isilon IsiAuthName \"namespace\" IsiAuthTypeBasic Off IsiAuthTypeSessionCookie On IsiDisabledZoneAllow Off IsiMultiZoneAllow On IsiCsrfCheck On Require valid-user SetHandler fastcgi-script Options +ExecCGI ErrorDocument 401 /json/401.json Header set Content-Security-Policy \"default-src 'none'\" </Location> # ================================================= # Remote-Service API # ================================================= Alias /remote-service /usr/sbin/isi_rsapi_d <Location /remote-service> AuthType Isilon IsiAuthName \"remote-service\" IsiAuthTypeBasic Off IsiAuthTypeSessionCookie On Require valid-user SetHandler fastcgi-script Options +ExecCGI ErrorDocument 401 /json/401.json </Location> # Session timeouts IsiAuthSessionTimeoutInactive 900 IsiAuthSessionTimeoutAbsolute 14400 Timeout 500 </VirtualHost>","title":"Apache Config"},{"location":"PowerScale%20Setup/","text":"PowerScale Setup PowerScale Setup Testing Test 1 - Generic Share Against Windows 11 Against Rocky Linux 9 Test 2 - Add FIPS Add FIPS Test Against Windows 11 Set Up Active Directory Test Against Rocky Linux 9 How Kerberos Works in This Scenario What is a Service Principal Debugging Testing Test 1 - Generic Share Created a system user grant on the local OS, set up a share, and gave that user privileges. Against Windows 11 I was able to access that without issue Default communication happened with SMBv2 Against Rocky Linux 9 Ran command sudo mount.cifs //10.10.25.80/ifs ~/share -o vers=2.0,username=grant,password='somepassword' which gave mount error(2): No such file or directory Received: I think the \"STATUS_FS_DRIVER_REQUIRED\" may be misleading because I have the CIFS module: [root@acas ~]# lsmod | grep cif cifs 2355200 0 cifs_arc4 16384 1 cifs rdma_cm 139264 1 cifs ib_core 450560 4 rdma_cm,cifs,iw_cm,ib_cm cifs_md4 16384 1 cifs dns_resolver 16384 1 cifs The problem was I was providing the share path not the share name - like a genius. sudo mount -t cifs //10.10.25.80/testshare /root/share -o username=grant,password='somepassword' works. Test 2 - Add FIPS Add FIPS Working from this procedure Check if FIPS is already active gcluster-1# isi security settings view FIPS Mode Enabled: No USB Ports Disabled: No Restricted shell Enabled: No Make sure nodes are healthy gcluster-1# isi status Cluster Name: gcluster Cluster Health: [ ATTN] Data Reduction: 1.00 : 1 Storage Efficiency: 0.31 : 1 Cluster Storage: HDD SSD Storage Size: 168.1G (234.9G Raw) 0 (0 Raw) VHS Size: 66.8G Used: 327.9M (< 1%) 0 (n/a) Avail: 167.8G (> 99%) 0 (n/a) Health Ext Throughput (bps) HDD Storage SSD Storage ID |IP Address |DASR |C/N| In Out Total| Used / Size |Used / Size ---+---------------+-----+---+-----+-----+-----+-----------------+----------------- 1|10.10.25.80 |-A-- | C |27.1k| 2.1M| 2.1M| 126M/56.0G(< 1%)|(No Storage SSDs) 2|10.10.25.81 |-A-- | C | 0|67.1k|67.1k| 109M/56.0G(< 1%)|(No Storage SSDs) 3|10.10.25.82 |-A-- | C | 0| 270k| 270k|93.1M/56.0G(< 1%)|(No Storage SSDs) ---+---------------+-----+---+-----+-----+-----+-----------------+----------------- Cluster Totals: |27.1k| 2.4M| 2.4M| 328M/ 168G(< 1%)|(No Storage SSDs) Health Fields: D = Down, A = Attention, S = Smartfailed, R = Read-Only External Network Fields: C = Connected, N = Not Connected Critical Events: Time LNN Event --------------- ---- ------------------------------------------------------- 07/27 12:04:21 1 One or more drives (location(s) Bay 7, Bay 8, Bay ... 07/27 12:30:35 3 Missing COMMITTED image in secure catalog 07/27 12:30:56 2 One or more drives (location(s) Bay 7, Bay 8, Bay ... 07/27 12:35:35 3 One or more drives (location(s) Bay 7, Bay 8, Bay ... Cluster Job Status: No running jobs. No paused or waiting jobs. No failed jobs. Recent job results: Time Job Event --------------- -------------------------- ------------------------------ 07/27 12:29:37 MultiScan[3] Succeeded 07/27 12:22:42 MultiScan[2] Succeeded 07/27 11:58:30 DomainTag[1] Succeeded Turn on FIPS gcluster-1# isi security settings modify --fips-mode-enabled=true gcluster-1# isi security settings view FIPS Mode Enabled: Yes USB Ports Disabled: No Restricted shell Enabled: No Test Against Windows 11 It nows fails: This tracks since it's clear from the NTLMSSP_NEGOTIATE flag that it is using NTLM which the docs say is disabled. Note: Updating the password hash also implicitly disables the NTLM support for SMB access that is used when shares are accessed through IP. The instructions also tell you to explicitly make the hash type SHA512 which also issues the warning regarding NTLM: gcluster-1# isi auth file modify System --password-hash-type=SHA512 NTLM support and authentication for all file protocols has been disabled for this provider due to change of password hash type. gcluster-1# isi auth local modify System --password-hash-type=SHA512 It also seems that without manual intervention the SSH key/cipher settings are more permissive than they should be: gcluster-1# isi ssh settings view Banner: /etc/motd CA Signature Algorithms: ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsa Ciphers: aes256-ctr Host Key Algorithms: +ssh-dss,ssh-dss-cert-v01@openssh.com Ignore Rhosts: Yes Kex Algorithms: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group14-sha256,diffie-hellman-group-exchange-sha256 Login Grace Time: 2m Log Level: INFO Macs: hmac-sha2-256 Max Auth Tries: 3 Max Sessions: - Max Startups: Permit Empty Passwords: No Permit Root Login: Yes Port: 22 Print Motd: Yes Pubkey Accepted Key Types: +ssh-dss,ssh-dss-cert-v01@openssh.com,ssh-rsa Strict Modes: No Subsystem: sftp /usr/local/libexec/sftp-server Syslog Facility: AUTH Tcp Keep Alive: No Auth Settings Template: any You have to follow this guide to fix them gcluster-1# isi ssh settings modify --kex-algorithms 'diffie-hellman-group16-sha512,diffie-hellman-group16-sha512,ecdh-sha2-nistp384' gcluster-1# isi ssh settings modify --ciphers 'aes256-ctr,aes256-gcm@openssh.com' gcluster-1# isi ssh settings modify --host-key-algorithms 'ecdsa-sha2-nistp384' gcluster-1# gcluster-1# isi_for_array 'yes | /usr/local/bin/ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -b 384 -N \"\"' gcluster-3: Generating public/private ecdsa key pair. gcluster-3: /etc/ssh/ssh_host_ecdsa_key already exists. gcluster-3: Overwrite (y/n)? Your identification has been saved in /etc/ssh/ssh_host_ecdsa_key gcluster-3: Your public key has been saved in /etc/ssh/ssh_host_ecdsa_key.pub gcluster-3: The key fingerprint is: gcluster-3: SHA256:D6AMW5qyjg0jk61DRU2ed67zxOtqydWEU0xxzsnV+4Y root@gcluster-3 gcluster-3: The key's randomart image is: gcluster-3: +---[ECDSA 384]---+ gcluster-3: | o. oo.. ..| gcluster-3: | .... o= o .| gcluster-3: | o .o.. .o = .| gcluster-3: | O ...oo . . | gcluster-3: |. = o S.+ ..| gcluster-3: | * o+ . E o| gcluster-3: |O . .ooo. . | gcluster-3: |=* ++ . | gcluster-3: |oo. ..o+ | gcluster-3: +----[SHA256]-----+ gcluster-2: Generating public/private ecdsa key pair. gcluster-2: /etc/ssh/ssh_host_ecdsa_key already exists. gcluster-1: Generating public/private ecdsa key pair. gcluster-1: /etc/ssh/ssh_host_ecdsa_key already exists. gcluster-2: Overwrite (y/n)? Your identification has been saved in /etc/ssh/ssh_host_ecdsa_key gcluster-2: Your public key has been saved in /etc/ssh/ssh_host_ecdsa_key.pub gcluster-2: The key fingerprint is: gcluster-2: SHA256:mv24dik4vJVvGbHhOorynFlNa8N6Ol2kiRGwoMrWuCs root@gcluster-2 gcluster-2: The key's randomart image is: gcluster-2: +---[ECDSA 384]---+ gcluster-2: | . .. | gcluster-2: | . . .. | gcluster-2: |. . . | gcluster-2: |o o . + | gcluster-2: |.+ . oS= + | gcluster-2: |. . .Boo= | gcluster-2: | . .+oXo + | gcluster-2: |E o. ==+B== | gcluster-2: |.. o* =Oo*o | gcluster-2: +----[SHA256]-----+ gcluster-1: Overwrite (y/n)? Your identification has been saved in /etc/ssh/ssh_host_ecdsa_key gcluster-1: Your public key has been saved in /etc/ssh/ssh_host_ecdsa_key.pub gcluster-1: The key fingerprint is: gcluster-1: SHA256:ahrGrkc/YE1Ii4+YCxJgwFraGmiG2cb6M3yaY/AwMNA root@gcluster-1 gcluster-1: The key's randomart image is: gcluster-1: +---[ECDSA 384]---+ gcluster-1: |+. | gcluster-1: |ooE . | gcluster-1: |BB o o | gcluster-1: |@o* o . | gcluster-1: |+X o o S | gcluster-1: |@ ..= .. | gcluster-1: |oO o+oo | gcluster-1: |. O+o+o | gcluster-1: | .+Oo . | gcluster-1: +----[SHA256]-----+ gcluster-1# gcluster-1# isi ssh settings modify --pubkey-accepted-key-types 'ssh-rsa' gcluster-1# isi ssh settings modify --macs 'hmac-sha2-256,hmac-sha2-512,hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com' gcluster-1# isi ssh settings view Banner: /etc/motd CA Signature Algorithms: ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsa Ciphers: aes256-ctr,aes256-gcm@openssh.com Host Key Algorithms: ecdsa-sha2-nistp384 Ignore Rhosts: Yes Kex Algorithms: diffie-hellman-group16-sha512,diffie-hellman-group16-sha512,ecdh-sha2-nistp384 Login Grace Time: 2m Log Level: INFO Macs: hmac-sha2-256,hmac-sha2-512,hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com Max Auth Tries: 3 Max Sessions: - Max Startups: Permit Empty Passwords: No Permit Root Login: Yes Port: 22 Print Motd: Yes Pubkey Accepted Key Types: ssh-rsa Strict Modes: No Subsystem: sftp /usr/local/libexec/sftp-server Syslog Facility: AUTH Tcp Keep Alive: No Auth Settings Template: any From the guide on having to disable FIPS mode: PowerScale clusters running OneFS 9.4.0.0 with FIPS mode enabled may upgrade to OneFS 9.5.0.0 or later. After upgrading to OneFS Release 9.5.0.0 or later and committing the upgrade, re-enable FIPS mode. Disabling FIPS mode before upgrading is not required. I noticed that turning on FIPS immediately broke the admin user for the web ui At this point I set up active directory I added domain admins to the admins roles for system and security for powerscale I added my grant domain user to the SMB share: At this point I swapped over to Linux. Set Up Active Directory I already had an active directory server to test against I was not able to join with isi auth ads create --name=win-6c2vli4n0lo.grant.lan --user=administrator --groupnet=groupnet0 DO NOT select the RFC2309 option Test Against Rocky Linux 9 Join the domain # Install required packages sudo dnf install -y realmd sssd oddjob oddjob-mkhomedir adcli samba-common # Discover and join the Active Directory domain sudo realm discover grant.lan sudo realm join -U administrator grant.lan # Allow domain users to log in sudo authselect select sssd --force # Enable home directory creation for domain users sudo systemctl enable oddjobd sudo systemctl start oddjobd # Verify the domain membership and users realm list Ensure domain join successful: [root@acas ~]# realm list grant.lan type: kerberos realm-name: GRANT.LAN domain-name: grant.lan configured: kerberos-member server-software: active-directory client-software: sssd required-package: oddjob required-package: oddjob-mkhomedir required-package: sssd required-package: adcli required-package: samba-common-tools login-formats: %U@grant.lan login-policy: allow-realm-logins Run the mount: [root@acas ~]# sudo mount -t cifs //10.10.25.80/testshare /mnt/testshare -o username=administrator,domain=grant.lan,password=somepassword mount error(13): Permission denied Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) Attempt to setting sec=krb5 returns bug-looking results: [root@acas ~]# sudo mount -t cifs //10.10.25.80/testshare /mnt/testshare -o username=administrator,domain=grant.lan,sec=krb5 mount error(0): Success Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) when you inspect dmseg you see: [86217.278254] CIFS: VFS: \\\\10.10.25.80 Send error in SessSetup = -13 [86228.682870] CIFS: Attempting to mount \\\\10.10.25.80\\testshare [86228.816520] CIFS: VFS: Verify user has a krb5 ticket and keyutils is installed [86228.816530] CIFS: VFS: \\\\10.10.25.80 Send error in SessSetup = -126 [86228.816564] CIFS: VFS: cifs_mount failed w/return code = -126 How Kerberos Works in This Scenario Overview: https://www.freecodecamp.org/news/how-does-kerberos-work-authentication-protocol/ Synopsis: the Active Directory user administrator@grant.lan logged into the Rocky 9 client ( acas.lan ) wants to mount a CIFS share on the Dell PowerScale ( gcluster-1 ) that requires Active Directory Kerberos authentication. TGT Acquisition with kinit: Before attempting to mount the CIFS share, the user administrator@grant.lan on the Rocky 9 client ( acas.lan ) must obtain a Ticket Granting Ticket (TGT) from the Key Distribution Center (KDC). To get the TGT, the user runs the kinit command and provides their password when prompted: bash-5.1$ kinit administrator@grant.lan Password for administrator@grant.lan: TGT Request to KDC: With the TGT in hand, the Rocky 9 client ( acas.lan ) can now initiate the request to mount the CIFS share on the Dell PowerScale ( gcluster-1 ) using the mount command. CIFS Share Mount: The user administrator@grant.lan runs the mount command with the required options to mount the CIFS share on the Dell PowerScale: bash-5.1$ sudo mount -t cifs //10.10.25.80/testshare /mnt/testshare -o username=administrator@grant.lan,domain=GRANT.LAN,sec=krb5 TGT Usage and Service Principal: The mount command uses the TGT acquired earlier to authenticate and obtain the Service Ticket from the KDC for accessing the CIFS service on gcluster-1 . The Service Ticket is generated for the service principal associated with the CIFS service on gcluster-1 . In this case, the service principal is CIFS/gcluster-1.grant.lan@GRANT.LAN . Service Ticket Response: The KDC ( dc.grant.lan ) validates the TGT and generates a Service Ticket for the CIFS service ( CIFS/gcluster-1.grant.lan ) on the Dell PowerScale. Mounting the CIFS Share: With the Service Ticket, the Rocky 9 client ( acas.lan ) successfully mounts the CIFS share on the Dell PowerScale ( gcluster-1 ) at the specified mount point. The user acquires a TGT using kinit , and then the mount command leverages the TGT to request and obtain the Service Ticket for the CIFS share from the KDC. The Service Ticket is then used for mounting the CIFS share on the Dell PowerScale, allowing the user to access the share securely without re-entering their password during the session. Mounting the CIFS Share: The Rocky 9 client ( acas.lan ) receives the Service Ticket and sends it, along with the request to mount the CIFS share, to the Dell PowerScale ( gcluster-1 ). The Dell PowerScale ( gcluster-1 ) decrypts the Service Ticket using the session key shared with the client and validates the user's identity and permissions to access the CIFS share. If everything checks out, the CIFS share is successfully mounted on the Rocky 9 client ( acas.lan ). Session Key for Secure Communication: The client ( acas.lan ) and the CIFS service on the Dell PowerScale ( gcluster-1 ) now have a shared session key for secure communication during the CIFS session. Throughout this process, the client, KDC, and CIFS service use symmetric encryption and shared secret keys to securely exchange credentials and generate tickets. Once the user is authenticated with a TGT, they can access the CIFS share without having to re-enter their password during the session. This provides a secure and seamless single sign-on (SSO) experience for the user. What is a Service Principal A service principal is a unique identity within a Kerberos-based authentication system that represents a specific network service or application. In a Kerberos authentication environment, each network service (e.g., web server, email server, file server) is assigned its own service principal, which is used to authenticate and authorize clients to access the service securely. Service principals are created and managed by the Key Distribution Center (KDC) in the Kerberos realm. The KDC issues a set of cryptographic keys to each service principal, which are used for secure communication between the client and the service. When a client wants to access a network service that requires Kerberos authentication, it requests a Ticket Granting Ticket (TGT) from the KDC by authenticating with its own principal (typically associated with a user). The TGT allows the client to request Service Tickets for specific service principals. The client then presents the Service Ticket to the service principal as proof of its identity, and the service principal validates the ticket and grants access to the requested service. Service principals are essential for securing communication in a Kerberos environment because they allow clients and services to establish trust and verify each other's identities. Each service principal has a unique name and is associated with a specific network service, ensuring that only authorized clients can access the corresponding service. For example, if you have a web server named \"example.com,\" it would have its own service principal called \"HTTP/example.com@REALM\" (where REALM is the Kerberos realm name). Clients authenticating to the web server would obtain Service Tickets for this specific service principal to gain access to the web server's resources securely. Debugging This command does not cause any traffic to the DC so it's not talking to it: bash-5.1$ kvno cifs/10.10.25.80 kvno: Server not found in Kerberos database while getting credentials for cifs/10.10.25.80@GRANT.LAN","title":"PowerScale Setup"},{"location":"PowerScale%20Setup/#powerscale-setup","text":"PowerScale Setup Testing Test 1 - Generic Share Against Windows 11 Against Rocky Linux 9 Test 2 - Add FIPS Add FIPS Test Against Windows 11 Set Up Active Directory Test Against Rocky Linux 9 How Kerberos Works in This Scenario What is a Service Principal Debugging","title":"PowerScale Setup"},{"location":"PowerScale%20Setup/#testing","text":"","title":"Testing"},{"location":"PowerScale%20Setup/#test-1-generic-share","text":"Created a system user grant on the local OS, set up a share, and gave that user privileges.","title":"Test 1 - Generic Share"},{"location":"PowerScale%20Setup/#against-windows-11","text":"I was able to access that without issue Default communication happened with SMBv2","title":"Against Windows 11"},{"location":"PowerScale%20Setup/#against-rocky-linux-9","text":"Ran command sudo mount.cifs //10.10.25.80/ifs ~/share -o vers=2.0,username=grant,password='somepassword' which gave mount error(2): No such file or directory Received: I think the \"STATUS_FS_DRIVER_REQUIRED\" may be misleading because I have the CIFS module: [root@acas ~]# lsmod | grep cif cifs 2355200 0 cifs_arc4 16384 1 cifs rdma_cm 139264 1 cifs ib_core 450560 4 rdma_cm,cifs,iw_cm,ib_cm cifs_md4 16384 1 cifs dns_resolver 16384 1 cifs The problem was I was providing the share path not the share name - like a genius. sudo mount -t cifs //10.10.25.80/testshare /root/share -o username=grant,password='somepassword' works.","title":"Against Rocky Linux 9"},{"location":"PowerScale%20Setup/#test-2-add-fips","text":"","title":"Test 2 - Add FIPS"},{"location":"PowerScale%20Setup/#add-fips","text":"Working from this procedure Check if FIPS is already active gcluster-1# isi security settings view FIPS Mode Enabled: No USB Ports Disabled: No Restricted shell Enabled: No Make sure nodes are healthy gcluster-1# isi status Cluster Name: gcluster Cluster Health: [ ATTN] Data Reduction: 1.00 : 1 Storage Efficiency: 0.31 : 1 Cluster Storage: HDD SSD Storage Size: 168.1G (234.9G Raw) 0 (0 Raw) VHS Size: 66.8G Used: 327.9M (< 1%) 0 (n/a) Avail: 167.8G (> 99%) 0 (n/a) Health Ext Throughput (bps) HDD Storage SSD Storage ID |IP Address |DASR |C/N| In Out Total| Used / Size |Used / Size ---+---------------+-----+---+-----+-----+-----+-----------------+----------------- 1|10.10.25.80 |-A-- | C |27.1k| 2.1M| 2.1M| 126M/56.0G(< 1%)|(No Storage SSDs) 2|10.10.25.81 |-A-- | C | 0|67.1k|67.1k| 109M/56.0G(< 1%)|(No Storage SSDs) 3|10.10.25.82 |-A-- | C | 0| 270k| 270k|93.1M/56.0G(< 1%)|(No Storage SSDs) ---+---------------+-----+---+-----+-----+-----+-----------------+----------------- Cluster Totals: |27.1k| 2.4M| 2.4M| 328M/ 168G(< 1%)|(No Storage SSDs) Health Fields: D = Down, A = Attention, S = Smartfailed, R = Read-Only External Network Fields: C = Connected, N = Not Connected Critical Events: Time LNN Event --------------- ---- ------------------------------------------------------- 07/27 12:04:21 1 One or more drives (location(s) Bay 7, Bay 8, Bay ... 07/27 12:30:35 3 Missing COMMITTED image in secure catalog 07/27 12:30:56 2 One or more drives (location(s) Bay 7, Bay 8, Bay ... 07/27 12:35:35 3 One or more drives (location(s) Bay 7, Bay 8, Bay ... Cluster Job Status: No running jobs. No paused or waiting jobs. No failed jobs. Recent job results: Time Job Event --------------- -------------------------- ------------------------------ 07/27 12:29:37 MultiScan[3] Succeeded 07/27 12:22:42 MultiScan[2] Succeeded 07/27 11:58:30 DomainTag[1] Succeeded Turn on FIPS gcluster-1# isi security settings modify --fips-mode-enabled=true gcluster-1# isi security settings view FIPS Mode Enabled: Yes USB Ports Disabled: No Restricted shell Enabled: No","title":"Add FIPS"},{"location":"PowerScale%20Setup/#test-against-windows-11","text":"It nows fails: This tracks since it's clear from the NTLMSSP_NEGOTIATE flag that it is using NTLM which the docs say is disabled. Note: Updating the password hash also implicitly disables the NTLM support for SMB access that is used when shares are accessed through IP. The instructions also tell you to explicitly make the hash type SHA512 which also issues the warning regarding NTLM: gcluster-1# isi auth file modify System --password-hash-type=SHA512 NTLM support and authentication for all file protocols has been disabled for this provider due to change of password hash type. gcluster-1# isi auth local modify System --password-hash-type=SHA512 It also seems that without manual intervention the SSH key/cipher settings are more permissive than they should be: gcluster-1# isi ssh settings view Banner: /etc/motd CA Signature Algorithms: ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsa Ciphers: aes256-ctr Host Key Algorithms: +ssh-dss,ssh-dss-cert-v01@openssh.com Ignore Rhosts: Yes Kex Algorithms: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group14-sha256,diffie-hellman-group-exchange-sha256 Login Grace Time: 2m Log Level: INFO Macs: hmac-sha2-256 Max Auth Tries: 3 Max Sessions: - Max Startups: Permit Empty Passwords: No Permit Root Login: Yes Port: 22 Print Motd: Yes Pubkey Accepted Key Types: +ssh-dss,ssh-dss-cert-v01@openssh.com,ssh-rsa Strict Modes: No Subsystem: sftp /usr/local/libexec/sftp-server Syslog Facility: AUTH Tcp Keep Alive: No Auth Settings Template: any You have to follow this guide to fix them gcluster-1# isi ssh settings modify --kex-algorithms 'diffie-hellman-group16-sha512,diffie-hellman-group16-sha512,ecdh-sha2-nistp384' gcluster-1# isi ssh settings modify --ciphers 'aes256-ctr,aes256-gcm@openssh.com' gcluster-1# isi ssh settings modify --host-key-algorithms 'ecdsa-sha2-nistp384' gcluster-1# gcluster-1# isi_for_array 'yes | /usr/local/bin/ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -b 384 -N \"\"' gcluster-3: Generating public/private ecdsa key pair. gcluster-3: /etc/ssh/ssh_host_ecdsa_key already exists. gcluster-3: Overwrite (y/n)? Your identification has been saved in /etc/ssh/ssh_host_ecdsa_key gcluster-3: Your public key has been saved in /etc/ssh/ssh_host_ecdsa_key.pub gcluster-3: The key fingerprint is: gcluster-3: SHA256:D6AMW5qyjg0jk61DRU2ed67zxOtqydWEU0xxzsnV+4Y root@gcluster-3 gcluster-3: The key's randomart image is: gcluster-3: +---[ECDSA 384]---+ gcluster-3: | o. oo.. ..| gcluster-3: | .... o= o .| gcluster-3: | o .o.. .o = .| gcluster-3: | O ...oo . . | gcluster-3: |. = o S.+ ..| gcluster-3: | * o+ . E o| gcluster-3: |O . .ooo. . | gcluster-3: |=* ++ . | gcluster-3: |oo. ..o+ | gcluster-3: +----[SHA256]-----+ gcluster-2: Generating public/private ecdsa key pair. gcluster-2: /etc/ssh/ssh_host_ecdsa_key already exists. gcluster-1: Generating public/private ecdsa key pair. gcluster-1: /etc/ssh/ssh_host_ecdsa_key already exists. gcluster-2: Overwrite (y/n)? Your identification has been saved in /etc/ssh/ssh_host_ecdsa_key gcluster-2: Your public key has been saved in /etc/ssh/ssh_host_ecdsa_key.pub gcluster-2: The key fingerprint is: gcluster-2: SHA256:mv24dik4vJVvGbHhOorynFlNa8N6Ol2kiRGwoMrWuCs root@gcluster-2 gcluster-2: The key's randomart image is: gcluster-2: +---[ECDSA 384]---+ gcluster-2: | . .. | gcluster-2: | . . .. | gcluster-2: |. . . | gcluster-2: |o o . + | gcluster-2: |.+ . oS= + | gcluster-2: |. . .Boo= | gcluster-2: | . .+oXo + | gcluster-2: |E o. ==+B== | gcluster-2: |.. o* =Oo*o | gcluster-2: +----[SHA256]-----+ gcluster-1: Overwrite (y/n)? Your identification has been saved in /etc/ssh/ssh_host_ecdsa_key gcluster-1: Your public key has been saved in /etc/ssh/ssh_host_ecdsa_key.pub gcluster-1: The key fingerprint is: gcluster-1: SHA256:ahrGrkc/YE1Ii4+YCxJgwFraGmiG2cb6M3yaY/AwMNA root@gcluster-1 gcluster-1: The key's randomart image is: gcluster-1: +---[ECDSA 384]---+ gcluster-1: |+. | gcluster-1: |ooE . | gcluster-1: |BB o o | gcluster-1: |@o* o . | gcluster-1: |+X o o S | gcluster-1: |@ ..= .. | gcluster-1: |oO o+oo | gcluster-1: |. O+o+o | gcluster-1: | .+Oo . | gcluster-1: +----[SHA256]-----+ gcluster-1# gcluster-1# isi ssh settings modify --pubkey-accepted-key-types 'ssh-rsa' gcluster-1# isi ssh settings modify --macs 'hmac-sha2-256,hmac-sha2-512,hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com' gcluster-1# isi ssh settings view Banner: /etc/motd CA Signature Algorithms: ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsa Ciphers: aes256-ctr,aes256-gcm@openssh.com Host Key Algorithms: ecdsa-sha2-nistp384 Ignore Rhosts: Yes Kex Algorithms: diffie-hellman-group16-sha512,diffie-hellman-group16-sha512,ecdh-sha2-nistp384 Login Grace Time: 2m Log Level: INFO Macs: hmac-sha2-256,hmac-sha2-512,hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com Max Auth Tries: 3 Max Sessions: - Max Startups: Permit Empty Passwords: No Permit Root Login: Yes Port: 22 Print Motd: Yes Pubkey Accepted Key Types: ssh-rsa Strict Modes: No Subsystem: sftp /usr/local/libexec/sftp-server Syslog Facility: AUTH Tcp Keep Alive: No Auth Settings Template: any From the guide on having to disable FIPS mode: PowerScale clusters running OneFS 9.4.0.0 with FIPS mode enabled may upgrade to OneFS 9.5.0.0 or later. After upgrading to OneFS Release 9.5.0.0 or later and committing the upgrade, re-enable FIPS mode. Disabling FIPS mode before upgrading is not required. I noticed that turning on FIPS immediately broke the admin user for the web ui At this point I set up active directory I added domain admins to the admins roles for system and security for powerscale I added my grant domain user to the SMB share: At this point I swapped over to Linux.","title":"Test Against Windows 11"},{"location":"PowerScale%20Setup/#set-up-active-directory","text":"I already had an active directory server to test against I was not able to join with isi auth ads create --name=win-6c2vli4n0lo.grant.lan --user=administrator --groupnet=groupnet0 DO NOT select the RFC2309 option","title":"Set Up Active Directory"},{"location":"PowerScale%20Setup/#test-against-rocky-linux-9","text":"Join the domain # Install required packages sudo dnf install -y realmd sssd oddjob oddjob-mkhomedir adcli samba-common # Discover and join the Active Directory domain sudo realm discover grant.lan sudo realm join -U administrator grant.lan # Allow domain users to log in sudo authselect select sssd --force # Enable home directory creation for domain users sudo systemctl enable oddjobd sudo systemctl start oddjobd # Verify the domain membership and users realm list Ensure domain join successful: [root@acas ~]# realm list grant.lan type: kerberos realm-name: GRANT.LAN domain-name: grant.lan configured: kerberos-member server-software: active-directory client-software: sssd required-package: oddjob required-package: oddjob-mkhomedir required-package: sssd required-package: adcli required-package: samba-common-tools login-formats: %U@grant.lan login-policy: allow-realm-logins Run the mount: [root@acas ~]# sudo mount -t cifs //10.10.25.80/testshare /mnt/testshare -o username=administrator,domain=grant.lan,password=somepassword mount error(13): Permission denied Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) Attempt to setting sec=krb5 returns bug-looking results: [root@acas ~]# sudo mount -t cifs //10.10.25.80/testshare /mnt/testshare -o username=administrator,domain=grant.lan,sec=krb5 mount error(0): Success Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) when you inspect dmseg you see: [86217.278254] CIFS: VFS: \\\\10.10.25.80 Send error in SessSetup = -13 [86228.682870] CIFS: Attempting to mount \\\\10.10.25.80\\testshare [86228.816520] CIFS: VFS: Verify user has a krb5 ticket and keyutils is installed [86228.816530] CIFS: VFS: \\\\10.10.25.80 Send error in SessSetup = -126 [86228.816564] CIFS: VFS: cifs_mount failed w/return code = -126","title":"Test Against Rocky Linux 9"},{"location":"PowerScale%20Setup/#how-kerberos-works-in-this-scenario","text":"Overview: https://www.freecodecamp.org/news/how-does-kerberos-work-authentication-protocol/ Synopsis: the Active Directory user administrator@grant.lan logged into the Rocky 9 client ( acas.lan ) wants to mount a CIFS share on the Dell PowerScale ( gcluster-1 ) that requires Active Directory Kerberos authentication. TGT Acquisition with kinit: Before attempting to mount the CIFS share, the user administrator@grant.lan on the Rocky 9 client ( acas.lan ) must obtain a Ticket Granting Ticket (TGT) from the Key Distribution Center (KDC). To get the TGT, the user runs the kinit command and provides their password when prompted: bash-5.1$ kinit administrator@grant.lan Password for administrator@grant.lan: TGT Request to KDC: With the TGT in hand, the Rocky 9 client ( acas.lan ) can now initiate the request to mount the CIFS share on the Dell PowerScale ( gcluster-1 ) using the mount command. CIFS Share Mount: The user administrator@grant.lan runs the mount command with the required options to mount the CIFS share on the Dell PowerScale: bash-5.1$ sudo mount -t cifs //10.10.25.80/testshare /mnt/testshare -o username=administrator@grant.lan,domain=GRANT.LAN,sec=krb5 TGT Usage and Service Principal: The mount command uses the TGT acquired earlier to authenticate and obtain the Service Ticket from the KDC for accessing the CIFS service on gcluster-1 . The Service Ticket is generated for the service principal associated with the CIFS service on gcluster-1 . In this case, the service principal is CIFS/gcluster-1.grant.lan@GRANT.LAN . Service Ticket Response: The KDC ( dc.grant.lan ) validates the TGT and generates a Service Ticket for the CIFS service ( CIFS/gcluster-1.grant.lan ) on the Dell PowerScale. Mounting the CIFS Share: With the Service Ticket, the Rocky 9 client ( acas.lan ) successfully mounts the CIFS share on the Dell PowerScale ( gcluster-1 ) at the specified mount point. The user acquires a TGT using kinit , and then the mount command leverages the TGT to request and obtain the Service Ticket for the CIFS share from the KDC. The Service Ticket is then used for mounting the CIFS share on the Dell PowerScale, allowing the user to access the share securely without re-entering their password during the session. Mounting the CIFS Share: The Rocky 9 client ( acas.lan ) receives the Service Ticket and sends it, along with the request to mount the CIFS share, to the Dell PowerScale ( gcluster-1 ). The Dell PowerScale ( gcluster-1 ) decrypts the Service Ticket using the session key shared with the client and validates the user's identity and permissions to access the CIFS share. If everything checks out, the CIFS share is successfully mounted on the Rocky 9 client ( acas.lan ). Session Key for Secure Communication: The client ( acas.lan ) and the CIFS service on the Dell PowerScale ( gcluster-1 ) now have a shared session key for secure communication during the CIFS session. Throughout this process, the client, KDC, and CIFS service use symmetric encryption and shared secret keys to securely exchange credentials and generate tickets. Once the user is authenticated with a TGT, they can access the CIFS share without having to re-enter their password during the session. This provides a secure and seamless single sign-on (SSO) experience for the user.","title":"How Kerberos Works in This Scenario"},{"location":"PowerScale%20Setup/#what-is-a-service-principal","text":"A service principal is a unique identity within a Kerberos-based authentication system that represents a specific network service or application. In a Kerberos authentication environment, each network service (e.g., web server, email server, file server) is assigned its own service principal, which is used to authenticate and authorize clients to access the service securely. Service principals are created and managed by the Key Distribution Center (KDC) in the Kerberos realm. The KDC issues a set of cryptographic keys to each service principal, which are used for secure communication between the client and the service. When a client wants to access a network service that requires Kerberos authentication, it requests a Ticket Granting Ticket (TGT) from the KDC by authenticating with its own principal (typically associated with a user). The TGT allows the client to request Service Tickets for specific service principals. The client then presents the Service Ticket to the service principal as proof of its identity, and the service principal validates the ticket and grants access to the requested service. Service principals are essential for securing communication in a Kerberos environment because they allow clients and services to establish trust and verify each other's identities. Each service principal has a unique name and is associated with a specific network service, ensuring that only authorized clients can access the corresponding service. For example, if you have a web server named \"example.com,\" it would have its own service principal called \"HTTP/example.com@REALM\" (where REALM is the Kerberos realm name). Clients authenticating to the web server would obtain Service Tickets for this specific service principal to gain access to the web server's resources securely.","title":"What is a Service Principal"},{"location":"PowerScale%20Setup/#debugging","text":"This command does not cause any traffic to the DC so it's not talking to it: bash-5.1$ kvno cifs/10.10.25.80 kvno: Server not found in Kerberos database while getting credentials for cifs/10.10.25.80@GRANT.LAN","title":"Debugging"},{"location":"Reset%20OS10%20Admin%20Password/","text":"Reset OS10 Admin Password Video: https://youtu.be/0VfJCa8s7yo Connect to the serial console port. The serial settings are 115,200 baud, 8 data bits, and no parity. Reboot or power up the system. Press ESC at the Grub prompt to view the boot menu. The OS10-A partition is selected by default. +-------------------------------------+ |*OS10-A | | OS10-B | | ONIE | +-------------------------------------+ Press e to open the OS10 GRUB editor. 1.Use the arrow keys to navigate to the end of the line that has set os_debug_args= and then add init=/bin/bash. +---------------------------------------------------------+ |setparams 'OS10-A' | | | | set os_debug_args=\"init=/bin/bash\" | | select_image A | | boot_os | | | +---------------------------------------------------------+ Press Alt + 0. The system boots to a root shell without a password. At the root prompt run passwd admin and set the password to whatever you want Run reboot -f to reboot the system When the system reboots log into the admin account with your new password. That password is temporary and is not permanently written to the system . Enter configuration mode with configure terminal and then run username admin password <YOURPASSWORD> role sysadmin to change the password Run write memory to make the changes permanent. Startup Config Location /config/etc/opt/dell/os10/db_init/startup.xml","title":"Reset OS10 Admin Password"},{"location":"Reset%20OS10%20Admin%20Password/#reset-os10-admin-password","text":"Video: https://youtu.be/0VfJCa8s7yo Connect to the serial console port. The serial settings are 115,200 baud, 8 data bits, and no parity. Reboot or power up the system. Press ESC at the Grub prompt to view the boot menu. The OS10-A partition is selected by default. +-------------------------------------+ |*OS10-A | | OS10-B | | ONIE | +-------------------------------------+ Press e to open the OS10 GRUB editor. 1.Use the arrow keys to navigate to the end of the line that has set os_debug_args= and then add init=/bin/bash. +---------------------------------------------------------+ |setparams 'OS10-A' | | | | set os_debug_args=\"init=/bin/bash\" | | select_image A | | boot_os | | | +---------------------------------------------------------+ Press Alt + 0. The system boots to a root shell without a password. At the root prompt run passwd admin and set the password to whatever you want Run reboot -f to reboot the system When the system reboots log into the admin account with your new password. That password is temporary and is not permanently written to the system . Enter configuration mode with configure terminal and then run username admin password <YOURPASSWORD> role sysadmin to change the password Run write memory to make the changes permanent.","title":"Reset OS10 Admin Password"},{"location":"Reset%20OS10%20Admin%20Password/#startup-config-location","text":"/config/etc/opt/dell/os10/db_init/startup.xml","title":"Startup Config Location"},{"location":"Reset%20OS10%20Admin%20Password/problems/","text":"Resetting Dell OS10 Password Working Instructions Connect to the serial console port. The serial settings are 115,200 baud, 8 data bits, and no parity. Reboot or power up the system. Press ESC at the Grub prompt to view the boot menu. The OS10-A partition is selected by default. +-------------------------------------+ |*OS10-A | | OS10-B | | ONIE | +-------------------------------------+ Press e to open the OS10 GRUB editor. 1.Use the arrow keys to navigate to the end of the line that has set os_debug_args= and then add init=/bin/bash. +---------------------------------------------------------+ |setparams 'OS10-A' | | | | set os_debug_args=\"init=/bin/bash\" | | select_image A | | boot_os | | | +---------------------------------------------------------+ Press Alt + 0. The system boots to a root shell without a password. At the root prompt run passwd admin and set the password to whatever you want Run reboot -f to reboot the system When the system reboots log into the admin account with your new password. That password is temporary and is not permanently written to the system . Enter configuration mode with configure terminal and then run username admin password <YOURPASSWORD> role sysadmin to change the password Run write memory to make the changes permanent. Problems with online documentation Based on official instructions here Instructions are for resetting the linuxadmin account. Majority of audience are network engineers who have little understanding of Linux. Even for me, a Linux engineer who also does network engineering, and has done extensive work with OS10 had no idea a linuxadmin account even existed much less what it was used for. Having worked extensively with customers in the field, I have never met one that actually knew that OS10 is just Debian Linux much less understood the relationship between the Linux command line and the OS10 shell. The instructions seem to assume that you understand the relationship between the OS10 shell, the Linux command line, and the Linux users. The vast majority of the users of OS10 will not understand these distinctions. In my case the customer was very confused as to what linuxadmin was. They had never used it and after resetting the password for linuxadmin tried logging into the admin account and was confused when it didn't work They were then further confused because they tried to log into OS10 B thinking it was some sort of synchronized backup. Since it was identical to OS10 A they thought changes made there would synchronize between the two. The instructions do not tell you that the changes made to the password are temporary and will not persist through reboot. As far as I can tell, we do not have any documentation describing how to reset the admin account for the OS10 command line which is what virtually all customers will want to do. Suggestions Ensure that instructions for resetting the admin account password are easily accessible online Clarify the purpose of the linuxadmin account If there are plans to expose the Linux nature of OS10 to the customer, provide documentation clearly articulating the relationship between Linux and OS10 from the perspective of what is relevant to someone with a network engineering background. I am happy to help with this.","title":"Resetting Dell OS10 Password"},{"location":"Reset%20OS10%20Admin%20Password/problems/#resetting-dell-os10-password","text":"","title":"Resetting Dell OS10 Password"},{"location":"Reset%20OS10%20Admin%20Password/problems/#working-instructions","text":"Connect to the serial console port. The serial settings are 115,200 baud, 8 data bits, and no parity. Reboot or power up the system. Press ESC at the Grub prompt to view the boot menu. The OS10-A partition is selected by default. +-------------------------------------+ |*OS10-A | | OS10-B | | ONIE | +-------------------------------------+ Press e to open the OS10 GRUB editor. 1.Use the arrow keys to navigate to the end of the line that has set os_debug_args= and then add init=/bin/bash. +---------------------------------------------------------+ |setparams 'OS10-A' | | | | set os_debug_args=\"init=/bin/bash\" | | select_image A | | boot_os | | | +---------------------------------------------------------+ Press Alt + 0. The system boots to a root shell without a password. At the root prompt run passwd admin and set the password to whatever you want Run reboot -f to reboot the system When the system reboots log into the admin account with your new password. That password is temporary and is not permanently written to the system . Enter configuration mode with configure terminal and then run username admin password <YOURPASSWORD> role sysadmin to change the password Run write memory to make the changes permanent.","title":"Working Instructions"},{"location":"Reset%20OS10%20Admin%20Password/problems/#problems-with-online-documentation","text":"Based on official instructions here Instructions are for resetting the linuxadmin account. Majority of audience are network engineers who have little understanding of Linux. Even for me, a Linux engineer who also does network engineering, and has done extensive work with OS10 had no idea a linuxadmin account even existed much less what it was used for. Having worked extensively with customers in the field, I have never met one that actually knew that OS10 is just Debian Linux much less understood the relationship between the Linux command line and the OS10 shell. The instructions seem to assume that you understand the relationship between the OS10 shell, the Linux command line, and the Linux users. The vast majority of the users of OS10 will not understand these distinctions. In my case the customer was very confused as to what linuxadmin was. They had never used it and after resetting the password for linuxadmin tried logging into the admin account and was confused when it didn't work They were then further confused because they tried to log into OS10 B thinking it was some sort of synchronized backup. Since it was identical to OS10 A they thought changes made there would synchronize between the two. The instructions do not tell you that the changes made to the password are temporary and will not persist through reboot. As far as I can tell, we do not have any documentation describing how to reset the admin account for the OS10 command line which is what virtually all customers will want to do.","title":"Problems with online documentation"},{"location":"Reset%20OS10%20Admin%20Password/problems/#suggestions","text":"Ensure that instructions for resetting the admin account password are easily accessible online Clarify the purpose of the linuxadmin account If there are plans to expose the Linux nature of OS10 to the customer, provide documentation clearly articulating the relationship between Linux and OS10 from the perspective of what is relevant to someone with a network engineering background. I am happy to help with this.","title":"Suggestions"},{"location":"Run%20VPN%20on%20OS10/","text":"Run VPN on OS10 My Configuration Dell 4112F-ON Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.4 Build Version: 10.5.0.4.638 Build Time: 2020-01-30T21:08:56+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 2 days 03:54:07 CentOS [root@centos ~]# cat /etc/*-release CentOS Linux release 7.6.1810 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.6.1810 (Core) CentOS Linux release 7.6.1810 (Core) Testing Topology Switch Configuration Research Sources Helpful Book Basics of Network Processor Packet Processing How Network Processors Work NPU Interface Problem The one big gotcha with doing this is that when you drop to the command line in OS10 and do a ip a s , the interfaces you see that look like physical interfaces ex: 13: e101-001-0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc multiq master br32 state UP group default qlen 1000 link/ether 50:9a:4c:d6:0a:71 brd ff:ff:ff:ff:ff:ff 14: e101-002-0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master br1 state DOWN group default qlen 1000 link/ether 50:9a:4c:d6:0a:72 brd ff:ff:ff:ff:ff:ff 15: e101-003-0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master br1 state DOWN group default qlen 1000 link/ether 50:9a:4c:d6:0a:73 brd ff:ff:ff:ff:ff:ff 16: e101-004-0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master br1 state DOWN group default qlen 1000 link/ether 50:9a:4c:d6:0a:74 brd ff:ff:ff:ff:ff:ff are not actual physical interfaces. Under the hood the operating system is actually using tap interfaces. Inside the switch there are two processors - a regular x86 processor and a separate processor called the Network Processing Unit (NPU). The interfaces are connected to the NPU. Most traffic that comes in on the physical interfaces managed by the NPU does not flow up to the x86 chip. This means that if you do a tcpdump on one of the interfaces you see in ip a s you will see very little. In fact, the only traffic you will see is management traffic which is handled by the Linux kernel. This means if you want to set up a VPN you have to have a way to make sure all the traffic is visible to the Linux kernel. Fortunately, there is a way to make this happen. VLAN interfaces are virtual and subsequently are handled entirely by the Linux kernel. In fact, VLAN interfaces actually show up under the hood as bridge interfaces: 29: br32: <BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 50:9a:4c:d6:0a:a1 brd ff:ff:ff:ff:ff:ff inet 192.168.32.1/24 brd 255.168.32.255 scope global br32 valid_lft forever preferred_lft forever inet6 fe80::529a:4cff:fed6:aa1/64 scope link valid_lft forever preferred_lft forever 41: br33: <BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 50:9a:4c:d6:0a:a1 brd ff:ff:ff:ff:ff:ff inet 192.168.33.1/24 brd 255.168.33.255 scope global br33 valid_lft forever preferred_lft forever inet6 fe80::529a:4cff:fed6:aa1/64 scope link valid_lft forever preferred_lft forever These two correspond to interface vlans 32 and 33. By using VLAN interfaces you can tie the VPN to these interfaces and everything works just fine. You just place any associated physical interfaces as access VLANs or trunks with the appropriate allowed VLANs. Installing OpenVPN as a Server on the 4112F-ON Note: I ran a VPN server on my switch, but you could just as easily make the switch a point to point VPN gateway connecting to a PFSense instance such that anything that can reach the switch could participate in a multipoint network. On the 4112F-ON: Enter configuration mode from user mode by running en and then config <enter> Run ip name-server 192.168.1.1 to add a name server. Run write mem in enable mode to save your configuration changes. Run system bash Before continuing, make sure that the time is correct on the device. WARNING If you do not do this and you generate certificates, none of the encryption will work and you will have to recreate all of your certificates! Run sudo apt-get install -y openvpn vim . I installed vim because I don't hate myself. I used this script from git.io/vpn to install OpenVPN. Having done the entire thing manually before, I can tell you this saves a huge amount of time. To run the script run wget https://git.io/vpn -O openvpn-install.sh && chmod +x openvpn-install.sh && ./openvpn-install.sh 1.Fill in the options as needed. I did find some things you have to tweak with their script. Perform the below to clean things up. 1.Run vim /lib/systemd/system/openvpn@.service . Where it says --config /etc/openvpn/%i.conf , change that to --config /etc/openvpn/%i/%i.conf . For details on specifies work see this post . When you are done run systemctl daemon-reload to reload the systemd daemon. 2.If you used my version of the script then you do not need to do this. Otherwise you need to run vim /etc/openvpn/server/server.conf and you need to prepend /etc/openvpn/server/ on several of the paths or the service won't start. See my config below: local 192.168.32.1 port 1194 proto udp dev tun ca /etc/openvpn/server/ca.crt cert /etc/openvpn/server/server.crt key /etc/openvpn/server/server.key dh /etc/openvpn/server/dh.pem auth SHA512 tls-crypt /etc/openvpn/server/tc.key topology subnet server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"redirect-gateway def1 bypass-dhcp\" push \"dhcp-option DNS 192.168.1.1\" keepalive 10 120 cipher AES-256-CBC user nobody group nogroup persist-key persist-tun status openvpn-status.log verb 3 crl-verify /etc/openvpn/server/crl.pem explicit-exit-notify You may want to add something like push route 192.168.1.0 255.255.255.0 to your server config. This allows the server to push routes to the client. For example, in my case the 192.168.1.0/24 network is behind my server, so I have to push a route so that the clients know how to get to it. Just keep in mind, that hosts on your distant network must have a route back to your VPN network. Run systemctl start openvpn@server to start the server. Rerun the script to add clients. Your output should look like the below. In my case I added one client to perform the test. ``` Looks like OpenVPN is already installed. What do you want to do? 1) Add a new user 2) Revoke an existing user 3) Remove OpenVPN 4) Exit Select an option: 1 Tell me a name for the client certificate. Client name: test-client Using SSL: openssl OpenSSL 1.1.0l 10 Sep 2019 Generating a RSA private key ........+++++ .......+++++ writing new private key to '/etc/openvpn/server/easy-rsa/pki/private/test-client.key.WONcIB6m1N' ----- Using configuration from ./safessl-easyrsa.cnf Check that the request matches the signature Signature ok The Subject's Distinguished Name is as follows commonName :ASN.1 12:'test-client' Certificate is to be certified until Mar 9 00:13:09 2030 GMT (3650 days) Write out database with 1 new entries Data Base Updated Client test-client added, configuration is available at: /root/test-client.ovpn ``` Copy the contents of your client config. In my case this was from /root/test-client.ovpn and it looked like: client dev tun proto udp remote <SERVER ADDRESS> 1194 resolv-retry infinite nobind persist-key persist-tun remote-cert-tls server auth SHA512 cipher AES-256-CBC ignore-unknown-option block-outside-dns block-outside-dns verb 3 <ca> -----BEGIN CERTIFICATE----- MIIDKzCCAhOgAwIBAgIJANmH49pJjiOUMA0GCSqGSIb3DQEBCwUAMBMxETAPBgNV BAMMCENoYW5nZU1lMB4XDTIwMDMxMTAwMTA1M1oXDTMwMDMwOTAwMTA1M1owEzER MA8GA1UEAwwIQ2hhbmdlTWUwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB AQD5FZJN5STAXRX7ZBq8CVf7DntSQTgnVVqwntKJwggTPHgwn8uMUWRdaIpXZVN5 MYTGPCICDoxdlF/2KUgH9n/L1Rlmm9RW4beXMwFJUR8NIExf5vQy03gk6JpEO1DA Pu+x0/EhXGvGo/lAEpF4rk0ZPpNEkFM71bIqhKAMAe9M5c2ZrAxqplyTz/Zl4nRm YQSsqnx3ikN+SkxdnifIBlF3MzCHqCCV9QaOkrztXHs9XFhnWpyu+OLqyP5+ipOZ gYsTDA4otjv6D9MX+BoWCZ6zSzo/kMSkM7ByZt5jjyp1lQQaYnZe8LmRkB3vcBb4 lWlN8Gu3tvunXSlKJWp7Fh7VAgMBAAGjgYEwfzAdBgNVHQ4EFgQUSDkx6kENF55m RsJZip/xOrv2E2EwQwYDVR0jBDwwOoAUSDkx6kENF55mRsJZip/xOrv2E2GhF6QV MBMxETAPBgNVBAMMCENoYW5nZU1lggkA2Yfj2kmOI5QwDAYDVR0TBAUwAwEB/zAL BgNVHQ8EBAMCAQYwDQYJKoZIhvcNAQELBQADggEBADwKrP9NcTakAbQnd+x+lBzv co0I2XOJrsm6N1r8MKVjEq9Ti5quGtoDLNQDlORnKAaWVzSg6oAFNVrItVJU5GRe J+XI+t2pXqo/OBlVoXcwG52m2rXd9e5wjdmrYwpzijvj//FjjfIZysJJiLW8xSA9 t+3/BCCGqy6uBy2KNvuYMQHr2BdHU05haXtp/mrsalSTlvLFwJeUbHDrqCKoFlDj tXkzcF4sIOfF0dzQXdXT5qerZGOMsXBQ8ALFoHd/wvS5cJvI8nWywEg3w3vWCSO1 zLdcNmvIqYEYrLZBhtLlwBnjKuHSsXorfJsUcmdKsgwIw1KtMBF2bBMyd8twBn8= -----END CERTIFICATE----- </ca> <cert> -----BEGIN CERTIFICATE----- MIIDSTCCAjGgAwIBAgIRAODlLyd7mnQoRNC4oqxJm5AwDQYJKoZIhvcNAQELBQAw EzERMA8GA1UEAwwIQ2hhbmdlTWUwHhcNMjAwMzExMDAxMzA5WhcNMzAwMzA5MDAx MzA5WjAWMRQwEgYDVQQDDAt0ZXN0LWNsaWVudDCCASIwDQYJKoZIhvcNAQEBBQAD ggEPADCCAQoCggEBAOP2megEI8f/e0Xxi6n+EKQwaLZweYFTVg25vT2X6a2HHJfg 8tXznih0NxGJFyITmpl+lddBXEnm/ZqSH6HBGujyd8aWHZ1algvbpyzU0qNXRoAu AjknbkcQ4/m+28/1ocGukY2aKYjQXddp4HzquSQupza/3JcJ+5roWte1PzLZCC74 yfdzhdBwHHOfG4B7SfYOuT7eXQwisCrTFZmtK1FoONhwSlhqcEbMBaEjT9ZP7K7p WSmx82c7xyYhdD4JMZ79qiIm/pbeszu1SpUqd3682mVwmZZOCUWf3pRKwcwEyJnk YKS9ksKTh0F9B9VibfvNw2harR3471qwt6pbSXUCAwEAAaOBlDCBkTAJBgNVHRME AjAAMB0GA1UdDgQWBBTv4I3fmPShB7U6scRReENGsLkiQDBDBgNVHSMEPDA6gBRI OTHqQQ0XnmZGwlmKn/E6u/YTYaEXpBUwEzERMA8GA1UEAwwIQ2hhbmdlTWWCCQDZ h+PaSY4jlDATBgNVHSUEDDAKBggrBgEFBQcDAjALBgNVHQ8EBAMCB4AwDQYJKoZI hvcNAQELBQADggEBACKCvwckhCZ7w5j79gYvRhujm02z2Bah7aggZ9uoyYFw3EVi 1GmyU6aoa3ui2UKciWglm8R21TuhnPsUopbWNniHDlFqOOrVxFST11FD02Qfae8P 6YWhkbUoaS3IwF7NOPg56Q7VaU1P8+GI2fR5kjHrb9pBPTCFX+1gSpiA0TE3DHj4 zO7NFRq+hE17QqeE1+W7pq4uyZYQFpbC6n+VsCJWBXDm/8WR97uJpjWUjFCNPm71 PD5YN6cSa9iasBQVvBWbKkMaf+aFvtLHGteYrVUGkvpnw9DquYFxMnHpwegU4DQh PRL2TL8szw7751o2v2CHZ+zLJbDaq26thdoIh64= -----END CERTIFICATE----- </cert> <key> -----BEGIN PRIVATE KEY----- MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDj9pnoBCPH/3tF 8Yup/hCkMGi2cHmBU1YNub09l+mthxyX4PLV854odDcRiRciE5qZfpXXQVxJ5v2a kh+hwRro8nfGlh2dWpYL26cs1NKjV0aALgI5J25HEOP5vtvP9aHBrpGNmimI0F3X aeB86rkkLqc2v9yXCfua6FrXtT8y2Qgu+Mn3c4XQcBxznxuAe0n2Drk+3l0MIrAq 0xWZrStRaDjYcEpYanBGzAWhI0/WT+yu6VkpsfNnO8cmIXQ+CTGe/aoiJv6W3rM7 tUqVKnd+vNplcJmWTglFn96USsHMBMiZ5GCkvZLCk4dBfQfVYm37zcNoWq0d+O9a sLeqW0l1AgMBAAECggEBAKU7AscG6SB3b1R9BWxLeKhpZhyGXat9Sexc6muQhpF+ Ux1KsPiewc40ng2Zvii26OHEvLru5wOx57N3onHN08FwrZxFBmYdWJBzvzJhd+No yPLzZi0jBW2BMpy81/pd4cbOzzVBvkUqMjqGxW4Fe/hb0FuAqVTYqYPYUq/y8UHa atIehY3jNc46pSRmmFIDDdyh6K5lmFVZntpRKg9RzUibQxBkLZZwnRwFLf58wJbr Os9OT2QZsaSDIIK4mtL3xTVbT9ORC/ADY6XXO+Yb6IyLqD6WD5Yqh7wEpp/Gv4Ob BvlObULOEZnjeAK9FIPs9gFuimBjcJK5kX3an8yok6kCgYEA/cqQIMR8ORRdTBaj v2CK8RtQOJ2VPEpINcxPHK8vh38CrKNmCjETXqhkCwI1wOT/WKA4IUHBLfOhgC00 cHYn6k2JfossQGh8DvjyY+JtdmSamzeecQ4i13RcnSj5G+kY/iEQogTaSALpB1Uo cugU116HiHSvcz+FK3Ia4lAHnjcCgYEA5fJ+lg3lCCd1Cq4UpzGWLMWpo5VBX9Eu QhWRC2uIGkO4BAXVlkU/1TOvzonfoHLcyVUlLjE//p6djyVezkdVHTYYXQwrWIYE oinC4YnxV1Pcvii7WaBw9t3s5REYdgyvT0Wh7GIm+o6TMnfBTvVV/DMU6K9z59f+ wLXfMZaZH7MCgYBOXhdlVub5BTXOAgusU9ZznziFUvu7M0DbA+zF8b6ee3TK9GXU 7dSKXTsPPy50EwJaTpcmhdRuKRYMq2jO9V1b93dmkPkoJltwkCTg/RFKBsTK+0C8 rl3J5A+ZJAbQPIlQJ8uoDBGPPP7SGdS0rr+IxZLaaxWmY83uXXy5t3ayvwKBgQCM YMrovljI7pWkTHvtSfddI9qZNAAyB5jO3S2sJBx1tEu9oPYwg9whQymb1E3CPP0O qD1HgueHgLu9bNoA4klSyPh8rXY017Qyb346hCTi5B6JtIITiEAOZZM+kH43ay0H HwJoNc+H/Mxd7gAEPQAeM+0a1CnVKuaqLR2xvzeBwwKBgC+vydOv2Fqu58b+/cWi 52/stI11Y+xkdQ+/SP+cAucN05xVrfFzEbv90/Tintk2G+oCb5lWxM2uGIfSMCMA CUHg03a0oZdTTapUs+i0fahuhR/ojK5i4COTHM0jF3ryr1Gjo0RUgbJe/RlnRY5v bbOS07Ao554/jPNrXGzImnQz -----END PRIVATE KEY----- </key> <tls-crypt> -----BEGIN OpenVPN Static key V1----- 470a961d29e78b8f4884b46741587ecf 6008c6bb16acf2eae299f68df994133d 7fbe5dbacd187c21ac9e61bc2aab3de0 c88f39674dec40ef4844dddb80884ad4 652542876fdadd98ca95cf4e9f4ed6e8 2b2f6315aa77c0ae9fc5dca6df687622 82f629e230990b340b1b95f6f7ca18a4 185176cf29c04d5d0a9f9c19083fe3b6 24e55a25f5e5ccf2a48f33373d56792a 20f60074f9e6ef855e0b0ceca0a07300 294718d41af0a97da641053397fdc944 d21f5a9a702a118de21440fce772ab17 11a575acc9ce0097e2fdefc1233ea2e6 01e49032eaf2aa3e0898c3f5b334839f f8c69c80614a45cfb0ba7d43d3476e37 a22a4d43b0dbc96430b1115a6b1f6aac -----END OpenVPN Static key V1----- </tls-crypt> NOTE: The script automatically accounts for NAT. Notice in your client config that it sets the remote server as whatever your external address is. You may not want this behavior. If that is the case you will need to go in and edit the remote line with the IP address of your VPN server. On CentOS 7 Make sure everything is up to date. yum update -y && reboot . The reboot is important because if your kernel might update. If this happens you need to reboot to load the new kernel. Run yum install -y epel-release && yum update -y && yum install -y openvpn easy-rsa chrony && systemctl enable chronyd && chronyc makestep This is a long series of commands, but it installs openvpn and chrony. You need chrony to ensure your time is synched. WARNING : If the time is not synched between the server and your clients, the VPN will fail to connect! You should have copied your client config to your client already. If you haven't, do that now. To run the VPN, run openvpn <client_config_name>","title":"Run VPN on OS10"},{"location":"Run%20VPN%20on%20OS10/#run-vpn-on-os10","text":"","title":"Run VPN on OS10"},{"location":"Run%20VPN%20on%20OS10/#my-configuration","text":"","title":"My Configuration"},{"location":"Run%20VPN%20on%20OS10/#dell-4112f-on","text":"Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.4 Build Version: 10.5.0.4.638 Build Time: 2020-01-30T21:08:56+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 2 days 03:54:07","title":"Dell 4112F-ON"},{"location":"Run%20VPN%20on%20OS10/#centos","text":"[root@centos ~]# cat /etc/*-release CentOS Linux release 7.6.1810 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.6.1810 (Core) CentOS Linux release 7.6.1810 (Core)","title":"CentOS"},{"location":"Run%20VPN%20on%20OS10/#testing-topology","text":"Switch Configuration","title":"Testing Topology"},{"location":"Run%20VPN%20on%20OS10/#research-sources","text":"Helpful Book Basics of Network Processor Packet Processing How Network Processors Work","title":"Research Sources"},{"location":"Run%20VPN%20on%20OS10/#npu-interface-problem","text":"The one big gotcha with doing this is that when you drop to the command line in OS10 and do a ip a s , the interfaces you see that look like physical interfaces ex: 13: e101-001-0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc multiq master br32 state UP group default qlen 1000 link/ether 50:9a:4c:d6:0a:71 brd ff:ff:ff:ff:ff:ff 14: e101-002-0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master br1 state DOWN group default qlen 1000 link/ether 50:9a:4c:d6:0a:72 brd ff:ff:ff:ff:ff:ff 15: e101-003-0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master br1 state DOWN group default qlen 1000 link/ether 50:9a:4c:d6:0a:73 brd ff:ff:ff:ff:ff:ff 16: e101-004-0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master br1 state DOWN group default qlen 1000 link/ether 50:9a:4c:d6:0a:74 brd ff:ff:ff:ff:ff:ff are not actual physical interfaces. Under the hood the operating system is actually using tap interfaces. Inside the switch there are two processors - a regular x86 processor and a separate processor called the Network Processing Unit (NPU). The interfaces are connected to the NPU. Most traffic that comes in on the physical interfaces managed by the NPU does not flow up to the x86 chip. This means that if you do a tcpdump on one of the interfaces you see in ip a s you will see very little. In fact, the only traffic you will see is management traffic which is handled by the Linux kernel. This means if you want to set up a VPN you have to have a way to make sure all the traffic is visible to the Linux kernel. Fortunately, there is a way to make this happen. VLAN interfaces are virtual and subsequently are handled entirely by the Linux kernel. In fact, VLAN interfaces actually show up under the hood as bridge interfaces: 29: br32: <BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 50:9a:4c:d6:0a:a1 brd ff:ff:ff:ff:ff:ff inet 192.168.32.1/24 brd 255.168.32.255 scope global br32 valid_lft forever preferred_lft forever inet6 fe80::529a:4cff:fed6:aa1/64 scope link valid_lft forever preferred_lft forever 41: br33: <BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 50:9a:4c:d6:0a:a1 brd ff:ff:ff:ff:ff:ff inet 192.168.33.1/24 brd 255.168.33.255 scope global br33 valid_lft forever preferred_lft forever inet6 fe80::529a:4cff:fed6:aa1/64 scope link valid_lft forever preferred_lft forever These two correspond to interface vlans 32 and 33. By using VLAN interfaces you can tie the VPN to these interfaces and everything works just fine. You just place any associated physical interfaces as access VLANs or trunks with the appropriate allowed VLANs.","title":"NPU Interface Problem"},{"location":"Run%20VPN%20on%20OS10/#installing-openvpn-as-a-server-on-the-4112f-on","text":"Note: I ran a VPN server on my switch, but you could just as easily make the switch a point to point VPN gateway connecting to a PFSense instance such that anything that can reach the switch could participate in a multipoint network. On the 4112F-ON: Enter configuration mode from user mode by running en and then config <enter> Run ip name-server 192.168.1.1 to add a name server. Run write mem in enable mode to save your configuration changes. Run system bash Before continuing, make sure that the time is correct on the device. WARNING If you do not do this and you generate certificates, none of the encryption will work and you will have to recreate all of your certificates! Run sudo apt-get install -y openvpn vim . I installed vim because I don't hate myself. I used this script from git.io/vpn to install OpenVPN. Having done the entire thing manually before, I can tell you this saves a huge amount of time. To run the script run wget https://git.io/vpn -O openvpn-install.sh && chmod +x openvpn-install.sh && ./openvpn-install.sh 1.Fill in the options as needed. I did find some things you have to tweak with their script. Perform the below to clean things up. 1.Run vim /lib/systemd/system/openvpn@.service . Where it says --config /etc/openvpn/%i.conf , change that to --config /etc/openvpn/%i/%i.conf . For details on specifies work see this post . When you are done run systemctl daemon-reload to reload the systemd daemon. 2.If you used my version of the script then you do not need to do this. Otherwise you need to run vim /etc/openvpn/server/server.conf and you need to prepend /etc/openvpn/server/ on several of the paths or the service won't start. See my config below: local 192.168.32.1 port 1194 proto udp dev tun ca /etc/openvpn/server/ca.crt cert /etc/openvpn/server/server.crt key /etc/openvpn/server/server.key dh /etc/openvpn/server/dh.pem auth SHA512 tls-crypt /etc/openvpn/server/tc.key topology subnet server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"redirect-gateway def1 bypass-dhcp\" push \"dhcp-option DNS 192.168.1.1\" keepalive 10 120 cipher AES-256-CBC user nobody group nogroup persist-key persist-tun status openvpn-status.log verb 3 crl-verify /etc/openvpn/server/crl.pem explicit-exit-notify You may want to add something like push route 192.168.1.0 255.255.255.0 to your server config. This allows the server to push routes to the client. For example, in my case the 192.168.1.0/24 network is behind my server, so I have to push a route so that the clients know how to get to it. Just keep in mind, that hosts on your distant network must have a route back to your VPN network. Run systemctl start openvpn@server to start the server. Rerun the script to add clients. Your output should look like the below. In my case I added one client to perform the test. ``` Looks like OpenVPN is already installed. What do you want to do? 1) Add a new user 2) Revoke an existing user 3) Remove OpenVPN 4) Exit Select an option: 1 Tell me a name for the client certificate. Client name: test-client Using SSL: openssl OpenSSL 1.1.0l 10 Sep 2019 Generating a RSA private key ........+++++ .......+++++ writing new private key to '/etc/openvpn/server/easy-rsa/pki/private/test-client.key.WONcIB6m1N' ----- Using configuration from ./safessl-easyrsa.cnf Check that the request matches the signature Signature ok The Subject's Distinguished Name is as follows commonName :ASN.1 12:'test-client' Certificate is to be certified until Mar 9 00:13:09 2030 GMT (3650 days) Write out database with 1 new entries Data Base Updated Client test-client added, configuration is available at: /root/test-client.ovpn ``` Copy the contents of your client config. In my case this was from /root/test-client.ovpn and it looked like: client dev tun proto udp remote <SERVER ADDRESS> 1194 resolv-retry infinite nobind persist-key persist-tun remote-cert-tls server auth SHA512 cipher AES-256-CBC ignore-unknown-option block-outside-dns block-outside-dns verb 3 <ca> -----BEGIN CERTIFICATE----- MIIDKzCCAhOgAwIBAgIJANmH49pJjiOUMA0GCSqGSIb3DQEBCwUAMBMxETAPBgNV BAMMCENoYW5nZU1lMB4XDTIwMDMxMTAwMTA1M1oXDTMwMDMwOTAwMTA1M1owEzER MA8GA1UEAwwIQ2hhbmdlTWUwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB AQD5FZJN5STAXRX7ZBq8CVf7DntSQTgnVVqwntKJwggTPHgwn8uMUWRdaIpXZVN5 MYTGPCICDoxdlF/2KUgH9n/L1Rlmm9RW4beXMwFJUR8NIExf5vQy03gk6JpEO1DA Pu+x0/EhXGvGo/lAEpF4rk0ZPpNEkFM71bIqhKAMAe9M5c2ZrAxqplyTz/Zl4nRm YQSsqnx3ikN+SkxdnifIBlF3MzCHqCCV9QaOkrztXHs9XFhnWpyu+OLqyP5+ipOZ gYsTDA4otjv6D9MX+BoWCZ6zSzo/kMSkM7ByZt5jjyp1lQQaYnZe8LmRkB3vcBb4 lWlN8Gu3tvunXSlKJWp7Fh7VAgMBAAGjgYEwfzAdBgNVHQ4EFgQUSDkx6kENF55m RsJZip/xOrv2E2EwQwYDVR0jBDwwOoAUSDkx6kENF55mRsJZip/xOrv2E2GhF6QV MBMxETAPBgNVBAMMCENoYW5nZU1lggkA2Yfj2kmOI5QwDAYDVR0TBAUwAwEB/zAL BgNVHQ8EBAMCAQYwDQYJKoZIhvcNAQELBQADggEBADwKrP9NcTakAbQnd+x+lBzv co0I2XOJrsm6N1r8MKVjEq9Ti5quGtoDLNQDlORnKAaWVzSg6oAFNVrItVJU5GRe J+XI+t2pXqo/OBlVoXcwG52m2rXd9e5wjdmrYwpzijvj//FjjfIZysJJiLW8xSA9 t+3/BCCGqy6uBy2KNvuYMQHr2BdHU05haXtp/mrsalSTlvLFwJeUbHDrqCKoFlDj tXkzcF4sIOfF0dzQXdXT5qerZGOMsXBQ8ALFoHd/wvS5cJvI8nWywEg3w3vWCSO1 zLdcNmvIqYEYrLZBhtLlwBnjKuHSsXorfJsUcmdKsgwIw1KtMBF2bBMyd8twBn8= -----END CERTIFICATE----- </ca> <cert> -----BEGIN CERTIFICATE----- MIIDSTCCAjGgAwIBAgIRAODlLyd7mnQoRNC4oqxJm5AwDQYJKoZIhvcNAQELBQAw EzERMA8GA1UEAwwIQ2hhbmdlTWUwHhcNMjAwMzExMDAxMzA5WhcNMzAwMzA5MDAx MzA5WjAWMRQwEgYDVQQDDAt0ZXN0LWNsaWVudDCCASIwDQYJKoZIhvcNAQEBBQAD ggEPADCCAQoCggEBAOP2megEI8f/e0Xxi6n+EKQwaLZweYFTVg25vT2X6a2HHJfg 8tXznih0NxGJFyITmpl+lddBXEnm/ZqSH6HBGujyd8aWHZ1algvbpyzU0qNXRoAu AjknbkcQ4/m+28/1ocGukY2aKYjQXddp4HzquSQupza/3JcJ+5roWte1PzLZCC74 yfdzhdBwHHOfG4B7SfYOuT7eXQwisCrTFZmtK1FoONhwSlhqcEbMBaEjT9ZP7K7p WSmx82c7xyYhdD4JMZ79qiIm/pbeszu1SpUqd3682mVwmZZOCUWf3pRKwcwEyJnk YKS9ksKTh0F9B9VibfvNw2harR3471qwt6pbSXUCAwEAAaOBlDCBkTAJBgNVHRME AjAAMB0GA1UdDgQWBBTv4I3fmPShB7U6scRReENGsLkiQDBDBgNVHSMEPDA6gBRI OTHqQQ0XnmZGwlmKn/E6u/YTYaEXpBUwEzERMA8GA1UEAwwIQ2hhbmdlTWWCCQDZ h+PaSY4jlDATBgNVHSUEDDAKBggrBgEFBQcDAjALBgNVHQ8EBAMCB4AwDQYJKoZI hvcNAQELBQADggEBACKCvwckhCZ7w5j79gYvRhujm02z2Bah7aggZ9uoyYFw3EVi 1GmyU6aoa3ui2UKciWglm8R21TuhnPsUopbWNniHDlFqOOrVxFST11FD02Qfae8P 6YWhkbUoaS3IwF7NOPg56Q7VaU1P8+GI2fR5kjHrb9pBPTCFX+1gSpiA0TE3DHj4 zO7NFRq+hE17QqeE1+W7pq4uyZYQFpbC6n+VsCJWBXDm/8WR97uJpjWUjFCNPm71 PD5YN6cSa9iasBQVvBWbKkMaf+aFvtLHGteYrVUGkvpnw9DquYFxMnHpwegU4DQh PRL2TL8szw7751o2v2CHZ+zLJbDaq26thdoIh64= -----END CERTIFICATE----- </cert> <key> -----BEGIN PRIVATE KEY----- MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDj9pnoBCPH/3tF 8Yup/hCkMGi2cHmBU1YNub09l+mthxyX4PLV854odDcRiRciE5qZfpXXQVxJ5v2a kh+hwRro8nfGlh2dWpYL26cs1NKjV0aALgI5J25HEOP5vtvP9aHBrpGNmimI0F3X aeB86rkkLqc2v9yXCfua6FrXtT8y2Qgu+Mn3c4XQcBxznxuAe0n2Drk+3l0MIrAq 0xWZrStRaDjYcEpYanBGzAWhI0/WT+yu6VkpsfNnO8cmIXQ+CTGe/aoiJv6W3rM7 tUqVKnd+vNplcJmWTglFn96USsHMBMiZ5GCkvZLCk4dBfQfVYm37zcNoWq0d+O9a sLeqW0l1AgMBAAECggEBAKU7AscG6SB3b1R9BWxLeKhpZhyGXat9Sexc6muQhpF+ Ux1KsPiewc40ng2Zvii26OHEvLru5wOx57N3onHN08FwrZxFBmYdWJBzvzJhd+No yPLzZi0jBW2BMpy81/pd4cbOzzVBvkUqMjqGxW4Fe/hb0FuAqVTYqYPYUq/y8UHa atIehY3jNc46pSRmmFIDDdyh6K5lmFVZntpRKg9RzUibQxBkLZZwnRwFLf58wJbr Os9OT2QZsaSDIIK4mtL3xTVbT9ORC/ADY6XXO+Yb6IyLqD6WD5Yqh7wEpp/Gv4Ob BvlObULOEZnjeAK9FIPs9gFuimBjcJK5kX3an8yok6kCgYEA/cqQIMR8ORRdTBaj v2CK8RtQOJ2VPEpINcxPHK8vh38CrKNmCjETXqhkCwI1wOT/WKA4IUHBLfOhgC00 cHYn6k2JfossQGh8DvjyY+JtdmSamzeecQ4i13RcnSj5G+kY/iEQogTaSALpB1Uo cugU116HiHSvcz+FK3Ia4lAHnjcCgYEA5fJ+lg3lCCd1Cq4UpzGWLMWpo5VBX9Eu QhWRC2uIGkO4BAXVlkU/1TOvzonfoHLcyVUlLjE//p6djyVezkdVHTYYXQwrWIYE oinC4YnxV1Pcvii7WaBw9t3s5REYdgyvT0Wh7GIm+o6TMnfBTvVV/DMU6K9z59f+ wLXfMZaZH7MCgYBOXhdlVub5BTXOAgusU9ZznziFUvu7M0DbA+zF8b6ee3TK9GXU 7dSKXTsPPy50EwJaTpcmhdRuKRYMq2jO9V1b93dmkPkoJltwkCTg/RFKBsTK+0C8 rl3J5A+ZJAbQPIlQJ8uoDBGPPP7SGdS0rr+IxZLaaxWmY83uXXy5t3ayvwKBgQCM YMrovljI7pWkTHvtSfddI9qZNAAyB5jO3S2sJBx1tEu9oPYwg9whQymb1E3CPP0O qD1HgueHgLu9bNoA4klSyPh8rXY017Qyb346hCTi5B6JtIITiEAOZZM+kH43ay0H HwJoNc+H/Mxd7gAEPQAeM+0a1CnVKuaqLR2xvzeBwwKBgC+vydOv2Fqu58b+/cWi 52/stI11Y+xkdQ+/SP+cAucN05xVrfFzEbv90/Tintk2G+oCb5lWxM2uGIfSMCMA CUHg03a0oZdTTapUs+i0fahuhR/ojK5i4COTHM0jF3ryr1Gjo0RUgbJe/RlnRY5v bbOS07Ao554/jPNrXGzImnQz -----END PRIVATE KEY----- </key> <tls-crypt> -----BEGIN OpenVPN Static key V1----- 470a961d29e78b8f4884b46741587ecf 6008c6bb16acf2eae299f68df994133d 7fbe5dbacd187c21ac9e61bc2aab3de0 c88f39674dec40ef4844dddb80884ad4 652542876fdadd98ca95cf4e9f4ed6e8 2b2f6315aa77c0ae9fc5dca6df687622 82f629e230990b340b1b95f6f7ca18a4 185176cf29c04d5d0a9f9c19083fe3b6 24e55a25f5e5ccf2a48f33373d56792a 20f60074f9e6ef855e0b0ceca0a07300 294718d41af0a97da641053397fdc944 d21f5a9a702a118de21440fce772ab17 11a575acc9ce0097e2fdefc1233ea2e6 01e49032eaf2aa3e0898c3f5b334839f f8c69c80614a45cfb0ba7d43d3476e37 a22a4d43b0dbc96430b1115a6b1f6aac -----END OpenVPN Static key V1----- </tls-crypt> NOTE: The script automatically accounts for NAT. Notice in your client config that it sets the remote server as whatever your external address is. You may not want this behavior. If that is the case you will need to go in and edit the remote line with the IP address of your VPN server.","title":"Installing OpenVPN as a Server on the 4112F-ON"},{"location":"Run%20VPN%20on%20OS10/#on-centos-7","text":"Make sure everything is up to date. yum update -y && reboot . The reboot is important because if your kernel might update. If this happens you need to reboot to load the new kernel. Run yum install -y epel-release && yum update -y && yum install -y openvpn easy-rsa chrony && systemctl enable chronyd && chronyc makestep This is a long series of commands, but it installs openvpn and chrony. You need chrony to ensure your time is synched. WARNING : If the time is not synched between the server and your clients, the VPN will fail to connect! You should have copied your client config to your client already. If you haven't, do that now. To run the VPN, run openvpn <client_config_name>","title":"On CentOS 7"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/","text":"Run VPN on OS10 My Configuration Dell 4112F-ON Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.4 Build Version: 10.5.0.4.638 Build Time: 2020-01-30T21:08:56+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 2 days 03:54:07 CentOS [root@centos ~]# cat /etc/*-release CentOS Linux release 7.6.1810 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.6.1810 (Core) CentOS Linux release 7.6.1810 (Core) Physical Configuration Interface ethernet 1/1/12 on the 4112F-ON plugged directly into a server running ESXi. That interface was assigned as an uplink associated with a vswitch when then was tied to a portgroup running on VLAN 32. ethernet 1/1/12 was configured as follows: OS10(conf-if-eth1/1/12)# show configuration ! interface ethernet1/1/12 no shutdown switchport mode trunk switchport access vlan 1 switchport trunk allowed vlan 32 flowcontrol receive on interface vlan 32 was configured as follows: OS10(conf-if-vl-32)# show configuration ! interface vlan32 no shutdown ip address 192.168.32.1/24 The full switch config is here Interface ethernet 1/1/1 was configured as an access port in VLAN Research Sources Helpful Book Basics of Network Processor Packet Processing How Network Processors Work NPU Problem Explanation Installing WireGuard On the 4112F-ON: Enter configuration mode from user mode by running en and then config <enter> Run ip name-server 192.168.1.1 to add a name server. Run write mem in enable mode to save your configuration changes. Run system bash If you don't have a default route on your switch, you will need to add one with sudo ip route add 0.0.0.0/0 via 192.168.1.1 . Before installing WireGuard you will need the latest kernel headers. 1.The kernel headers on the system will work a bit differently than regular systems. I found the relevant kernel headers with apt search linux-headers | grep $(uname -r) 2.You should see an entry mentioning all - something like linux-headers-4.9.0-11-all . You want to install that package with sudo apt-get install -y <LINUX HEADER NAME> bc 3.At this point you will need to reboot. Do this by exiting the command line and in enable mode running reload 4.If you do not have a permanent default route set, when you log back in you will need to run system bash and then readd the default route with sudo ip route add 0.0.0.0/0 via 192.168.1.1 mkdir /opt/wireguard && cd /opt/wireguard Now you will either need to run all of the following as sudo or you will need to add a password to the root account with sudo passwd and then su - to become root. After you have done the above run: echo \"deb http://deb.debian.org/debian/ unstable main\" > /etc/apt/sources.list.d/unstable-wireguard.list printf 'Package: *\\nPin: release a=unstable\\nPin-Priority: 90\\n' > /etc/apt/preferences.d/limit-unstable apt update apt install wireguard Generate key pairs wg genkey | tee wg-private.key | wg pubkey > wg-public.key On CentOS 7 Make sure everything is up to date. yum update -y && reboot . The reboot is important because if your kernel might update. If this happens you need to reboot to load the new kernel. Wireguard requires kernel 3.10 or higher - I noticed if you haven't updated CentOS for a bit than your kernel might be to old and you'll get RTNETLINK answers: Operation not supported . Run: sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm sudo curl -o /etc/yum.repos.d/jdoss-wireguard-epel-7.repo https://copr.fedorainfracloud.org/coprs/jdoss/wireguard/repo/epel-7/jdoss-wireguard-epel-7.repo sudo yum install wireguard-dkms wireguard-tools mkdir /opt/wireguard && cd /opt/wireguard Generate key pairs wg genkey | tee wg-private.key | wg pubkey > wg-public.key ip link add wg0 type wireguard Set Wireguard interface IP ip address add dev wg0 10.0.0.2/24 . This IP address is the tunnel IP address. 1.If there are only two peers together you can do something like ip address add dev wg0 10.0.0.2 peer 10.0.0.1 wg set wg0 listen-port 51820 private-key /opt/wireguard/wg-private.key peer OQiSLUOd3YWCfEkHazJHuuaJVNc++8QOb2+sOOZl/2c= endpoint 192.168.32.1:8172 1.listen-port: the port this host will listen on 2.private-key: the private key for this host 3.peer: I thought this was a bit misleading - you want the public key of the other host to which you are connecting 4.endpoint: the other endpoint of the VPN and the port on which it is listening Strange Behavior OS10(config)# management route 192.168.1.0/24 192.168.1.1 % Error: Overlapping route for Management interface OS10(config)# ip route 0.0.0.0/0 192.168.1.1 interface ethernet 1/1/1 % Error: Network unreachable OS10(config)# ping 192.168.1.1 PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data. 64 bytes from 192.168.1.1: icmp_seq=1 ttl=64 time=0.452 ms 64 bytes from 192.168.1.1: icmp_seq=2 ttl=64 time=0.388 ms ^C --- 192.168.1.1 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1005ms rtt min/avg/max/mdev = 0.388/0.420/0.452/0.032 ms OS10(config)# do system bash admin@OS10:~$ su - Password: root@OS10:~# ip route 192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.20 192.168.4.0/24 dev br32 proto none scope link root@OS10:~# ip route add 0.0.0.0/0 via 192.168.1.1 root@OS10:~# ip route default via 192.168.1.1 dev eth0 192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.20 192.168.4.0/24 dev br32 proto none scope link root@OS10:~# ping google.com PING google.com (216.58.193.142) 56(84) bytes of data. 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=1 ttl=55 time=25.4 ms 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=2 ttl=55 time=22.9 ms 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=3 ttl=55 time=22.1 ms 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=4 ttl=55 time=22.2 ms ^C --- google.com ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3002ms rtt min/avg/max/mdev = 22.149/23.185/25.408/1.329 ms","title":"Run VPN on OS10"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#run-vpn-on-os10","text":"","title":"Run VPN on OS10"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#my-configuration","text":"","title":"My Configuration"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#dell-4112f-on","text":"Dell EMC Networking OS10 Enterprise Copyright (c) 1999-2020 by Dell Inc. All Rights Reserved. OS Version: 10.5.0.4 Build Version: 10.5.0.4.638 Build Time: 2020-01-30T21:08:56+0000 System Type: S4112F-ON Architecture: x86_64 Up Time: 2 days 03:54:07","title":"Dell 4112F-ON"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#centos","text":"[root@centos ~]# cat /etc/*-release CentOS Linux release 7.6.1810 (Core) NAME=\"CentOS Linux\" VERSION=\"7 (Core)\" ID=\"centos\" ID_LIKE=\"rhel fedora\" VERSION_ID=\"7\" PRETTY_NAME=\"CentOS Linux 7 (Core)\" ANSI_COLOR=\"0;31\" CPE_NAME=\"cpe:/o:centos:centos:7\" HOME_URL=\"https://www.centos.org/\" BUG_REPORT_URL=\"https://bugs.centos.org/\" CENTOS_MANTISBT_PROJECT=\"CentOS-7\" CENTOS_MANTISBT_PROJECT_VERSION=\"7\" REDHAT_SUPPORT_PRODUCT=\"centos\" REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" CentOS Linux release 7.6.1810 (Core) CentOS Linux release 7.6.1810 (Core)","title":"CentOS"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#physical-configuration","text":"Interface ethernet 1/1/12 on the 4112F-ON plugged directly into a server running ESXi. That interface was assigned as an uplink associated with a vswitch when then was tied to a portgroup running on VLAN 32. ethernet 1/1/12 was configured as follows: OS10(conf-if-eth1/1/12)# show configuration ! interface ethernet1/1/12 no shutdown switchport mode trunk switchport access vlan 1 switchport trunk allowed vlan 32 flowcontrol receive on interface vlan 32 was configured as follows: OS10(conf-if-vl-32)# show configuration ! interface vlan32 no shutdown ip address 192.168.32.1/24 The full switch config is here Interface ethernet 1/1/1 was configured as an access port in VLAN","title":"Physical Configuration"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#research","text":"","title":"Research"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#sources","text":"Helpful Book Basics of Network Processor Packet Processing How Network Processors Work","title":"Sources"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#npu-problem","text":"Explanation","title":"NPU Problem"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#installing-wireguard","text":"On the 4112F-ON: Enter configuration mode from user mode by running en and then config <enter> Run ip name-server 192.168.1.1 to add a name server. Run write mem in enable mode to save your configuration changes. Run system bash If you don't have a default route on your switch, you will need to add one with sudo ip route add 0.0.0.0/0 via 192.168.1.1 . Before installing WireGuard you will need the latest kernel headers. 1.The kernel headers on the system will work a bit differently than regular systems. I found the relevant kernel headers with apt search linux-headers | grep $(uname -r) 2.You should see an entry mentioning all - something like linux-headers-4.9.0-11-all . You want to install that package with sudo apt-get install -y <LINUX HEADER NAME> bc 3.At this point you will need to reboot. Do this by exiting the command line and in enable mode running reload 4.If you do not have a permanent default route set, when you log back in you will need to run system bash and then readd the default route with sudo ip route add 0.0.0.0/0 via 192.168.1.1 mkdir /opt/wireguard && cd /opt/wireguard Now you will either need to run all of the following as sudo or you will need to add a password to the root account with sudo passwd and then su - to become root. After you have done the above run: echo \"deb http://deb.debian.org/debian/ unstable main\" > /etc/apt/sources.list.d/unstable-wireguard.list printf 'Package: *\\nPin: release a=unstable\\nPin-Priority: 90\\n' > /etc/apt/preferences.d/limit-unstable apt update apt install wireguard Generate key pairs wg genkey | tee wg-private.key | wg pubkey > wg-public.key On CentOS 7 Make sure everything is up to date. yum update -y && reboot . The reboot is important because if your kernel might update. If this happens you need to reboot to load the new kernel. Wireguard requires kernel 3.10 or higher - I noticed if you haven't updated CentOS for a bit than your kernel might be to old and you'll get RTNETLINK answers: Operation not supported . Run: sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm sudo curl -o /etc/yum.repos.d/jdoss-wireguard-epel-7.repo https://copr.fedorainfracloud.org/coprs/jdoss/wireguard/repo/epel-7/jdoss-wireguard-epel-7.repo sudo yum install wireguard-dkms wireguard-tools mkdir /opt/wireguard && cd /opt/wireguard Generate key pairs wg genkey | tee wg-private.key | wg pubkey > wg-public.key ip link add wg0 type wireguard Set Wireguard interface IP ip address add dev wg0 10.0.0.2/24 . This IP address is the tunnel IP address. 1.If there are only two peers together you can do something like ip address add dev wg0 10.0.0.2 peer 10.0.0.1 wg set wg0 listen-port 51820 private-key /opt/wireguard/wg-private.key peer OQiSLUOd3YWCfEkHazJHuuaJVNc++8QOb2+sOOZl/2c= endpoint 192.168.32.1:8172 1.listen-port: the port this host will listen on 2.private-key: the private key for this host 3.peer: I thought this was a bit misleading - you want the public key of the other host to which you are connecting 4.endpoint: the other endpoint of the VPN and the port on which it is listening","title":"Installing WireGuard"},{"location":"Run%20VPN%20on%20OS10/README_wireguard_%28unfinished%29/#strange-behavior","text":"OS10(config)# management route 192.168.1.0/24 192.168.1.1 % Error: Overlapping route for Management interface OS10(config)# ip route 0.0.0.0/0 192.168.1.1 interface ethernet 1/1/1 % Error: Network unreachable OS10(config)# ping 192.168.1.1 PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data. 64 bytes from 192.168.1.1: icmp_seq=1 ttl=64 time=0.452 ms 64 bytes from 192.168.1.1: icmp_seq=2 ttl=64 time=0.388 ms ^C --- 192.168.1.1 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1005ms rtt min/avg/max/mdev = 0.388/0.420/0.452/0.032 ms OS10(config)# do system bash admin@OS10:~$ su - Password: root@OS10:~# ip route 192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.20 192.168.4.0/24 dev br32 proto none scope link root@OS10:~# ip route add 0.0.0.0/0 via 192.168.1.1 root@OS10:~# ip route default via 192.168.1.1 dev eth0 192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.20 192.168.4.0/24 dev br32 proto none scope link root@OS10:~# ping google.com PING google.com (216.58.193.142) 56(84) bytes of data. 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=1 ttl=55 time=25.4 ms 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=2 ttl=55 time=22.9 ms 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=3 ttl=55 time=22.1 ms 64 bytes from dfw25s34-in-f14.1e100.net (216.58.193.142): icmp_seq=4 ttl=55 time=22.2 ms ^C --- google.com ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3002ms rtt min/avg/max/mdev = 22.149/23.185/25.408/1.329 ms","title":"Strange Behavior"},{"location":"idrac%20with%20LDAP/","text":"idrac with LDAP idrac with LDAP Version Info Setup FreeIPA Helpful Commands Setup idrac YouTube Video of Login Version Info Fedora release 33 (Thirty Three) NAME=Fedora VERSION=\"33 (Workstation Edition)\" ID=fedora VERSION_ID=33 VERSION_CODENAME=\"\" PLATFORM_ID=\"platform:f33\" PRETTY_NAME=\"Fedora 33 (Workstation Edition)\" ANSI_COLOR=\"0;38;2;60;110;180\" LOGO=fedora-logo-icon CPE_NAME=\"cpe:/o:fedoraproject:fedora:33\" HOME_URL=\"https://fedoraproject.org/\" DOCUMENTATION_URL=\"https://docs.fedoraproject.org/en-US/fedora/f33/system-administrators-guide/\" SUPPORT_URL=\"https://fedoraproject.org/wiki/Communicating_and_getting_help\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Fedora\" REDHAT_BUGZILLA_PRODUCT_VERSION=33 REDHAT_SUPPORT_PRODUCT=\"Fedora\" REDHAT_SUPPORT_PRODUCT_VERSION=33 PRIVACY_POLICY_URL=\"https://fedoraproject.org/wiki/Legal:PrivacyPolicy\" VARIANT=\"Workstation Edition\" VARIANT_ID=workstation Fedora release 33 (Thirty Three) Fedora release 33 (Thirty Three) Setup FreeIPA Install Fedora Change hostname 1. hostname freeipa.grant.lan && hostnamectl set-hostname freeipa.grant.lan 2.Change in /etc/hostname 3.Configure DNS to return for this hostname. Double check with dig +short freeipa.grant.lan A && dig +short -x 192.168.1.95 Follow RHEL's instructions 1.I used Chapter 5 for primary installation 2.Make sure you add the requested DNS entries at the end Run firewall-cmd --permanent --add-port={80/tcp,443/tcp,389/tcp,636/tcp,88/tcp,464/tcp,88/udp,464/udp,123/udp} && firewall-cmd --reload to allow the appropriate ports Run kinit admin - this allows you to use the command line tools otherwise they'll complain about kerberos. Log into FreeIPA server at https://<your_hostname> . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Add a user other than administrator. Create a new user and new group in the UI and assign the new user to the new group. WARNING I had to actually add the user to a new group. The group could not be admins or it wouldn't work. When I dumped ldapsearch -x -H ldap://localhost -b \"cn=admins,cn=groups,cn=accounts,dc=grant,dc=lan\" -D \"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" -w PASSWORD | less my user actually didn't show in the admins group. When I created my own group and checked it worked fine. Helpful Commands To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status . Test LDAP credentials: ldapwhoami -vvv -h 192.168.1.95 -p 389 -D 'uid=grant,cn=users,cn=accounts,dc=grant,dc=lan' -x -w <PASSWORD> Dump the structure of FreeIPA: ldapsearch -x -H ldap://localhost -b \"cn=accounts,dc=grant,dc=lan\" -D \"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" -w <YOUR_USERS_PASSWORD> | less You can also use this to check to see if a user is a member of a group by changing the base path to search (-b). Change it to what you think the FQDN of the group is. The user in question should show up. Setup idrac Go into the idrac and click the directories prompt. I ran without certs I used the following values: Generic LDAP: Enabled Use Distinguished Name to Search Group Membership: Enabled LDAP Server Address: freeipa.grant.lan LDAP Server Port: 636 Bind DN: uid=grant,cn=users,cn=accounts,dc=grant,dc=lan Bind Password: Your password Base DN to Search: cn=accounts,dc=grant,dc=lan Attribute of User Login: uid Attribute of Group Membership: member Click next and for Group DN I used cn=grantgroup,cn=groups,cn=accounts,dc=grant,dc=lan where grantgroup was the name of the user group I added I ran the test with the following results: # Test Results Ping Directory Server Not Run Directory Server DNS Name Passed LDAP connection to the Directory Server Passed User DN existence Passed Certificate Validation Disabled User Authentication Passed User Authorization Passed # Test Log 16:49:14 Initiating Directory Services Settings Diagnostics: 16:49:14 trying LDAP server freeipa.grant.lan:636 16:49:14 Server Address freeipa.grant.lan resolved to 192.168.1.95 16:49:14 connect to 192.168.1.95:636 passed 16:49:14 Connecting to ldaps://[freeipa.grant.lan]:636... 16:49:14 Test user authenticated user=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan host=freeipa.grant.lan 16:49:14 Search command: Bind DN: uid=grant,cn=users,cn=accounts,dc=grant,dc=lan Scope: subtree Base DN: cn=accounts,dc=grant,dc=lan Search filter: (uid=grant) Attribute list: objectClass memberOf dn uid objectCategory defaultNamingContext namingContexts ldapServiceName supportedControl supportedExtension 16:49:14 Connecting to ldaps://[freeipa.grant.lan]:636... 16:49:14 Test user authenticated user=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan host=freeipa.grant.lan 16:49:15 Connecting to ldaps://[freeipa.grant.lan]:636... 16:49:15 Test user authenticated user=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan host=freeipa.grant.lan 16:49:15 Search command: Bind DN: uid=grant,cn=users,cn=accounts,dc=grant,dc=lan Scope: base Base DN: cn=grantgroup,cn=groups,cn=accounts,dc=grant,dc=lan Search filter: (member=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan) Attribute list: objectClass memberOf dn uid objectCategory defaultNamingContext namingContexts ldapServiceName supportedControl supportedExtension 16:49:15 Privileges gained from role group 'cn=grantgroup,cn=groups,cn=accounts,dc=grant,dc=lan': Login Config iDRAC Config User Clear Logs Server Control Virtual Console Virtual Media Test Alerts Diagnostic Command 16:49:15 Test user grant authorized 16:49:15 Cumulative privileges gained: Login Config iDRAC Config User Clear Logs Server Control Virtual Console Virtual Media Test Alerts Diagnostic Command YouTube Video of Login See: https://youtu.be/-fHlHhF9vH4","title":"idrac with LDAP"},{"location":"idrac%20with%20LDAP/#idrac-with-ldap","text":"idrac with LDAP Version Info Setup FreeIPA Helpful Commands Setup idrac YouTube Video of Login","title":"idrac with LDAP"},{"location":"idrac%20with%20LDAP/#version-info","text":"Fedora release 33 (Thirty Three) NAME=Fedora VERSION=\"33 (Workstation Edition)\" ID=fedora VERSION_ID=33 VERSION_CODENAME=\"\" PLATFORM_ID=\"platform:f33\" PRETTY_NAME=\"Fedora 33 (Workstation Edition)\" ANSI_COLOR=\"0;38;2;60;110;180\" LOGO=fedora-logo-icon CPE_NAME=\"cpe:/o:fedoraproject:fedora:33\" HOME_URL=\"https://fedoraproject.org/\" DOCUMENTATION_URL=\"https://docs.fedoraproject.org/en-US/fedora/f33/system-administrators-guide/\" SUPPORT_URL=\"https://fedoraproject.org/wiki/Communicating_and_getting_help\" BUG_REPORT_URL=\"https://bugzilla.redhat.com/\" REDHAT_BUGZILLA_PRODUCT=\"Fedora\" REDHAT_BUGZILLA_PRODUCT_VERSION=33 REDHAT_SUPPORT_PRODUCT=\"Fedora\" REDHAT_SUPPORT_PRODUCT_VERSION=33 PRIVACY_POLICY_URL=\"https://fedoraproject.org/wiki/Legal:PrivacyPolicy\" VARIANT=\"Workstation Edition\" VARIANT_ID=workstation Fedora release 33 (Thirty Three) Fedora release 33 (Thirty Three)","title":"Version Info"},{"location":"idrac%20with%20LDAP/#setup-freeipa","text":"Install Fedora Change hostname 1. hostname freeipa.grant.lan && hostnamectl set-hostname freeipa.grant.lan 2.Change in /etc/hostname 3.Configure DNS to return for this hostname. Double check with dig +short freeipa.grant.lan A && dig +short -x 192.168.1.95 Follow RHEL's instructions 1.I used Chapter 5 for primary installation 2.Make sure you add the requested DNS entries at the end Run firewall-cmd --permanent --add-port={80/tcp,443/tcp,389/tcp,636/tcp,88/tcp,464/tcp,88/udp,464/udp,123/udp} && firewall-cmd --reload to allow the appropriate ports Run kinit admin - this allows you to use the command line tools otherwise they'll complain about kerberos. Log into FreeIPA server at https://<your_hostname> . In my case, Windows popped up a username and password prompt. That prompt didn't work - I had to exit it and then log into the webGUI. Add a user other than administrator. Create a new user and new group in the UI and assign the new user to the new group. WARNING I had to actually add the user to a new group. The group could not be admins or it wouldn't work. When I dumped ldapsearch -x -H ldap://localhost -b \"cn=admins,cn=groups,cn=accounts,dc=grant,dc=lan\" -D \"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" -w PASSWORD | less my user actually didn't show in the admins group. When I created my own group and checked it worked fine.","title":"Setup FreeIPA"},{"location":"idrac%20with%20LDAP/#helpful-commands","text":"To start the IPA service use ipactl start|stop|restart . You can check the status with ipactl status . Test LDAP credentials: ldapwhoami -vvv -h 192.168.1.95 -p 389 -D 'uid=grant,cn=users,cn=accounts,dc=grant,dc=lan' -x -w <PASSWORD> Dump the structure of FreeIPA: ldapsearch -x -H ldap://localhost -b \"cn=accounts,dc=grant,dc=lan\" -D \"uid=grant,cn=users,cn=accounts,dc=grant,dc=lan\" -w <YOUR_USERS_PASSWORD> | less You can also use this to check to see if a user is a member of a group by changing the base path to search (-b). Change it to what you think the FQDN of the group is. The user in question should show up.","title":"Helpful Commands"},{"location":"idrac%20with%20LDAP/#setup-idrac","text":"Go into the idrac and click the directories prompt. I ran without certs I used the following values: Generic LDAP: Enabled Use Distinguished Name to Search Group Membership: Enabled LDAP Server Address: freeipa.grant.lan LDAP Server Port: 636 Bind DN: uid=grant,cn=users,cn=accounts,dc=grant,dc=lan Bind Password: Your password Base DN to Search: cn=accounts,dc=grant,dc=lan Attribute of User Login: uid Attribute of Group Membership: member Click next and for Group DN I used cn=grantgroup,cn=groups,cn=accounts,dc=grant,dc=lan where grantgroup was the name of the user group I added I ran the test with the following results: # Test Results Ping Directory Server Not Run Directory Server DNS Name Passed LDAP connection to the Directory Server Passed User DN existence Passed Certificate Validation Disabled User Authentication Passed User Authorization Passed # Test Log 16:49:14 Initiating Directory Services Settings Diagnostics: 16:49:14 trying LDAP server freeipa.grant.lan:636 16:49:14 Server Address freeipa.grant.lan resolved to 192.168.1.95 16:49:14 connect to 192.168.1.95:636 passed 16:49:14 Connecting to ldaps://[freeipa.grant.lan]:636... 16:49:14 Test user authenticated user=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan host=freeipa.grant.lan 16:49:14 Search command: Bind DN: uid=grant,cn=users,cn=accounts,dc=grant,dc=lan Scope: subtree Base DN: cn=accounts,dc=grant,dc=lan Search filter: (uid=grant) Attribute list: objectClass memberOf dn uid objectCategory defaultNamingContext namingContexts ldapServiceName supportedControl supportedExtension 16:49:14 Connecting to ldaps://[freeipa.grant.lan]:636... 16:49:14 Test user authenticated user=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan host=freeipa.grant.lan 16:49:15 Connecting to ldaps://[freeipa.grant.lan]:636... 16:49:15 Test user authenticated user=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan host=freeipa.grant.lan 16:49:15 Search command: Bind DN: uid=grant,cn=users,cn=accounts,dc=grant,dc=lan Scope: base Base DN: cn=grantgroup,cn=groups,cn=accounts,dc=grant,dc=lan Search filter: (member=uid=grant,cn=users,cn=accounts,dc=grant,dc=lan) Attribute list: objectClass memberOf dn uid objectCategory defaultNamingContext namingContexts ldapServiceName supportedControl supportedExtension 16:49:15 Privileges gained from role group 'cn=grantgroup,cn=groups,cn=accounts,dc=grant,dc=lan': Login Config iDRAC Config User Clear Logs Server Control Virtual Console Virtual Media Test Alerts Diagnostic Command 16:49:15 Test user grant authorized 16:49:15 Cumulative privileges gained: Login Config iDRAC Config User Clear Logs Server Control Virtual Console Virtual Media Test Alerts Diagnostic Command","title":"Setup idrac"},{"location":"idrac%20with%20LDAP/#youtube-video-of-login","text":"See: https://youtu.be/-fHlHhF9vH4","title":"YouTube Video of Login"},{"location":"idrac%20with%20LDAP/open-LDAP-failed/","text":"Configuring idrac with OpenLDAP Configuring idrac with OpenLDAP Setup OpenLDAP Debugging Configure idrac Stopped Setup OpenLDAP I used osixia's openldap container for testing. I used osixia's phpLDAPadmin container for administration. Add an entry to your DNS server for ldap.granttest.lan podman run -p 389:389 -p 636:636 --name my-openldap-container --env LDAP_TLS=false --env LDAP_LOG_LEVEL=8 --env LDAP_ORGANISATION=\"Grant Test\" --env LDAP_DOMAIN=\"granttest.lan\" --env LDAP_ADMIN_PASSWORD=\"admin\" --detach osixia/openldap:1.5.0 --loglevel debug && podman run -p 6443:443 --env PHPLDAPADMIN_LDAP_HOSTS=ldap.granttest.lan --detach osixia/phpldapadmin:0.9.0 1.Test the container: podman exec my-openldap-container ldapsearch -x -H ldap://localhost -b dc=granttest,dc=lan -D \"cn=admin,dc=granttest,dc=lan\" -w admin . That should output: # extended LDIF # # LDAPv3 # base <dc=example,dc=org> with scope subtree # filter: (objectclass=*) # requesting: ALL # [...] # numResponses: 3 # numEntries: 2 Configure firewall: firewall-cmd --add-port=389/tcp --permanent && firewall-cmd --add-port=636/tcp --permanent && firewall-cmd --add-port=6443/tcp --permanent && firewall-cmd --reload Make sure you can log into https://<YOUR_IP_ADDRESS>:6443 with username cn=admin,dc=granttest,dc=lan and password admin Debugging You can use podman inspect <container_name> and then search for Log to find the location of the logs. Configure idrac I disabled certificates (yes I was lazy) Stopped For whatever reason the container networking never quite cooperated. Even though DNS entries were present for the external IP when either OME or idrac would try to hit it they would both say the LDAP server was unavailable. phpldapadmin worked without issue. I know it's a probably with the networking but decided it wasn't worth diving into so I abandonded this approach and went with a baremetal FreeIPA instance.","title":"Configuring idrac with OpenLDAP"},{"location":"idrac%20with%20LDAP/open-LDAP-failed/#configuring-idrac-with-openldap","text":"Configuring idrac with OpenLDAP Setup OpenLDAP Debugging Configure idrac Stopped","title":"Configuring idrac with OpenLDAP"},{"location":"idrac%20with%20LDAP/open-LDAP-failed/#setup-openldap","text":"I used osixia's openldap container for testing. I used osixia's phpLDAPadmin container for administration. Add an entry to your DNS server for ldap.granttest.lan podman run -p 389:389 -p 636:636 --name my-openldap-container --env LDAP_TLS=false --env LDAP_LOG_LEVEL=8 --env LDAP_ORGANISATION=\"Grant Test\" --env LDAP_DOMAIN=\"granttest.lan\" --env LDAP_ADMIN_PASSWORD=\"admin\" --detach osixia/openldap:1.5.0 --loglevel debug && podman run -p 6443:443 --env PHPLDAPADMIN_LDAP_HOSTS=ldap.granttest.lan --detach osixia/phpldapadmin:0.9.0 1.Test the container: podman exec my-openldap-container ldapsearch -x -H ldap://localhost -b dc=granttest,dc=lan -D \"cn=admin,dc=granttest,dc=lan\" -w admin . That should output: # extended LDIF # # LDAPv3 # base <dc=example,dc=org> with scope subtree # filter: (objectclass=*) # requesting: ALL # [...] # numResponses: 3 # numEntries: 2 Configure firewall: firewall-cmd --add-port=389/tcp --permanent && firewall-cmd --add-port=636/tcp --permanent && firewall-cmd --add-port=6443/tcp --permanent && firewall-cmd --reload Make sure you can log into https://<YOUR_IP_ADDRESS>:6443 with username cn=admin,dc=granttest,dc=lan and password admin","title":"Setup OpenLDAP"},{"location":"idrac%20with%20LDAP/open-LDAP-failed/#debugging","text":"You can use podman inspect <container_name> and then search for Log to find the location of the logs.","title":"Debugging"},{"location":"idrac%20with%20LDAP/open-LDAP-failed/#configure-idrac","text":"I disabled certificates (yes I was lazy)","title":"Configure idrac"},{"location":"idrac%20with%20LDAP/open-LDAP-failed/#stopped","text":"For whatever reason the container networking never quite cooperated. Even though DNS entries were present for the external IP when either OME or idrac would try to hit it they would both say the LDAP server was unavailable. phpldapadmin worked without issue. I know it's a probably with the networking but decided it wasn't worth diving into so I abandonded this approach and went with a baremetal FreeIPA instance.","title":"Stopped"}]}